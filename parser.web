\input macros
\setchapno{-1}
\def\title{Mizar Parser}

@* [C] Introduction.
We are trying to understand Mizar. So I am transcribing the source
code into a literate program, following the order of
compilation. Perhaps this ``goes against the spirit'' of literate
programming, but it makes the most sense to understand what is going
on for programmers. 

We will begin with the ``Parser module'' (\texttt{base/parser.pas}), and all the
dependencies needed to compile it. For clarity (or at least ease of
reference) each ``chapter'' appearing in the table of contents
corresponds to a different file.

We are studying Mizar's source code as of Git commit \texttt{9e814a9568cfb44253d677e5209c360390fe6437}
(dated 2023 October 11).

@ \node{Files are chapters.}
We will organize the text by compiler dependencies. It makes sense to
treat each file as a separate ``chapter''. With the exception of this
introductory chapter (``chapter 0''), all future chapters are called
``File $n$''.

Just as Knuth's \emph{\TeX: The Program} (Addison--Wesley, 1986) was
organized into modules which are presented ``bottom-up'', each module
is discussed and programmed ``top-down'', we shall try to do
likewise. File $n+1$ can only depend on code appearing in Files $1$
through File $n$.

There are natural ways to ``cluster'' the discussion in each File,
which motivates the ``section'' and ``subsections''. Each section
(\emph{but not subsections!\/}) starts on a new page, written in sans
serif bold prefixed with explicit an ``Section''. Subsections are
written in sans serif bold prefixed with an explicit ``Subsection'',
with vertical whitespace separting it. This chapter has 
two sections (one discussing the flow of Mizar, and the other
enumerating observations and ``to do'' items).

@ Each chapter is written using numbered paragraphs, since we are
using Donald Knuth's \WEB/ to write a literate program. References
will be made to the paragraphs. Index entries give the paragraph
numbers associated with each entry. And even though I just used the
term ``paragraph number'', they really group several paragraphs into a
unit of writing.

Paragraphs are numbered \emph{independently} of chapter, section,
subsection. This is a quirk of \WEB/. This was how Mathematicians
wrote texts back in Euler's day. We will refer to a paragraph by
writing (\section$n$) to refer to paragraph $n$. Again, this was the
conventions used by Euler.

Each paragraph consists of three parts: the ``text part'' (informal
prose written in English), the ``macros part'' (which introduces
macros written in the \WEB/ language), and the ``code part'' (which
contains a pretty-printed snippet of \PASCAL/ code). A paragraph may
omit any of these parts but has at least one of them. Thus far, all
our numbered paragraphs have consisted of ``text parts'' only. The
``code part'' can optionally have a name in angled brackets. If the name is
missing, then it continues the previous chunk of code from the
previous numbered paragraph. 

@ The Mizar program is released under the GNU license. So let us place
this license in one place early on. (This is an example of a numbered
paragraph with a ``named code part''.)

@<GNU License@>=
{
   This file is part of the Mizar system.
   Copyright (c) Association of Mizar Users.
   License terms: GNU General Public License Version 3 or any later version.
}

@ \node{Asides and opinions.} Some paragraphs will be labeled as
``asides'' which are tangential remarks not directly relevant to
understanding the code, but will enrich the reader's life. \Ithink{The author
will offer opinions about the design and implementation of Mizar
in parenthetic sentences like this one, surrounded by double brackets.}
If the reader is unsatisfied by the arbitrary opinions of a random
programmer, then they can disable the asides by redefining
the \texttt{\BS Ithink} macro to have an empty body.

@ \node{Aside: Typography of ``Modern'' Pascal.}%
We will be following the typographical style as found in Niklaus
Wirth's@^Wirth, Niklaus@> \textit{Algorithms + Data Structures = Programs}
(Prentice--Hall, 1975) and Donald Knuth's@^Knuth, Donald E.@> \textit{\TeX: The Program}
(Addison--Wesley, 1986). But there are a few typographical situations
which requires thinking hard about, since ``classical'' \PASCAL/ does
not have \emph{object} or inheritence (or \emph{unit} modules).

First, we need to know that ``modern \PASCAL/'' differs from
the \PASCAL/ Knuth worked with, in several ways. Mizar uses ``units''
which are a module system introduced by UCSD \PASCAL/
(\textit{c{.}}~1977). We will need to format them for \WEAVE/.

Documentation and tutorials frequently compare \textbf{unit} to |program|, so
we should probably typeset it as such. The big question is whether the
\texttt{interface}, \texttt{implementation}, and \texttt{uses}
keywords are |var|-like or |const|-like. I ultimately decided for the
latter (since \&{var}-like typography would have them appear in the
index underlined).

We will treat |implementation| typographically \emph{as if} it were a
|const| because the |end| will not be indented properly otherwise.

@f unit==program
@f interface==const
@f implementation==const
@f uses==const

@ Objects appear in Free \PASCAL/, and they behave like records.
There are also |constructor| and |destructor| functions.

@f object==record
@f constructor==function
@f destructor==function

@ \node{Primitive functions.}
We have several primitive functions which should be formatted
especially. For example, |shr| is an infix operator like |mod| or
|div|. It corresponds to bitwise shifting right.

@f shr==div

@ \node{Cases.}
Following Knuth's ``\TeX: The Program'' (\section4), we will use |endcases| to
pair with |case|. The ``default case'' will be |othercases| (because
|else| gets too confusing).

@d othercases == others: {default for cases not listed explicitly}
@d endcases == @+end {follows the default case in an extended |case| statement}
@f othercases == else
@f endcases == end

@ \node{Debugging.} There are conditional compiler directives for
debugging purposes. Importantly, these \emph{must} be printed to the
source code when we invoke \TANGLE/.

@d mdebug == @{@&$IFDEF MDEBUG@}
@d end_mdebug == @{@&$ENDIF@}
@f mdebug == begin
@f end_mdebug == end

@ Actually, it may be useful just to have helper macros.

@d if_def(#) == @{@&$IFDEF #@}
@d if_not_def(#) == @{@&$IFNDEF #@}
@d else_if_def(#) == @{@&$ELSEIF DEFINED(#)@}
@d else_def == @{@&$ELSE@}
@d endif == @{@&$ENDIF@}
@d end_if == @+ endif
@f if_def == if
@f if_not_def == if
@f else_if_def == else
@f else_def == else
@f endif == end
@f end_if == end

@ \node{Toggling IO Checking.} Another compiler directive enables and
disables IO checking

@d disable_io_checking == @{@&$I-@}
@d enable_io_checking == @{@&$I+@}
@d without_io_checking(#) == disable_io_checking; #; enable_io_checking

@ \node{References.}
I have inline citations to the literature, but there's some references
worth explicitly drawing the reader's attention to (which may or may
not make it to an inline citation):
\enumerate
\item Andrzej Trybulec, ``Some Features of the Mizar Language'', ESPRIT Workshop, Torino, 1993.\hfill\break
  Eprint: \href{https://mizar.uwb.edu.pl/project/trybulec93.pdf}{{\tt mizar.uwb.edu.pl/project/trybulec93.pdf}} --- \section4 discusses grammatical aspects of Mizar
\item Freek Wiedijk, ``Mizar's Soft Type System''. In K.\ Schneider and J.\
Brandt, eds., \emph{Theorem Proving in Higher Order Logics. TPHOLs 2007},
Springer, \doi{10.1007/978-3-540-74591-4_28}
(\href{https://www.cs.ru.nl/F.Wiedijk/mizar/miztype.pdf}{Eprint pdf}).
\item Adam Grabowski,
  Artur Korni\l{}owicz, and
  Adam Naumowicz's ``Mizar in a Nutshell''\hfill\break
  (\doi{10.6092/issn.1972-5787/1980})
\item Artur Korni\l{}owicz's
  ``Registrations vs Redefinitions in Mizar''
  (in A.\ Kohlhase, P.\ Libbrecht, BR.\ Miller, A.\ Naumowicz, W.\ Neuper, P.\ Quaresma, F.\ Wm.\ Tompa, M.\ Suda
  (eds) \emph{Joint Proc.\ FM4M, MathUI, and ThEdu}, 2016, pp.17--20,
  \href{https://ceur-ws.org/Vol-1785/F5.pdf}{{\tt ceur-ws.org/Vol-1785/F5.pdf}})
\item Artur Korni\l{}owicz's
  ``On rewriting rules in Mizar''
  (\emph{J.\ Autom.\ Reason.} \textbf{50} no.2 (2013) 203--210,
  \doi{10.1007/s10817-012-9261-6})
\item Mario Carneiro, ``Reimplementing Mizar in Rust''.
Eprint \arXiv{2304.08391}, see
especially the first two sections for an overview of Mizar's
workflow. (The code is available
at \href{https://github.com/digama0/mizar-rs}{{\tt github.com/digama0/mizar-rs}}.)
\endenumerate

\medbreak\noindent%
I should also credit Wayne Sewell's \emph{Weaving a Program: Literate Programming in Web}
(Van Nostrand Reinhold Computer, 1989) for discussing how to take a
pre-existing \PASCAL/ program and turn it into a \WEB/. Or, depending
on the quality of writing in this literate program, it's all his fault.

@^Grabowski, Adam@>
@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>
@^Naumowicz, Adam@>
@^Trybulec, Andrzej@>
@^Wiedijk, Freek@>

@* [S] Mizar's workflow.
This section will give a brief overview of what Mizar
``does'' when we run it. The analogy to bear in mind is with a batch
compiler: there's parsing, some intermediate steps, then emits some
output.

Just to give some rough estimates of where Mizar spends most of its
time, there are four phases Mizar reports when checking an article:
\enumerate
\item Parser (transforms input into an abstract syntax tree, writes it
to an \XML/ file);
\item MSM (transforms the abstract syntax tree into an explicitly
  typed intermediate representation) --- \texttt{base/first\_identification.pas},
  the \\{MSMAnalyzer} procedure; this will require
  transcribing \texttt{kernel/limits.pas} (which is mostly just a
  bunch of constant parameters);
\item Analyzer (performs type checking, tracks the goals, and other
  miscellaneous jobs) --- the \\{Analyze} procedure in \texttt{kernel/analyzer.pas};
  this requires transcribing kernel code
  (\texttt{lexicon.pas}, \texttt{inout.pas}, \texttt{iocorrel.pas}, \texttt{correl.pas}, \texttt{generato.pas}, \texttt{builtin.pas}, \texttt{justhan.pas}, \texttt{enums.pas}, \texttt{formats.pas},
  \texttt{identify.pas})
  and base code (\texttt{xmldict.pas}), approximately 19590 lines
  (16764 lines of code, the rest is whitespace and comments)
\item Checker (performs the proof checking for validity) ---
the \\{InferenceChecker} procedure
in \texttt{kernel/checker.pas}. This requires transcribing kernel
files (\texttt{checker.pas prechecker.pas equalizer.pas unifier.pas justhan.pas}),
approximately 8191 lines of code.
\endenumerate

Using numbers Mario Carneiro reported in his github repository,
roughly $14/15$ of Mizar's runtime (as measured in CPU time)
is spent on the Analyzer and Checker phases (among which, Mizar
spends about 5 times longer in the Checker phase than the Analyzer
phase). Parsing and MSM transforms the input into an intermediate
representation used in the latter two phases. Mizar spends about
$1/15$ of its time here.

@ \node{Accommodator.}
This will produce, among other outputs, the ``\texttt{.dct}'' file
(and its \XML/ counterpart, the ``\texttt{.dcx}'' file). The
``\texttt{.dct}'' file contains all the identifiers imported from
other articles and reserved keywords for Mizar. The Tokeniser needs it
to properly tokenise an article.

@ \node{Parsing phase.}
We can look at \texttt{kernel/verfinit.pas} to find the parsing phase
of the Mizar program is handled by the following lines of code:
\medbreak
\setbox0=\vbox{
\Y\P$\\{InitPass}(\.{\'Parser\ \ \'})$;\5
$\\{FileExam}(\\{EnvFileName}+\.{\'.dct\'})$;\5
$\\{InitScanning}(\\{MizFileName}+\\{ArticleExt},\39\\{EnvFileName})$;\5
\\{InitWSMizarArticle};\5
\\{Parse};\5
$\\{gFormatsColl}.\\{StoreFormats}(\\{EnvFileName}+\.{\'.frx\'})$;\5
\\{gFormatsColl}.\\{Done};\5
\\{FinishScanning};\5
$\\{Write\_WSMizArticle}(\\{gWSTextProper},\39\\{EnvFileName}+\.{\'.wsx\'})$;%
\par}
\boxblock{\box0}
\medbreak\noindent%
Our goal is to examine these functions, and understand what is going on.
We know \\{Parse} is defined in \texttt{base/parse.pas}, it
populates the \\{gWSTextProper} global variable using \texttt{base/parseraddition.pas},
and \\{Write\_WSMizArticle} is defined in \texttt{base/wsmarticle.pas}.
The \\{Parse} function continuously invokes \\{ReadToken}
(\section\xref{ReadToken}). 

This phase will be responsible for generating a ``\texttt{.frx}''
(formats \XML/) and a ``\texttt{.wsx}'' (weakly strict Mizar \XML/) file.


@* [s] Map of Mizar.
It will be useful to provide a summary of the files, to give the
reader an idea where to find various things. We offer the following
grouping of files. We will enumerate them by the chapter wherein the file is
discussed.

@ \node{System-dependent code.}
\enumerate
\item \texttt{base/mizenv.pas} provides functions for manipulating
  strings and file I/O
\item \texttt{base/pcmizver.pas} contains the major and minor version
  for Mizar, and data about the build
\item \texttt{base/mconsole.pas} provides common functions for
  printing messages to the console and parsing command line optional
  arguments % needs pcmizver
\item \texttt{base/errhan.pas} contains the \\{Position} type,
  functions for reporting errors, writing them in particular files % used by mstate.pas
\item \texttt{base/info.pas} for debugging purposes, logging to
  a \texttt{.inf} file % used by monitor.pas
\item \texttt{base/monitor.pas} code for signal processing, reports errors,
  and when calamity strikes exit Mizar  % used by mstate.pas
\item \texttt{base/mtime.pas} uniform framework for timing things% used by mstate.pas
\item \texttt{base/mstate.pas} code for reset the current position in
  an article and marking the time \edef\resumecounting{\the\enumi}
\endenumerate

@ \node{Infrastructure for the rest of Mizar's object-oriented code.}
\enumerate\enumi=\resumecounting
\item \texttt{base/numbers.pas} contains code for arbitrary-precision
  integers, rational numbers, and rational complex numbers
\item \texttt{base/mobjects.pas} contains the common data structures
  used in Mizar, things like dynamic arrays and the \\{MObject} base class;
\edef\resumecounting{\the\enumi}
\endenumerate

@ \node{XML infrastructure.}
\enumerate\enumi=\resumecounting
\item \texttt{base/xml\_dict.pas} contains only constant parameters
  and enumerated types
\item \texttt{base/librenv.pas} code for accessing the \texttt{prel/}
  subdirectories of the current article and of \texttt{\$MIZFILES/}
  --- this is only here because it defines the \\{MizFiles} global
  variable which stores the full path of the \texttt{\$MIZFILES/}
  environmental variable, and \\{MizFiles} is needed in \texttt{xml\_inout.pas};
  \Ithink{This \\{MizFiles} global variable should be refactored out to an earlier
  unit, because \texttt{librenv.pas} seems out of place here;}
\item \texttt{base/xml\_parser.pas} provides an abstract syntax tree
  for \XML/ and parses \XML/  
\item \texttt{base/xml\_inout.pas} handles reading from and writing to \XML/
  files, plus escaping strings, etc.
\edef\resumecounting{\the\enumi}
\endenumerate

@ \node{Tokenisation and other ``intermediate file management''.}
\enumerate\enumi=\resumecounting
\item \texttt{base/dicthan.pas} loading ``\texttt{.voc}'' files,
  and transform them into ``\texttt{.vct}'' and \XML/
  ``\texttt{.vcx}'' files
\item \texttt{base/scanner.pas} the Tokeniser and Scanner are implemented here
  (the naming is a little confusing, the \\{Scanner} class \textbf{is}
  the Tokeniser, and the \\{Tokeniser} class is an ``abstract
  Tokeniser'' operating on an arbitrary input stream accessed by an
  abstract \\{GetPhrase} method); also note, if we want to extend
  Mizar to support \UTF8 character encoding instead of \ASCII/, then
  this is the file we would modify;
\item \texttt{base/\_formats.pas} contains the data structures for ``formats''
  (basically a $\langle$Identifier, Number of arguments to left, Number of arguments to right$\rangle$ triple)
  used for parsing expressions;
\edef\resumecounting{\the\enumi}
\endenumerate

%\par\hang\textindent\item
@ \node{Abstract syntax tree class hierarchies.}
\enumerate\enumi=\resumecounting
\item \texttt{base/syntax.pas} provides ``abstract'' classes \\{Subexpression} and \\{Expression}
  for expressions, \\{Item} and \\{Block} for statements; the actual
  subclasses used by the parser are in
  the \texttt{parseraddition.pas} file;
\item \texttt{base/mscanner.pas} provides a number of important global
  variables for the parser, ``\texttt{.prf}'' file management, as well
  as the \\{gScanner} global variable for the parser;
\item \texttt{base/abstract\_syntax.pas} provides the abstract syntax
  tree for terms, types, attributes, formulas, and ``within expressions'';
\item \texttt{base/wsmarticle.pas} ``weakly strict Mizar'' is the name
  for the initial internal representation of Mizar, which has its own
  class hierarchy here, as well as writing a ``weakly strict Mizar'' article
  to an \XML/ file and reading back from an \XML/ file into a ``weakly strict
  Mizar'' abstract syntax tree;
\edef\resumecounting{\the\enumi}
\endenumerate

@ \node{Parser ``proper''.}
\enumerate\enumi=\resumecounting
\item \texttt{base/pragmas.pas} for parsing pragmas like ``\texttt{::\$P-}'',
  and global variables related to them;
\item \texttt{base/parseraddition.pas} for subclasses of the syntax
  tree class hierarchy from \texttt{syntax.pas}, used for constructing a
  ``weakly strict Mizar'' AST when parsing
\item \texttt{base/parser.pas} for parsing a token stream into an
  abstract syntax tree
\endenumerate

@* [S] Log of todos, bugs, improvements.
I have a number of observations from transcribing Mizar
into \WEB/. They're the last thing I have included in the introductory chapter.

@ \node{Possible improvements.}
\enumerate
\item In quicksort, picking the pivot is done by |P := (Low + High)/2|,
but it should be done by |P := Low + ((High - Low)/2)| to avoid
overflow.
\item Actually, quicksort should delegate work to a different sorting
algorithm when there is less than 10 items in the list. Sedgewick
pointed this out in his PhD thesis. (If quicksort \emph{were} a
culprit for slowness, we could even hardcode sort networks for small lists.)
\item We should also determine the pivot by looking at the median
value of |P = (3*Low + High)/4|, |P2 := (Low + High)/2|,
|P3 := (Low + 3*High)/4|. This will improve the performance of quicksort.
\item In \section\xref{numbers:gcd}, |GCD| could be optimized to avoid
calculating |Mul(i,i)| in every loop iteration.
\item In \section\xref{MStringList.ObjectOf}, |MStringList.ObjectOf|
has duplicate code.
\item It seems that parsing Mizar text, emitting \XML/, and
parsing \XML/ seem to contain a lot of code which could be
autogenerated from a grammar (a hypothetical ``\texttt{.ebnf}''
file). This would avoid duplicate work.
\endenumerate 

@ \node{Possible bugs.} I have been working through the source code
with the mindset of, ``How can I possibly break this?'' This has led
me to identify a number of situations where things can ``go
badly''. But they are not all bugs (some are impossible to occur).

\startbugs%\par\advance\leftskip\parindent%
\bug In \section\xref{numbers:rationalgt}, |RationalGT| is
either misnamed (should be |RationalGEQ|) or implemented incorrectly
(we should have |RationalGT(a,b) = RationalLT(b,a)| but do not)
\bug In \section\xref{numbers:isrationalle} |IsRationalGT| is misnamed (should be |IsRationalGEQ|)
\bug In \section\xref{MsortedExtList.FindInterval},
|MSortedExtList.FindInterval| appears to assume that
 |MSortedExtList.Find| returns the left-most index.
\bug In \section\xref{MSortedCollection.Search}, |MSortedCollection.Search|
may not return the correct index when there are duplicates.
This is not terrible, since |IndexOf| corrects for this possibility.
\bug In \section\xref{TXTStreamObj.Done}, I think |TXTStreamObj.Done|
needs to close the associated file.
\bug In \section\xref{TSymbol.Init}, |TSymbol.Init| expects an
|fInfinitive| argument, but does not use it --- shouldn't it
 initialize |Infinite := fInfinitive|?
\bug In \section\xref{XMLScannObj.GetAttrValue}, escaped quotation
marks are not properly handled.
\bug For StreamObj (\section\xref{StreamObj}), the constructors and
destructors are not virtual which would impact XMLOutStreamObj
(\section\xref{XmlOutStreamObj}) --- well, we just do duplicate work
in XMLOutStreamObj's constructors and destructors.
\bug Shouldn't \\{TokensCollection.InitTokens} (\section\xref{TokensCollection.InitTokens})
invoke the inherited constructor?
\bug Shouldn't \\{MTokenObj.Init} (\section\xref{MTokenObj.Init})
invoke inherited constructors? At least to insulate itself from
changes to any of its parent (or grandparent) classes?
\bug The constructor \\{OutWSMizFileObj.OpenFileWithXSL} (\section\xref{OutWSMizFileObj.OpenFileWithXSL})
expects the \XML/-stylesheet located at \texttt{"file://'+\$MIZFILES+'/wsmiz.xml"},
but that file is not present in Mizar.
\bug In \\{extItemObj.FinishFunctorPattern} (\section\xref{extItemObj.FinishFunctorPattern}),
the default case does not add a new format to the \\{gFormatsColl} dictionary.
\bug In \\{CreateArgs} (\section\xref{CreateArgs}) in \texttt{parseraddition.pas}, when |aBase <= 0|, this
will set |TermNbr| to a negative number.
\bug In the Subexpression class, there is duplicate code
(\section\xref{extSubexpObj.CompleteAttributeArguments}) ---
the \\{CompleteAttributeArguments} and \\{FinishAttributeArguments}
are identical, but only the latter is consistent with the naming
conventions for the Parser. Or (probably more likely) I am misunderstanding the naming conventions?
\bug In \\{CompleteArgument}
(\section\xref{CompleteArgument:parser.pas}), we should also test
that \\{fParenthCnt} is positive, shouldn't we?
\bug The \\{CreateSubexpression} method (\section\xref{extExpressionObj.CreateSubexpression}),
for extended expression objects, may result in a memory leak
when |gSubexpPtr <> nil| --- that is to say, if \\{KillSubexpression}
has not been invoked prior to \\{CreateSubexpression}.
\bug Misnamed variable: \\{gIdenifyEqLociList} should be \\{gIdentifyEqLociList}
(i.e., ``idenify'' should be ``identify'' --- with a `t'). (This typo
has been corrected in the literate presentation of the code.)
\bug As discussed in (\section\xref{extItemObj.StartFixedVariables}),
there is a mismatch between the documentation and the Parser when it
comes to parsing loci declarations in a definition
block. The \texttt{syntax.txt} file is more restrictive than the
Parser, and should be updated to reflect the Parser.
\bug The \\{gSuchThat} global variable is never used anywhere (\section\xref{extItemObj.FinishFixedVariables})
\bug In \\{ATTSubexpression} (\section\xref{ATTSubexpression}), in the
|else| block when the conditional
|if lAttrExp or (aExpKind = exAdjectiveCluster)| is executed,
|aExpKind = exAdjectiveCluster| is never true (so there's no need for it).
\endbugs


@ \node{To do list.} There are some things I should revisit, revise,
and edit --- specifically about this running commentary (\emph{not} the Mizar
source code).
\enumerate
\item [Missing transcription] I skipped over transcribing
the \\{ItemName} and other constants from \texttt{wsmarticle.pas},
which I should probably include.
\item [Revise] The \XML/ schema should use the \texttt{doc/mizar/xml/Mizar.rnc}
  schema snippets.
\item [Revise] Make an introduction to dynamic arrays as a data structure, just
to standardize the terminology used. (Make sure I stick to the
standardized terminology!) Including pictures may help\dots
\item [Revise] Review quicksort. I should prove that it works, too. (Has this
been done in Mizar? \texttt{exchsort} seems to be the closest match.)
\item [Improve] Give a ``big picture'' summary of the architecture. For example,
the most interesting routine in parsing Mizar, well, it's all handled
in \\{MTokeniser.SliceIt} (\section\xref{MTokeniser.SliceIt}).
\item [Linting] Standardize the names of basic data types. \PASCAL/
accepts \\{integer} as synonymous with \\{Integer}, but they give
different index entries.
\item [Cosmetics] Check the typography is correct for the code
\item [Cosmetics] Create more \WEB/ macros for conditional compilation
\item [Cosmetics] Would it help to include more UML class diagrams?
\item [Improve] It may be useful to use UML State diagrams to explain
the parser --- or it may be a huge distraction?
\endenumerate

@ \node{Formatting types.}%
This is still a finicky aspect of \WEB/.
Strings are a type in Free \PASCAL/, like \emph{Boolean}.

Looking at Wirth's book, he typesets a type in \emph{italics} and
lowercase --- so we have \\{boolean} and not \&{boolean}
or \\{Boolean} (or \&{Boolean} or \texttt{boolean} or\dots). Knuth's
``\TeX: the program'' follows this convention
(using \\{integer}, \\{boolean}, \\{char}, etc.).

@ \node{Using Twill (or not).}%
Knuth invented Twill as a ``hack'' atop \WEAVE/ to include
``mini-indices'' every couple pages. The problem I have with Twill is
that it does not adequately index local variables (in the sense that:
Knuth's \TeX\ is a giant monolithic program, and any |var| appearing
in it is almost certainly a global variable --- hence it makes sense
to index \emph{all} variables, since they are almost certainly
global).

I \emph{want} to use Twill, but it is designed specifically \emph{for} Knuth.
Consequently it is not terribly useful for our purposes. We would have
to tailor it quite heavily, and I don't have the energy or patience to
do so.

@ \node{Caution:} Knuth takes advantage of \WEB/ to
use \texttt{snake\_case} when naming things instead
of Pascal's idiomatic \texttt{PascalCase}. This probably greatly
improves the readability of the code. We should probably think hard
about using it.

When \WEAVE/ extracts the \PASCAL/ code, it will remove all
underscores from the identifiers and capitalize all letters. So
instead of ``|screaming_run_on_case|'' (which appears in the PDF), we
will instead obtain ``\texttt{SCREAMINGRUNONCASE}'', which\dots yeah, that's a hot mess.

@* [S] Review of Pascal.
Following Wirth's \textit{Systematic Programming: An Introduction}
(Prentice-Hall, 1973; viz., Chapter~7), we can
offer the following axiomatic semantics for most of \PASCAL/'s statements.
@^Wirth, Niklaus@>

Assignment statements: $${{}\over\LB\,P[w/v]\,\RB\ v\K w\ \LB\,P\,\RB}$$
Compound statements: 
$${\displaystyle{\LB\,P\,\RB\ S_{1}\ \LB\,Q\,\RB\atop
\LB\,Q\,\RB\ S_{2}\ \LB\,R\,\RB}\over\LB\,P\,\RB\ S_{1};\ S_{2}\ \LB\,R\,\RB}$$
Conditional statements:
$${\displaystyle{\LB\,P\W B\,\RB\ S_{1}\ \LB\,Q\,\RB\atop
\LB\,P\W\R B\,\RB\ S_{2}\ \LB\,Q\,\RB}\over\LB\,P\,\RB\ \&{if}\ B\ \&{then}\ S_{1}\ \&{else}\ S_{2}\ \LB\,Q\,\RB}$$
Simpler conditional statements:
$${\displaystyle{\LB\,P\W B\,\RB\ S\ \LB\,Q\,\RB\atop
\LB\,P\W\R B\,\RB\implies\LB\,Q\,\RB}\over\LB\,P\,\RB\ \&{if}\ B\ \&{then}\ S\ \LB\,Q\,\RB}$$
While statements: $${{\LB\,P\W B\,\RB\ S\ \LB\,P\,\RB}\over\LB\,P\,\RB\ \&{while}\ B\ \&{do}\ S\ \LB\,P\W\R B\,\RB}$$
Repeat statements:
$${\displaystyle{{\LB\,P\,\RB\ S\ \LB\,Q\,\RB}\atop\LB\,Q\W\R B\,\RB\ S\ \LB\,Q\,\RB}\over\LB\,P\,\RB\ \&{repeat}\ \37S\ \&{until}\ B\ \LB\,Q\W B\,\RB}$$
Selective statement (and $i=L_{k}$ for some $k$):
$$\vbox{\halign{\hfil#\hfil\cr
${\LB\, P\W (i = L_{k})\,\RB\ S_{k}\ \LB\,Q\,\RB\hbox{ for all }k=1,\dots,n}$\cr
\noalign{\vskip2pt\hrule\vskip2pt}\cr
%\noalign{\hrule}\cr
\vbox{\halign{#\hfil\cr
$\LB\,P\,\RB\ \&{case}\ i\ \&{of}$\cr
\quad$L_{1}{:}\ S_{1};$\cr
\quad$L_{2}{:}\ S_{2};$\cr
\quad$\ \vdots\quad\;\,\vdots$\cr
\quad$L_{n}{:}\ S_{n};$\cr
$\&{end};\quad\LB\,Q\,\RB$\cr}}\cr}}$$
When there is no $k$ such that $i=L_{k}$, the \&{case} statement is
the same as evaluating $i$.

We can weaken the precondition:
$${{P_{1}\implies P_{2},\qquad \LB\,P_{2}\,\RB\ S\ \LB\,Q\,\RB}\over\LB\,P_{1}\,\RB\ S\ \LB\,Q\,\RB}$$
We can strengthen the postcondition (Equation (11.16), page 85, of
Wirth's book):
$${{Q_{2}\implies Q_{1},\qquad \LB\,P\,\RB\ S\ \LB\,Q_{2}\,\RB}\over\LB\,P\,\RB\ S\ \LB\,Q_{1}\,\RB}$$
These rules are justified as \emph{a priori} valid in Chapter~5 of
Wirth.

For-loops may be derived as:
$${\displaystyle{\LB\,(V=a)\W P\,\RB\ S\ \LB\,Q(a)\,\RB\atop
\LB\,Q(\\{pred}(x))\,\RB\ S\ \LB\,Q(x)\,\RB\hbox{ for all }a<x\leq b}\over
\displaystyle{\LB\,(a\leq b)\W P\,\RB\ \&{for}\ V\K a\ \&{to}\ b\ \&{do}\ S\ \LB\,Q(b)\,\RB\atop
\LB\,(a>b)\W P\,\RB\ \&{for}\ V\K a\ \&{to}\ b\ \&{do}\ S\ \LB\,P\,\RB}}$$


@* [F] Mizar environment.
We want to abstract away all the system dependent code, and provide a
set of common functions Mizar will use to interact with the file
system. This will include some helper functions for trimming
whitespace from a String.

@<mizenv.pas@>=
@<GNU License@>

unit mizenv;

interface @| @/

@<interface for mizenv.pas@> @; @#

implementation @|@/

@<Modules used by \texttt{mizenv.pas}@> @; @/

@<implementation of mizenv.pas@> @t\2@> 

end.

@ There are a few common ``global variables'' used by the rest of
Mizar. Specifically, Mizar will be processing a file (``article'').
The file may be an absolute path
(e.g., \texttt{/path/to/article.miz}), a relative path (\texttt{../article.miz}), or just the
filename (\texttt{article.miz}). In any event, we will want to refer
to the filename (\texttt{article.miz}) as well as what Mizar calls the
``article ID'' (in this case, ``\texttt{ARTICLE}'' --- the filename
without the file extension, transformed to all capital letters).

Modern programmers may find discomfort working with global variables
(and for good reason!). We remind such readers that it was common
practice, until very recently, for compilers and interpreters to use
global variables to describe the state of the compiler (or
interpreter). We will freely refer to these global variables as
``state variables'', since that captures the role they play more accurately.

@^State variable@>
@^Variable, global@>
@^Variable, state@>
@^Global variable@>

\label{mizenv-global-vars}

@<interface for mizenv.pas@>=
var MizFileName : string; { the article ``\texttt{article.miz}'' }
  ArticleName : string; { the ``\texttt{article}'' without the ``\texttt{.miz}''}
  ArticleID : string; { ``\texttt{ARTICLE}'' in screaming snake case}
  ArticleExt : string; { ``\texttt{.miz}'' from the |MizFileName| }
  EnvFileName : string; { the file name given to Mizar as a command-line argument } @#

procedure @? SetStringLength(var aString: string; aLength: integer);

@ The implementation begins with various ``uses''. Depending on
the \PASCAL/ compiler and operating system, different libraries need
to be loaded.

@<Modules used by \texttt{mizenv.pas}@>=
uses {compiler dependent imports}@/
if_def(DELPHI)
  IOUtils,SysUtils,windows, @+
endif
if_def(FPC)
  dos,SysUtils, @+
endif @/
  mconsole; {the only Mizar module \texttt{mizenv.pas} uses}

@ As far as setting the String length, this is a straightforward
implementation. When the desired \\{aLength} is less than the actual
length of \\{aString}, simply delete all characters after \\{aLength}.

Otherwise, \\{aString} has \textit{fewer} characters than desired, so we
pad it on the right with however many spaces until the String is as
long as \\{aLength}.

@<implementation of mizenv.pas@>=
procedure SetStringLength(var aString: string; aLength: integer);
var I, L: integer;
begin
  L := length(aString);
  if aLength <= L then
    Delete(aString, aLength + 1, L - aLength)
  else
    for I := 1 to aLength - L do aString := aString + ' ';
end;

@ \node{Trimming whitespace.}
Trimming the left String will repeatedly delete any leading
whitespace, until the String is empty or has no leading whitespace.

Similarly, trimming the right String will repeatedly delete the \textit{last}
character until it is no longer whitespace (or until the String becomes empty).

Remember, \PASCAL/ is call-by-value, so the string arguments are
copied when these functions are invoked. We are mutating the copy of
the argument, and returning them to the user.

@<interface for mizenv.pas@>=
function @? TrimStringLeft(aString: string): string; @t\2@>
function @? TrimStringRight(aString: string): string;

@ @<implementation of mizenv.pas@>=
function TrimStringLeft(aString: string): string;
begin
  while (length(aString) > 0) and (aString[1] = ' ') do Delete(aString, 1, 1);
  TrimStringLeft := aString;
end;
@#
function TrimStringRight(aString: string): string;
begin
  while (length(aString) > 0) and (aString[length(aString)] = ' ') do Delete(aString, length(aString), 1);
  TrimStringRight := aString;
end;

@ Trimming a String amounts to trimming it on the left and right.

@<interface for mizenv.pas@>=
function @? TrimString(const aString: string): string;

@ @<implementation of mizenv.pas@>=
function TrimString(const aString: string): string;
begin
  TrimString := TrimStringRight(TrimStringLeft(aString));
end;

@ \node{Uppercase and lowercase strings.}
We have a few more String manipulation functions for changing case,
and turning an integer into a String.

@<interface for mizenv.pas@>=
function @? UpperCase(const aStr:string): string; @t\2@>
function @? MizLoCase(aChar: char): char; @t\2@>
function @? LowerCase(const aStr: string): string; @t\2@>
function @? IntToStr(aInt: integer): string;

@ Now, uppercase strings are obtained by uppercasing each character.

@<implementation of mizenv.pas@>=
function UpperCase(const aStr:string): string;
 var k: integer; {index ranging over |aStr|}
  lStr: string;  {the uppercased String being built and returned}
begin
 lStr:=aStr;
 for k:=1 to length(aStr) do lStr[k]:=UpCase(aStr[k]);
 UpperCase:=lStr;
end;

@ Lowercasing a String can be done by iteratively replacing each
character with its lowercase version. This ``lowercase a single
character'' function is precisely |MizLoCase|.

If the reader wished for a \UTF8 version of Mizar, then this function
would require thinking very hard about how to generalize.

@p
function MizLoCase(aChar: char): char;
begin
 if aChar in ['A'..'Z'] then
   MizLoCase := Chr(Ord('a') + Ord(aChar) - Ord('A'))
 else
   MizLoCase := aChar;
end;
@#

function LowerCase(const aStr: string): string;
 var i: integer;  {index ranging over |aStr|'s length}
     lStr: String; {result being built up}
begin
  lStr:=aStr;
  for i:=1 to length(aStr) do lStr[i]:=MizLoCase(aStr[i]);
  LowerCase:=lStr;
end;

@ We also want a \emph{funtion} to convert an integer to a
String. \PASCAL/ provides us with a \emph{procedure}.

@p
function IntToStr(aInt: integer): string;
 var lStr: string;
begin
 Str(aInt,lStr);
 IntToStr:=lStr;
end;

@ {\bf File name manipulation.} We will want to test if a file exists,
or split a path (represented as a String) into a directory and a filename.

Testing if a file exists uses the Free Pascal's primitive |FileExists|
function.

Similarly, |EraseFile| is just relying on Free Pascal's |SysUtils.DeleteFile|
function.

\label{MFileExists}

@<interface for mizenv.pas@>=
function @? MFileExists(const aFileName : string) : Boolean; @t\2@>
procedure @? EraseFile(const aFileName:string);

@ @<implementation of mizenv.pas@>=
function MFileExists(const aFileName : String) : Boolean;
begin
 MFileExists:=FileExists(aFileName); @+
end;
@#
procedure EraseFile(const aFileName:String);
begin
 SysUtils.DeleteFile(aFileName); @+
end;

@ We will destructively rename a file. If a file with the name already
exists, we delete it. \CAUTION/: This function is not used anywhere,
and it appears to be buggy (the file is deleted and then renamed,
which begs the question---why is it deleted?).

@<interface for mizenv.pas@>=
procedure @? RenameFile(const aName1,aName2:string);

@ @<implementation of mizenv.pas@>=
procedure RenameFile(const aName1,aName2:String); {unused}
begin
 if MFileExists(aName1) then
   EraseFile(aName2);
 SysUtils.RenameFile(aName1,aName2);
end;

@ Again, relying on Free Pascal's |FileAge| function, which returns
the modification time of the file. \CAUTION/: this will return a
signed 32-bit integer, which will run into problems after 03:14:07~UTC on 19 January 2038
because that's $2^{31}-1$ seconds since the \UNIX/ epoch.

\label{GetFileTime}

@<interface for mizenv.pas@>=
function @? GetFileTime(aFileName: string): Longint;

@ @<implementation of mizenv.pas@>=
function GetFileTime(aFileName: String): Longint;
begin
 GetFileTime := FileAge(aFileName); @+
end;

@ Split a file name into components, namely (1) the directory, (2) the
file name, (3) its extension.
For example, \texttt{/path/to/my/file.exe} will be split
into \texttt{/path/to/my/}, \texttt{file}, and \texttt{exe}.

This implementation depends on the compiler used (Delphi or Free Pascal).

@<interface for mizenv.pas@>=
procedure @? SplitFileName(@t\hskip-0.5em@>@+const aFileName: string; @/
@t\hskip8.75pc@>@+ var aDir, aName, aExt: string);

@ @<implementation of mizenv.pas@>=
procedure SplitFileName(@t\hskip-0.5em@>@+const aFileName: string; {input} @/
@t\hskip8.75pc@>@+  var aDir, aName, aExt: string) @t\2@>; {output}
begin@|@/
if_def(FPC) @/
 aDir := SysUtils.ExtractFilePath(aFileName); @/
 aName := SysUtils.ExtractFileName(aFileName); @/
 aExt := SysUtils.ExtractFileExt(aFileName);
endif@;
if_def(DELPHI) @/
 aDir := TPath.GetDirectoryName(aFileName); @/
 aName := TPath.GetFileName(aFileName); @/
 aExt := TPath.GetExtension(aFileName);
endif@;
end;

@ ``Truncating a directory'' means ``throw away the directory part of
the  path'' so we end up with just a filename and the file extension.

@<interface for mizenv.pas@>=
function @? TruncDir(const aFileName: string): string;

@ @<implementation of mizenv.pas@>=
function TruncDir(const aFileName: string): string;
var
  Dir, lName, Ext: string;
begin
  SplitFileName(aFileName, Dir, lName, Ext);
  TruncDir := lName + Ext;
end;

@ ``Truncating the extension'' means throwing away the extension part
of a path.

@<interface for mizenv.pas@>=
function @? TruncExt(const aFileName: string): string;
@ @<implementation of mizenv.pas@>=
function TruncExt(const aFileName: string): string;
var
  Dir, lName, Ext: string;
begin
  SplitFileName(aFileName, Dir, lName, Ext);
  TruncExt := Dir + lName;
end;

@ Extracting the file directory will return \textit{just} the directory
part of a path.

@<interface for mizenv.pas@>=
function @? ExtractFileDir(const aFileName: string): string;

@ @<implementation of mizenv.pas@>=
function ExtractFileDir(const aFileName: string): string;
 var
   Dir, lName, Ext: string;
begin
  SplitFileName(aFileName, Dir, lName, Ext);
  ExtractFileDir := Dir;
end;

@ Extracting the file name will throw away both the directory and
extension. For example, extracting the file name from the path
``\texttt{/path/to/file.ext}'' gives us ``\texttt{file}''. Extracting
the file extension from the same path gives us ``\texttt{.ext}''.

@<interface for mizenv.pas@>=
function @? ExtractFileName(const aFileName: string): string; @t\2@>
function @? ExtractFileExt(const aFileName: string): string;

@ @<implementation of mizenv.pas@>=
function ExtractFileName(const aFileName: string): string;
var
  Dir, lName, Ext: string;
begin
  SplitFileName(aFileName, Dir, lName, Ext);
  ExtractFileName := lName;
end;
@#
function ExtractFileExt(const aFileName: string): string;
var
  Dir, lName, Ext: string;
begin
  SplitFileName(aFileName, Dir, lName, Ext);
  ExtractFileExt := Ext;
end;

@ Changing a file name's extension. See:

\href{https://www.freepascal.org/docs-html/rtl/sysutils/changefileext.html}{{\tt freepascal.org/docs-html/rtl/sysutils/changefileext.html}}

\noindent Note this does not actually change the filename in the file
system, it just changes it \emph{as a string}.

@<interface for mizenv.pas@>=
function @? ChangeFileExt(const aFileName,aFileExt: string): string;

@ @<implementation of mizenv.pas@>=
function ChangeFileExt(const aFileName,aFileExt: string): string;
begin
 ChangeFileExt:=SysUtils.ChangeFileExt(aFileName,aFileExt); @+
end;

@ \node{Environment variables.}
Getting an environment variable. The reader wishing to learn more
about what \POSIX/ says about environmental variables may consult
the \POSIX/ standard, Volume~1 Chapter~8:

\smallbreak
\href{https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap08.html}{{\tt pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap08.html}}
\smallbreak\noindent%
The Free \PASCAL/ compiler handles this situation far friendlier than
Delphi. 

@<interface for mizenv.pas@>=
function GetEnvStr(aEnvName: string): string;

@ @<implementation of mizenv.pas@>=
function GetEnvStr(aEnvName: string): string; @/
if_def(FPC) 
begin
 GetEnvStr:=GetEnv(aEnvname); @+
end; @/
endif 
if_def(DELPHI) 
@<Get environment variable, Delphi-compatible mode@>
endif 

@ The Delphi-compatible version of obtaining an environment variable
is rather involved: copy the string, make it null terminated, look up
the value.

@<Get environment variable, Delphi-compatible mode@>=
const cchBuffer=255;
var lName,lpszTempPath: array[0..cchBuffer] of char;
     i: integer;
     lStr: string; @t\2@>
begin
 @<Copy the variable name as a null-terminated string@>;

 if GetEnvironmentVariable(lName,lpszTempPath,cchBuffer) > 0 then
  begin
   @<Copy environment variable's value into |lStr| until we find null character@>;
  end;
 GetEnvStr:=lStr;
end;

@ @<Copy the variable name as a null-terminated string@>=
 lStr:='';
 for i:=1 to length(aEnvname) do
  lName[i-1]:=aEnvname[i];
 lName[length(aEnvname)]:=#0

@ @<Copy environment variable's value into |lStr| until we find null character@>=
   for i:=0 to cchBuffer do
    begin
     if lpszTempPath[i]=#0 then break;
     lStr:=lStr+lpszTempPath[i];
    end

@ \node{Common printing routines.}
Examining a file amounts to testing if we can open the file. We close
the file after opening it (because we don't want to actually want to
do anything with it).

We should tweak how \WEB/ formats a file to make it resemble the other
types, rather than leave it as a ``type opertor'' like \&{array}
(which is the default due to Knuth).

@f file==integer;

@<implementation of mizenv.pas@>=
procedure FileExam(const aFileName: string);
var Source: file; {the file named |aFileName|}
I: byte; {|IOResult| from trying to open the file}
begin
  if aFileName = '' then @<Halt: we can't open the file@>;
  FileMode:=0;
  Assign(Source,aFileName); without_io_checking(Reset(Source));
  I:=IOResult;
  if I<>0 then DrawIOResult(aFileName,I); {(\section\xref{mconsole:drawioresult})}
  close(Source);
  FileMode:=2;
end;

@ @<Halt: we can't open the file@>=
    begin DrawMessage('Can''t open '' .miz ''',''); @t\hskip-1em@> {(\section\xref{mconsole:drawmessage})}@+
     halt(1);
    end

@ The user provides a file to Mizar as the command line argument. This
typically looks like a relative path ``\texttt{tex/article}'' without
any file extension. Before even trying to open ``\texttt{tex/article.miz}'', or any of the
related autogenerated intermediate files, we should test the file exists.

This procedure will notify the user if the file does not exist,
otherwise it is silent.

Again, |DrawMessage| comes from \texttt{mconsole.pas} (\section\xref{mconsole:drawmessage}).

@<implementation of mizenv.pas@>=
procedure EnvFileExam(const aFileExt: string);
begin
  if not MFileExists(EnvFileName+aFileExt) then
   begin
     DrawMessage('Can''t open '' '+EnvFileName+aFileExt+' ''','');
     Halt(1);
   end;
end; 

@ This function isn't used anywhere in Mizar. It's also misnamed: we
are not ``getting'' the file name, we are \emph{updating} the file
extension if the file lacks one. A better name might be ``populate
missing file extension''. Further, this does not test if the |Nr|
command line argument is actually a file name or not, which is a
possible source of bugs.

Remember, the \\{ParamCount} is \PASCAL/'s way of counting the command-line
parameters passed to the program.

@<implementation of mizenv.pas@>=
procedure GetFileName(ParamNr:byte; DefaultExt:string; var aFileName:string);
 var  lFileExt: string;
begin
 if ParamNr <= ParamCount then
  begin aFileName:=ParamStr(ParamNr);
    lFileExt:=ExtractFileExt(aFileName);
    if lFileExt='' then aFileName:=ChangeFileExt(aFileName,DefaultExt);
    exit
  end;
 aFileName:='';
end;

@ This procedure will take the |Nr| command line argument. If it lacks
a file extension, then it will append the |DefaultExt| to it. At the
end, this will populate |aFileName| and |aFileExt| based on the
command line. It's only used in the |GetMizFileName| procedure, and
nowhere else in Mizar.

The |ParamStr(Nr)| returns the ${\it Nr}^{th}$ parameter as a String (it's
a \PASCAL/ primitive).

@<implementation of mizenv.pas@>=
procedure GetFileExtName(Nr:byte; DefaultExt: string;
                      var aFileName: string; var aFileExt:s tring);
begin
 if Nr <= ParamCount then
  begin aFileName:=ParamStr(Nr);
    aFileExt:=ExtractFileExt(aFileName);
    if aFileExt='' then aFileExt:=DefaultExt
    else aFileName:=ChangeFileExt(aFileName,'');
    exit
  end;
 aFileName:=''; aFileExt:='';
end;

@ \node{Populate the state variables using the command-line arguments.}
We need to find the first command-line argument which resembles a
Mizar article name. Note that Mizar articles have several files
associated with it (the article's contents in a \texttt{.miz} file,
the vocabulary in a \texttt{.voc} file, and \XML/ related intermediate
representation in \texttt{.xml} files, as well as \texttt{.evl} files).

Command line flags prefixed with a dash (``\texttt{-}'') will not be
interpreted as the name of a Mizar article.

If there are multiple articles passed to Mizar as command-line
arguments, then this function finds the first one (and uses it to
populate the state variables).

A possible bug: if there are multiple files passed to Mizar and the
first file passed is not a ``\texttt{.miz}'' file, then Mizar will
halt as a failure instead of continuing looking for the needle in the
haystack. 

@<implementation of mizenv.pas@>=
procedure GetMizFileName(aFileExt:String);
var i:integer;
begin
 MizFileName:=''; ArticleName:=''; ArticleExt:=''; EnvFileName:='';
 for i:=1 to ParamCount do
  if ParamStr(i)[1]<>'-' then
   begin
    MizFileName:=ParamStr(i);
    GetFileExtName(i,aFileExt,MizFileName,ArticleExt);
    ArticleName:=ExtractFileName(MizFileName);
    ArticleID:=UpperCase(ArticleName);
    if not IsMMLIdentifier(ArticleName) then
    @<Halt: invalid article name@>;
    EnvFileName:=MizFileName;
    exit;
   end;
end;

@ @<Halt: invalid article name@>=
     begin
      DrawMessage('Only letters, numbers and _ allowed in Mizar file names','');
      halt(1);
     end

@ We will provide a standard way to populate the global variables.

@<implementation of mizenv.pas@>=
procedure GetArticleName;
begin
 GetMizFileName('.miz');
end;

@ The second file provided to Mizar is treated as the |EnvFileName|.
We need to populate the global variables if they have not been
extracted from the command-line arguments already.

@<implementation of mizenv.pas@>=
procedure GetEnvironName;
var i,c:integer;
begin
 if MizFileName = '' then GetArticleName;
 EnvFileName:=MizFileName;
 c:=0;
 for i:=1 to ParamCount do
  if (ParamStr(i)[1]<>'-') then
   begin
    inc(c);
    if c=2 then EnvFileName:=ParamStr(i);
   end;
end;

@ The valid characters which can appear in a Mizar article name (an
``MML Identifier'') are uppercase Latin letters (\texttt{A-Z}), lowercase Latin
letters (\texttt{a-z}), decimal digits (\texttt{0-9}), and underscores
(\texttt{\_}). 

@p
function IsMMLIdentifier(const aID: String): Boolean;
 const Allowed: array[chr(0)..chr(255)] of byte =
   (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0, {\texttt{0}--\texttt{9}}
    0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1, {\texttt{A}--\texttt{Z}, ``\texttt{\_}''}
    0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0, {\texttt{a}--\texttt{z}}
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0);
 var i: integer;
begin
  for i:=1 to length(aID) do
   if Allowed[aID[i]] = 0 then
    begin
     IsMMLIdentifier:=false;
     exit; @+
    end;
 @t\quad @>  IsMMLIdentifier:=true;
end;


@* [F] PC Mizar Version.
This is used to track the version of Mizar.

@<pcmizver.pas@>=
  @<GNU License@>
unit pcmizver;

interface @|@#

const  @<Constants for \texttt{pcmizver.pas}@>@;

@<Public functions for \texttt{pcmizver.pas}@>@;

implementation @|@#

@<Implementation for \texttt{pcmizver.pas}@>  @t\2@> @; @#

end.

@
Note the slight variant of terminology compared to semantic versioning
``Major.Minor.Patch'', Mizar uses ``Release.Version.Variant''. This
appears to be just a minor difference in vocabulary.

@<Constants for \texttt{pcmizver.pas}@>=
   PCMizarReleaseNbr = 8; @/
   PCMizarVersionNbr = 1; @/
   PCMizarVariantNbr = 14;

@ The current year could probably be determined from the \PASCAL/
system utilities, but it is hardcoded to 2025. The \\{CurrentYear} is
only used in one procedure in this module, so we could easily replace
it with (the possibly non-portable) |FormatDateTime('YYYY',Now)|.

@<Constants for \texttt{pcmizver.pas}@>=
   CurrentYear = 2025; @#

@ The directory separator for the file system supports Windows
and \UNIX/-like file systems. So Classic \macOS/ and \QNX/ users would
have to request this changed. 

@<Constants for \texttt{pcmizver.pas}@>=
@{@&$IFDEF WIN32@}
   DirSeparator = '\'; @/
@{@&$ELSE@}
   DirSeparator = '/'; @/
@{@&$ENDIF@}

@ There are only four functions provided by this module.

\interface
@<Public functions for \texttt{pcmizver.pas}@>=
function @? PCMizarVersionStr: string;
function @? VersionStr: string;
function @? PlatformNameStr: string;
function @? Copyright : string;
@ \endinterface
Their implementation is relativiely straightforward: just print the
appropriate constants to the screen.


@<Implementation for \texttt{pcmizver.pas}@>=
function Copyright : string;
var s:string;
begin
 Str(CurrentYear,s);
 Copyright:='Copyright (c) 1990-'+s+' Association of Mizar Users';
end;

@ @<Implementation for \texttt{pcmizver.pas}@>=
function  VersionStr: string;
 var lRel,lVer,lVar: string[2]; lStr:string;
begin
 Str(PCMizarReleaseNbr,lRel);
 Str(PCMizarVersionNbr,lVer);
 Str(PCMizarVariantNbr,lVar);
 if length(lVar) = 1 then lVar:='0'+lVar; @/
@{@&$IFDEF VERALPHA@} 
 lStr:='-alpha'; @/
@{@&$ELSE@}
 lStr:=''; @/
@{@&$ENDIF@} @/
 VersionStr:=lRel+'.'+lVer+'.'+lVar+lStr;
end;

@ There are a number of platforms supported, a surprisingly large
number. If we were to support more platforms (other \BSD/s, \BeOS/, \GNU/
Hurd, etc.), then we would need to update this function. To see what
platforms are predefined for FreePascal, consult:
\item{$\bullet$}\href{https://wiki.freepascal.org/Platform_defines}{\texttt{https://wiki.freepascal.org/Platform_defines}}

\noindent Ostensibly, we could extend the platform name string to
display ``generic \UNIX/'' (and even ``generic \BSD/''), as well as
``generic Windows''.


@<Implementation for \texttt{pcmizver.pas}@>=
function  PlatformNameStr: string;
var lStr: string;
begin
   lStr:=''; @#
   
   if_def(WIN32) lStr:=lStr+'Win32'; @+ end_if
   if_def(LINUX) lStr:=lStr+'Linux'; @+ end_if
   if_def(SOLARIS) lStr:=lStr+'Solaris'; @+ end_if
   if_def(FREEBSD) lStr:=lStr+'FreeBSD'; @+ end_if
   if_def(DARWIN) lStr:=lStr+'Darwin'; @+ end_if @#

   if_def(FPC) lStr:=lStr+'/FPC'; @+ end_if
   if_def(DELPHI) lStr:=lStr+'/Delphi'; @+ end_if @#

   PlatformNameStr:=lStr;
end;

@ The last function in the \texttt{pcmizver.pas} file provides a
string for the Mizar version.

@<Implementation for \texttt{pcmizver.pas}@>=
function  PCMizarVersionStr: string;
begin
 PCMizarVersionStr:='Mizar Ver. '+VersionStr;
end;

@* [F] Mizar Console.
The Mizar Console unit is used for interacting with the command line.
Specifically, this module will be used for printing error messages,
reporting progress, and parsing command-line arguments for
configuration options.

@<mconsole.pas@>=
@<GNU License@>

unit mconsole;

interface
@<Report results to command line@>@;

@<Constants for common error messages reported to console@>@;

@<Interface for accommodator command line options@>@;

@<Interface for |MakeEnv| command line options@>@;

@<Interface for transfer-specific command line options@>@;

@<Interface for other command line options@>@;

implementation
@|@#
@<Import units for \texttt{mconsole.pas}@>
@#
@<Implementation for mconsole.pas@>

@t\2@>end

@ We import two modules, \\{pcmizver} and \\{mizenv},

@<Import units for \texttt{mconsole.pas}@>=
uses pcmizver,mizenv;

@ We want to have a method which allows us to flag an error
(\\{fErrNbr}) on a given line of the article being processed. But the
user may request Mizar to silence these messages. We can facilitate
this by 

@<|DisplayLine| global constant@>=
const@+DisplayLine:@+procedure(fLine,fErrNbr: integer) = NoDisplayLine; @t\2@>

@ Now, we have accommodator specific options.

@<Interface for accommodator command line options@>=
{Accommodator specific options:}

var
 SignatureProcessing, {unused}
 TheoremListsProcessing, {unused}
 SchemeListsProcessing, {unused}
 InsertHiddenFiles, {Include \.{HIDDEN} automatically?}
 FormatsProcessing:Boolean;


var {Registrations-related configuration for Accommodator}
 ClustersProcessing,IdentifyProcessing,ReductionProcessing,PropertiesProcessing: Boolean;

var {The environ-specifical Accommodator options}
 VocabulariesProcessing, {Accommodator will run \\{ProcessVocabularies}}
 NotationsProcessing, {Accommodator processes \.{notations} directive}
 ConstructorsProcessing, {Will the Accommodator determine which constructor to use for identifier?}
 DefinitionsProcessing,EqualitiesProcessing,ExpansionsProcessing, {Definition environs}
 TheoremsProcessing,SchemesProcessing: Boolean;

@ Among the state variables introduced in the \texttt{mconsole} unit,
there is one for handling \.{SIGINT}, \.{SIGQUIT}, and \.{SIGTERM} signals. \Ithink{The other \UNIX/
signals should probably be supported, as well.}

@<Interface for other command line options@>=
{Other options:}

var
 CtrlCPressed : Boolean = false; {\.{SIGINT}, \.{SIGQUIT}, or \.{SIGTERM} signal received?}
 LongLines : Boolean = false; {Allow lines longer than 80 characters}
 QuietMode : Boolean = false; {Don't print anything to the console?}
 StopOnError: Boolean = false; @#

 FinishingPass: Boolean = false;
 ParserOnly : Boolean = false; {No analyzing or checking}
 AnalyzerOnly : Boolean = false; {Analyze, but no parsing or checking}
 CheckerOnly : Boolean = false; {Check, but do not re-analyze or re-parse}
 SwitchOffUnifier: Boolean = false; @#

 AxiomsAllowed: Boolean = false;

@ \endinterface
The implementation begins by initializing the Accommodator specific options.

@ @<Interface for accommodator command line options@>=
procedure @? InitAccOptions;

@ @<Implementation for mconsole.pas@>=
procedure InitAccOptions;
begin
 InsertHiddenFiles:=true;
 VocabulariesProcessing:=true;
 FormatsProcessing:=true;
 NotationsProcessing:=true;
 SignatureProcessing:=true;
 ConstructorsProcessing:=true;
 ClustersProcessing:=true;
 IdentifyProcessing:=true;
 ReductionProcessing:=true;
 PropertiesProcessing:=true;
 DefinitionsProcessing:=true;
 EqualitiesProcessing:=true;
 ExpansionsProcessing:=true;
 TheoremsProcessing:=true;
 SchemesProcessing:=true;
 TheoremListsProcessing:=false;
 SchemeListsProcessing:=false;
end;

@ Similarly, we want to be able to \emph{reset} the configuration for
the accommodator to the default (initial) values. This is a private
helper function for other things in the \texttt{mconsole}.

@ @<Implementation for mconsole.pas@>=
procedure ResetAccOptions;
begin
 InsertHiddenFiles:=true;
 VocabulariesProcessing:=false;
 FormatsProcessing:=false;
 NotationsProcessing:=false;
 SignatureProcessing:=false;
 ConstructorsProcessing:=false;
 ClustersProcessing:=false;
 IdentifyProcessing:=false;
 ReductionProcessing:=false;
 PropertiesProcessing:=false;
 DefinitionsProcessing:=false;
 EqualitiesProcessing:=false;
 ExpansionsProcessing:=false;
 TheoremsProcessing:=false;
 SchemesProcessing:=false;
 TheoremListsProcessing:=false;
 SchemeListsProcessing:=false;
end;

@ \node{Accommodator options.}%
We will get options for the accommodator passed in from the command
line. Broadly, these are:

\item{$\bullet$} \texttt{-v} resets the accommodator options, and then toggles
|VocabulariesProcessing| to true

\item{$\bullet$} \texttt{-f}, \texttt{-p} resets the accommodator
options, and then toggles |VocabulariesProcessing| to true (so far
like \texttt{-v}), and then toggles |FormatsProcessing| to true.

\item{$\bullet$} \texttt{-P} resets the accommodator options, and then toggles
|VocabulariesProcessing| to true (so far like \texttt{-v}), and then
toggles |FormatsProcessing| to true (so far like \texttt{-f}
and \texttt{-p}), then toggles |TheoremListsProcessing| and
|SchemeListsProcessing| to both be true.

\item{$\bullet$} \texttt{-e} will do everything \texttt{-f} does, and
then toggles |ConstructorsProcessing|, |SignatureProcessing|,\hfill\break
|ClustersProcessing|, and |NotationsProcessing| to all be true.

\item{$\bullet$} \texttt{-h} will set |InsertHiddenFalse| to false
(presumably preventing Mizar from loading the ``hidden'' article,
i.e., the primitive notions
of ``\texttt{object}'', ``\texttt{<>}'', ``\texttt{in}'', and ``\texttt{strict}'' will
not be loaded).

\item{$\bullet$} \texttt{-l} will toggle |LongLines| to true (allowing
lines with more than 80 characters)

\item{$\bullet$} \texttt{-q} will toggle |QuietMode| to true

\item{$\bullet$} \texttt{-s} will toggle |StopOnError| to true

\medbreak
Note this processes \emph{all} command line options \emph{in order}.
So \texttt{-e -v} will produce the same results as \texttt{-v} alone.

@<Interface for accommodator command line options@>=
procedure @? GetAccOptions;

@ @<Implementation for mconsole.pas@>=
procedure GetAccOptions;
 var i,j: integer;
begin
 InitAccOptions;
 for j:=1 to ParamCount do
  if ParamStr(j)[1]='-' then
   for i:=2 to length(ParamStr(j)) do
    case ParamStr(j)[i] of
     'v': begin ResetAccOptions; VocabulariesProcessing:=true end;
     'f','p':
      begin
       ResetAccOptions;
       VocabulariesProcessing:=true;
       FormatsProcessing:=true;
      end;
     'P':
      begin
       ResetAccOptions;
       VocabulariesProcessing:=true;
       FormatsProcessing:=true;
       TheoremListsProcessing:=true;
       SchemeListsProcessing:=true;
      end;
     'e':
      begin
       ResetAccOptions;
       VocabulariesProcessing:=true;
       FormatsProcessing:=true;
       ConstructorsProcessing:=true;
       SignatureProcessing:=true;
       ClustersProcessing:=true;
       NotationsProcessing:=true;
      end;
     'h': begin InsertHiddenFiles:=false; @+ end;
     'l': LongLines:=true;
     'q': QuietMode:=true;
     's': StopOnError:=true;
    endcases;
end;

@ Similarly, we have |MakeEnv| specific options parsed from the
command line flags.


@ @<Interface for |MakeEnv| command line options@>=
{MakeEnv specific options:}

var Accomodation : Boolean = false;
    NewAccom : Boolean = false;

procedure @? GetMEOptions;

@ @<Implementation for mconsole.pas@>=
procedure GetMEOptions;
 var i,j: integer;
begin
 for j:=1 to ParamCount do
  if ParamStr(j)[1]='-' then
   for i:=2 to length(ParamStr(j)) do
    case ParamStr(j)[i] of
     'n': NewAccom:=true;
     'a': Accomodation:=true;
     'l': LongLines:=true;
     'q': QuietMode:=true;
     's': StopOnError:=true;
    endcases;
end;

@ The ``other'' options.

Notably, there is a feature to allow axioms,@^Axioms@> which is completely
undocumented (and probably for good reason!). The axioms must appear
in ``\texttt{.axm}'' files.

@<Interface for other command line options@>=
procedure @? GetOptions;

@ @<Implementation for mconsole.pas@>=
procedure GetOptions;
 var i,j: integer;
begin
 for j:=1 to ParamCount do
  if ParamStr(j)[1]='-' then
   for i:=2 to length(ParamStr(j)) do
    case ParamStr(j)[i] of
     'q': QuietMode:=true;
     'p': ParserOnly:=true;
     'a': AnalyzerOnly:=true;
     'c': CheckerOnly:=true;
     'l': LongLines:=true;
     's': StopOnError:=true;
     'u': SwitchOffUnifier:=true;
     'x': AxiomsAllowed:=true;
      othercases break;
    endcases;
 if ArticleExt = '.axm' then
   AxiomsAllowed:=true;
end;

@ Transfer specific options.

@<Interface for transfer-specific command line options@>=
{Transfer specific options:}

var PublicLibr: Boolean; {use ``\texttt{prel/}\<Article-name>\texttt{/}'' subdirectory?}

procedure @? GetTransfOptions;

@ @<Implementation for mconsole.pas@>=
procedure GetTransfOptions;
 var lOption: string;
begin
 PublicLibr:=false;
 if ParamCount>=2 then
  begin lOption:=ParamStr(2);
   if (length(lOption) = 2) and (lOption[1] in ['/','-']) then
    PublicLibr:=UpCase(lOption[2]) = 'P';
  end
end;

@ We have a number of functions useful for ``drawing'', i.e.,
reporting progress and results (and so on).


@<Report results to command line@>= 
procedure @? InitDisplayLine(const aComment: string); @t\2@>
procedure @? NoDisplayLine(fLine,fErrNbr: integer); @t\2@> @#

@t\4@>@<|DisplayLine| global constant@>@; @#

@ The \\{gComment} is used only within this module. Mizar stores the
name of the pass (parser, MSM, analyzer, checker) in \\{gComment},
which is used in a helper function to print the progress to the console.

@<Implementation for mconsole.pas@>=
var gComment: string = ''; {The pass currently being run}
@#
disable_io_checking;
@#
procedure NoDisplayLine(fLine,fErrNbr: integer);
begin
end;
@#
procedure InitDisplayLine(const aComment: string);
begin
 gComment:=aComment;
 WriteLn;
 write(aComment);
 DisplayLine:=DisplayLineInCurPos
end;

@ @<Report results to command line@>= 
procedure @? DrawMizarScreen(const aApplicationName: string); @t\2@>
procedure @? DrawArticleName(const fName: string); @t\2@> @#

procedure @? DrawStr(const aStr: string); @t\2@>
procedure @? FinishDrawing;

@ @<Implementation for mconsole.pas@>=
procedure DrawStr(const aStr: string);
begin write(aStr) @+ end;
@#
procedure FinishDrawing;
begin WriteLn; end;
@#
procedure DrawTPass(const fPassName: string);
begin write(fPassName) @+ end;
@#
procedure DrawMizarScreen(const aApplicationName: string);
begin
 WriteLn(aApplicationName,', ',PCMizarVersionStr,' (',PlatformNameStr,')');
 WriteLn(Copyright);
end;

@ The \\{Noise} parameter rings the bell three times (the |^G| is
Caret notation ``Ctrl+G'', which is \ASCII/ code 10 \.{BEL}). For
non-Windows systems, this will write three \.{BEL} characters to the
standard output stream. Windows will do nothing.

@<Report results to command line@>=
procedure @? EmptyParameterList; @t\2@>
procedure @? Noise;

@ @<Implementation for mconsole.pas@>=
procedure Noise; @t\2@>
begin @|@/
  if_not_def(WIN32)
  write(^G^G^G); @+
  endif;
end;
@#
procedure EmptyParameterList;
begin
 Noise;
 WriteLn; WriteLn('****  Empty Parameter List ? ****');
 halt(2);
end;

@ When the user asks Mizar to verify an article, Mizar will begin by
writing to the standard output stream ``Processing: \<Article name>''.

@<Implementation for mconsole.pas@>=
procedure DrawArticleName(const fName: string);
begin
 WriteLn('Processing: ',fName); @+
end;

@ @<Report results to command line@>=
procedure @? DrawPass(const aName: string); @t\2@>
procedure @? DrawTime(const aTime: string); @t\2@>
procedure @? DrawVerifierExit(const aTime: string);

@ @<Implementation for mconsole.pas@>=
procedure DrawPass(const aName: string);
begin
 WriteLn;
 write(aName); @+
end;
@#
procedure DrawTime(const aTime: string);
begin
 write(aTime); @+
end;
@#
procedure DrawVerifierExit(const aTime: string);
begin
 WriteLn;
 WriteLn('Time of mizaring:',aTime);
end;

@ On non-Windows machines, |^M| is used in \\{write} to add a carriage
return. Windows machines will require |#13| instead. This is because
|^M| is ``Ctrl+M'' which has \ASCII/ code 77-64=13 (see, it's the same
as |#13|).

% https://stackoverflow.com/a/50188627

@<Report results to command line@>=
procedure @? DisplayLineInCurPos(fLine,fErrNbr: integer);

@<Implementation for mconsole.pas@>=
procedure DisplayLineInCurPos(fLine,fErrNbr: integer);
begin
 if (not CtrlCPressed) and (not QuietMode)then
  begin
   write(^M+gComment+' [',fLine:4);
   if fErrNbr>0 then write(' *',fErrNbr);  
   write(']' );
  end; 
 if FinishingPass then
  begin
   write(' [',fLine:4);
   if fErrNbr>0 then write(' *',fErrNbr);  
   write(']' );
  end; 
end;

@ When Mizar needs to notify the user that a critical error has
occurred, \\{DrawMessage} will be used for communicating it. By
``critical error'', I mean things like Mizar cannot open the file, or
there was a stack overflow, or the hard drive exploded.

\label{mconsole:drawmessage}

@<Report results to command line@>=
procedure @? DrawMessage(const Msg1,Msg2: string);

@ @<Implementation for mconsole.pas@>=
procedure DrawMessage(const Msg1,Msg2: string);
 var Lh: byte;
begin
  Noise;
  WriteLn;
  write('**** ',Msg1);
  Lh:=length(Msg1);
  if length(Msg2)>Lh then Lh:=length(Msg2);
  if Lh > length(Msg1) then write(' ':Lh-length(Msg1));
  WriteLn(' ****');
  if Msg2<>'' then
   begin write('**** ',Msg2);
     if Lh > length(Msg2) then write(' ':Lh-length(Msg2));
     WriteLn(' ****');
   end;
end;

@ The \texttt{monitor.pas} file uses \\{BugInProcessor} when reporting
errors. It's a logging function for severe situations.

@<Report results to command line@>=
procedure @? BugInProcessor;

@ @<Implementation for mconsole.pas@>=
procedure BugInProcessor;
begin
  DrawMessage('Internal Error',''); @+
end;

@ When \\{reset} (or \\{rewrite}) fails, Mizar will cease. We should
specifically report the situation to the user, because they can
address the situation whereas we cannot.

\label{mconsole:drawioresult}
@<Report results to command line@>=
procedure @? DrawIOResult(const FileName: string; @+ I:byte);

@ @<Implementation for mconsole.pas@>=
procedure DrawIOResult(const FileName: string;@+ I:byte);
begin
 if I in [2..6,12,100] then
   begin
     if I=12 then I:=7 else if I=100 then I:=8;
     DrawMessage(ErrMsg[I],'Can''t open '' '+FileName+' ''')
   end
  else DrawMessage('Can''t open '' '+FileName+' ''','');
 halt(1);
end;

@ We also have a constant for error messages commonly encountered.

@<Constants for common error messages reported to console@>=
const
  ErrMsg: array[1..6] of string[20] = @/
       ('', @/
        'File not found', @/
        'Path not found', @/
        'Too many open files', @/
        'Disk read error', @/
        'Disk write error'
       );


@ @<Report results to command line@>=
procedure @? DrawErrorsMsg(aErrorNbr: integer);

@ @<Implementation for mconsole.pas@>=
procedure DrawErrorsMSg(aErrorNbr: integer);
begin
  if aErrorNbr > 0 then
  begin
    WriteLn;
    if aErrorNbr = 1 then
      WriteLn('**** 1 error detected')
    else
      WriteLn('**** ', aErrorNbr, ' errors detected');
  end;
end;

@* [F] Error handling.

@<errhan.pas@>=
  @<GNU License@>

unit errhan;

interface @;@|@/

@<Interface for \texttt{errhan.pas}@>@;

implementation @; @|@/

uses mconsole,mizenv; @/

@<Implementation for \texttt{errhan.pas}@>@; @+ @t\2@>

end;

@ We have a few custom types and internal variables describing the
state of the Mizar error handler.

\label{type:Position}

@<Interface for \texttt{errhan.pas}@>=
type Position = @<Declare |Position| as |record|@>;
     ErrorReport = @+ procedure(Pos:Position; ErrNr:integer); @t\2 @>

const ZeroPos : Position = (Line:0; Col:0); @#

var  CurPos:    Position; {current position}
     ErrorNbr:  integer;  {current error number}

     PutError: ErrorReport = nil; {reporter for errors}

     RTErrorCode: integer = 0; {runtime error code}
     OverflowErroor: boolean = false; {overflow error? They're horrible, treat accordingly}

@ Position is just a pair of integers recording the line and offset
(``column'').

@<Declare |Position| as |record|@>=
record Line,Col: integer end

@ And we just provide the public-facing functions and procedures.

\interface
@<Interface for \texttt{errhan.pas}@>=
procedure @? Error(Pos:Position; ErrNr:integer);
procedure @? ErrImm(ErrNr:integer); @#

procedure @? WriteError(Pos:Position; ErrNr:integer);
procedure @? OpenErrors(FileName:String);
procedure @? AppendErrors(FileName:String);
procedure @? EraseErrors;
procedure @? CloseErrors; @#

procedure @? OverflowError(ErrorCode:word);
procedure @? Mizassert (ErrorCode:word; Cond:boolean);
procedure @? RunTimeError(ErrorCode:word);

@ \endinterface
The implementation begins as we would expect/hope. If we have
a \emph{preferred} error reporter already present in |PutError|, then
we just use it. If we have toggled |StopOnError| to true, then we
should end the program here (with a message).

If we want to report an error at the |CurrPos| (current position),
then we have a helper function do that for us.

\label{ErrImm}

@<Implementation for \texttt{errhan.pas}@>=
procedure Error(Pos:Position; ErrNr:integer);
begin
   inc(ErrorNbr);
   if @@PutError <> nil then PutError(Pos,ErrNr);
   if StopOnError then 
   begin 
      DrawMessage('Stopped on first error',''); 
      Halt(1); @+
   end;
end; @#

procedure ErrImm(ErrNr:integer);
begin
 Error(CurPos,ErrNr);
end;

@ We also can write errors to a file. This requires keeping track of
the file (dubbed |Errors|) and whether it has been opened or not (in
the Boolean condition |OpenedErrors|).

Note this takes advantage of |with| to destructure |Pos| into a |Line|
and |Col| for us.

@p
var
  Errors: text; {file name for errors file}
  OpenedErrors: boolean = false; {have we opened it yet?}

procedure WriteError(Pos:Position; ErrNr:integer);
begin
 if not OpenedErrors then RunTimeError(2001);
 with Pos do WriteLn(Errors,Line,' ',Col,' ',ErrNr);
end;

@ \node{Opening an errors file.}%
We can open an errors file, which will reset the |ErrorNbr| counter to
zero and re-initialize |CurPos| to line 1 and column 1.

When |PutError| is |nil|, we initialize it to be |WriteError|.

@p
procedure OpenErrors(FileName:String);
begin
   if ExtractFileExt(FileName)='' then FileName:=FileName+'.err';
   Assign(Errors,FileName);
   without_io_checking(Rewrite(Errors));
   if IOResult <> 0 then
   begin
      DrawMessage('Can''t open errors file '''+FileName+''' for writing','');
      halt(1);
   end;
   OpenedErrors:=true;
   ErrorNbr:=0;  with CurPos do begin Line:=1; Col:=1 end;
   if @@PutError = nil then PutError:=WriteError;
end;

@ Appending errors to the errors file.

@p
procedure AppendErrors(FileName:String);
begin
 OpenedErrors:=true;
 if ExtractFileExt(FileName)=''  then FileName:=FileName+'.err';
 Assign(Errors,FileName);
 ErrorNbr:=0;
 with CurPos do begin Line:=1; Col:=1 end; @/
 without_io_checking(append(Errors));
 if ioresult<>0 then Rewrite(Errors);
end;

@ We can also close the errors file and unset the |Errors| variable,
``forgetting'' where we logged the errors.

@p
procedure EraseErrors;
begin
 if OpenedErrors then
  begin
   OpenedErrors:=false;
   close(Errors); erase(Errors);
  end;
end;

@ We can also just close the errors file.

@p
procedure CloseErrors;
begin
 if OpenedErrors then
  begin
   OpenedErrors:=false;
   close(Errors);
  end;
end;

@ Like I said, overflow errors are especially problematic. If/when
they occur, we should just bail out immediately.

@p
procedure OverflowError(ErrorCode:word);
begin
 RTErrorCode:=ErrorCode;
 OverflowErroor:=true;
 RunError(97);
end;

@ We have an assertion utility to check if a |Cond| is |true|. When it
is |false|, we should report a runtime error.

\label{MizAssert}

@p
procedure MizAssert( ErrorCode:word; Cond: boolean );
begin
 if not Cond then
  begin
   RTErrorCode:=ErrorCode;
   RunError(98);
  end;
end;

@ Last, we have a catchall for runtime errors encountered.

@p
procedure RunTimeError(ErrorCode:word);
begin
 RTErrorCode:=ErrorCode;
 RunError(99);
end;

@* [F] Info file handling.
I don't think this is actually used anywhere, but I am including it
for completeness.

@<info.pas@>=
  @<GNU License@>

unit info;

interface

uses errhan;

var InfoFile: text; @#

procedure InfoChar (C: char); @t\2@>
procedure InfoInt (I: integer); @t\2@>
procedure InfoWord (C: char; I: integer); @t\2@>
procedure InfoNewLine; @t\2@>
procedure InfoString (S: string); @t\2@>
procedure InfoPos (Pos: Position); @t\2@>
procedure InfoCurPos; @t\2@> @#

procedure OpenInfoFile; @t\2@>
procedure CloseInfofile; @t\2@> @#

implementation @|@#

uses mizenv,mconsole; @#

procedure InfoChar (C: char);
begin write(InfoFile,C) end; @#

procedure InfoInt (I: integer);
begin write(InfoFile,I,' ') end; @#

procedure InfoWord (C: char; I: integer);
begin write(InfoFile,C,I,' ') end; @#

procedure InfoNewLine;
begin WriteLn(InfoFile) end; @#

procedure InfoString (S: string);
begin write(InfoFile,S) end; @#

procedure InfoPos (Pos: Position);
begin with Pos do write(InfoFile,Line,' ',Col,' ') end; @#

procedure InfoCurPos;
begin with CurPos do write(InfoFile,Line,' ',Col,' ') end;

@ There are a few helper functions which is more than ``Write
$\langle$data type$\rangle$ to info file''.

@p
var _InfoExitProc:pointer;

procedure InfoExitProc;
begin
   CloseInfoFile;
   ExitProc:=_InfoExitProc;
end; @#

procedure OpenInfoFile;
begin
   Assign(InfoFile,MizFileName+'.inf');
   Rewrite(InfoFile);
   WriteLn(InfoFile,'Mizared article: "',MizFileName,'"');
   _InfoExitProc := ExitProc;
   ExitProc:=@@InfoExitProc;
end; @#

procedure CloseInfofile;
begin close(InfoFile) end; @#

end.


@* [F] Monitor.

@<monitor.pas@>=
  @<GNU License@>

unit monitor;

interface @;@|@/

procedure @? InitExitProc; @t\2@>

implementation @; @|@/

@<Units used by \texttt{monitor.pas}@>;@#

var
   _ExitProc: pointer;
   _IOResult:integer; @|@/

@<Implementation for \texttt{monitor.pas}@>

@t\2@>
end

@ The monitor is used for reporting errors, which is heavily system
dependent. The modules used by it are\dots wonky. We need
the \\{baseunix} unit for \UNIX/ systems, and the \\{windows} unit for
Windows-based systems.

@<Units used by \texttt{monitor.pas}@>=
uses @|@/
@{@&$IFDEF FPC@} @/
 @t\quad @> @{@&$IFNDEF WIN32@} @/
   baseunix, @/
 @t\quad @> @{@&$ENDIF@} @/
@{@&$ENDIF@} @/
mizenv,errhan,mconsole @/
@{@&$IFDEF WIN32@} @+ ,windows @{@&$ENDIF@}
mdebug @+ ,info @+ end_mdebug

@ There are a few private helper functions in this module.

@<Implementation for \texttt{monitor.pas}@>=
procedure _Halt_(ErrorCode: word);
begin
  _IOResult:=IOResult;
   ErrorAddr:=nil;
  if ErrorCode>1 then
   case ErrorCode of
    2..4:     begin ErrImm(1000+ErrorCode);
                DrawMessage('I/O error',ErrMsg[ErrorCode]) @+
              end;
    5..6:     begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    12:       begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    97,98,99:
     begin ErrImm(RTErrorCode);
       @<Handle runtime error cases for \texttt{monitor.pas}@>
     end;
    100..101: begin ErrImm(1000+ErrorCode);
                DrawMessage('I/O error',ErrMsg[ErrorCode-95]);
              end;
    102..106: begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    150..162: begin ErrImm(1000+ErrorCode);
                DrawMessage('I/O error','Critical disk error');
              end;
    200..201: begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    202:      begin ErrImm(1000+ErrorCode); DrawMessage('Stack overflow error','') @+ end;
    203,204:  begin ErrImm(1000+ErrorCode); DrawMessage('Heap overflow error','') @+ end;
    208:      begin ErrImm(1000+ErrorCode); DrawMessage('Overlay manager not installed','') @+ end;
    209:      begin ErrImm(1000+ErrorCode); DrawMessage('Overlay file read error','') @+ end;
    210..212: begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    213:      begin ErrImm(1000+ErrorCode); DrawMessage('Collection Index out of range','') @+ end;
    214:      begin ErrImm(1000+ErrorCode); DrawMessage('Collection overflow error','') @+ end;
    215:      begin ErrImm(1000+ErrorCode); DrawMessage('Arithmetic overflow error','') @+ end;
    216:      begin ErrImm(1000+ErrorCode); DrawMessage('General Protection fault','') @+ end;
    217:      begin ErrImm(1000+ErrorCode); DrawMessage('Segmentation fault','') @+ end;
    218..254: begin ErrImm(1000+ErrorCode); BugInProcessor @+ end;
    255:      ErrImm(1000+ErrorCode);
    othercases
     begin ErrImm(ErrorCode);
      if OverflowErroor then
       DrawMessage('Mizar parameter overflow error','')
      else BugInProcessor
     end;
   endcases;
  CloseErrors;
  ExitProc:=_ExitProc;
  if (ErrorCode = 0) and (ErrorNbr <> 0) then Halt(1) else Halt(ErrorCode);
end;

@ @<Handle runtime error cases for \texttt{monitor.pas}@>=
case RTErrorCode of
  800,804:  DrawMessage('Library Corrupted','');
  857:      DrawMessage('Connection Fault','');
  {900..999: DrawMessage('Mizar parameter overflow: '+IntToStr(RTErrorCode),'');}
  1255:     DrawMessage('User break','');
  othercases
    if OverflowErroor then
      DrawMessage('Mizar parameter overflow: '+IntToStr(RTErrorCode),'')
    else BugInProcessor
endcases;

@ The |MizExitProc| is a private ``bail out'' function.

@<Implementation for \texttt{monitor.pas}@>=
procedure MizExitProc;
begin @|@/
@{@&$IFDEF IODEBUG@}
  ExitProc:=_ExitProc; @/
@{@&$ELSE@}
  _Halt_(ExitCode); @/
@{@&$ENDIF@}
end;

@ We use the |MizExitProc| to initialize the |ExitProc| pointer.

@p
procedure InitExitProc;
begin ExitProc := @@MizExitProc end;

@ \node{Initializing Control.}%
This is a \emph{heavily} system dependent piece of code. There are two
ways to implement it (one way for Windows, another way for everyone
else). Once we're done, we have to initialize the |_ExitProc| and
invoke |InitCtrl|.

@p
@<Non-windows FreePascal implemenation for |InitCtrl|@>@; @#

@<Windows implemenation for |InitCtrl|@>@;@#

begin
  _ExitProc := ExitProc;
   InitCtrl;
end.

@ @<Non-windows FreePascal implemenation for |InitCtrl|@>=
@{@&$IFDEF FPC@}
@t\quad @> @{@&$IFNDEF WIN32@}
procedure CatchSignal(aSig : integer);cdecl;
begin @t\1@> @/
 case aSig of
@t\qquad @>    SIGINT,SIGQUIT,SIGTERM:
     begin
      CtrlCPressed:=true;
      RunTimeError(1255); @+
     end; @+
 endcases; @t\2@>
end; @#

var NewSignal, OldSigInt : SignalHandler; @#

procedure InitCtrl;
begin
  NewSignal:=SignalHandler(@@CatchSignal);
  OldSigInt:=fpSignal(SIGINT,NewSignal);
  OldSigInt:=fpSignal(SIGQUIT,NewSignal);
  OldSigInt:=fpSignal(SIGTERM,NewSignal);
end; @|@/
@t\quad @> @{@&$ENDIF@}
@{@&$ENDIF@}

@ Microsoft breaks everything. This is a mess because of them.

@<Windows implemenation for |InitCtrl|@>=
@{@&$IFDEF WIN32@} @t\1@> @/
@<Windows implemenation for |CtrlSignal|@>@; @/
@{@&$IFDEF FPC@} @t\1@> @/
@<FreePascal implementation of |InitCtrl| for Windows@>@; @t\2@>
@t\4@> @{@&$ENDIF@}@/
@{@&$IFDEF DELPHI@} @t\1@> @/
@<Delphi implementation of |InitCtrl| for Windows@>@;  @t\2@>
@t\4@>  @{@&$ENDIF@} @t\2@>@/
 @{@&$ENDIF@}

@ The FreePascal implementation is pretty succinct thanks to the
libraries they provide.

@<FreePascal implementation of |InitCtrl| for Windows@>=
procedure InitCtrl;
begin
 SetConsoleCtrlHandler(CtrlSignal, TRUE); @+
end;

@ @<Delphi implementation of |InitCtrl| for Windows@>=
procedure InitCtrl;
var
  ConsoleMode,lConsoleMode: DWORD;
begin
  if GetConsoleMode(GetStdHandle(STD_INPUT_HANDLE), ConsoleMode) then
  begin
    lConsoleMode := ConsoleMode or ENABLE_PROCESSED_INPUT;
     {Treat Ctrl+C as a signal}
    if SetConsoleMode(GetStdHandle(STD_INPUT_HANDLE), lConsoleMode) then
    begin
      SetConsoleCtrlHandler(@@CtrlSignal, TRUE);
    end;
  end;
end;

@ Windows requires a helper function |CtrlSignal| for this Microsoft
mania.

@<Windows implemenation for |CtrlSignal|@>=
@<FreePascal declaration of |CtrlSignal| for Windows@>@;
@<Delphi declaration of |CtrlSignal| for Windows@>@;
begin
  {TRUE: do not call next handler in the queue, FALSE: call it}
  CtrlCPressed:=true;
  RunTimeError(1255);
  CtrlSignal := true;
  {ExitProcess(1);}
end;

@ @<FreePascal declaration of |CtrlSignal| for Windows@>=
@{@&$IFDEF FPC@}
function CtrlSignal(aSignal: DWORD): WINBOOL ;stdcall; @/
@{@&$ENDIF@}

@ @<Delphi declaration of |CtrlSignal| for Windows@>=
@{@&$IFDEF DELPHI@} 
function CtrlSignal(aSignal: DWORD): BOOL; cdecl; @/
@t\hskip-1em @>  @{@&$ENDIF@}


@* [F] Time utilities.
This is another heavily ``system dependent'' library.

@<mtime.pas@>=
  @<GNU License@>

unit mtime;

interface @;@|@/

@<Interface for \texttt{mtime.pas}@>@;

implementation @; @|@/

@<Implementation for \texttt{mtime.pas}@>@; @+ @t\2@>

end;

@ @<Interface for \texttt{mtime.pas}@>=
procedure @? TimeMark(var W:longint);  @t\2@>
function @? ElapsedTime(W:longint): longint; @t\2@>
procedure @? MUnpackTime(W:longint; var H,M,S,F: word); @t\2@>
function @? ReportTime(W:longint): String;

@ We also have one global variable tracking the start time.

@p
var
  gStartTime: longint;
@ The implementation begins with a rather \emph{thorny} digression
depending on which compiler we're using.

@<Implementation for \texttt{mtime.pas}@>=
@<Timing utilities |uses| for Delphi@>@;
@<Timing utilities |uses| for FreePascal@>@;
@ Delphi simply requires us to introduce a constant for milliseconds.

@<Timing utilities |uses| for Delphi@>=
@{@&$IFDEF DELPHI@}
uses windows;
const cmSecs = 1000; @/
@{@&$ENDIF@}
@ FreePascal requires a bit more work, alas.

@<Timing utilities |uses| for FreePascal@>=
@{@&$IFDEF FPC@}
uses dos;
const cmSecs = 100;
type
   TSystemTime = @/
     record
      wHour:word;
      wMinute:word;
      wSecond:word;
      wMilliseconds:word;
     end;
procedure GetLocalTime(var aTime: TSystemTime);
begin
 with aTime do GetTime(wHour,wMinute,wSecond,wMilliseconds);
end; @/
@{@&$ENDIF@}

@ Now we can happily plug along implementing the functions we need.

@<Implementation for \texttt{mtime.pas}@>=
function SystemTimeToMiliSec(const fTime: TSystemTime): longint;
begin
 SystemTimeToMiliSec:=fTime.wHour*(3600*cmSecs)+
                      fTime.wMinute*longint(60*cmSecs)+
                      fTime.wSecond*cmSecs+
                      fTime.wMilliseconds;
end;

@ We ``start the clock''.

@p
procedure TimeMark(var W:longint);
 var @? SystemTime: TSystemTime;
begin
 GetLocalTime(SystemTime);
 W:=SystemTimeToMiliSec(SystemTime);
end;

@ We measure the time lapse since we ``started the clock''.

@p
function ElapsedTime(W:longint): longint;
 var @? T : longint;
     @? SystemTime: TSystemTime;
begin
 GetLocalTime(SystemTime);
 T := SystemTimeToMiliSec(SystemTime)-W;
 if T < 0 then T:=86400*cmSecs+T;
 ElapsedTime:=T;
end;

@ We can transform an interval of time (in milliseconds) into hours,
minutes, seconds, a fractional amount of time.

@p
procedure MUnpackTime(W:longint; var H,M,S,F: word);
begin
 H := W div (3600*cmSecs);
 M := (W-H*3600*cmSecs) div (60*cmSecs);
 S := (W-H*3600*cmSecs-M*60*cmSecs) div cmSecs;
 F := W-H*3600*cmSecs-M*60*cmSecs-S*cmSecs;
end;

@ When reporting time, we want to pad the time by a zero. This is
standard conventional stuff (e.g., I have an appointment at 11:01~AM,
not 11:1~AM).

@p
function LeadingZero(w : word) : String;
var lStr: String;
begin
  Str(w:0,lStr);
  if length(lStr) = 1 then lStr := '0' + lStr;
  LeadingZero := lStr;
end;

@
Reporting time transforms a time interval (measured in milliseconds)
into a human readable String.

@p
function ReportTime(W:longint): String;
var H,M,S,F: word; lTimeStr: String;
begin
   MUnpackTime(ElapsedTime(W),H,M,S,F);
   if F >= (cmSecs div 2) then inc(S);
   if H<>0 then
   begin Str(H,lTimeStr); lTimeStr:=lTimeStr+'.'+LeadingZero(M) end
   else Str(M:2,lTimeStr);
   ReportTime:=lTimeStr+':'+LeadingZero(S);
end;

@ When we run the program, we should mark the time.

@p
begin
 TimeMark(gStartTime);
end.

@* [F] Mizar internal state.
As far as \emph{processing} an article, Mizar works like a ``batch compiler''
and works in multiple ``passes''.

@<mstate.pas@>=
  @<GNU License@>

unit mstate;

interface @;@|@/

@<Interface for \texttt{mstate.pas}@> @#

implementation @; @|@/

uses mizenv, pcmizver, monitor, errhan, mconsole, mtime @/
mdebug @+ ,info @+ end_mdebug @+; @t\1@>

var PassTime: longint; @|@/

@<Implementation for \texttt{mstate.pas}@>

@t\2@>
end

@ @<Interface for \texttt{mstate.pas}@>=
procedure @? InitPass(const aPassName: String); @t\2@>
procedure @? FinishPass; @t\2@>
procedure @? InitProcessing(const aProgName,aExt: String); @t\2@>
procedure @? ProcessingEnding;

@ The implementation amounts to, well, these four functions. We have a
couple ``private'' functions to help us: |MError| and |MizarExitProc|.

@<Implementation for \texttt{mstate.pas}@>=
procedure InitPass(const aPassName: String);
begin
 CurPos.Line:=1;
 CurPos.Col:=1;
 InitDisplayLine(aPassName);
 TimeMark(PassTime);
end;

procedure FinishPass;
begin
 FinishingPass:=true;
 if QuietMode then DisplayLine(CurPos.Line,ErrorNbr);
 FinishingPass:=false;
 DrawTime('  '+ReportTime(PassTime));
end;

procedure MError(Pos:Position; ErrNr:integer);
begin
 WriteError(Pos,ErrNr);
 DisplayLine(CurPos.Line,ErrorNbr);
end;
@ We also have |MizarExitProc| as a private ``helper'' function.

@p
var _ExitProc: pointer;
procedure MizarExitProc;
begin
 ExitProc := _ExitProc; @/
 disable_io_checking;
 if IOResult<>0 then;
 if not StopOnError then DisplayLine(CurPos.Line,ErrorNbr);
 PutError:=WriteError;
 DrawVerifierExit(ReportTime(gStartTime));
{Halt(ErrorCode);}
 enable_io_checking;
end;

@ @p
procedure InitProcessing(const aProgName,aExt: String);
begin
  DrawMizarScreen(aProgName);
  if ParamCount<1 then EmptyParameterList;
  GetArticleName;
  GetEnvironName;
  DrawArticleName(MizFileName+aExt);
  GetOptions;
  InitExitProc;
  FileExam(MizFileName+aExt);
  _ExitProc := ExitProc;
  ExitProc:=@@MizarExitProc;
  PutError:=MError;
  OpenErrors(MizFileName); @/
  mdebug
  OpenInfoFile; @+
  end_mdebug
end;
@ At the end, we should report the number of errors (if any were encountered).

@p
procedure ProcessingEnding;
begin
 if ErrorNbr > 0 then
  begin
   DrawErrorsMsg(ErrorNbr);
   FinishDrawing;
  end;
end;

@* [F] Arbitrary precision arithmetic.
Specifically, arbitrary precision arithmetic on \emph{integers}
and \emph{rational complex} numbers. integers are represented as
Strings of digits.

Note:
\enumerate
\item The naming convention dictates all functions suffixed with |_XXX|
presuppose the arguments are positive.
\item Also there are \emph{no checks} whether the parameters
contain only digits (and an optional sign ``-'').
\item Further, |DEBUGNUM| is a conditional variable that can be used (with
|DEBUG|) for testing.
\endenumerate

@<numbers.pas@>=
  @<GNU License@>

unit numbers;

interface @|@/
@<Basic arithmetic operations declarations@>@;

@<Types for arbitrary-precision arithmetic@>@;

@<Zero and units for arbitrary-precision@>@;

@<Rational arithmetic declarations@>@;

@<Predicate declarations for arbitrary-precision arithmetic@>@;

@<Declare public complex-valued arbitrary precision arithmetic@>@;

@<Declare public comparison operators for arbitrary-precision numbers@>@;

implementation @|@/

uses mizenv @/
@{@&$IFDEF CH_REPORT@}@+,req_info,prephan,builtin @{@&$ENDIF@} 
 mdebug@+,info @+ end_mdebug; @t\2@> @|@# 

@<Trim leading zeros from arbitrary-precision integers@>@;

@<Check if arbitrary-precision integers are zero@>@;

@<Absolute value for an arbitrary-precision number@>@;

@<Test if one arbitrary-precision number is less than or equal to another@>@;

@<Arithmetic for arbitrary-precision integers@>@;

@<Arbitrary-precision rational arithmetic@>@;

@<Complex-rational arbitrary-precision arithmetic@>@;

@ @<Basic arithmetic operations declarations@>=
function @? Add(a,b: String): String; @t\2@>
function @? Sub(a,b: String): String; @t\2@>
function @? Mul(a,b: String): String; @t\2@>
function @? Diva(a,b: String): String; @t\2@> {*Note: divides absolute values and preserves the sign of the division}
function @? _Div(a,b: String): String; @t\2@>
function @? _Mod(a,b: String): String; @t\2@>
function @? GCD(a,b: String): String; @t\2@> {*Note: always returns a positive value}
function @? LCM(a,b: String): String; @t\2@> {*Note: always returns a positive value}
function @? Abs(a :String ): String; @t\2@>
function @? IsPrime(a: String): boolean; @t\2@>
function @? Divides(a,b: String): boolean;

@ Rational numbers are a pair of arbitrary precision integers
(represented as a String).

Rational complex numbers are represented by a pair of rational numbers
in Cartesian form $z = p + {\rm i} q$.

@<Types for arbitrary-precision arithmetic@>=
type
   Rational = record Num,Den : String end;
   RComplex = record  Re,Im: Rational end;

@ @<Zero and units for arbitrary-precision@>=
const
   RZero:Rational = (Num:'0'; Den:'1');
   ROne:Rational  = (Num:'1'; Den:'1');
   CZero: RComplex     = (Re:(Num:'0'; Den:'1'); Im:(Num:'0'; Den:'1'));
   COne: RComplex      = (Re:(Num:'1'; Den:'1'); Im:(Num:'0'; Den:'1'));
   CMinusOne: RComplex = (Re:(Num:'-1'; Den:'1'); Im:(Num:'0'; Den:'1'));
   CImUnit: RComplex   = (Re:(Num:'0'; Den:'1'); Im:(Num:'1'; Den:'1'));

@ @<Rational arithmetic declarations@>=
procedure @? RationalReduce(var r: Rational); @t\2@>
function @? RationalAdd(const r1,r2: Rational): Rational; @t\2@>
function @? RationalSub(const r1,r2: Rational): Rational; @t\2@>
function @? RationalNeg(const r1: Rational): Rational; @t\2@>
function @? RationalMult(const r1,r2: Rational): Rational; @t\2@>
function @? RationalInv(const r: Rational): Rational; @t\2@>
function @? RationalDiv(const r1,r2: Rational): Rational; @t\2@>
function @? RationalEq(const r1,r2: Rational): boolean; @t\2@>
function @? RationalLE(const r1,r2: Rational): boolean; @t\2@>
function @? RationalGT(const r1,r2: Rational): boolean;

@ @<Predicate declarations for arbitrary-precision arithmetic@>=
function @? IsintegerNumber(const z: RComplex): boolean; @t\2@>
function @? IsNaturalNumber(const z: RComplex): boolean; @t\2@>
function @? IsPrimeNumber(const z: RComplex): boolean; @t\2@> @#

function @? AreEqComplex(const z1,z2: RComplex): boolean; @t\2@>
function @? IsEqWithInt(const z: RComplex; @t\hskip11.25pc@> n: longint): boolean; @t\2@>
function @? IsRationalLE(const z1,z2 : RComplex): boolean; @t\2@>
function @? IsRationalGT(const z1,z2 : RComplex): boolean;

@ @<Declare public complex-valued arbitrary precision arithmetic@>=
function @? IntToComplex(x: integer): RComplex; @t\2@>
function @? ComplexAdd (const z1,z2: RComplex): RComplex; @t\2@>
function @? ComplexSub(const z1,z2: RComplex): RComplex; @t\2@>
function @? ComplexNeg (const z: RComplex): RComplex; @t\2@>
function @? ComplexMult(const z1,z2: RComplex): RComplex; @t\2@>
function @? ComplexInv(const z: RComplex): RComplex; @t\2@>
function @? ComplexDiv(const z1,z2: RComplex): RComplex; @t\2@>
function @? ComplexNorm(const z: RComplex): Rational;

@ @<Declare public comparison operators for arbitrary-precision numbers@>=
function @? CompareInt(X1,X2: Longint): integer; @t\2@>
function @? CompareIntStr(X1,X2: String): integer; @t\2@>
function @? CompareComplex(const z1,z2: RComplex): integer;

@ If we are given single character String consisting of zero or the
empty String, then we are done.

If we are given anything else, we find the first index (from the left)
of a nonzero character. Then we create a copy of the subString
starting from the first nonzero digit to the rest of the String.

@<Trim leading zeros from arbitrary-precision integers@>=
function trimlz(a : String) : String;
var i : integer;
begin
   if (a='0') or (a='') then trimlz:=a else
   begin
   i:=0;
   repeat
   i:=i+1;
   if a[i]<>'0' then break;
   until i=length(a);
   trimlz:=copy(a,i,length(a));
   end;
end;

@ First, we check if $a$ starts with ``$-0$''. If so, replace $a$ with
$0$. Then we do the same thing with $b$.

We invoke \\{trimlz} on $a$ and store the result in |a1|. If $\\{a1}\I a$,
then we update $a\K\\{a1}$.

Then we do likewise on $b$.

@<Check if arbitrary-precision integers are zero@>=
procedure checkzero(var a,b :String);
var a1,b1 : String;
begin
   if copy(a,1,2)='-0' then
   begin @|@/
      @{@&$IFDEF DEBUGNUM@}
      WriteLn(infofile,'a=-0'); @/
      @{@&$ENDIF@}
      a:='0';
   end;
   if copy(b,1,2)='-0' then
   begin @|@/
      @{@&$IFDEF DEBUGNUM@}
      WriteLn(infofile,'b=-0'); @/
      @{@&$ENDIF@} @/
      b:='0';
   end;
   a1:=trimlz(a); if a1<>a then
   begin @|@/
      @{@&$IFDEF DEBUGNUM@}
      WriteLn(infofile,'ZEROS1:',a); @/
      @{@&$ENDIF@}
      a:=a1;
   end;
   b1:=trimlz(b); if b1<>b then
   begin @|@/
      @{@&$IFDEF DEBUGNUM@}
      WriteLn(infofile,'ZEROS2:',b); @/
      @{@&$ENDIF@}
      b:=b1;
   end;
end;

@ Since arbitrary precision numbers (as Strings) are negative if they
begin with a leading ``-'' character, it is easy to obtain the
absolute value (just delete the minus sign).

@<Absolute value for an arbitrary-precision number@>=
function Abs(a :String ):String;
begin
   if length(a)>0 then if a[1]='-' then delete(a,1,1);
   Abs:=a;
end;
@ When checking $a\leq b$ for two non-negative integers, written as
Strings (without leading zeros) you can check if the length of $a$ is
less than the length of $b$.

If the length of $b$ is less than the length of $a$, then $b<a$.

When the length of the two Strings are equal, use lexicographic
ordering to determine which is less.

@<Test if one arbitrary-precision number is less than or equal to another@>=
function _leq(a,b :String): boolean;
var i,x,y,z:integer;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_leq(',a,',',b,')');@/
   @{@&$ENDIF@}
   checkzero(a,b);
   if length(a)<length(b) then _leq:=true
   else if length(a)>length(b) then _leq:=false
   else begin
      for i:=1 to length(a) do
      begin
         val(a[i],x,z); val(b[i],y,z);
         if x>y then begin _leq:=false; exit; end;
         if x<y then begin _leq:=true; exit; end;
      end;
      _leq:=true;
   end;
end;

@ Now the \emph{general} case is when $a$ and $b$ are
arbitrary-precision \emph{integers}. If $a$ starts with a minus sign
and $b$ starts with a minus sign, then test if $a\geq b$.

When $a$ does not start with a minus sign, but $b$ \emph{does} start
with a minus sign, then we're done: $b<a$.

When neither $a$ nor $b$ starts with a minus sign, then we use
$\\{\_leq(a,b)}$ to determine the result.

@p
function leq(a,b :String):boolean;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'leq(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if a=b then leq:=true else
      begin
	 if (a[1]='-') and (b[1]<>'-') then leq:=true;
	 if (a[1]='-') and (b[1]='-') then leq:=not _leq(abs(a),abs(b));
	 if (a[1]<>'-') and (b[1]='-') then leq:=false;
	 if (a[1]<>'-') and (b[1]<>'-') then leq:=_leq(a,b);
      end;
end;

@ Testing if $a\geq b$ is simply testing if $b\leq a$ after
normalizing the Strings.

@p
function geq(a,b :String):boolean;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'geq(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b); @/
   geq:=(not leq(a,b)) or (a=b);
end;

@ Similarly, we may check if $a<b$ by testing $a\neq b$ and $a\leq b$.

@p
function le(a,b :String):boolean;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'le(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   le:=(a<>b) and (leq(a,b));
end; @#

function gt(a,b :String):boolean;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'gt(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   gt:= not leq(a,b);
end;

@ \node{Arithmetic operations.}%
Now we get to some interesting bits.

We have \\{\_Add} for the addition of two non-negative integers. The
basic strategy is to go digit-by-digit, use the \PASCAL/-provided
integer arithmetic, manually ``carrying'' 1 if necessary.

The basic strategy is to initialize \\{a1} to be the larger of the two
numbers, and \\{b1} to the smaller of the two numbers. Then generically
we will have
$${{\displaystyle{{}\atop{+}}{a_{n}\atop{}}{\dots\atop{}}{a_{m+1}\atop{}}{a_{m}\atop b_{m}}{a_{m-1}\atop b_{m-1}} {\dots\atop\dots}{a_{1}\atop b_{1}}}\over{}}\eqno(\modno.1)$$
We will separate this out into two sums. First we compute
$${\displaystyle{{{}\atop{+}}{{}\atop{}}{a_{m}\atop b_{m}}{a_{m-1}\atop b_{m-1}} {\dots\atop\dots}{a_{1}\atop b_{1}}}\over{\hphantom{+}c_{m+1}\;r_{m}\;r_{m-1}\cdots\; r_{1}}}\eqno(\modno.2)$$
Then we will compute
$${\displaystyle{{}\atop{+}}{a_{n}\atop{}}{\dots\atop{}}{a_{m+1}\atop{c_{m+1}}}}\over{r_{n+1}\;r_{n}\;\dots\;r_{m+1}}\eqno(\modno.3)$$
The result is assembled from the digits $r_{n+1}r_{n}\cdots r_{1}$.

@<Arithmetic for arbitrary-precision integers@>=
function _Add(a,b :String):String;
var c,x,y,z,v : integer;i:integer; a1,b1,s,r : String;
begin
   a1:=a; b1:=b; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Add(',a1,',',b1,')'); @/
   @{@&$ENDIF@}
   checkzero(a1,b1);
   if length(a1)<length(b1) then begin s:=b1; b1:=a1; a1:=s; @+ end;
   r:='';
   c:=0;
   begin
      for i:=0 to length(b1)-1 do {step 1, Eq (\modno.2)}
      begin
	 val(a1[length(a1)-i],x,z);
	 val(b1[length(b1)-i],y,z);
	 if x+y+c>9 then begin v:=(x+y+c)-10; c:=1; end else begin v:=x+y+c; c:=0; end;
	 Str(v,s);
	 r:=s+r;
      end;
      for i:=length(b1) to length(a1)-1 do {step 2, Eq (\modno.3)}
      begin
	 val(a1[length(a1)-i],x,z);
	 if x+c>9 then begin v:=(x+c)-10; c:=1; end else begin v:=x+c; c:=0; end;
	 Str(v,s);
	 r:=s+r;
      end;
      if c=1 then r:='1'+r; @+ end; @/
   _Add:=trimlz(r);
end;

@ Subtraction is a bit trickier, because of the ``borrowing''
operation.

Also note that \\{\_Sub(a,b)} will start by computing
$a_{1}\gets\max(a,b)$ and $b_{1}\gets\min(a,b)$, then return $a_{1}-b_{1}$.

@p 
function _Sub(a,b :String):String;
var x,y,z,v : integer;i:integer; a1,b1,s,r : String; @/

   @<Borrow 1 for |Sub_|@>@;   

begin
   a1:=a; b1:=b; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Sub(',a1,',',b1,')'); @/
   @{@&$ENDIF@}
   checkzero(a1,b1);
   if not _leq(b1,a1) then @+ begin s:=b1; b1:=a1; a1:=s; @+ end;
   r:=''; @t\1@>
   begin @t\1@>@/
      for i:=0 to length(b1)-1 do
      begin
         val(a1[length(a1)-i],x,z);
         val(b1[length(b1)-i],y,z);
         if x<y then
         begin
            borrow(length(a1)-i);
            x:=x+10; @+
         end;
         v:=x-y;
         Str(v,s);
         r:=s+r;
      end;
      for i:=length(a1)-length(b1) downto 1 do
      begin
         r:=a1[i]+r; @+ @t\2@> @+
      end;
   end; @t\2@> @/
   _Sub:=trimlz(r); @t\2@>
end;

@ This is a private ``helper function'' for subtraction.

@<Borrow 1 for |Sub_|@>=
procedure Borrow(k :integer);
   var xx,zz : integer;sx:String;
   begin
      val(a1[k-1],xx,zz);
      if xx>=1 then begin xx:=xx-1; Str(xx,sx); a1[k-1]:=sx[1]; end
      else begin a1[k-1]:='9'; borrow(k-1); end;
   end;

@ \node{Multiplication.}%
Multiplication of $a$ by $b$ works digit-by-digit, in the sense that
for each digit $b_{i}$ of $b$, we need to multiply $a$ by $b_{i}$. The
function \\{\_Mul1} does this.

@<Arithmetic for arbitrary-precision integers@>=
function _Mul1(a:String ;y :integer ):String;
var c,x,z,v : integer;i:integer; s,r : String;
begin  @t\1@>@/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Mul1(',a,',',y,')'); @/
   @{@&$ENDIF@}
   r:='';
   c:=0;
   begin   @t\1@>@/
      for i:=0 to length(a)-1 do
      begin
        val(a[length(a)-i],x,z);
        if x*y+c>9 then begin v:=(x*y+c) mod 10; c:=(x*y+c) div 10; @+ end
        else begin v:=x*y+c; c:=0; @+ end;
        Str(v,s);
        r:=s+r;
      end;
      if c<>0 then
      begin
        Str(c,s);
        r:=s+r; @+
      end; @t\2@>
   end;  @/
   _mul1:=trimlz(r); @t\2@>
end;

@ Then multiplication proper amounts to decomposing $b$ into its
decimal expansion $\sum_{k}b_{k}10^{k}$ and computing $(a\times b_{k})10^{k}$.

@p
function _Mul(a,b :String):String;
var y,z : integer;i,j:integer; a1,b1,s,r : String;
begin @t\1@> @/
   a1:=a;b1:=b; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Mul(',a1,',',b1,')'); @/
   @{@&$ENDIF@}
   checkzero(a1,b1);
   if length(a1)<length(b1) then begin s:=b1; b1:=a1; a1:=s; @+ end;
   r:='0';
   for i:=0 to length(b1)-1 do
   begin
      val(b1[length(b1)-i],y,z);
      s:=_mul1(a1,y);
      for j:=0 to i-1 do s:=s+'0';
      r:=_Add(r,s);
   end;
   _Mul:=trimlz(r);  @t\2@>
end;

@ \node{Division.}%
The basic design is similar to multiplication. We will try to divide
$a$ by $b\times 10^{k}$ (which is zero whenever $b\times10^{k}>a$).

@p
function _Div1(a,b : String) : String;
var i : integer; r : String;
begin @|@/
   @{@&$IFDEF DEBUGNUM@} 
   WriteLn(infofile,'_Div1(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if not _leq(b,a) then _div1:='0'
   else
      for i:=9 downto 1 do
      begin
         Str(i,r);
         if _leq(_mul(b,r),a) then
         begin
            _div1:=trimlz(r);
            exit; @+
         end;
      end;
end;

@ @p
function _Div(a,b : String):String;
var z,c,i:integer; s,r,rs : String;b_GPC:boolean; @/
@<Get the next digit for dividing arbitrary-precision integers@>@;
begin @t\1@> @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Div(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if a=b then _div:='1'
   else if not _leq(b,a) then _div:='0' @t\2@>
   else
   begin
      s:='';r:='';z:=1;
      for i:=1 to length(b) do s:=s+a[i];
      if not _leq(b,s) then
      begin
         s:=s+a[length(b)+1];
         z:=length(b)+1; @+
      end
      else
      begin
         z:=length(b); @+
      end;
      repeat
         rs:=_div1(s,b);
         r:=r+rs;
         gets;
         b_GPC:= _leq(b,s);
      until not b_GPC;
      _div:=trimlz(r); @t\2@>
   end; @t\1@>
end;

@ @<Get the next digit for dividing arbitrary-precision integers@>=
procedure gets;
var j : integer;
begin
   c:=1;
   s:=_Sub(s,_mul(rs,b));
   if (s='0') and (trimlz(copy(a,z+c,length(a)))='0') then
   begin
      @{@&$IFDEF DEBUGNUM@}
      WriteLn(infofile,'Rewriting zeros:',copy(a,z+c,length(a))); @/
      @{@&$ENDIF@}
      r:=r+copy(a,z+c,length(a)); exit;
   end;
   if z+1<=length(a) then
   begin
      s:=s+a[z+1]; inc(c);
      if (not _leq(b,s)) then r:=r+'0';
   end;
   while (not _leq(b,s)) and (z+c<=length(a)) do
   begin
      s:=s+a[z+c];
      inc(c);
      if (not _leq(b,s)) then r:=r+'0';
   end;
   z:=z+c-1;
end; {gets}

@ \node{Modulo.} We can compute $a\mathbin{\&{mod}}b$ by observing if
$a < b$ then we should obtain $a$. Otherwise, we should compute
$r\K a\mathbin{\&{div}} b$, then $a - rb$ is $a\mathbin{\&{mod}}b$.

@<Arithmetic for arbitrary-precision integers@>=
function _Mod(a,b : String): String;
var r : String;
begin @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'_Mod(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if le(a,b) then r:=a
   else r:=_Sub(a,_mul(b,_div(a,b)));
   _Mod:=trimlz(r); @/
   @{@&$IFDEF DEBUGNUM@}
    WriteLn(infofile,'End _Mod:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Greatest common divisor.} \label{numbers:gcd}
We can compute $\gcd(a,b)$ first by setting $a_{1}\gets\abs{a}$ and
$b_{1}\gets\abs{b}$ (since $\gcd(a,b)=\gcd(\abs{a},\abs{b})$. Then we
handle the special cases: 
\enumerate
\item $a_{1}=1$ or $b_{1}=1$, then $\gcd(a_{1},b_{1})=1$
\item $a_{1}=0$ and $b_{1}\neq0$, then $\gcd(a_{1},b_{1})=b_{1}$
\item $a_{1}\neq0$ and $b_{1}=0$, then $\gcd(a_{1},b_{1})=a_{1}$
\item $a_{1}=b_{1}$, then $\gcd(a_{1},b_{1})=a_{1}$
\endenumerate

\medbreak
\noindent Otherwise, we end up in the default case, which is handled
by the \&{while} loop.

@p
function GCD(a,b:String):String;
label ex;var a1,b1,p,r:String;
begin
   a1:=a; b1:=b; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'GCD(',a1,',',b1,')'); @/
   @{@&$ENDIF@}
   checkzero(a1,b1);
   a1:=abs(a1); b1:=abs(b1);
   if (a1='1') or (b1='1') then begin r:='1'; goto ex; @+ end;
   if (a1='0') and (b1<>'0') then begin r:=b1; goto ex; @+ end;
   if (b1='0') and (a1<>'0') then begin r:=a1; goto ex; @+ end;
   if a1=b1 then begin GCD:=a1; r:=a1; goto ex; @+ end;
   while gt(b1,'0') do begin p:=b1; b1:= _mod(a1,b1); a1:=p @+ end;
   r:=a1;
   ex:
      GCD:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End GCD:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Least common multiple.} We recall $\lcm(a,b)=\abs{ab}/\gcd(\abs{a},\abs{b})$.

@p
function LCM(a,b:String):String;
var a1,b1,r:String;
begin
   a1:=a; b1:=b; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'LCM(',a1,',',b1,')'); @/
   @{@&$ENDIF@}
   checkzero(a1,b1);
   a1:=abs(a1); b1:=abs(b1);
   r:=Diva(Mul(a1,b1),GCD(a1,b1));
   LCM:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End LCM:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Addition.} This is a bit obfuscated with the reliance of \&{goto} \\{ex},
but the basic idea is (recalling that \\{\_Sub(a,b)} calculates
$\max(a,b)-\min(a,b)$ for $a\geq0$ and $b\geq0$):
\enumerate
\item If $a<0$ and $b<0$, then $a+b=-(\abs{a}+\abs{b})$
\item Else if $a\geq0$ and $b\geq0$, then $a+b$ is computed using \\{\_Add}
\item Else if $a<0$ and $b\geq0$, then we have two cases
\itemitem{(i)} If $\abs{a}\geq b$, compute $a+b=-(\abs{a}-b)$
\itemitem{(ii)} Otherwise, $a+b=b-\abs{a}$
\item Else if $a\geq0$ and $b<0$, then $a+b=a-\abs{b}$
\item Otherwise, when $a\geq0$ and $b\geq0$, $a+b$ is computed
using \\{\_Add}.
\endenumerate

@p
function Add(a,b :String ):String;
label ex; var r : String;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'Add(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if (a[1]='-') and (b[1]='-') then begin r:='-'+_Add(abs(a),abs(b)); if r='-0' then r:='0'; goto ex; end;
   if (a[1]<>'-') and (b[1]<>'-') then begin r:=_Add(a,b); goto ex; @+ end;
   if (a[1]='-') and (b[1]<>'-') then
      if gt(abs(a),b) then begin r:='-'+_Sub(abs(a),b); if r='-0' then r:='0'; goto ex; end
      else begin r:=_Sub(abs(a),b); goto ex; @+ end;
   if (a[1]<>'-') and (b[1]='-') then
      if gt(abs(b),a) then begin r:='-'+_Sub(abs(b),a); if r='-0' then r:='0'; goto ex; end
      else begin r:=_Sub(abs(b),a); goto ex; @+ end;
   ex:
      Add:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End Add:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Subtraction.} Now, given two arbitrary precision integers, we
can compute their difference. Again, \&{goto} \\{ex} obfuscates the flow
here, but the basic logic is:
\enumerate
\item If $a<0$ and $b\geq0$, then $a-b=-(\abs{a}+b)$
\item Else if $a\geq0$ and $b<0$, then $a-b=a+\abs{b}$
\item Else if $a<0$ and $b<0$, then we have two cases
\itemitem{(i)} If $\abs{a}>\abs{b}$, then $a-b=-(\abs{a}-\abs{b})$
\itemitem{(ii)} Otherwise $\abs{a}\leq\abs{b}$, so $a-b=\abs{a}-\abs{b}$
\item Else if $a\geq0$ and $b\geq0$, then we have two cases
\itemitem{(i)} If $b>a$, then $a-b=-(b-a)$
\itemitem{(ii)} Otherwise compute $a-b$ using \\{\_Sub(a,b)}
\endenumerate

\medbreak\noindent Testing if $x<0$ is done by checking $\sgn(x)=-1$, and
$x\geq0$ tests if $\sgn(x)\neq-1$.

@p
function Sub(a,b :String ):String;
label ex; var r : String;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'Sub(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if (a[1]='-') and (b[1]<>'-') then
   begin
      r:='-'+_Add(abs(a),b);
      if r='-0' then r:='0';
      goto ex;
   end;
   if (a[1]<>'-') and (b[1]='-') then begin r:=_Add(a,abs(b)); goto ex; @+ end;
   if (a[1]='-') and (b[1]='-') then
      if gt(abs(a),abs(b)) then
      begin
         r:='-'+_Sub(abs(a),abs(b));
         if r='-0' then r:='0';
         goto ex;
      end
      else begin r:=_Sub(abs(a),abs(b)); goto ex; @+ end;
   if (a[1]<>'-') and (b[1]<>'-') then
      if gt(b,a) then
      begin
         r:='-'+_Sub(b,a);
         if r='-0' then r:='0';
         goto ex;
      end
      else begin r:=_Sub(a,b); goto ex; @+ end;
   ex:
      Sub:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End Sub:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Multiplication of arbitrary-precision integers.}
We calculate the product of $a$ with $b$ by handling the case where
$\sgn(a)\neq\sgn(b)$ as $ab=-\abs{a}\cdot\abs{b}$. Otherwise we can
just rely on the \\{\_Mul(a,b)} to do our work.

@p
function Mul(a,b :String ):String;
label ex; var r : String;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'Mul(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if ((a[1]='-') and (b[1]<>'-')) or ((a[1]<>'-') and (b[1]='-')) then
   begin
      r:='-'+_Mul(abs(a),abs(b));
      if r='-0' then r:='0';
   end
   else r:=_Mul(abs(a),abs(b));
   ex:
      Mul:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End Mul:',r); @/
   @{@&$ENDIF@}
end;

@ \node{DivA.} This is the division for arbitrary-precision
integers. Like multiplication, we handle the case $\sgn(a)\neq\sgn(b)$
by computing $a/b = -\abs{a}/\abs{b}$.

@p
function DivA(a,b :String ):String;
label ex; var r : String;
begin
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'DivA(',a,',',b,')'); @/
   @{@&$ENDIF@}
   checkzero(a,b);
   if ((a[1]='-') and (b[1]<>'-')) or ((a[1]<>'-') and (b[1]='-')) then
   begin
      r:='-'+_Div(abs(a),abs(b));
      if r='-0' then r:='0';
   end
   else r:=_Div(abs(a),abs(b));
   ex:
      DivA:=r; @/
   @{@&$IFDEF DEBUGNUM@}
   WriteLn(infofile,'End DivA:',r); @/
   @{@&$ENDIF@}
end;

@ \node{Testing for primality.}
We can test if a given arbitrary-precision integer is prime or not.
Specifically, we restrict attention to \emph{positive} integers.

The \&{while} loop calculates \\{Mul(i,i)} because Fermat observed we only
need to check numbers \emph{up to} $\lceil\sqrt{x}\rceil$ as prime
factors of $x$. But this calulation is a bit costly. This could be
approximated by taking the length of the underlying String $n=\abs{s}$
and looking at the leading $\lceil n/2\rceil$ digits $s_{\rm lead}$.
It's not hard to see that the number $x_{\rm lead}$ described
by $s_{\rm lead}$ satisfies $x_{\rm lead}^{2}\geq x$.

@p
function IsPrime(a: String): boolean;
var i: String;
r: boolean;
begin
   if leq('2',a) then 
   begin
      r:=true;
      i:='2';
      while leq(Mul(i,i),a) do
      begin
         if GCD(a,i)=i then
         begin
            r:=false;
            break; @+
         end;
         i:=Add(i,'1');
      end;
   end
   else r:=false;
   IsPrime:=r;
end;

@ \node{Divides relation.}
We can check if ``$x$ divides $y$'' by testing if $\gcd(x,y)=\abs{x}$.

@p
function Divides(a,b: String): boolean;
var r: boolean;
begin
    r:=GCD(a,b)=abs(a);
    Divides:=r;
end;

@ \node{Rational arithmetic.} Now we begin the rational arithmetic
``in earnest''. The first thing to do is provide a way to compute the
reduced form for a fraction, i.e.,
$$\frac{n}{d} = \frac{n/\gcd(n,d)}{d/\gcd(n,d)}$$

@<Arbitrary-precision rational arithmetic@>=
procedure RationalReduce(var r: Rational);
var lGcd:String;
begin
   lGcd := gcd(r.Num,r.Den);
   r.Num := diva(r.Num,lGcd);
   r.Den := diva(r.Den,lGcd);
end;

@ \node{Rational addition.}
We recall
$$ \frac{a}{b} + \frac{c}{d} = \frac{ad+bc}{bd} $$

@p
function RationalAdd(const r1,r2: Rational): Rational;
var lRes: Rational;
begin
   lRes.Num := Add(Mul(r1.Num,r2.Den),Mul(r1.Den,r2.Num));
   lRes.Den := Mul(r1.Den,r2.Den);
   RationalReduce(lRes);
   RationalAdd:=lRes;
end;

@ \node{Rational subtraction.} Similar to addition, but the numerator
is $ad-bc$.

@p
function RationalSub(const r1,r2: Rational): Rational;
var lRes: Rational;
begin
   lRes.Num := Sub(Mul(r1.Num,r2.Den),Mul(r1.Den,r2.Num));
   lRes.Den := Mul(r1.Den,r2.Den);
   RationalReduce(lRes);
   RationalSub:= lRes;
end;

@ Negating a rational number amounts to multiplying the numerator by
$-1$.

@p
function RationalNeg(const r1: Rational): Rational;
var lRes: Rational;
begin
   lRes.Num:= Mul('-1',r1.Num);
   lRes.Den:= r1.Den;
   RationalNeg := lRes;
end;

@ \node{Multiplying rational numbers.}
This uses the school-book formula
$$\frac{a}{b}\times\frac{c}{d}=\frac{ac}{bd}$$

@p
function RationalMult(const r1,r2: Rational): Rational;
var lRes: Rational;
begin
   lRes.Num := Mul(r1.Num,r2.Num);
   lRes.Den := Mul(r1.Den,r2.Den);
   RationalReduce(lRes);
   RationalMult:= lRes;
end;

@ \node{Inverting a rational number.}
This is easy, provided the numerator is nonzero. The convention is to
make the numerator carry the sign of the number (so $n/d$ has
$n\in\ZZ$ while $d\in\NN$).

When the rational number \emph{is} zero, we simply take $0^{-1}=0$ (as
is conventional among proof assistants).

@p
function RationalInv(const r: Rational): Rational;
var lRes: Rational;
begin
   if r.Num <> '0' then
   begin
      if le(r.Num,'0') then
         lRes.Num := Mul('-1',r.Den)
      else lRes.Num := r.Den;
      lRes.Den := Abs(r.Num);
   end
   else lRes := RZero;
   RationalInv:= lRes;
end;

@ \node{Dividing rational numbers.}
We see that $r_{1}/r_{2}=r_{1}\times(r_{2}^{-1})$. That's the trick.

@p
function RationalDiv(const r1,r2: Rational): Rational;
begin
   RationalDiv := RationalMult(r1,RationalInv(r2));
end;

@ \node{Equality of rational numbers.}
Two rational numbers $n_{1}/d_{1}$ and $n_{2}/d_{2}$ are equal if
$n_{1}=n_{2}$ and $d_{1}=d_{2}$. This assumes that both rational
numbers are in reduced form.

@p
function RationalEq(const r1,r2: Rational): boolean;
begin
   RationalEq := (r1.Num = r2.Num) and (r1.Den = r2.Den);
end;

@ \node{Testing inequality of rational numbers.}\label{numbers:rationalgt}
We have $n_{1}/d_{1} < n_{2}/d_{2}$ if $n_{1}d_{2}<n_{2}d_{1}$.

Similarly, we have $n_{1}/d_{1}\geq n_{2}/d_{1}$ is just the negation
of $n_{1}/d_{1} < n_{2}/d_{2}$. \textbf{But:} this is misleadingly
called \\{RationalGT} instead of \\{RationalGEQ}.

@p
function RationalLE(const r1,r2: Rational): boolean;
begin
   RationalLE := leq(Mul(r1.Num,r2.Den),Mul(r1.Den,r2.Num));
end;

function RationalGT(const r1,r2: Rational): boolean;
begin
   RationalGT := not RationalLE(r1,r2);
end;

@ \node{Rational complex arbitrary-precision arithmetic.}
We now begin with $\QQ+{\rm i}\QQ\subset\CC$, the subset of
complex-numbers where the real and imaginary parts are rational
numbers.

We want to know when these numbers describe integers (i.e., the
imaginary part is zero and the denominator of the real part is 1) and
natural numbers (i.e., when furthermore the numerator of the real part
is non-negative).

@<Complex-rational arbitrary-precision arithmetic@>=
function IsintegerNumber(const z: RComplex): boolean;
begin
   IsintegerNumber := (z.Im.Num = '0') and (z.Re.Den = '1'); @+
end;@#

function IsNaturalNumber(const z: RComplex): boolean;
begin
   IsNaturalNumber := (z.Im.Num = '0') and (z.Re.Den = '1') and (geq(z.Re.Num,'0')); @+
end;@#

function IsPrimeNumber(const z: RComplex): boolean;
begin
    if IsNaturalNumber(z) and IsPrime(z.Re.Num) then IsPrimeNumber := true
    else IsPrimeNumber := false;
end;

@ \node{Equality of complex numbers.}
This amounts to checking if the real and imaginary parts are equal to
each other as rational numbers.

@p
function AreEqComplex(const z1,z2: RComplex): boolean;
begin
   AreEqComplex := RationalEq(z1.Re,z2.Re) and RationalEq(z1.Im,z2.Im); @+
end;@#

function IsEqWithInt(const z: RComplex; @t\hskip10.3333pc@> n: longint): boolean;
var s : String;
begin
   Str(n,s);
   IsEqWithInt := (z.Im.Num = '0') and (z.Re.Num = s) and (z.Re.Den = '1'); @+
end;

@ \node{``Inequalities''.}\label{numbers:isrationalle}
We ``induce'' the binary relations $<$ and $\geq$
on the subset $\{q+{\rm i}0\mid q\in\QQ\}\subset\CC$.
Again, what we said earlier about \\{RationalGT} being badly named holds
for \\{IsRationalGT} being badly named as well.

@p
function IsRationalLE(const z1,z2 : RComplex): boolean;
begin
   IsRationalLE := (z1.Im.Num = '0') and (z2.Im.Num = '0') and RationalLE(z1.Re,z2.Re); @+
end; @#

function IsRationalGT(const z1,z2 : RComplex): boolean;
begin
   IsRationalGT := (z1.Im.Num = '0') and (z2.Im.Num = '0') and RationalGT(z1.Re,z2.Re); @+
end;

@ \node{Converting integers to complex numbers.} We have a function to
convert an integer $x\in\ZZ$ to be the complex number $(x/1) + {\rm i}(0/1)\in\CC$.

@p
function IntToComplex(x: integer): RComplex;
var lRes:RComplex;
begin
   lRes:=COne;
   lRes.Re.Num:=IntToStr(x);
   IntToComplex:= lRes;
end;

@ \node{Adding complex numbers.}
We compute the sum of $(x_{1}+{\rm i}y_{1})$
and $x_{2} + {\rm i}y_{2}$ to be $(x_{1}+x_{2})+{\rm i}(y_{1}+y_{2})$.

@p
function ComplexAdd(const z1,z2 : RComplex): RComplex;
var lRes:RComplex;
begin
   lRes.Re := RationalAdd(z1.Re,z2.Re);
   lRes.Im := RationalAdd(z1.Im,z2.Im); @/
   @{@&$IFDEF CH_REPORT@}
   CHReport.Out_NumReq3(rqRealAdd, z1, z2, lRes); @/
   @{@&$ENDIF@} 
   ComplexAdd:= lRes;
end;

@ \node{Subtracting complex numbers.}
We find the difference of complex numbers componentwise.

@p
function ComplexSub(const z1,z2: RComplex): RComplex;
var lRes:RComplex;
begin
   lRes.Re := RationalSub(z1.Re,z2.Re);
   lRes.Im := RationalSub(z1.Im,z2.Im); @/
   @{@&$IFDEF CH_REPORT@}
   CHReport.Out_NumReq3(rqRealDiff, z1, z2, lRes); @/
   @{@&$ENDIF@}  
   ComplexSub:= lRes;
end;

@ \node{Negating complex numbers.} We negate a complex number $-z$ by
negating its real and imaginary parts.

@p
function ComplexNeg(const z: RComplex): RComplex;
var lRes:RComplex;
begin
   lRes.Re := RationalNeg(z.Re);
   lRes.Im := RationalNeg(z.Im); @/
   @{@&$IFDEF CH_REPORT@}
   CHReport.Out_NumReq2(rqRealNeg, z, lRes); @/
   @{@&$ENDIF@}  
   ComplexNeg:=lRes;
end;

@ \node{Multiplying complex numbers.}
We use the usual formula
$$(x_{1}+{\rm i}y_{1})(x_{2}+{\rm i}y_{2}) = (x_{1}x_{2}-y_{1}y_{2})+{\rm i}(x_{1}y_{2}+y_{1}x_{2}).$$

@p
function ComplexMult(const z1,z2 : RComplex): RComplex;
var lRes:RComplex;
begin
   if IsEqWithInt(z1, -1) then ComplexMult:= ComplexNeg(z2)
   else if IsEqWithInt(z2, -1) then ComplexMult:= ComplexNeg(z1)
   else
   begin
      lRes.Re := RationalSub(RationalMult(z1.Re,z2.Re),RationalMult(z1.Im,z2.Im));
      lRes.Im := RationalAdd(RationalMult(z1.Re,z2.Im),RationalMult(z1.Im,z2.Re));
      ComplexMult:=lRes; @/
      @{@&$IFDEF CH_REPORT@}
      CHReport.Out_NumReq3(rqRealMult, z1, z2, lRes); @/
      @{@&$ENDIF@}  
   end;
end;

@ \node{Dividing complex numbers.} We recall
$$\frac{x_{1} + {\rm i}y_{1}}{x_{2} + {\rm i}y_{2}} = \frac{(x_{1} + {\rm i}y_{1})(x_{2} - {\rm i}y_{2})}{x_{2}^{2} + y_{2}^{2}}$$
This is the case for nonzero $z_{2}\neq0$. When we try to divide
$z_{1}/0$, we return $0$.

@p
function ComplexDiv(const z1,z2: RComplex) : RComplex;
var lDenom : Rational;
   lRes:RComplex;
begin
   lRes:=CZero;
   with z2 do
      lDenom := RationalAdd(RationalMult(Re,Re),RationalMult(Im,Im));
   if lDenom.Num <> '0' then
   begin @|@/
      lRes.Re := RationalDiv(RationalAdd(RationalMult(z1.Re,z2.Re),
                                         RationalMult(z1.Im,z2.Im)),
                          @t\hskip7.5pc@>   lDenom); @/
      lRes.Im := RationalDiv(RationalSub(RationalMult(z1.Im,z2.Re),
                                         RationalMult(z1.Re,z2.Im)),
                          @t\hskip7.5pc@>   lDenom); @/
      @{@&$IFDEF CH_REPORT@}
      CHReport.Out_NumReq3(rqRealDiv, z1, z2, lRes); @/
      @{@&$ENDIF@}     
   end;
   ComplexDiv:=lRes;
end;

@ \node{Inverting complex numbers.}
We can now calculate $z^{-1}$ as just $1/z$.

@p
function ComplexInv(const z: RComplex): RComplex;
begin
   ComplexInv:=ComplexDiv(COne,z); @+
end;

@ \node{Norm of complex numbers.} The ``norm'' or \emph{modulus} for a
complex number is just the sum of the square of its components (well,
the squareroot of this sum).

@p
function ComplexNorm(const z: RComplex): Rational;
begin
   ComplexNorm:=RationalAdd(RationalMult(Z.Re,Z.Re),RationalMult(Z.Im,Z.Im)); @+
end;

@ \node{Comparison functions.}
The remainder of \texttt{numbers.pas} defines functions which compares
numbers. These must return a value in the set $\{-1,0,+1\}$ as
a \PASCAL/ \\{integer}.

@p
function CompareInt(X1, X2: Longint): integer;
begin
   if X1 = X2 then CompareInt := 0
   else if X1 > X2 then CompareInt := 1
   else CompareInt := -1;
end; @#

function CompareIntStr(X1, X2: String): integer;
begin
   if X1 = X2 then CompareIntStr := 0
   else if gt(X1,X2) then CompareIntStr := 1
   else CompareIntStr := -1;
end;

@ There is also a function to ``compare'' complex numbers. This treats
a complex number
$$ z = \frac{n_{1}}{d_{1}} + {\rm i}\frac{n_{2}}{d_{2}}$$
as a tuple $(n_{1},d_{1},n_{2},d_{2})$ then uses lexicographic
ordering based on the components.

@p
function CompareComplex(const z1,z2: RComplex): integer;
var lInt: integer;
begin
   lInt:=CompareIntStr(z1.Re.Num,z2.Re.Num);
   if lInt <> 0 then begin CompareComplex:=lInt; exit @+ end;
   lInt:=CompareIntStr(z1.Re.Den,z2.Re.Den);
   if lInt <> 0 then begin CompareComplex:=lInt; exit @+ end;
   lInt:=CompareIntStr(z1.Im.Num,z2.Im.Num);
   if lInt <> 0 then begin CompareComplex:=lInt; exit @+ end;
   CompareComplex:=CompareIntStr(z1.Im.Den,z2.Im.Den);
end;

@* [F] Mizar Objects and Data Structures.
This is one of the largest files in Mizar (it clocks in at 6594 lines
of code). Its interface consists of 552 lines alone (roughly 1/13 of
the file).
\def\keepgtitle{\gtitle={Mizar Objects and Data Structures}}

@<mobjects.pas@>=
  @<GNU License@>

unit mobjects;

interface @|@#
uses numbers; @|@#
@<Public interface for \texttt{mobjects.pas}@>@;

implementation @|@#

mdebug
  uses info;
end_mdebug@; @#

@<Implementation for \texttt{mobjects.pas}@>@;

end;

@ We have an error method for situations when a method is not
implemented, for example when there is no ordering operator when the
user invokes \\{MSortedCollection.Compare} (\section\xref{MSortedCollection.Compare}).

\label{Abstract1}

@<Implementation for \texttt{mobjects.pas}@>=
procedure Abstract1;
begin
  RunError(211);
end; @#

@<|MObject| implementation@>@;

@<|MStrObj| implementation@>@;

@<|MList| implementation@>@;

@<|MCollection| implementation@>@;

@<|MExtList| implementation@>@;

@<|MSortedList| implementation@>@;

@<|MSortedExtList| implementation@>@;

@<|MSortedStrList| implementation@>@;

@<|MSortedCollection| implementation@>@;

@<String collection implementation@>@;

@<|MIntCollection| implementation@>@;

@<Stacked object implementation@>@;

@<String list implementation@>@;

@<Int relation implementation@>@;

@<Partial integer function implementation@>@;

@<|NatFunc| implementation@>@;

@<NatSeq implementation@>@;

@<|IntSequence| implementation@>@;

@<|IntSet| Implementation@>@;

@<Partial Binary integer Functions@>@;

@<Partial integers to Pair of integers Functions@>@;

@ \node{Constant parameters.}

@<Public interface for \texttt{mobjects.pas}@>=
const

{Maximum MCollection size}
  @! MaxSize = 2000000; @/
  @! MaxCollectionSize = MaxSize div SizeOf(Pointer); @/

{Maximum MStringList size}
  @! MaxListSize = MaxSize  div (SizeOf(Pointer)*2); @/

{Maximum IntegerList size}
  @! MaxIntegerListSize = MaxSize  div (SizeOf(integer)); @/

{MCollection error codes}
  @! coIndexError = -1;              {Index out of range}
  @! coOverflow   = -2;              {Overflow}
  @! coConsistentError = -3; @/
  @! coDuplicate   = -5;             {Duplicate}
  @! coSortedListError = -6; @/
  @! coIndexExtError = -7;

@ \node{Type aliases.}

@<Public interface for \texttt{mobjects.pas}@>=
type @/

{String pointers}
  @! PString = ^ShortString; @/

{Character set type}
  @! PCharSet = ^TCharSet; @/
  @! TCharSet = set of char; @/

@t\hfil@> {General arrays}
  @! PByteArray = ^TByteArray; @/
  @! TByteArray = array[0..32767] of byte; {$32767=2^{15}-1$} @#

  @! PWordArray = ^TWordArray; @/
  @! TWordArray = array[0..16383] of word; {$16383=2^{14}-1$}

@* [S] Base object.
Object-oriented \PASCAL/ is a bit crufty (like
all Object-oriented \ALGOL/-descended languages).

The base \\{MObject} ``class'' has a constructor, destructor, a clone
function named \\{CopyObject}, and a ``move'' function called \\{MCopy}.

\label{MObject:class}

@<Public interface for \texttt{mobjects.pas}@>=
{MObject base object}

  @! PObject = ^MObject; @/
  @! ObjectPtr = PObject; @/
  @! MObject = object @t\1@> @| @/
    constructor @? Init;  @t\2@>
    procedure @? Free; @t\2@>
    destructor @? Done; virtual; @t\2@>
    function @? CopyObject: PObject; @t\2@>
    function @? MCopy: PObject; virtual;  @t\2\2\2@>
  end;

@ Note that the \\{VER70} conditional compilation only plays a role
here, in \\{MObject.Init}.

The constructor will initialize the memory allocated for the \\{MObject}
to be zero.

\label{MObject.Init}

@<|MObject| implementation@>=
{MObject}

constructor MObject.Init; @|@/
@{@&$IFDEF VER70@}
type Image = record Link: word; Data: record @+ end; end; @/
@{@&$ENDIF@}
begin @|@/
@{@&$IFDEF VER70@}
   FillChar(Image(Self).Data, SizeOf(Self) - SizeOf(MObject), 0); @/
@{@&$ENDIF@}
end; @#

@ \node{Destructor.}
The \\{MObject.Free} procdure frees all the memory allocated to the
caller.

The destructor is, well, what \CPLUSPLUS/ programmers would call an
``abstract method''.

@p
procedure MObject.Free;
begin
   Dispose(PObject(@@Self), Done); @+
end; @#

destructor MObject.Done;
begin
end; @#

@ Copying an object allocates new memory using the Free \PASCAL/
\\{GetMem} function, then \emph{moves} the contents of the caller to the
new region. It \textbf{does not} ``copy'' the contents of the caller
to the new region. If we wanted to copy the contents of the caller, we
should call something like \\{Fillchar} or \\{Fillword}.

It then returns a pointer to the newly allocated object.
\label{MObject.CopyObject} 

@p

function MObject.CopyObject: PObject;
var lObject:PObject;
begin
   GetMem(lObject,SizeOf(Self));
   Move(Self,lObject^,SizeOf(Self));
   CopyObject:=lObject;
end; @#

@ The virtual method for copying Mizar objects
can be overridden by subclasses. But the default method is just \\{CopyObject}.
\label{MObject.MCopy} 

@p
function MObject.MCopy: PObject;
begin
   MCopy:=CopyObject; @+
end;

@* [S] Mizar String Object. 
Strings in Mizar amount to a wrapper around the underlying string data type.

\label{MStrObj}

@<Public interface for \texttt{mobjects.pas}@>=
{Specyfic objects based on MObjects for collections} 
 @! PStr = ^MStrObj; @/
 @! MStrPtr = PStr; @/
 @! MStrObj = object(MObject) @t\1@> @/
     fStr: String;
    constructor @? Init(const aStr: String); @t\2\2\2@>
 end;

@ \node{Constructor.}
The constructor for a string object expects a string, and simply
initializes its contents to the given string.

@<|MStrObj| implementation@>=
{Specyfic objects based on MObjects for collections}

constructor MStrObj.Init(const aStr: String);
begin
   fStr:=aStr; @+
end;

@* [S] Mizar List.
A \\{MList} is a dynamic array data structure, which represents a list
using an array. We reserve an array whose length is referred to as
its \define{Capacity} in the literature.

Not all of the underlying array is used by the user.
The number of entries which are used by the dynamic array contents is
referred to as its \define{Logical Size} (or just its \emph{Size})
in the literature.

When the dynamic array is filled, it ``grows''; i.e., it allocates a
new array that's larger, and copies over the contents of its old
array, then frees the old array. The growth factor is controlled by
the \\{GrowLimit}(\\{oldSize}) value.

@ \node{Review of pointers in Pascal.}
We have a few parameters needed for
collections. Remember, if $T$ is a type, then $\^T$ is the type of
pointers to $T$ objects. If we want to have a pointer without
referring to the \emph{type} of the object referenced, we can use
\\{Pointer}.

The @@ operator is the ``address of'' operator. When
setting a pointer $p$ to point to something \\{Foo}, we have
$p\K@@\\{Foo}$.

The $\^$ operator is the ``dereferencing'' operator which is appended
to a pointer identifier.
When we want to update the object referenced by a pointer $p$, we have
$p\^\K\\{newValue}$.

@^Address of@>
@^Dereferencing@>
@^Pointer@> 

@<Public interface for \texttt{mobjects.pas}@>=
{MCollection types}

  @! PItemList = ^MItemList; @/
  @! MItemList = array[0..MaxCollectionSize - 1] of Pointer;

@ A |MList| object is known as a dynamic array. @^Dynamic Array@>
Java programmers would know thas as an ArrayList.

@<Public interface for \texttt{mobjects.pas}@>=
{MList object}

  @! PList = ^MList; @/
  @! MListPtr = PList; @/
  @! MList = object(MObject) @t\1@> @/
     Items: PItemList; {Contents of dynamic array}
     Count: integer; {Logical size of dynamic array}
     Limit: integer; {Capacity of dynamic array}
     constructor @? Init(ALimit: integer); @t\2@>
     constructor @? MoveList(var aAnother: MList); @t\2@>
     constructor @? CopyList(var aAnother: MList); @t\2@>
     destructor @? Done; virtual; @t\2@>
     function @? MCopy: PObject; virtual; @t\2@> @#
     
     procedure @? ListError(aCode, aInfo: integer); virtual; @t\2@> @#
     
     function @? At(Index: integer): Pointer; @t\2@>
     function @? Last: Pointer; @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     procedure @? AtInsert(aIndex: integer; aItem: Pointer); virtual; @t\2@>
     procedure @? InsertList(var aAnother: MList); virtual; @t\2@>
     function @? GetObject(aIndex: integer): Pointer; virtual; @t\2@>
     function @? IndexOf(aItem: Pointer): integer; virtual; @t\2@>
     procedure @? DeleteAll; virtual; @t\2@>
     procedure @? FreeItem(Item: Pointer); virtual; @t\2@>
     procedure @? FreeAll; virtual; @t\2@>
     procedure @? FreeItemsFrom(aIndex:integer); virtual; @t\2@>
     procedure @? Pack; virtual; @t\2@>
     procedure @? SetLimit(ALimit: integer); virtual; @t\2@> @#
     
     procedure @? AppendTo(var fAnother:MList); virtual; @t\2@>
     procedure @? TransferItems(var fAnother:MList); virtual; @t\2@>
     procedure @? CopyItems(var fOrigin:MList); virtual; @t\2\2\2@>
  end;

@ \node{Growth factor.}
How quickly an Dynamic Array grows is a subject of debate. Just for a
table of the growth factors:\label{growth-factor}

\smallbreak%
\centerline{
\vbox{\tabskip=0pt \offinterlineskip
\def\tablerule{\noalign{\hrule}}
\halign{\strut#& \vrule#\tabskip=1em plus2em&
\hfil#& \vrule#& \hfil#\hfil& \vrule#\tabskip=0pt\cr%
\tablerule
&&\omit\hidewidth Implementation\hidewidth&&
\omit\hidewidth Growth Factor\hidewidth&\cr\tablerule
&&Java's ArrayList && $3/2=1.5$&\cr
&&Microsoft's Visual \Cpp && $3/2=1.5$&\cr
&&Facebook folly/FBVector && $3/2=1.5$&\cr%
\tablerule
&&Unreal Engine's TArray && $n+((3n)\gg3)\sim 1.375$&\cr%
\tablerule
&&Python PyListObject && $n+(n\gg3)\sim1.125$&\cr%
\tablerule
&&Go slices && between $1.25$ and $2$&\cr%
\tablerule
&&Gnu \Cpp && 2&\cr
&&Clang && 2&\cr
&&Rust's Vec && $2$&\cr
&&Nim sequences && $2$&\cr
&&SBCL vectors && $2$&\cr
&&\CSHARP/ && $2$&\cr\tablerule
}}}
\smallbreak\noindent%
The |MList| uses a staggered growth factor, specifically something
like $s(n)\gets s(n) + \\{GrowLimit}\bigl(s(n)\bigr)$. The sequence of
Dynamic Array size would be:
$$s(n)=(0, 4, 8, 12, 28, 44, 60, 76,\dots)$$
followed by $s(n+1)\gets (5/4)s(n)$. I am not sure this is optimal, but I have
no better solution.

\CAUTION/: If the memory allocator uses a first-fit allocation, then
growth factors like $\alpha\geq2$ can cause dynamic array expansion to
run out of memory even though a significant amount of memory may still
be available. For a discussion about this point, see:
\item{$\bullet$} \pdfURL{{\tt http://www.gahcep.com/cpp-internals-stl-vector-part-1/}}{https://web.archive.org/web/20150806162750/http://www.gahcep.com/cpp-internals-stl-vector-part-1/}\par\noindent%
It seems that a growth factor $\alpha\leq\varphi=(1+\sqrt{5})/2$ must
be not bigger than the golden ratio. To see this, we need a dyanmic
array of size $S$ to have its first growth to allocate $\alpha S$,
then frees up the $S$ bytes from the pre-growth allocation. The second
allocation needs $\alpha^{2}S$ bytes. Observe the first two
allocations requires $S+\alpha S$ bytes available. Now suppose we want
this to be able to fit into the newly freed space,
$$ \alpha^{2}S\leq S + \alpha S $$
which means
$$ \alpha^{2} - \alpha + 1\leq 0$$
or (requiring $\alpha>0$)
$$ \alpha\leq\varphi=\frac{1+\sqrt{5}}{2}.$$
When this fails to hold, a first-fit allocation could run out of memory.

@<|MList| implementation@>=
{Simple Collection}

function GrowLimit(aLimit: integer): integer;
begin
   GrowLimit:=4;
   if aLimit > 64 then GrowLimit := aLimit div 4
   else if aLimit > 8 then GrowLimit := 16;
end;

@ \node{Constructor.} The constructor creates an empty list.
@!@:MList.Init}{\\{MList.Init}@>

@p
constructor @? MList.Init(aLimit: integer);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   SetLimit(aLimit); @+
end;

@ Moving a list into the caller.
@!@:MList.MoveList}{\\{MList.MoveList}@>

@p
constructor @? MList.MoveList(var aAnother:MList);
begin
   MObject.Init; @/
   Count := aAnother.Count;
   Limit := aAnother.Limit;
   Items := aAnother.Items; {move} @/
   aAnother.DeleteAll;
   aAnother.Limit:=0;
   aAnother.Items:=nil; {delete |aAnother|}
end;

@ Copying the contents of |aAnother| list into the current list will
essentially reinitialize the current list, the insert all items from
the other list into the current list.
@!@:MList.CopyList}{\\{MList.CopyList}@>

@p
constructor @? MList.CopyList(var aAnother:MList);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0; {initialize}
   SetLimit(aAnother.Limit);
   InsertList(aAnother);
end;

@ A list is ``done'' frees all items in the list, sets the limit to
zero, and then invokes the superclass's |Done| method.
@!@:MList.Done}{\\{MList.Done}@>

@p
destructor @? MList.Done;
begin
   FreeAll;
   SetLimit(0);
   inherited Done; @+
end;

@ We override the |MObject.MCopy| method (\section\xref{MObject.MCopy}).
This will copy the base object using |CopyObject|
(\section\xref{MObject.CopyObject}), allocate a new array of pointers, copy
over the contents of the caller, and
then returns the new list.
@!@:MList.MCopy}{\\{MList.MCopy}@>

@p
function @? MList.MCopy: PObject;
var lList: PObject; i: integer;
begin
   lList:=CopyObject;
   GetMem(PList(lList)^.Items, Self.Limit * SizeOf(Pointer));
   for i:=0 to Self.Count-1 do
      PList(lList)^.Items^[i]:=PObject(Self.Items^[i])^.MCopy;
   MCopy:=lList;
end;

@ This is the same as |MList.GetObject| (\section\xref{mlist.getobject}), and I am not sure why we have
two versions of the same function.
@!@:MList.At}{\\{MList.At}@>

@p
function @? MList.At(Index: integer): Pointer;
begin
   if (Index < 0) or (Index >= Count) then
   begin
      ListError(coIndexError,0);
      At :=nil; @+
   end
   else At := Items^[Index];
end;

@ The |MList.Count| tracks the number of allocated
items. So the last item would be located at |MList.Count - 1| (since
we count with zero offset).
@!@:MList.Last}{\\{MList.Last}@>

@p
function @? MList.Last: Pointer;
begin Last:= At(Count - 1); @+ end;

@ Inserting an item into a list requires checking there's enough free
space to the list, then sets the first spot to the item.
@!@:MList.Insert}{\\{MList.Insert}@>

@p
procedure @? MList.Insert(aItem: Pointer);
begin
   if Limit = Count then
      SetLimit(Limit+GrowLimit(Limit));
   Items^[Count] := aItem;
   inc(Count);
end;

@ If we want to insert a pointer \emph{at a specific index}, then we
proceed as follows:
\enumerate
\item Check if the index is negative. If so, then we should flag an
error using |ListError|, and exit.
\item Check if the index is larger than the logical size of the
dynamic array; if so, then we grow the dynamic array using |SetLimit|
\endenumerate

@!@:MList.AtInsert}{\\{MList.AtInsert}@>
@p
procedure @? MList.AtInsert(aIndex: integer; aItem: Pointer);
var i,lLimit: integer;
begin
   if aIndex < 0 then
   begin
      ListError(coIndexError,0);
      exit;
   end;
   if (aIndex >= Limit) or ((aIndex = Count) and (Limit = Count)) then {ensure capacity}
   begin
      lLimit:=Limit+GrowLimit(Limit);
      while aIndex+1 > lLimit do
         lLimit:=lLimit+GrowLimit(lLimit);
      SetLimit(lLimit); {Copy contents}
   end;
   for i:=Count to aIndex-1 do
      Items^[i]:=nil; {fill new entries as |nil|}
   Items^[aIndex]:=aItem; {set the entry at |aIndex| to the pointer}
   if aIndex >= Count then
      Count:=aIndex+1; {update logical size, if necessary}
end;

@ When we insert |aAnother| list into the current list, we simply
iterate through all the other list's items, and insert (a copy of the
pointer to) each one into the current list. This should leave
|aAnother| list unmodified.
@!@:MList.InsertList}{\\{MList.InsertList}@>

@p
procedure @? MList.InsertList(var aAnother: MList);
var i: integer;
begin
   for i:=0 to pred(aAnother.Count) do
      Insert(PObject(aAnother.Items^[i])^.MCopy); 
end;

@ \label{mlist.getobject} Given an index, find the item located there. Well, the pointer to
the object. When the index is illegal (out of bounds or negative),
then flag an error and return |nil|. Otherwise return the pointer
located at the index. @!@:MList.GetObject}{\\{MList.GetObject}@>

@p
function @? MList.GetObject(aIndex: integer): Pointer;
begin
   if (aIndex < 0) or (aIndex >= Count) then
   begin
      ListError(coIndexError,0);
      GetObject :=nil; @+
   end
   else GetObject := Items^[aIndex];
end;

@ We have a default error code for lists. @!@:MList.ListError}{\\{MList.ListError}@>

@p
procedure @? MList.ListError(aCode, aInfo: integer);
begin
   RunError(212 - aCode); @+
end;

@ Looking for the index of an item requires iterating through each
item of the list, until we find the needle in the hay stack. Once
found, we return the index for the needle.

If the needle is not in the haystack, return
$-1$. @!@:MList.IndexOf}{\\{MList.ListError}@>

@p
function @? MList.IndexOf(aItem: Pointer): integer;
var i : integer;
begin
   IndexOf := -1;
   for i := 0 to pred(Count) do
      if aItem = Items^[i] then
      begin
         IndexOf := i;
         break @+
      end
end;

@ Deleting all items from a list simply updates the list's logical
size (i.e., |Count|) to zero.
This will not alter the underlying array allocated for the dynamic array.
@!@:MList.DeleteAll}{\\{MList.DeleteAll}@>

@p
procedure @? MList.DeleteAll;
begin
   Count := 0; @+
end;

@ Freeing a single item will invoke \PASCAL/'s primitive |Dispose|
function (which frees up the memory in heap). This is a helper
function to avoid accidentally invoking |Dispose(PObject(nil), Done)|
which would throw errors.
@!@:Mlist.FreeItem}{\\{Mlist.FreeItem}@>

@p
procedure @? MList.FreeItem(Item: Pointer);
begin
   if Item <> nil then Dispose(PObject(Item), Done); @+
end;

@ We delegate all the heavy work of |FreeAll| to |FreeItemsFrom|.
@!@:MList.FreeAll}{\\{MList.FreeAll}@>

@p
procedure @? MList.FreeAll;
begin
   FreeItemsFrom(0); @+
end;

@ We can itereate through a list from a start index, freeing the rest
of the list starting from |aIndex|. Remember, the data structure for
|MList| consists of an |MObject| extended with its capacity, logical
size, and a \emph{pointer} to the array on the heap. When freeing an
item from the array, we dereference the pointer to look up item \\{I}
in the array.
@!@:MList.FreeItemsFrom}{\\{MList.FreeItemsFrom}@>

@p
procedure @? MList.FreeItemsFrom(aIndex:integer);
var I:integer;
begin
   for I:=Count-1 downto aIndex do FreeItem(Items^[I]);
   Count:=aIndex;
end;

@ If an item has become |nil| in the list, we should shift the rest of
the list down. Basically, in Lisp, if \texttt{null (cadr l)},
then \texttt{setf l (cdr l)}.

Care must be taken to iterate over the items in the list. Shifting
items down by one item requires iterating over $k$ from $i$ to
$\\{Count}-2$ (because the maximum index is $\\{Count}-1$ due to zero
offset indexing).

Once we have shifted everything down, we decrement the logical size of
the dynamic array.
@!@:MList.Pack}{\\{MList.Pack}@>

@p
procedure @? MList.Pack;
var i,k: integer;
begin
   for i := Count-1 downto 0 do
      if Items^[i] = nil then
      begin
         for k:=i to Count-2 do Items^[k]:=Items^[k+1];
         dec(Count);
      end;
end;

@ Growing a list handles a few edgecases:\label{MList.SetLimit}
\enumerate
\item If the new limit is \emph{smaller} than the existing limit,
then just set the new limit equal to the existing limit.
\item If the new limit is \emph{larger} than the maximum limit,
then just set the new limit equal to the maximum limit.
\item If the new limit is not equal to the existing limit, then we
have the ``standard situation''.
\itemitem{(i)} When the new limit is zero, simply set the pointer to
the item list to |nil|
\itemitem{(ii)} Otherwise (for a new limit which is a nonzero number),
allocate a new chunk of memory for the number of pointers needed, then
move them. Be sure to free up the pointers, and update the variables.
\endenumerate

@!@:MList.SetLimit}{\\{MList.SetLimit}@>

@p
procedure @? MList.SetLimit(ALimit: integer);
var lItems: PItemList;
begin
   if ALimit < Count then ALimit := Count;
   if ALimit > MaxCollectionSize then ALimit := MaxCollectionSize;
   if ALimit <> Limit then
   begin
      if ALimit = 0 then lItems := nil else
      begin
         GetMem(lItems, ALimit * SizeOf(Pointer));
         if ((Count) <> 0) and (Items <> nil) then
            Move(Items^, lItems^, Count*SizeOf(Pointer));
      end;
      if Limit <> 0 then FreeMem(Items, Limit*SizeOf(Pointer));
      Items := lItems;
      Limit := ALimit;
   end;
end;

@ Appending another list to the current list will expand the current
list to support the new items, insert the other list's items at the
end of the current list, and then free the other list from memory.
@!@:MList.AppendTo}{\\{MList.AppendTo}@>

@p
procedure @? MList.AppendTo(var fAnother:MList);
var k:integer;
begin
   SetLimit(Count+fAnother.Count);
   for k:=0 to fAnother.Count-1 do Insert(fAnother.Items^[k]);
   fAnother.DeleteAll; fAnother.Done;
end;

@ There is a comment in Polish at the beginning of this function stating ``Przeznaczeniem tej procedury jest uzycie jej w konstruktorach Move, ktore wykonuja jakgdyby pelna instrukcje przypisania (razem z VMTP)''
which Google translates as ``The purpose of this procedure is to be used in Move constructors, which execute a full assignment statement (including VMTP).''

There is also another comment in Polish, ``Nie wolno uzyc SetLimit, bo
rozdysponuje Items'' which I translated into English and kept inline
(``You cannot use SetLimit because it will distribute the Items'').

The semantics of |Object := Object| will \emph{copy} the right-hand
side to the left-hand side.

@!@:MList.TransferItems}{\\{MList.TransferItems}@>

@p
procedure @? MList.TransferItems(var fAnother:MList);
begin
   Self:=fAnother; {copy contents of |fAnother| over to |Self|}
   fAnother.DeleteAll;
   fAnother.Limit:=0; fAnother.Items:=nil;
   {You cannot use |SetLimit| because it will distribute the Items.}
end;

@ Copying items from a list simply loops through the original list,
inserting them into the caller.
@!@:MList.CopyItems}{\\{MList.CopyItems}@>

@p
procedure @? MList.CopyItems(var fOrigin:MList);
var i:integer;
begin
   for i:=0 to fOrigin.Count-1 do
      Insert(PObject(fOrigin.Items^[i])^.CopyObject);
end;

@* [S] Mizar Collection Class.
Curiously, the ``Collection'' class extends the ``List'' class, which
surprises me. This will change the growth rate from $s(n+1)=s(n)+\\{GrowLimit}(s(n))$
to be
$$s(n+1)=s(n)+\\{GrowLimit}\bigl(\Delta+s(n)\bigr)$$
where $\Delta\geq0$ is a field of the Collection object. When we move
an |MList| into an |MCollection|, we have |Delta := 2| be the default value.

@<Public interface for \texttt{mobjects.pas}@>=
{MCollection object}

  @! PCollection = ^MCollection; @/
  @! MCollection = object(MList) @t\1@> @/
     Delta: integer;
     constructor @? Init(ALimit, ADelta: integer);  @t\2@>
     destructor @? Done; virtual; @t\2@> @# 

     procedure @? AtDelete(Index: integer); @t\2@>
     procedure @? AtFree(Index: integer); @t\2@>
     procedure @? AtInsert(Index: integer; Item: Pointer); virtual; @t\2@>
     procedure @? AtPut(Index: integer; Item: Pointer); @t\2@>
     procedure @? Delete(Item: Pointer); @t\2@>
     procedure @? Free(Item: Pointer); @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     procedure @? Pack; virtual; @t\2@> @#
     
     constructor @? MoveCollection(var fAnother:MCollection); @t\2@>
     constructor @? MoveList(var aAnother:MList); @t\2@>
     constructor @? CopyList(var aAnother: MList); @t\2@>
     constructor @? CopyCollection(var AAnother:MCollection); @t\2@>
     constructor @? Singleton(fSing:PObject; fDelta:integer); @t\2@> @#

     procedure @? Prune; virtual; @t\2\2\2@>
  end;


@ \node{Constructor.} When constructing a new Collection, we allocate
an array of the desired limit (using the |SetLimit| (\section\xref{MList.SetLimit}) to handle this allocation).

@<|MCollection| implementation@>=
{MCollection}

constructor MCollection.Init(ALimit, ADelta: integer);
begin
  MObject.Init;
  Items := nil;
  Count := 0;
  Limit := 0;
  Delta := ADelta;
  SetLimit(ALimit);
end;

destructor MCollection.Done;
begin
  FreeAll;
  SetLimit(0);
end;

@ When trying to delete an element at |Index|, we first check if the
|Index| is within the bounds of the collection. If it's out of bounds,
we invoke |ListError| and exit the function.

Otherwise, we shift everything in the collection down by one position.

@p
procedure MCollection.AtDelete(Index: integer);
 var i: integer;
begin
   if (Index < 0) or (Index >= Count) then
   begin
      ListError(coIndexError,0);
      exit; @+
   end;
   if Index < pred(Count) then
     for i:=Index to Count-2 do Items^[i]:=Items^[i+1];
   Dec(Count);
end;

@ If we want to also \emph{free} an object in a collection, we store
it in a temporary variable, then invoke |AtDelete(Index)| to update
the collection, and finally |Free| the item.

@p
procedure MCollection.AtFree(Index: integer);
var lItem: Pointer;
begin
  lItem := At(Index);
  AtDelete(Index);
  FreeItem(lItem); @+
end;

@ Inserting an item at an |Index|, we first need to check if the
position is within the bounds of the collection. If it's out of
bounds, then flag a |ListError| and exit the function.

Otherwise, we check if the collection is at capacity (|Limit = Count|).
If so, we try to expand the collection by |Delta| items. When |Delta|
is zero, then raise an error and exit.

Now we are at the ``default'' case. Simply shift items starting at
|Index| up by one. Then set the item at |Index| to be the new |Item|,
and increment the count of the collection.

@p
procedure MCollection.AtInsert(Index: integer; Item: Pointer);
begin
  if (Index < 0) or ( Index > Count) then
   begin
      ListError(coIndexError,0);
      exit; @+
   end;
  if Limit = Count then
   begin
    if Delta = 0 then
     begin
        ListError(coOverFlow,0);
        exit; @+
     end;
     SetLimit( Limit+Delta);
   end;
  if Index <> Count then 
      Move(Items^[Index], Items^[Index+1], (Count - Index)*SizeOf(pointer));
  Items^[Index] := Item;
  inc(Count);
end;

@ \node{Overwrite contents at index.} We can insert a new item at a
given index without shifting the collection.

@p
procedure MCollection.AtPut(Index: integer; Item: Pointer);
begin
   if (Index < 0) or (Index >= Count) then
     ListError(coIndexError,0)
   else Items^[Index] := Item;
end;

@ Deleting an item finds the index of the item, then invokes
|AtDelete| on that index.

@p
procedure MCollection.Delete(Item: Pointer);
begin
  AtDelete(IndexOf(Item)); @+
end;

@ Similarly, freeing an item is just |Delete|-ing the item, then
calling |FreeItem| on the pointer.

@p
procedure MCollection.Free(Item: Pointer);
begin
  Delete(Item);
  FreeItem(Item); @+
end;

@ Inserting an item at the end of the collection.

@p
procedure MCollection.Insert(aItem: Pointer);
begin
  AtInsert(Count, aItem); @+
end;

@ We can also ``fit'' the collection by deleting all |nil| elements.

@p
procedure MCollection.Pack;
 var i: integer;
begin
  for i := pred(Count) downto 0 do
   if Items^[i] = nil then AtDelete(i);
end;

@ Move semantics for creating a new collection.

@p
constructor MCollection.MoveCollection(var fAnother:MCollection);
begin
 Init(0,fAnother.Delta);
 TransferItems(fAnother) @+
end;

@ Cloning a collection will simply create an empty collection, the
loop through |AAnother| inserting each item from the original
collection into the newly minted collection.

@p
constructor MCollection.CopyCollection(var AAnother:MCollection);
var i: integer;
begin
   Init(AAnother.Limit,AAnother.Delta);
   for i:=0 to AAnother.Count-1 do
      Insert(aAnother.Items^[i]);
end;

@ A singleton allocates as little as possible.

@p
constructor MCollection.Singleton(fSing:PObject; fDelta:integer);
begin Init(2,fDelta); Insert(fSing) @+ end;

@ Pruning a collection merely sets its limits to zero. It does not
free the contents of the collection.

@p
procedure MCollection.Prune;
begin SetLimit(0) @+ end;

@ Moving an |MList| uses \PASCAL/'s inheritance semantics to invoke
|MList.MoveList| and then sets the |Delta| to 2.

@p
constructor MCollection.MoveList(var aAnother:MList);
begin
   inherited MoveList(aAnother);
   Delta := 2;
end;

@ Copying a list invokes |MList.CopyList| on the collection, then sets
|Delta := 2|.

@p
constructor MCollection.CopyList(var aAnother:MList);
begin
   inherited CopyList(aAnother);
   Delta := 2; @+
end;


@* [S] Simple Stacked (Extendible) Lists.
This is used to track newly registered clusters in Mizar.

The basic idea is that we partition the array into the first $N$
entries, then the remaining $k$ entries. The last $k$ entries are the
``extendible'' entries.

We will eventually ``digest'' the extendible entries (by incrementing
$N\gets N+1$ and decrementing $k\gets k-1$ until $k=0$).

@<Public interface for \texttt{mobjects.pas}@>=
{MExtList object}

@!  MExtListPtr = ^MExtList; @/
@!  MExtList = object(MList)  @t\1@> @/
     fExtCount: integer; 
     constructor @? Init(aLimit: integer); @t\2@>
     destructor @? Done; virtual; @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     procedure @? Mark(var aIndex: integer); virtual; @t\2@>
     procedure @? FreeItemsFrom(aIndex:integer); virtual; @t\2@>
     procedure @? DeleteAll; virtual; @t\2@>
     procedure @? FreeAll; virtual; @t\2@>
     procedure @? Pack; virtual; @t\2@>
     procedure @? InsertExt(AItem: Pointer); virtual; @t\2@>
     procedure @? SetLimit(ALimit: integer); virtual; @t\2@>
     procedure @? AddExtObject; virtual; @t\2@>
     procedure @? AddExtItems; virtual; @t\2@>
     procedure @? DeleteExtItems; @t\2@>
     procedure @? FreeExtItems; @t\2\2\2@>
  end;

@ \node{Simple Stacked (Extendable) Collection.}
@!@:MExtList.Init}{\\{MExtList.Init}@>

@<|MExtList| implementation@>=
constructor @? MExtList.Init(ALimit: integer);
begin
   MObject.Init; @/
   Items := nil; @/
   Count := 0;
   Limit := 0; @/
   SetLimit(ALimit);
   fExtCount:=0;
end;

@ \node{Destructor for \texttt{MExtList}.}
The destructor for |MExtList| invokes \\{self.FreeExtItems} and then
calls the inherited destructor from the superclass.

@!@:MExtList.Done}{\\{MExtList.Done}@>

@p
destructor @? MExtList.Done;
begin
   FreeExtItems;
   inherited Done; @+
end;

@ \node{Inserting an item.} The |fExtCounter| field is unclear to me.
But if it's nonzero, then an error has occurred and we bail out.

Otherwise, we possibly grow the extendible list, and we insert at the
end the given pointer and increment the |Count| of items allocated.

@!@:MExtList.Insert}{\\{MExtList.Insert}@>

@p
procedure @? MExtList.Insert(aItem: Pointer);
begin
   if fExtCount <> 0 then
   begin
      ListError(coIndexExtError,0);
      exit; @+
   end;
   if Limit = Count then
      SetLimit(Limit+GrowLimit(Limit));
   Items^[Count] := aItem; {Append the item to the list}
   inc(Count);
end;
@ \node{Deleting all entries.}
We can only call this when the extendible entries have been
``digested'' into the underlying array (i.e., when |fExtCount = 0|).
Otherwise we need to flag an error. Otherwise, when all the extendible
entries have been ``digested'', we call the parent's |DeleteAll| method.

@!@:MExtList.DeleteAll}{\\{MExtList.DeleteAll}@>

@p
procedure @? MExtList.DeleteAll;
begin
   if fExtCount <> 0 then
   begin
      ListError(coIndexExtError,0);
      exit;
   end;
   inherited DeleteAll;
end;
@ \node{Free all entries.} Like deleting all the entries, we need to
fully digest all the extendible entries before invoking the parent
class's |FreeAll| method. If there are extendible entries not fully
digested, then we get indigestion (i.e., a list error).

@!@:MExtList.FreeAll}{\\{MExtList.FreeAll}@>

@p
procedure @? MExtList.FreeAll;
begin
   if fExtCount <> 0 then
   begin
      ListError(coIndexExtError,0);
      exit;
   end;
   inherited FreeAll;
end;
@ \node{Packing.} When packing an extendible list, we assert the
extendible items have been digested fully. If not, raise an error. If
fully digested, then invoke the parent class's |Pack| method.

@!@:MExtList.Pack}{\\{MExtList.Pack}@>
@p
procedure @? MExtList.Pack;
begin
   if fExtCount <> 0 then
   begin
      ListError(coIndexExtError,0);
      exit;
   end;
   inherited Pack;
end;
@ \node{Insert extendible items.} We can add an extendible item by
first growing the list (if necessary), then adding an item at index
$N+k$. Then increment the number of extendible items $k\gets k+1$.

@!@:MExtList.InsertExt}{\\{MExtList.InsertExt}@>
@p
procedure @? MExtList.InsertExt(AItem: Pointer);
begin
   if Limit = Count+fExtCount then
      SetLimit(Limit+GrowLimit(Limit));
   Items^[Count+fExtCount] := AItem;
   inc(fExtCount);
end;
@ \node{Ensure capacity of extendible list.}
\enumerate
\item When the new limit is less than the logical size $N$ and
the extendible size $k$, we just set the capacity to $N+k$.
\item Else if the new limit is larger than |MaxCollectionSize|, then
just use the maximum collection size as the capacity.
\item Else if the new limit is different than the existing
capacity, then we have to check if the new limit is zero. When it is,
just set the capacity to zero and the list of items to
|nil|. Otherwise, allocate space for a new array, and move over the
contents from the existing array (and then free the existing array).
Update the capacity and pointer to the items.
\endenumerate

@!@:MExtList.SetLimit}{\\{MExtList.SetLimit}@>
@p
procedure @? MExtList.SetLimit(ALimit: integer);
var lItems: PItemList;
begin
   if ALimit < Count+fExtCount then ALimit := Count+fExtCount;
   if ALimit > MaxCollectionSize then ALimit := MaxCollectionSize;
   if ALimit <> Limit then
   begin
      if ALimit = 0 then lItems := nil else
      begin
         GetMem(lItems, ALimit * SizeOf(Pointer));
         if ((Count+fExtCount) <> 0) and (Items <> nil) then
            Move(Items^, lItems^, (Count+fExtCount)*SizeOf(Pointer));
      end;
      if Limit <> 0 then FreeMem(Items, Limit*SizeOf(Pointer));
      Items := lItems;
      Limit := ALimit;
   end;
end;
@ ``Marking'' an extendible list amounts to setting the procedure's
variable to the capacity of the extendible list.

@!@:MExtList.Mark}{\\{MExtList.Mark}@>
@p
procedure @? MExtList.Mark(var aIndex:integer);
begin
   aIndex:=Count;
end;
@ Freeing items starting at a given index requires the extendible
items to be fully digested (if not, raise an error). Then simply free
each object using the virtual destructor |MObject.Done|.

@!@:MExtList.FreeItemsFrom}{\\{MExtList.FreeItemsFrom}@>
@p
procedure @? MExtList.FreeItemsFrom(aIndex:integer);
var I:integer;
begin
   if fExtCount <> 0 then
   begin
      ListError(coIndexExtError,0);
      exit;
   end;
   for I:=Count-1 downto aIndex do
      if Items^[I] <> nil then Dispose(PObject(Items^[I]), Done);
   Count:=aIndex;
end;
@ \node{Digesting one extendible item.}
We can instruct the extendible list to digest exactly one extendible
item. This requires the number of extendible items to be positive $k>0$.
If not, raise an error. Otherwise increment the logical capacity
$N\gets N+1$ and decrement the number of extendible items $k\gets k-1$.

@!@:MExtList.AddExtObject}{\\{MExtList.AddExtObject}@>
@p
procedure @? MExtList.AddExtObject;
begin
   if fExtCount <= 0 then
   begin
      ListError(coIndexExtError,0);
      exit;
   end;
   inc(Count);
   dec(fExtCount);
end;
@ \node{Digest all extendible items.} This simply updates capacity to
be incremented by the number of extendible items. Then the number of
extendible items is set to zero. No error is raised if there are no
extendible items (unlike digesting one single extendible item).

@!@:MExtList.AddExtItems}{\\{MExtList.AddExtItems}@>
@p
procedure @? MExtList.AddExtItems;
begin
   Count:=Count+fExtCount;
   fExtCount:=0;
end;
@ Deleting all extendible items simply sets the \emph{number} of
extendible items to zero. This is a ``soft delete'' which does not
affect anything else on the heap.

@!@:MExtList.DeleteExtItems}{\\{MExtList.DeleteExtItems}@>
@p
procedure @? MExtList.DeleteExtItems;
begin
   fExtCount:=0;
end;
@ Freeing all the extendible items will ``hard delete'' each
extendible item, removing them from the heap.

@!@:MExtList.FreeExtItems}{\\{MExtList.FreeExtItems}@>
@p
procedure @? MExtList.FreeExtItems;
var I: integer;
begin
   for I := 0 to fExtCount-1 do
      if Items^[Count+I] <> nil then Dispose(PObject(Items^[Count+I]), Done);
   fExtCount := 0;
end;

@* [S] Sorted lists.
These are used in the equalizer and in the correlator, specifically
for keeping a collection of identifiers.

A sorted list uses an array of indices (called \\{fIndex}). The array
of indices are sorted according to a comparison of values.

Invariant: $\\{Length}(\\{fIndex})=\\{Length}(\\{Items})$

Invariant (sorted): for each $i=0,\dots,\\{Length}(\\{Items})-2$,
we have $\\{Items}\^[\\{fIndex}\^[i]]\leq\\{Items}\^[\\{fIndex}\^[i+1]]$.

Also, we are taking the convention that $\\{fCompare}(x,y)$ returns
$-1$ when $x<y$; returns $0$ when $x=y$; returns $+1$ when $x>y$.

\label{MSortedList:declarations}

@<Public interface for \texttt{mobjects.pas}@>=
{MSortedList Object}

@!  IndexListPtr = ^MIndexList; @/
@!  MIndexList = array[0..MaxCollectionSize - 1] of integer; @/
@!  CompareProc = @+ function (aItem1, aItem2: Pointer): integer;  @t\2@> @/
  
@!  MSortedList = object(MList) @t\1@> @/
     fIndex: IndexListPtr;
     fCompare: CompareProc;
     constructor @? Init(ALimit: integer); @t\2@>
     constructor @? InitSorted(aLimit: integer; aCompare: CompareProc); @t\2@>
     constructor @? MoveList(var aAnother: MList); @t\2@>
     constructor @? CopyList(const aAnother: MList); @t\2@>
     procedure @? AtInsert(aIndex:integer; aItem: Pointer); virtual; @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     function @? IndexOf(aItem: Pointer): integer; virtual; @t\2@>
     procedure @? Sort(aCompare: CompareProc); @t\2@>
     procedure @? SetLimit(ALimit: integer); virtual; @t\2@>
     function @? Find(aKey: Pointer; var aIndex: integer): boolean; virtual; @t\2@>
     function @? Search(aKey: Pointer; var aIndex: integer): boolean; virtual; @t\2@>
     procedure @? Pack; virtual; @t\2@>
     procedure @? FreeItemsFrom(aIndex:integer); virtual; @t\2\2\2@>
  end;@#
@ \node{Constructors.} There are four constructors:
\enumerate
\item \\{Init} simply creates an empty list with a given capacity.
\item \\{InitSorted} is like \\{Init}, but expects an ordering operator.
\item \\{MoveList} moves all the items from another list into the
     caller, sorting as needed. This will also empty the other list.
\item \\{CopyList} is like \\{MoveList} but leaves the other list untouched.
\endenumerate

\label{MSortedList.InitSorted}

@:MSortedList.Init}{\\{MSortedList.Init}@>
@:MSortedList.InitSorted}{\\{MSortedList.InitSorted}@>
@<|MSortedList| implementation@>=
{MSortedList object}

constructor @? MSortedList.Init(aLimit: integer);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   fIndex:=nil;
   fCompare:=nil;
   SetLimit(ALimit);
end; @#

constructor @? MSortedList.InitSorted(aLimit: integer; aCompare: CompareProc);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   fIndex:=nil;
   fCompare:=aCompare;
   SetLimit(ALimit);
end;
@ \node{Move constructor.}
When we move items from an |MList| into the caller, we also sort as we insert.

@:MSortedList.MoveList}{\\{MSortedList.MoveList}@>
@p
constructor @? MSortedList.MoveList(var aAnother:MList);
var I: integer;
begin
   Items := aAnother.Items;
   Count := aAnother.Count;
   Limit := aAnother.Limit;
   GetMem(fIndex, Limit * SizeOf(integer));
   fCompare:=nil;
   for I:=0 to pred(aAnother.Count) do fIndex^[I]:=I; @/
   {Empty out the other list}
   aAnother.DeleteAll;
   aAnother.Limit:=0; aAnother.Items:=nil;
end;
@ The \\{CopyList} constructor is like the \\{MoveList} \textbf{except}
that the other list is not modified.

@:MSortedList.CopyList}{\\{MSortedList.CopyList}@>
@p
constructor @? MSortedList.CopyList(const aAnother:MList);
var i: integer;
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   fIndex:=nil;
   fCompare:=nil;
   SetLimit(aAnother.Limit);
   Count := aAnother.Count;
   for i:=0 to Count-1 do
   begin
      Items^[i]:=PObject(aAnother.Items^[i])^.MCopy;
      fIndex^[I]:=I;
   end;
end;
@ \node{Insert element at an index.} We can insert (potentially
overwriting an existing entry) at a given index.

@:MSortedList.Z}{\\{MSortedList.Z}@>
@p
{used in CollectCluster not to repeat the search, should
  be used only when |@@fCompare <> nil|}
procedure @? MSortedList.AtInsert(aIndex:integer; aItem: Pointer);
begin
   if Limit = Count then
      SetLimit(Limit+GrowLimit(Limit)); {Ensure capacity}
   if aIndex <> Count then
      Move(fIndex^[aIndex], fIndex^[aIndex+1],(Count-aIndex)*SizeOf(integer));
   Items^[Count] := aItem;
   fIndex^[aIndex] := Count;
   inc(Count);
end;
@ \node{Inserting an item.}
Inserting an item into a sorted list boils down to two cases:
\enumerate
\item If there is an ordering operator, we check if the item is
in the underlying array using |Find|
(\section\xref{MSortedList.Find}), which will mutate the |lIndex| to be where
it should be located. When the item is missing, simply insert it at
|lIndex|. When the item is present, then we do nothing.
\item If there is no ordering operator, then check if the item
already is present in the sorted list. If so, then don't do
annything. Otherwise, insert the item at the start of the list.
\endenumerate

@:MSortedList.Insert}{\\{MSortedList.Insert}@>
@p
procedure @? MSortedList.Insert(aItem: Pointer);
var lIndex: integer;
begin
   if @@fCompare = nil then
   begin
      if Limit = Count then
         SetLimit(Limit+GrowLimit(Limit));
      Items^[Count] := aItem;
      fIndex^[Count] := Count;
      inc(Count);
      exit;
   end;
   if not Find(aItem, lIndex) then
      AtInsert(lIndex,aItem);
end;
@ \node{Resizing a sorted list.}
The invariant is that the list is sorted when it has an ordering
operator (and so restricting to |aLimit| preserves the list being
sorted), and it is a ``set'' when it does not have an ordering (and so
restricting to |aLimit| preserves this property of being a finite set
without duplicate entries).

@:MSortedList.SetLimit}{\\{MSortedList.SetLimit}@>
@p
procedure @? MSortedList.SetLimit(aLimit: integer);
var lItems: PItemList; lIndex: IndexListPtr;
begin
   if aLimit < Count then aLimit := Count;
   if aLimit > MaxCollectionSize then aLimit := MaxCollectionSize;
   if aLimit <> Limit then
   begin
      if aLimit = 0 then
      begin
         lItems:=nil;
         lIndex:=nil; @+
      end
      else
      begin
         GetMem(lItems, aLimit*SizeOf(Pointer));
         GetMem(lIndex, aLimit*SizeOf(integer));
         if Count <> 0 then
         begin
            if Items <> nil then
            begin
               Move(Items^, lItems^, Count*SizeOf(Pointer));
               Move(fIndex^, lIndex^, Count*SizeOf(integer));
            end;
         end;
      end;
      if Limit <> 0 then
      begin
         FreeMem(Items, Limit*SizeOf(Pointer));
         FreeMem(fIndex, Limit*SizeOf(integer));
      end;
      Items := lItems;
      fIndex := lIndex;
      Limit := aLimit;
   end;
end;

@ \node{Quick sort an array.} We have a private helper function for
quicksorting an |IndexListPtr| (\section\xref{MSortedList:declarations}).
Initially |L := 0| and |R := length(aList)-1|. It may be instructive
to compare this to Algorithm Q in \emph{The Art of Computer Programming},
third ed., volume 3, \section5.2.2. @! @^Quicksort@>
@:The Art of Computer Programming}{\texttt{The Art of Computer Programming}@>
Specifically Mizar appears to use Hoare partitioning. We can summarize
its algorithm thus:

\algbegin Algorithm S (Quicksort). This uses Hoare partition. We
assume that |L <= R|, and that |aCompare| is a total order (it's
transitive an the law of trichotomy holds on all pairs of
elements). Steps S1 through S4 are better known as the ``partition''
procedure. 
\algstep S0. [Initialize] Set |I := L|, |J := R|, and
  the pivot index |@t$P_{idx}$@> := (L+R) shr 1|,
  and the pivot value |P := aList^[aIndex^[(L + R) shr 1]]|.
  Observe |I <= @t$P_{idx}$@> <= J| at this point.
\algstep S1. [Move $I$ right] While |aList[I] < P|, we increment |I := I + 1|.
  This is guaranteed to terminate since |I <= @t$P_{idx}$@>|,
  so eventually we will get to |aList[i] = P|.
\algstep S2. [Move $J$ left] While |P < aList[J]|, we decrement |J := J - 1|.
  This is guaranteed to terminate since |@t$P_{idx}$@> <= J|,
  so eventually we will get to |aList[J] = P|.
\algstep S3. [Keep going?] If $I>J$, then we're done ``partitioning''
  (so everything to the left of the pivot is not greater than the
  pivot value, and everything to the right of the pivot is not lesser
  than the pivot value),
  and we go to step S5; otherwise go to the next step. 
\algstep S4. [Swap entries $I$ and $J$]
  We swap the entries located at $I$ and $J$, then set |I := I + 1|,
  and |J := J - 1|. If |I <= J|, then return to step S1.
\algstep S5. [Recur on left half] If |L < J|, then recursively call
  quicksort on the left half of the index (entries between |L..J-1|).
\algstep S6. [Sort the right half] If |I>=R|, then terminate.
  Otherwise, set |L := I| and return to step S0. \quad\slug

\medbreak\noindent%
%We annotate the following code snippet with comments which should be viewed as Hoare logic-like assertions.
For readability, we also introduce a \WEB/ macro for swapping the indices.\label{ListQuickSort}

@d steal_from(#)== aIndex^[#];
            aIndex^[#] := T;
@d swap_indices(#)==
            T := aIndex^[#];
            aIndex^[#] := steal_from

@p
procedure ListQuickSort(aList: PItemList; aIndex: IndexListPtr;
                        L, R: integer; aCompare: CompareProc);
var I, J, T : integer; P: Pointer;
begin
   repeat
      I := L;
      J := R;
      P := aList^[aIndex^[(L + R) shr 1]];
      repeat @|@/
@t\4@>         {|I <= (L + R) shr 1 <= J|}
         while aCompare(aList^[aIndex^[I]], P) < 0 do inc(I);@/
@t\4@>         {|P <= aList^[aIndex^[I]]|}
         while aCompare(aList^[aIndex^[J]], P) > 0 do Dec(J); @/
@t\4@>         {|aList^[aIndex^[J]] <= P|}
  @t\4@> {|I <= (L + R) shr 1 <= J|}
         if I <= J then
         begin @|@/
 @t\4@>           {|aList^[aIndex^[J]] < P < aList^[aIndex^[I]] |}
            swap_indices(I)(J); @/
@t\4@>            {|aList^[aIndex^[I]] < P < aList^[aIndex^[J]] |}
@t\4@>            {|I < J| implies |inc(I) <= dec(J)|}
@t\4@>            {|I = J| implies |inc(I) > dec(J)|}
            inc(I);
            Dec(J);
         end;
      until I > J; @/
@t\4@> {|J <= (L + R) shr 2 <= I| and |J < I|}
      if L < J then ListQuickSort(aList, aIndex, L, J, aCompare);
      {quicksort left half}
      L := I; {recursively quicksort the right half of the array}
   until I >= R;
end;

@ \node{Remarks.} \par

\enumerate
\item It is unclear to me whether we must have |aCompare| be a
linear order, and not a total pre-order. The difference is: do we
really need $a\leq b\land b\leq a\implies a=b$ (i.e., a total order)
or not (i.e., a total pre-order)?
\item P{\sc RECONDITION}: We need to prove the |compare| operators are total orders
for quicksort to work as expected.
\item A{\sc SSERT}: Upon arriving to step Q5, the entries in |L .. J-1| are
partitioned (i.e., less than the pivot value) as is the entries in |I..R|.
In particular, the maximal element in |L .. J-1| is located at |J - 1|
while the minimal element in |I..R| is located at |I|.
\item Robert Sedgewick's \emph{Quicksort} (1980) is
literally \emph{the} book on the subject. An abbreviated reference may
be found in Sedgewick's ``The Analysis of Quicksort Programs''
(\emph{Acta Inform.}\ \textbf{7} (1977) 327--355, \pdfURL{eprint}{https://sedgewick.io/wp-content/themes/sedgewick/papers/1977Analysis.pdf})
@^Sedgewick, Robert@>
\item I{\sc MPROVEMENT}: This can be improved when recursively sorting the left half of
the arrays by first checking if |J - L<=9| then use insertion sort
otherwise recursively quicksort the left half. (Similarly, instead of
iterating the outermost while-loop, we should test if |R - I<=9| then
invoking insertion on the subarray indexed by |I..R|.)
\item I{\sc MPROVEMENT}: The pivot index $P_{ind}$ is selected as
  |@t$P_{ind}$@> := (L+R)/2|, which can lead to overflow. A safer way
  to compute this would be |@t$P_{ind}$@> := L + ((R - L)/2)|.
\endenumerate

According to the paper by Sedgewick we cited, when quicksorting a list
of size less than $M$ with a different sorting algorithm, the optimal choice of
$M$ (the cutoff for delegating to another sort algorithm) contributes
to the runtime of quicksort,
$$ f(M) = \frac{1}{6}\left(8M + 71 - 70 H_{M+2}+\frac{270}{M+2}+\frac{54}{2M+3}-36\frac{H_{M+1}}{M+2}\right).$$
We can use the approximation for Harmonic numbers
$$ H_{n} = \ln(n)+\gamma+\frac{1}{2n}+O(n^{-2})$$
where $\gamma\approx0.57721$ is Euler-Mascheroni constant. Using this
replacement, we have
$$f'(M) \approx \frac{4}{3} + \frac{3}{(1+m)^{2}} - \frac{6}{1+m}+\frac{36\gamma-253}{6(2+m)^{2}}-\frac{17}{3(2+m)}-\frac{18}{(3+2m)^{2}}+\frac{6\ln(1+m)}{(2+m)^{2}}.$$
We can numerically find the root for this to be $m_{0}\approx8.9888$
which gives a global minimum of $f(9)\approx-8.47671$.

This analysis is sketched out in Knuth's \emph{The Art of Computer Programming},
volume III, but it may be worth sitting down and working this analysis
out more fully.

@ \node{Sorting a sorted list.}
We can update a sorted list to sort according to a new ordering
operator, and also update the data structure to record this new
ordering operator. This relies on \\{ListQuickSort}
(\section\xref{ListQuickSort}) to do the actual sorting.

@:MSortedList.Sort}{\\{MSortedList.Sort}@>
@p
procedure @? MSortedList.Sort(aCompare: CompareProc);
var I: integer;
begin
   fCompare:=aCompare;
   for I:=0 to Count-1 do fIndex^[I]:=I;
   if (Count > 0) then
      ListQuickSort(Items, fIndex, 0, Count-1, aCompare);
end;
@ \node{Find item.} Finding an item in a sorted list boils down to two
cases: do we have |fCompare| populated or not? If so, then use a
binary search. If not, then just iterate item-by-item testing if
|aKey| is in the underlying array.

C{\sc AUTION}:\enspace\ignorespaces%
The ``find'' function returns the index for the \\{fIndex} field, \textbf{NOT}
the index for the underlying array of values (inherited from
the \\{MList} class).

\label{MSortedList.Find}

@:MSortedList.Find}{\\{MSortedList.Find}@>
@p
function MSortedList.Find(aKey: Pointer; var aIndex: integer): boolean;
var L, H, I, C: integer;
begin
   Find := False;
   if @@fCompare = nil then
      @<Find needle in |MSortedList| by brute force@>;
   @<Find needle in |MSortedList| by binary search@>@;
end;

@ Binary search is a little clever. We have $L$ be the lower bounds
index, and $H$ the upper bounds index. The midpoint is obtained by
taking their sum $L+H$ and shifting to the right by 1 bit (which
corresponds to dividing by 2, truncating the result).

We compare the item located at the midpoint to the given |aKey|, and
store the result of this comparison in the variable $C$.
If $C<0$, then |aKey| is located to the right of the midpoint (so set
|L := I + 1|).

On the other hand, if $C\geq0$, update |H := I - 1|. When $C=0$
(i.e., the midpoint \emph{is equal to} |aKey|), then we set |L := I + 1|
so we have $H < L$ to terminate the loop. We set the return value to
|True| when $C=0$, and we mutate the |aIndex| to the index where we
found the needle in the haystack.

@<Find needle in |MSortedList| by binary search@>=
   L := 0;
   H := Count-1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := fCompare(Items^[fIndex^[I]], aKey);
      if C < 0 then L := I + 1
      else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Find := True;
            L := I; @+
         end;
      end;
   end;
   aIndex := L;

@ We can simply iterate through the underlying array, testing
item-by-item if each entry is equal to the needle or not.

@<Find needle in |MSortedList| by brute force@>=
begin
   aIndex := Count;
   for I := 0 to Count-1 do
      if aKey = Items^[I] then
      begin
         Find := True;
         aIndex := I;
         break @+
      end;
   exit;
end
@ \node{Search.} We recall that \\{Find} returns the index of
the \\{fIndex} field matching the needle. Usually, we want to know the
index \emph{of the value} itself. This is what \\{Search} performs.

@:MSortedList.Search}{\\{MSortedList.Search}@>
@<|MSortedList| implementation@>=
function MSortedList.Search(aKey: Pointer; var aIndex: integer): boolean;
var I: integer;
begin
   aIndex:=Count;
   Search:=false;
   if Find(aKey, I) then
   begin
      Search:=true;
      aIndex := fIndex^[I];
   end;
end;
@ \node{Index of a needle.}
Given a ``needle'', where in the haystack is it? Well, we require the
ordering operator be non-nil for the sorted list --- otherwise raise
an error. Then using \\{Find} (\section\xref{MSortedList.Find}), check
if the entry is present. If it is, then return the index for the
underlying array of values.

If the needle is not in the haystack, return $-1$.

@!@:MSortedList.IndexOf}{\\{MSortedList.IndexOf}@>
@p
function @? MSortedList.IndexOf(aItem: Pointer): integer;
var I: integer;
begin
   if @@fCompare = nil then
   begin
      ListError(coSortedListError,0);
      exit;
   end;
   IndexOf := -1;
   if Find(aItem, I) then
   begin
      {if $I < \\{fCount}$ then}
      IndexOf := fIndex^[I];
   end;
end;
@ \node{Packing a sorted list.} Use the superclass's \\{Pack}
method. Then, when there is an ordering operator present, sort the list.

@!@:MSortedList.Pack}{\\{MSortedList.Pack}@>
@p
procedure @? MSortedList.Pack;
var lCount: integer;
begin
   lCount:=Count;
   inherited Pack;
   if(@@fCompare <> nil) and (lCount > Count) then Sort(fCompare);
end;
@ \node{Free items starting at an index.}
When we want to remove all items starting at index $a$, we simply
iterate through the array of indices starting at entry $i=a$ and
delete the value associated with \\{Items[i]} when it is non-|nil|.

This will also keep the indices for the non-deleted entries.

@!@:MSortedList.FreeItemsFrom}{\\{MSortedList.FreeItemsFrom}@>
@p
procedure @? MSortedList.FreeItemsFrom(aIndex:integer);
var I,k:integer;
begin
   if aIndex = Count then exit; @#
 @t\4@> {Delete entries from the array of values}
   for I:=aIndex to Count-1 do
      if Items^[I] <> nil then Dispose(PObject(Items^[I]), Done); @#
 @t\4@>  {Update the array of indices}
   k:=0; 
   for I:=0 to Count-1 do
   begin
      if fIndex^[I] < aIndex then
      begin
         fIndex^[k]:=fIndex^[I];
         inc(k); @+
      end;
   end;
   if k <> aIndex then ListError(coSortedListError, 0);
   Count:=aIndex;
end;

@* [S] Sorted extendible lists.
We want to handle a sorted (\section\xref{MSortedList:declarations})
version of extendible lists --- an \\{MSortedExtList}. It's used in
the correlator for functorial registrations and inferred definition
constants.

Like \\{MSortedList}, we add a field \\{fIndex} for the indices of the
entries. This will track the \emph{digested} items, not the extendible
items.

An important invariant: the ordering operator (\\{fCompare}) must be
non-|nil|. 

@!@:MSortedExtList.Z}{\\{MSortedExtList.Z}@>
@<Public interface for \texttt{mobjects.pas}@>=
@!  MSortedExtList = object(MExtList) @t\1@> @/
     fIndex: IndexListPtr;
     fCompare: CompareProc;
     constructor @? Init(ALimit: integer); @t\2@>
     constructor @? InitSorted(aLimit: integer; aCompare: CompareProc); @t\2@>
     destructor @? Done; virtual; @t\2@>
     function @? Find(aKey: Pointer; var aIndex: integer): boolean; virtual; @t\2@>
     function @?  FindRight(aKey: Pointer; var aIndex: integer): boolean; virtual; @t\2@>
     function @? FindInterval(aKey: Pointer; var aLeft,aRight: integer): boolean; virtual; @t\2@>
     function @? AtIndex( aIndex: integer): Pointer; virtual; @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     procedure @? Pack; virtual; @t\2@>
     procedure @? InsertExt(AItem: Pointer); virtual; @t\2@>
     procedure @? SetLimit(ALimit: integer); virtual; @t\2@>
     procedure @? FreeItemsFrom(aIndex:integer); virtual; @t\2@>
     procedure @? AddExtObject; virtual; @t\2@>
     procedure @? AddExtItems; virtual; @t\2\2\2@>
  end; @#


@ \node{Constructors.}
The \\{Init} constructor should not be used, and should raise an error
if anyone tries to use it.

Instead, the \\{InitSorted} should be used to construct a new [empty] sorted
extendible list with a given ordering operator.

@<|MSortedExtList| implementation@>=
{MSortedExtList always with possible duplicate keys, always sorted}
constructor MSortedExtList.Init(ALimit: integer);
begin ListError(coIndexExtError,0); @+ end; @#

constructor MSortedExtList.InitSorted(aLimit: integer; aCompare: CompareProc);
begin
   inherited Init( aLimit);
   fCompare := aCompare;
end;
@ \node{destructor} The destructor for sorted extendible lists is just
the inherited destructor from extendible lists.

@!@:MSortedExtList.Done}{\\{MSortedExtList.Done}@>
@p
destructor MSortedExtList.Done;
begin
   inherited Done; @+
end;
@ \node{Finding a needle in the haystack.} We require \\{fCompare} to
be non-|nil| and enforce that invariant by raising an error when it is |nil|.

Then we just use bisection search to find the needle in the haystack.
Once found, we mutate \\{aIndex} to the index $L$ of the \\{fIndex} array
which indexes the needle.

@!@:MSortedExtList.Find}{\\{MSortedExtList.Find}@>
@p
@t\4\4@> {find the left-most if duplicates}
function MSortedExtList.Find(aKey: Pointer; var aIndex: integer): boolean;
var L,H,I,C: integer;
begin
   if not Assigned(fCompare) then ListError(coIndexExtError,0);
   Find := False;
   L := 0;
   H := Count-1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := fCompare(Items^[fIndex^[I]], aKey);
      if C < 0 then L := I + 1
      else
      begin
         H := I - 1;
         if C = 0 then Find := True;
      end;
   end;
   aIndex := L;
end;
@ \node{Find the rightmost index for a needle in the haystack.}
Since the underlying array is sorted, we check to see if the needle is
in the haystack. If it is, we keep incrementing \\{aIndex} until it is
no longer indexing the needle.

So upon return, if it returns \\{True}, then the \\{aIndex} parameter
is mutated to equal the rightmost index for the needle's appearance in
the haystack.

@p
@t\4\4@> {find the left-most with higher aKey, this is where we can insert}
function MSortedExtList.FindRight(aKey: Pointer; var aIndex: integer): boolean;
begin
   if Find(aKey, aIndex) then
   begin
      while (aIndex < Count)
            and (0 = fCompare(Items^[fIndex^[ aIndex]], aKey)) do inc( aIndex);
      FindRight := true;
   end
   else FindRight := false;
end;
@ Since we allow duplicate values in a sorted extendible list, we will
sometimes wish to know the ``interval'' of entries equal to a
needle. This will mutate \\{aLeft} and \\{aRight} to point to the
beginning and end of the interval.

When the needle is not in the haystack, the function will mutate the
variables to ensure |aRight < aLeft| to stress the point.

\textbf{Possible bug:} This assumes the \\{MSortedExtList.Find}
returns the left-most index where the needle appears in the haystack.

\label{MsortedExtList.FindInterval}

@p
@t\4\4@> {find the interval of equal guys}
function MSortedExtList.FindInterval(aKey: Pointer; var aLeft,aRight: integer): boolean;
begin
   if Find(aKey, aLeft) then
   begin
      aRight:= aLeft + 1;
      while (aRight < Count)
            and (0 = fCompare(Items^[fIndex^[aRight]], aKey)) do inc(aRight);
      dec(aRight);
      FindInterval := true;
   end
   else begin aRight:= aLeft - 1; FindInterval := false; end;
end;
@ \node{Get value at index.}
We check if the index $i$ is within bounds of the sorted extendible
list. If not, then we raise an error.

Otherwise, the default course of action, we simply lookup the entry
$\\{fIndex}[i]$ and then lookup the entry in the array of values
located with that index.

@p
function MSortedExtList.AtIndex( aIndex: integer): Pointer;
begin
   if (aIndex < 0) or (aIndex >= Count) then
      ListError(coIndexExtError,0);
   AtIndex:= Items^[fIndex^[ aIndex]];
end;
@ \node{Inserting items.}
We can only insert an item into an extendible list when it has fully
digested all its extendible items. This requirement carries over to
sorted extendible lists.

When there are no extendible items, we delegate the work to |InsertExt|.

@p
procedure MSortedExtList.Insert(aItem: Pointer);
begin
   if fExtCount <> 0 then ListError(coIndexExtError,0);
   InsertExt(aItem);
   AddExtObject;
end;

@ Packing a sorted extendible list is unsupported, so just raise an
error if anyone tries to use it.

@p
procedure MSortedExtList.Pack;
begin ListError(coIndexExtError,0); end;

@ \node{Adding an extendible item.}
We ensure there is sufficient capacity in the underlying array of
items, then add |AItem| at the position located by the logical size of
the array of items. We also increment the number of extendible items.

@p
procedure MSortedExtList.InsertExt(AItem: Pointer);
begin
   if Limit = Count+fExtCount then
      SetLimit(Limit+GrowLimit(Limit));
   Items^[Count+fExtCount] := AItem;
   inc(fExtCount);
end;

@ \node{Ensure capacity.}
We can ensure the capacity of a sorted extendible list to be at least
as large as |ALimit|.

When |ALimit| is smaller than the current capacity of the sorted
extendible list, we allocate new arrays and copy over the old
data. More importantly: we keep the last |fExtCount| items as (``undigested'')
extendible items.

@p
procedure MSortedExtList.SetLimit(ALimit: integer);
var lItems: PItemList; lIndex: IndexListPtr;
begin
   Count:= Count + fExtCount;
   if aLimit < Count then aLimit := Count;
   if aLimit > MaxCollectionSize then aLimit := MaxCollectionSize;
   if aLimit <> Limit then
   begin
      if aLimit = 0 then
      begin
         lItems:=nil;
         lIndex:=nil;
      end
      else
      begin {Allocate new arrays for indices and items}
         GetMem(lItems, aLimit*SizeOf(Pointer));
         GetMem(lIndex, aLimit*SizeOf(integer));
         if Count <> 0 then {Copy items and indices from old arrays to new ones}
         begin
            if Items <> nil then
            begin
               Move(Items^, lItems^, Count*SizeOf(Pointer));
               Move(fIndex^, lIndex^, Count*SizeOf(integer));
            end;
         end;
      end;
      if Limit <> 0 then {Free old arrays}
      begin
         FreeMem(Items, Limit*SizeOf(Pointer));
         FreeMem(fIndex, Limit*SizeOf(integer));
      end;
      Items := lItems;
      fIndex := lIndex;
      Limit := aLimit; {Update the caller to use new arrays}
   end;
   Count:= Count - fExtCount;
end;
@ \node{Freeing items starting at an index.}
We have two exceptional situations:
\enumerate
\item The \\{fExtCount} must be zero, and if it is nonzero, then
an error is raised; and
\item If the index given is equal to the logical size of the
sorted extendible list, then we terminate early (since there is
nothing to do).
\endenumerate

@p
procedure MSortedExtList.FreeItemsFrom(aIndex:integer);
var I,k:integer;
begin
   if fExtCount <> 0 then ListError(coIndexExtError,0);
   if aIndex = Count then exit; @/
   @t\4@> {Free items indexed by |I>=aIndex|}
   for I:=aIndex to Count-1 do
      if Items^[I] <> nil then Dispose(PObject(Items^[I]), Done);
   @t\4@> {Sort |fIndex| for entries less than |aIndex|}
   k:=0;
   for I:=0 to Count-1 do
   begin
      if fIndex^[I] < aIndex then
      begin
         fIndex^[k]:=fIndex^[I];
         inc(k);
      end;
   end;
   if k <> aIndex then ListError(coSortedListError, 0);
   Count:=aIndex;
end;
@ \node{Digest an extendible object.} When there are extendible
objects left to digest among the values (i.e., when |fExtCount > 0|), 
When |fExtCount <= 0|, then raise an error (there's nothing left to digest).

The first extendible item left to be digested is located at |Count| in
the array of items. Then we find the right most index for the same
extendible item. We digest all of them at once, shifting the |fIndex|
as needed.

Note that the need to shift |fIndex| down by 1 is needed to keep the
array of items sorted.

@p
procedure MSortedExtList.AddExtObject;
var lIndex: integer;
begin
   if fExtCount <= 0 then ListError(coIndexExtError,0);
   FindRight(Items^[Count], lIndex);
   if lIndex <> Count then {shift |fIndex| to right by 1}
      Move(fIndex^[lIndex], fIndex^[lIndex+1],(Count-lIndex)*SizeOf(integer));
   fIndex^[lIndex] := Count; {extendible item's index}
   inc(Count);
   Dec(fExtCount);
end;

@ \node{Digest all extendible items.}
We can simply iterate through all the extendible items, digesting them
one-by-one.

@p
procedure MSortedExtList.AddExtItems;
begin while fExtCount > 0 do AddExtObject; end;

@* [S] Sorted list of strings.
This is used in the kernel to track directives, as well
as \texttt{makenv} and \texttt{accdict} needs it.

@<Public interface for \texttt{mobjects.pas}@>=
@!  MSortedStrList = object(MSortedList) @t\1@>
     constructor @? Init(ALimit: integer); @t\2@>
     function @? IndexOfStr(const aStr: String): integer; virtual; @t\2@>
     function @? ObjectOf(const aStr: String): PObject; virtual; @t\2\2\2@>
  end;

@ \node{Pointer comparison.}
For strings, it is faster to use pointer comparison than lexicographic
ordering. Although pointer comparison is a total linear order, it may
not produce intuitive comparisons.

@<|MSortedStrList| implementation@>=
{MSortedStrList}

function CompareStringPtr(aKey1, aKey2: Pointer): integer;
begin
   if PStr(aKey1)^.fStr < PStr(aKey2)^.fStr then
      CompareStringPtr := -1
   else if PStr(aKey1)^.fStr = PStr(aKey2)^.fStr then
      CompareStringPtr := 0
   else
      CompareStringPtr := 1;
end;

@ \node{Constructor.} We just defer to the \\{InitSorted} constructor
for sorted lists (\section\xref{MSortedList.InitSorted}).

As an invariant, the |fCompare| ordering operator is \emph{always}
assumed to be set to the |CompareStringPtr|. There is no other way to
construct a sorted string list besides this constructor, which
enforces this invariant.
@:MSortedStrList.Init}{\\{MSortedStrList.Init}@>

@p
constructor @? MSortedStrList.Init(ALimit: integer);
begin
   InitSorted(ALimit,CompareStringPtr);
end;

@ We can locate a string by |Find|-ing its entry in the |fIndex| array.
@:MSortedStrList.IndexOfStr}{\\{MSortedStrList.IndexOfStr}@>

@p
function @? MSortedStrList.IndexOfStr(const aStr: string): integer;
var I: integer; lStringObj: MStrObj;
begin
   IndexOfStr := -1;
   if @@fCompare = nil then {Invariant violation}
   begin
      ListError(coSortedListError,0);
      exit;
   end;
   lStringObj.Init(aStr);
   if Find(@@lStringObj, I) then
   begin
      if I < Count then IndexOfStr := fIndex^[I];
   end;
end;

@ We also can return the pointer to the object, if it is present in
the sorted string list.
@:MSortedStrList.ObjectOf}{\\{MSortedStrList.ObjectOf}@>

@p

function @? MSortedStrList.ObjectOf(const aStr: string): PObject;
var I: integer;
begin
   ObjectOf:=nil;
   I:=IndexOfStr(aStr);
   if I>=0 then ObjectOf:=Items^[I];
end;


@* [S] Sorted collections.

@<Public interface for \texttt{mobjects.pas}@>=
{MSortedCollection object}

@!  PSortedCollection = ^MSortedCollection; @/
@!  MSortedCollection = object(MCollection)  @t\1@> @/
     Duplicates: boolean;
     fCompare: CompareProc;
     constructor @? Init(ALimit, ADelta: integer); @t\2@>
     constructor @? InitSorted(ALimit, ADelta: integer; aCompare: CompareProc); @t\2@>
     function @? Compare(Key1, Key2: Pointer): integer; virtual; @t\2@>
     function @? IndexOf(aItem: Pointer): integer; virtual; @t\2@>
     procedure @? Insert(aItem: Pointer); virtual; @t\2@>
     procedure @? InsertD(Item: Pointer); virtual; @t\2@>
     function @? KeyOf(Item: Pointer): Pointer; virtual; @t\2@>
     function @? Search(Key: Pointer; var Index: integer): boolean; virtual; @t\2\2\2@>
  end;

@ \node{Constructors.}
We can construct a sorted collection without an ordering operator, and
we can construct one with an ordering operator.
@!@:MSortedCollection.Init}{\\{MSortedCollection.Init}@>
@!@:MSortedCollection.InitSorted}{\\{MSortedCollection.InitSorted}@>

@<|MSortedCollection| implementation@>=
{MSortedCollection}

constructor @? MSortedCollection.Init(aLimit, aDelta: integer);
begin
   inherited Init(ALimit, ADelta);
   Duplicates := False;
   fCompare := nil;
end; @#

constructor @? MSortedCollection.InitSorted(aLimit, aDelta: integer; aCompare: CompareProc);
begin
   inherited Init(ALimit, ADelta);
   Duplicates := False;
   fCompare := aCompare;
end;

@ \node{Comparing entries.} This will invoke |Abstract1| (\section\xref{Abstract1}) when there is
no ordering operator, which itself raises an error 211.

Otherwise, this just invokes |fCompare| on the two entries.

\label{MSortedCollection.Compare}
@!@:MSortedCollection.Compare}{\\{MSortedCollection.Compare}@>

@p
function @? MSortedCollection.Compare(Key1, Key2: Pointer): integer;
begin
   if @@fCompare = nil then Abstract1;
   Compare := fCompare(Key1, Key2);
end;

@ Find the right-most index for an item in the collection.
Searching (\section\xref{MSortedCollection.Search}) for the |KeyOf| (\section\xref{MSortedCollection.KeyOf}).
This function corrects for the possible bug in |Search| (\section\xref{MSortedCollection.Search})
which will return the index \emph{just to the left} of an item.
@!@:MSortedCollection.IndexOf}{\\{MSortedCollection.IndexOf}@>

@p
function @? MSortedCollection.IndexOf(aItem: Pointer): integer;
var I: integer;
begin
   IndexOf := -1;
   if Search(KeyOf(aItem), I) then
   begin
      if Duplicates then
         while (I < Count) and (aItem <> Items^[I]) do inc(I);
      if I < Count then IndexOf := I;
   end;
end;

@ Insert the item when it is not in the collection (or if duplicates
are allowed). Otherwise do not mutate the caller.
@!@:MSortedCollection.Insert}{\\{MSortedCollection.Insert}@>

@p
procedure @? MSortedCollection.Insert(aItem: Pointer);
var I: integer;
begin
   if not Search(KeyOf(aItem), I) or Duplicates then AtInsert(I, aItem);
end;

@ Insert an item if it's not in the collection (or if there are
duplicates allowed in the collection). Otherwise, delete the
item and do not mutate the caller.

@p
procedure MSortedCollection.InsertD(Item: Pointer);
var I: integer;
begin
   if not Search(KeyOf(Item), I) or Duplicates then AtInsert(I, Item)
   else Dispose(PObject(Item),Done);
end;

@ We treat the item itself as the key, so return the item. That is to
say, this is the identity function.

It does not mutate the caller.

\label{MSortedCollection.KeyOf}

@p
function MSortedCollection.KeyOf(Item: Pointer): Pointer;
begin
   KeyOf := Item;
end;

@ \node{Binary search.}
This is binary search through a sorted collection.

If there are duplicates, this will return the left-most index.

\label{MSortedCollection.Search}

@p
function MSortedCollection.Search(Key: Pointer; var Index: integer): boolean;
var
   L, H, I, C: integer;
begin
   Search := False;
   L := 0;
   H := Count - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := Compare(KeyOf(Items^[I]), Key);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Search := True;
            if not Duplicates then L := I;
         end;
      end;
   end;
   Index := L;
end;

@ Perform the lexicographic ordering of $(x_{1},y_{1})$ against
$(x_{2},y_{2})$.

@p
function CompareIntPairs(X1, Y1, X2,Y2: Longint): integer;
var lRes: integer;
begin
   lRes := CompareInt(X1,X2);
   if lRes = 0 then
      lRes := CompareInt(Y1,Y2);
   CompareIntPairs := lRes;
end;

@* [S] String collection.

@<Public interface for \texttt{mobjects.pas}@>=
{MStringCollection object}

@!  PStringCollection = ^MStringCollection; @/
@!  MStringCollection = object(MSortedCollection) @t\1@>
     function Compare(Key1, Key2: Pointer): integer; virtual;  @t\2@>
     procedure FreeItem(Item: Pointer); virtual;  @t\2\2\2@>
  end;@#

{UnsortedStringCollection}

@!  PUsortedStringCollection = ^StringColl; @/
@!  StringColl = object(MCollection) @t\1@>
     procedure @? FreeItem(Item:pointer); virtual;  @t\2\2\2@>
  end; @#
@ \node{String ordering operator.}
We have the usual lexicograph ordering as an operator ordering.

@<String collection implementation@>=
{MStringCollection}

function CompareStr(aStr1, aStr2: string): integer;
begin
   if aStr1 < aStr2 then
      CompareStr := -1
   else if aStr1 = aStr2 then
      CompareStr := 0
   else
      CompareStr := 1;
end;

@ We then have a convenience function to handle pointer dereferencing.

@p
function MStringCollection.Compare(Key1, Key2: Pointer): integer;
begin
   Compare := CompareStr(PString(Key1)^,PString(Key2)^);
end;

@ \node{Freeing items.}
We can free an item by simply freeing the string. This is the same for
unsorted string collections, too.

@p
procedure MStringCollection.FreeItem(Item: Pointer);
begin
   DisposeStr(Item);
end; @/ @#

@t\4\4@>{UnsortedStringCollection}

procedure StringColl.FreeItem(Item:pointer);
begin
   DisposeStr(Item);
end;

@* [S] Int collections.
The |TIntItem| is needed for the unifier and equalizer.

@<Public interface for \texttt{mobjects.pas}@>=
{MIntCollection object}

@!  IntPair = record
     X,Y : integer; @+
  end; @#
  
@!  IntPairItemPtr = ^IntPairItem; @/
 @! IntPairItem = object(MObject) @t\1@> @/
     fKey: IntPair; @/
     constructor @? Init(X,Y: integer);  @t\2\2\2@>
  end; @#

  IntPtr = ^integer; @#

@!  PIntItem = ^TIntItem; @/
@!  TIntItem = object(MObject)  @t\1@> @/
     IntKey: integer;
     constructor  @? Init(fInt:integer); @t\2\2\2@>
  end; @#

@!  PIntKeyCollection = ^TIntKeyCollection; @/
@!  TIntKeyCollection = object(MSortedCollection)  @t\1@> @/
     function @? KeyOf(Item:pointer):pointer; virtual;  @t\2@>
     function @? Compare(Key1,Key2:pointer): integer; virtual; @t\2\2\2@>
  end; @#
  
@!  IntPairKeyCollectionPtr = ^IntPairKeyCollection; @/
@!  IntPairKeyCollection = object(MSortedCollection) @t\1@> @/
     function @? Compare(Key1,Key2:pointer): integer; virtual; @t\2@>
     function @? ObjectOf(X,Y: integer): IntPairItemPtr; virtual; @t\2@>
     function @? FirstThat(X: integer): IntPairItemPtr; virtual; @t\2\2\2@>
  end; @#

@ \node{TIntItem constructor.}
This just copies the given integer over to the newly allocated
|TIntItem| object.

@<|MIntCollection| implementation@>=
{MIntCollection}
constructor TIntItem.Init(fInt:integer);
begin IntKey:=fInt; end;

@ We use |TIntItem|s as keys in a |TIntKeyCollection|.

@p
function TIntKeyCollection.KeyOf(Item:pointer):pointer;
begin KeyOf:=addr(PIntItem(Item)^.IntKey); end;

@ Comparing items just looks at the integers referred by the pointers.

@p
function TIntKeyCollection.Compare(Key1,Key2:pointer): integer;
begin
   Compare:=1;
   if IntPtr(Key1)^ < IntPtr(Key2)^ then begin Compare:=-1; exit end;
   if IntPtr(Key1)^ = IntPtr(Key2)^ then Compare:=0;
end;

@ \node{Constructor for pairs of integers.}

@p
constructor IntPairItem.Init(X,Y: integer);
begin fKey.X:=X; fKey.Y:=Y; end;

@ Comparing two keys in a collection indexed by |IntPair|s is done
``in the obvious way''.

@p
function IntPairKeyCollection.Compare(Key1,Key2:pointer): integer;
begin
   Compare:=CompareIntPairs(IntPairItemPtr(Key1)^.fKey.X,IntPairItemPtr(Key1)^.fKey.Y,
 @t\hskip12.25pc@>          IntPairItemPtr(Key2)^.fKey.X,IntPairItemPtr(Key2)^.fKey.Y);
end;

@ We can lookup the value associated to the key $(X,Y)$ leveraging the
|MSortedCollection.Search| function.

@p
function IntPairKeyCollection.ObjectOf(X,Y: integer): IntPairItemPtr;
var lPairItem: IntPairItem; I: integer;
begin
   ObjectOf:=nil;
   lPairItem.Init(X,Y);
   if Search(addr(lpairItem),I) then
      ObjectOf:=Items^[I];
end;

@ This is used in \texttt{justhan.pas} and \texttt{mizprep.pas}.

@p
function IntPairKeyCollection.FirstThat(X: integer): IntPairItemPtr;
var I: integer;
begin
   FirstThat:=nil;
   for i:=0 to Count-1 do
      if IntPairItemPtr(Items^[I])^.fKey.X = X then
      begin FirstThat:=Items^[I]; exit end;
end;



@* [S] Stacked list of objects.
``Stacked'' lists are really linked lists.

\label{StackedObj}

@<Public interface for \texttt{mobjects.pas}@>=
{Stacked Object (List of objects)}

@!  StackedPtr = ^StackedObj; @/
@!  StackedObj = object(MObject) @t\1@> @/
     Previous: StackedPtr;
     constructor @? Init; @t\2@>
     destructor @? Done; virtual; @t\2\2\2@>
  end;

@ The constructors and destructors are not implemented, so if you try
to use them, just raise an error.

@<Stacked object implementation@>=
{Stacked Object (List of objects)}
constructor StackedObj.Init;
begin Abstract1; end; @#

destructor StackedObj.Done;
begin Abstract1; end;

@* [S] String list.

@<Public interface for \texttt{mobjects.pas}@>=
{MStringList object}

@!  MDuplicates = (dupIgnore, dupAccept, dupError); @#

@!  PStringItem = ^MStringItem; @/
@!  MStringItem = record
     fString: PString;
     fObject: PObject; 
  end; @#

@!  PStringItemList = ^MStringItemList; @/
@!  MStringItemList = array[0..MaxListSize] of MStringItem; @#

@!  PStringList = ^MStringList; @/
@!  MStringList = object(MObject) @t\1@> @/
     fList: PStringItemList;
     fCount: integer;
     fCapacity: integer;
     fSorted: boolean;
     fDuplicate: MDuplicates;
     
     constructor @? Init(aCapacity: integer); @t\2@>
     constructor @? MoveStringList(var aAnother:MStringList); @t\2@>
     
     {-- Internal methods- do not use them directly --}
     procedure @? StringListError(Code, Info: integer); virtual; @t\2@>
     procedure @? Grow; @t\2@>
     procedure @? QuickSort(L, R: integer); @t\2@>
     procedure @? ExchangeItems(Index1, Index2: integer); @t\2@>
     procedure @? InsertItem(aIndex: integer; const aStr: String); @t\2@>
     {--                                            --}
     
     procedure @? SetSorted(aValue: boolean); @t\2@>
     procedure @? Sort; virtual; @t\2@>
     function @? GetString(aIndex: integer): String; virtual; @t\2@>
     function @? GetObject(aIndex: integer): PObject; virtual; @t\2@>
     procedure @? PutString(aIndex: integer; const aStr: String); virtual; @t\2@>
     procedure @? PutObject(aIndex: integer; aObject: PObject); virtual; @t\2@>
     procedure @? SetCapacity(aCapacity: integer); virtual; @t\2@>
     
     destructor @? Done; virtual; @t\2@>
     
     function @? AddString(const aStr: String): integer; virtual; @t\2@>
     function @? AddObject(const aStr: String; aObject: PObject): integer; virtual; @t\2@>
     procedure @? AddStrings(var aStrings: MStringList); virtual; @t\2@>
     procedure @? Clear; virtual; @t\2@>
     procedure @? Delete(aIndex: integer); virtual; @t\2@>
     procedure @? Exchange(Index1, Index2: integer); virtual; @t\2@>
     procedure @? MoveObject(CurIndex, NewIndex: integer); virtual; @t\2@>
     
     function @? Find(const aStr: String; var aIndex: integer): boolean; virtual; @t\2@>
     function @? IndexOf(const aStr: String): integer; virtual; @t\2@>
     function @? ObjectOf(const aStr: String): PObject; virtual; @t\2@>
     function @? IndexOfObject(aObject: PObject): integer; @t\2@>
     procedure @? Insert(aIndex: integer; const aStr: String); virtual; @t\2@>
     procedure @? InsertObject(aIndex: integer; const aStr: String; aObject: PObject); @t\2\2\2@>
  end;

@ \node{Constructors.}
We can construct an empty string collection using |Init|. We can also
move the contents of |aAnother| string collection into the caller
using |MoveStringList|.

@<String list implementation@>=
{--------------------  MStringList ---------------------------------}

constructor MStringList.Init(aCapacity: integer);
begin
   MObject.Init;
   fList := nil;
   fCount := 0;
   fCapacity := 0;
   fSorted := false;
   fDuplicate:=dupError;
   SetCapacity(aCapacity);
end;

constructor MStringList.MoveStringList(var aAnother:MStringList);
begin
   MObject.Init;
   fCount := aAnother.fCount;
   fCapacity := aAnother.fCapacity;
   fSorted := aAnother.fSorted;
   fList := aAnother.fList;
   fDuplicate := aAnother.fDuplicate;@#
   {Empty out the other list}
   aAnother.fCount := 0;
   aAnother.fCapacity:=0;
   aAnother.fList:=nil;
end;

@ \node{Destructor.} Since a |MStringItem| is a pointer to a string
and a pointer to an |MObject|, freeing an |MStringItem| should free
both of these (when they are present).
@:MStringList.Done}{\\{MStringList.Done}@>

@p
destructor @? MStringList.Done;
var I: integer;
begin
   inherited Done;
   for I:=0 to fCount-1 do
      with fList^[I] do {free |fList^[I]|}
   begin
      DisposeStr(fString);
      if fObject <> nil then Dispose(fObject,Done);
   end;
   fCount := 0;
   SetCapacity(0);
end;

@ \node{Adding a string.}
This boils down to determining the position where we will insert the
new string, then inserting the string into that location, and finally
returning the index to the user.

\label{MStringList.AddString}
@:MStringList.AddString}{\\{MStringList.AddString}@>

@p
function @? MStringList.AddString(const aStr: string): integer;
var lResult: integer;
begin
   @<Set |lResult| to the index of the newly inserted string@>;
   InsertItem(lResult, aStr);
   AddString:=lResult;
end;

@ Determining the index for the string boils down to whether the
collection is sorted or not. If it is unsorted, then just append the
string at the end of the collection.

For sorted collections, find the location for the string. We need to
give particular care when adding the new string would create a
duplicate entry in the string list.

@<Set |lResult| to the index of the newly inserted string@>=
   if not fSorted then
      lResult := fCount
   else
      if Find(aStr, lResult) then
      begin
         AddString:=lResult;
         @<De-duplicate a string list@>;
      end

@ When we ignore duplicates (i.e., the |fDuplicate| flag is equal to
|dupIgnore|), we can just terminate adding a string to the collection
here.

But when we want to flag an error upon inserting a duplicate entry,
then we should raise an error.

All other situations ``fall through''.

@<De-duplicate a string list@>=
         case fDuplicate of 
            dupIgnore: Exit;
            dupError: StringListError(coDuplicate, 0);
         endcases

@ \node{Inserting an object.}
We can treat a string list as a dictionary whose keys are
strings. This is because the entries are string-(pointer to object) pairs.

@:MStringList.AddObject}{\\{MStringList.AddObject}@>

@<String list implementation@>=
function @? MStringList.AddObject(const aStr: string; @+ aObject: PObject): integer;
var lResult: integer;
begin
   lResult := AddString(aStr); {Insert key}
   PutObject(lResult, aObject); {Insert value}
   AddObject:=lResult; {Return index}
end;

@ \node{Appending a string list.}
We can add all the entries from another |MStringList| to the caller,
which is what we do in the |AddStrings| function. It does not mutate
|aStrings|.

@:MStringList.AddStrings}{\\{MStringList.AddStrings}@>
@p
procedure @? MStringList.AddStrings(var aStrings: MStringList);
var I,r: integer;
begin
   for I := 0 to aStrings.fCount - 1 do
      r:=AddObject(aStrings.fList^[I].fString^, aStrings.fList^[I].fObject);
end;

@ \node{Clear a string list.}
We can delete all the strings from a string list. This \emph{will not}
free the ``values'' in each key-value pair.

@:MStringList.Clear}{\\{MStringList.Clear}@>

@p
procedure @? MStringList.Clear;
var I: integer;
begin
   if fCount <> 0 then
   begin
      for I:=0 to fCount-1 do DisposeStr(fList^[I].fString);
      fCount := 0;
      SetCapacity(0);
   end;
end;

@ \node{Deleting an entry by index.}
When given an index which is within the bounds of the caller, we free
the string located at that index, decrement the size, and then shift
all entries after it down by one.

@:MStringList.Delete}{\\{MStringList.Delete}@>

@p
procedure @? MStringList.Delete(aIndex: integer);
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      StringListError(coIndexError, aIndex);
   DisposeStr(fList^[aIndex].fString);
   Dec(fCount);
   if aIndex < fCount then
      Move(fList^[aIndex + 1], fList^[aIndex],
           (fCount - aIndex) * SizeOf(MStringItem));
end;

@ \node{Exchanging items.}
We have |Exchange| check if the indices are within the bounds of the
string list, then |ExchangeItems| swaps the items around.

@:MStringList.Exchange}{\\{MStringList.Exchange}@>
@:MStringList.ExchangeItems}{\\{MStringList.ExchangeItems}@>

@p
procedure @? MStringList.Exchange(Index1, Index2: integer);
begin
   if (Index1 < 0) or (Index1 >= fCount) then
      StringListError(coIndexError, Index1);
   if (Index2 < 0) or (Index2 >= fCount) then
      StringListError(coIndexError, Index2);
   ExchangeItems(Index1, Index2);
end; @#

procedure @? MStringList.ExchangeItems(Index1, Index2: integer);
var Temp: MStringItem;
begin
   Temp := fList^[Index1];
   fList^[Index1] := fList^[Index2];
   fList^[Index2] := Temp;
end;

@ \node{Find an entry by bisection search.}
We can use bisection search to find the needle in the haystack.

@:MStringList.Find}{\\{MStringList.Find}@>

@p
function @? MStringList.Find(@+const aStr: string; @+ var aIndex: integer): boolean;
var
   L, H, I, C: integer;
   lResult: boolean; @t\2@>
begin
   lResult := False;
   L := 0;
   H := fCount - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareStr(fList^[I].fString^, aStr);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            lResult := True;
            if fDuplicate <> dupAccept then L := I;
         end;
      end;
   end;
   aIndex := L;
   Find:=lResult;
end;

@ \node{Reporting errors.} We can propagate errors, adjusting the
error code as needed.
The comment here is in Polish ``poprawic bledy'' (which Google
translates to ``correct the errors'')

@:MStringList.StringListError}{\\{MStringList.StringListError}@>

@p
procedure @? MStringList.StringListError(Code, Info: integer);
begin
   RunError(212 - Code); {! poprawic bledy}
end;

@ \node{Getting the string at an index.}
When given an index within bounds, we try to get the string located
there. If there is no string located at that entry, return the empty string.

@:MStringList.GetString}{\\{MStringList.GetString}@>

@p
function @? MStringList.GetString(aIndex: integer): string;
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      StringListError(coIndexError, aIndex);
   GetString:='';
   if fList^[aIndex].fString <> nil then
      GetString := fList^[aIndex].fString^;
end;

@ \node{Get object at index.}
We can get the object at an index, provided it is within bounds.
\label{MStringList.GetObject}
@:MStringList.GetObject}{\\{MStringList.GetObject}@>

@p
function @? MStringList.GetObject(aIndex: integer): PObject;
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      StringListError(coIndexError, aIndex);
   GetObject := fList^[aIndex].fObject;
end;

@ \node{Ensure capacity for string lists.}
The growth rate for string lists differs from the earlier discussion
on the growth rate for dynamic arrays. Well, actually, recalling our
discussion (\section\xref{growth-factor}), we find this is identical
to the previous growth rate. So I am not sure why this code is duplicated.

@:MStringList.Grow}{\\{MStringList.Grow}@>

@p
procedure @? MStringList.Grow;
var
   Delta: integer;
begin
   if fCapacity > 64 then Delta := fCapacity div 4 else
      if fCapacity > 8 then Delta := 16 else
         Delta := 4;
   SetCapacity(fCapacity + Delta);
end;

@ \node{Index of a string.}
There are two branches to this function: one for unsorted string
lists, the second for sorted string lists.

@!@:MStringList.IndexOf}{\\{MStringList.IndexOf}@>

@p
function @? MStringList.IndexOf(const aStr: string): integer;
var lResult: integer;
begin
   if not fSorted then
   begin
      for lResult := 0 to fCount - 1 do
         if CompareStr(fList^[lResult].fString^, aStr) = 0 then
         begin
            IndexOf:=lResult;
            Exit; @+
         end;
      lResult := -1;
   end
   else
      if not Find(aStr, lResult) then lResult := -1; @/
@t\4@> {Assert: $\\{lResult} = -1$ if |aStr| is not in the caller} 
   IndexOf:=lResult;
end;

@ \node{Value for a key.} This appears to duplicate code from
|GetObject| (\section\xref{MStringList.GetObject}).

\label{MStringList.ObjectOf}
@:MStringList.ObjectOf}{\\{MStringList.ObjectOf}@>

@p
function @? MStringList.ObjectOf(const aStr: string): PObject;
var I: integer;
begin
   ObjectOf:=nil;
   I:=IndexOf(aStr);
   if I>=0 then ObjectOf:=fList^[I].fObject;
end;

@ \node{Insert a string at an index.}
This seems to involve duplicate code as |AddString|
(\section\xref{MStringList.AddString}), but allows duplicate entries
(which might violate the invariants of a string list).

@!@:MStringList.Insert}{\\{MStringList.Insert}@>

@p
procedure @? MStringList.Insert(aIndex: integer; const aStr: string);
begin
   if fSorted then
      StringListError(coSortedListError, 0);
   if (aIndex < 0) or (aIndex > fCount) then
      StringListError(coIndexError, aIndex);
   InsertItem(aIndex, aStr);
end;

@ \node{Inserting an item at an index.}
We ensure the capacity of the string list. Then we shift the entries
to the right by 1, if needed. We insert the string associated with no
object. Then increment the logical size of the dynamic array.

@:MStringList.InsertItem}{\\{MStringList.InsertItem}@>
@p
procedure @? MStringList.InsertItem(aIndex: integer; const aStr: string);
begin
   if fCount = fCapacity then Grow; @/
   @t\4@> {Shift existing entries to right by 1}
   if aIndex < fCount then
      Move(fList^[aIndex], fList^[aIndex + 1],
           (fCount - aIndex) * SizeOf(MStringItem));
   with fList^[aIndex] do
   begin
      fObject := nil;
      fString := NewStr(aStr); @+
   end;
   inc(fCount);
end;

@ \node{Find the index for an object.}
Find the first instance of a key-value entry whose value is equal to
the given object. If the given object is absent from the string list,
return $-1$.

@:MStringList.Z}{\\{MStringList.Z}@>
@:MStringList.IndexOfObject}{\\{MStringList.IndexOfObject}@>

@p
function @? MStringList.IndexOfObject(aObject: PObject): integer;
var lResult: integer;
begin
   for lResult := 0 to fCount - 1 do
      if GetObject(lResult) = aObject then
      begin
         IndexOfObject:=lResult;
         Exit; @+
      end;
   IndexOfObject := -1;
end;

@ \node{Inserting an object associated with a string.}

@p
procedure @? MStringList.InsertObject(aIndex: integer; 
 const aStr: string;
@t\quad @> aObject: PObject);
begin
   Insert(aIndex, aStr);
   PutObject(aIndex, aObject);
end;

@ \node{Moving a key-value entry around.}
We can take the key-value entry at |CurIndex|,
remove it from the string list, then insert it at |NewIndex|.
It is important to note: the |NewIndex| is the index \emph{after}
the delete operation has occurred.

@p
procedure MStringList.MoveObject(CurIndex, NewIndex: integer);
var
   TempObject: PObject;
   TempString: string;
begin
   if CurIndex <> NewIndex then
   begin
      TempString := GetString(CurIndex);
      TempObject := GetObject(CurIndex);
      Delete(CurIndex);
      InsertObject(NewIndex, TempString, TempObject);
   end;
end;

@ \node{Inserting a string at an index.}
Well, if this is a sorted collection, then raise an error: you can't
insert strings willy-nilly!

Then check the index is within bounds, raise an error for
out-of-bounds indices.

Then mutate the entry at |aIndex| to have its string be equal to
|NewStr(aStr)|.

This will always mutate the caller, even when the string located at
the entry indexed by |aIndex| is identical to |aStr|.

@:MStringList.PutString}{\\{MStringList.PutString}@>

@p
procedure @? MStringList.PutString(aIndex: integer; const aStr: string);
begin
   if fSorted then StringListError(coSortedListError, 0);
   if (aIndex < 0) or (aIndex >= fCount) then
      StringListError(coIndexError, aIndex);
   fList^[aIndex].fString := NewStr(aStr);
end;

@ \node{Inserting an object at an index.}
When given an index within bounds of the caller's underlying array,
mutate its object to be the given |aObject|. Again, this \emph{always}
mutates the caller.

@:MStringList.PutObject}{\\{MStringList.PutObject}@>

@p
procedure @? MStringList.PutObject(aIndex: integer; aObject: PObject);
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      StringListError(coIndexError, aIndex);
   fList^[aIndex].fObject := aObject;
end;

@ \node{Quicksorting a string list.} See also \section\xref{ListQuickSort}
and \section\xref{IntQuickSort}.

\label{MStringList.QuickSort}

@^Quicksort@>
@:MStringList.QuickSort}{\\{MStringList.QuickSort}@>

@p
procedure @? MStringList.QuickSort(L, R: integer);
var
   I, J: integer;
   P: string;
begin
   repeat
      I := L;
      J := R;
      P := fList^[(L + R) shr 1].fString^;
      repeat
         while CompareStr(fList^[I].fString^, P) < 0 do inc(I);
         while CompareStr(fList^[J].fString^, P) > 0 do Dec(J);
         if I <= J then
         begin
            ExchangeItems(I, J);
            inc(I);
            Dec(J); @+
         end;
      until I > J; 
      if L < J then QuickSort(L, J);
      L := I;
   until I >= R;
end;

@ \node{Changing the capacity of a string list.}
Of particular note here, changing the capacity of a string
list \emph{does not} delete anything. That work must be delegated
elsewhere when |aCapacity < Self.fCapacity| (if that case ever occurs).

@:MStringList.SetCapacity}{\\{MStringList.SetCapacity}@>

@p
procedure @? MStringList.SetCapacity(aCapacity: integer);
var
   lList: PStringItemList;
begin
   if aCapacity < fCount then aCapacity := fCount;
   if aCapacity > MaxListSize then aCapacity := MaxListSize;
   if aCapacity <> fCapacity then
   begin
      if aCapacity = 0 then lList := nil else
      begin
         GetMem(lList, aCapacity * SizeOf(MStringItem));
         if (fCount <> 0) and (fList <> nil) then
            Move(fList^, lList^, fCount * SizeOf(MStringItem));
      end;
      if fCapacity <> 0 then FreeMem(fList, fCapacity * SizeOf(MStringItem));
      fList := lList;
      fCapacity := aCapacity;
   end;
   {ReallocMem(fList, NewCapacity * SizeOf(MStringItem));
      fCapacity := NewCapacity;}
end;

@ \node{Toggle `sorted' flag.}
Allow the user to toggle the ``sorted'' flag. When toggled to |True|,
be sure to sort the string list.

@:MStringList.SetSorted}{\\{MStringList.SetSorted}@>

@p
procedure @? MStringList.SetSorted(aValue: boolean);
begin
   if fSorted <> aValue then
   begin
      if aValue then Sort;
      fSorted := aValue;
   end;
end;

@ \node{Sorting.}
This is a wrapper around the quicksort function
(\section\xref{MStringList.QuickSort}), invoked when the 
|fSorted| flag is false.

This appears to be used in the |SetSorted| procedure, but that is not
used anywhere.

@^Quicksort@>
@:MStringList.Sort}{\\{MStringList.Sort}@>

@p
procedure @? MStringList.Sort;
begin
   if not fSorted and (fCount > 1) then
   begin fSorted:=true;
   QuickSort(0, fCount - 1);
   end;
end;

@ \node{Allocating a new string.} Allocating a new |PString| from a
string. When the empty string is given, return |nil|. Otherwise
allocate a new block of memory in the Heap, then set its contents
equal to |S|.

@p
@t\4\4@> {Dynamic string handling routines}

function @? NewStr(const S: String): PString;
var
   P: PString;
begin
   if S = '' then P := nil else
   begin
      GetMem(P, length(S) + 1);
      P^ := S;
   end;
   NewStr := P;
end;

@ \node{Deleting a string.} A convenience function to avoid
accidentally freeing a |nil| string pointer.

@p
procedure DisposeStr(P: PString);
begin
   if P <> nil then FreeMem(P, length(P^) + 1);
end;

@* [S] Tuples of integers.

@<Public interface for \texttt{mobjects.pas}@>=
{Partial integers Functions}

  IntTriplet = record
     X1,X2,Y : integer;
  end; @#

const
   MaxIntPairSize = MaxSize div SizeOf(IntPair);
   MaxIntTripletSize = MaxSize div SizeOf(IntTriplet);

@ Now, this is the remainder of the interface

@<Public interface for \texttt{mobjects.pas}@>=
type
   IntPairListPtr = ^IntPairList;
   IntPairList = array[0..MaxIntPairSize- 1] of IntPair; @#

   IntPairSeqPtr = ^BinIntFunc;
   IntPairSeq = object(MObject) @t\1@> @/
      Items: IntPairListPtr;
      Count: integer;
      Limit: integer;
      constructor Init(aLimit: integer); @t\2@>
      procedure NatSetError(Code, Info: integer); virtual; @t\2@>
      destructor Done; virtual; @t\2@>
      procedure SetLimit(aLimit: integer); virtual; @t\2@> @#
      
      procedure Insert(const aItem: IntPair); virtual; @t\2@>
      procedure AtDelete(aIndex: integer); @t\2@>
      procedure DeleteAll; @t\2@> @#
      
      procedure AssignPair(X,Y:integer); virtual; @t\2\2\2@>
   end;

@ First, we have a helper function for flagging errors.

@<Tuples of integers@>=
{Pairs of an integers}

procedure IntPairSeq.NatSetError(Code, Info: integer);
begin
   RunError(212 - Code); @+
end;

@ \node{Constructor.}

@p
constructor IntPairSeq.Init(aLimit: integer);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   SetLimit(aLimit);
end;

@ \node{Destructor.}

@p
destructor IntPairSeq.Done;
begin
   Count := 0;
   SetLimit(0);
end;
@ \node{Insert an element.}

@p
procedure IntPairSeq.Insert(const aItem: IntPair);
begin
   if Count >= MaxIntPairSize then NatSetError(coOverflow,0);
   if Limit = Count then
      SetLimit(Limit+ GrowLimit(Limit));
   Items^[Count] := aItem;
   inc(Count);
end;

@ \node{Delete an element at an index.}

@p
procedure IntPairSeq.AtDelete(aIndex: integer);
var i: integer;
begin
   if (aIndex < 0) or (aIndex >= Count) then
   begin
      NatSetError(coIndexError,0);
      exit; @+
   end;
   if aIndex < Count-1 then
      for i:=aIndex to Count-2 do Items^[i]:=Items^[i+1];
   Dec(Count);
end;

@ \node{Resizing an IntPair sequence.}

@p
procedure IntPairSeq.SetLimit(aLimit: integer);
var aItems: IntPairListPtr;
begin
   if aLimit < Count then aLimit := Count;
   if aLimit > MaxIntPairSize then ALimit := MaxIntPairSize;
   if aLimit <> Limit then
   begin
      if ALimit = 0 then AItems := nil else
      begin
         GetMem(AItems, ALimit * SizeOf(IntPair));
         if (Count <> 0) and (Items <> nil) then
            Move(Items^, aItems^, Count * SizeOf(IntPair));
      end;
      if Limit <> 0 then FreeMem(Items, Limit * SizeOf(IntPair));
      Items := aItems;
      Limit := aLimit;
   end;
end;

@ \node{Deleting all entries.} We just set the logical size to zero.
It leaves everything else untouched.

@p
procedure IntPairSeq.DeleteAll;
begin
   Count := 0; @+
end;

@ \node{Append a pair of integers.} We create a new |IntPair| using
$X$ and $Y$, then append it to the caller.

@p
procedure IntPairSeq.AssignPair(X,Y:integer);
var lIntPair: IntPair;
begin
   lIntPair.X:=X;
   lIntPair.Y:=Y;
   Insert(lIntPair);
end;

@* [S] Int rel.
This is used in
the \texttt{iocorrel.pas}, \texttt{identify.pas}, \texttt{equalizer.pas},
the analyzer, and a polynomial library.

@<Public interface for \texttt{mobjects.pas}@>=
   IntRelPtr = ^IntRel; @/
   IntRel = object(IntPairSeq) @t\1@> @/      
      constructor Init(aLimit: integer); @t\2@>@#
      
      procedure Insert(const aItem: IntPair); virtual; @t\2@>
      procedure AtInsert(aIndex: integer; const aItem: IntPair); virtual; @t\2@>
      
      function Search(X,Y: integer; var aIndex: integer): boolean; virtual; @t\2@>
      function IndexOf(X,Y:integer): integer; @t\2@>
      constructor CopyIntRel(var aFunc: IntRel); @t\2@> @#
      
      function IsMember(X,Y:integer): boolean; virtual; @t\2@>
      procedure AssignPair(X,Y:integer); virtual; @t\2\2\2@>
   end;

@ \node{Constructor.} This is just the inherited constructor.

@<Int relation implementation@>=
@t\4\4@> {IntRel}

constructor IntRel.Init(aLimit: integer);
begin
   inherited Init(aLimit);
end;

@ \node{Inserting an entry.}

@p
procedure IntRel.Insert(const aItem: IntPair);
var I: integer; @t\2@>
begin
   if not Search(aItem.X,aItem.Y, I) then
   begin
      if (I < 0) or ( I > Count) then
      begin
         NatSetError(coIndexError,0);
         exit; @+
      end;
      if Count >= MaxIntPairSize then NatSetError(coOverflow,0); @/
      {Finished with the possible errors}
      if Limit = Count then
         SetLimit(Limit+ GrowLimit(Limit));
      if I <> Count then  
         Move(Items^[I], Items^[I+1],(Count - I)*SizeOf(IntPair));
      Items^[I] := aItem;
      inc(Count);
   end; @t\2@>
end;

@ \node{Insert at a specific index.}

@p
procedure IntRel.AtInsert(aIndex: integer; const aItem: IntPair);
begin
   if (aIndex < 0) or (aIndex > Count) then
      NatSetError(coIndexError, aIndex);
   if Count = Limit then
      SetLimit(Limit + GrowLimit(Limit)); @/
   {Shift everything to the right by 1}
   if aIndex < Limit then
      Move(Items^[aIndex], Items^[aIndex+1],(Count - aIndex)*SizeOf(IntPair));@/
   {Update the items, increment the logical size}
   Items^[aIndex] := aItem;
   inc(Count);
end;

@ \node{Bisection search for a relation.}
Search through |IntRel| for a relation $X = Y$. Note that this is not
symmetric, i.e., if we have $Y = X$ in the |IntRel|, then it will not
match.

Mutates the |aIndex|. If the relation is missing, |aIndex| will return
where it \emph{should} be.

@p
function IntRel.Search(X,Y: integer; var aIndex: integer): boolean;
var
   L, H, I, C: integer;
begin
   Search := False;
   L := 0;
   H := Count - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareIntPairs(Items^[I].X, Items^[I].Y, X, Y);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Search := True;
            L := I; @+
         end;
      end;
   end;
   aIndex := L;
end;

@ \node{Copy constructor.} This moves the contents of |aFunc| into the
caller. It will mutate the caller \emph{but not} the argument supplied.
The \\{Move} function copies the contents of one region of memory to another.

@p
constructor IntRel.CopyIntRel(var aFunc: IntRel);
begin
   Init(aFunc.Limit);
   Move(aFunc.Items^,Items^,aFunc.Limit*SizeOf(IntPair));
   Count:=aFunc.Count;
end;

@ \node{Index of a relation.}
This will return the index of the $X = Y$ entry. If it is absent from
the caller, then return $-1$.

@p
function IntRel.IndexOf(X,Y:integer): integer;
var I: integer;
begin
   IndexOf:=-1;
   if Search(X,Y, I) then IndexOf:=I;
end;

@ \node{Test for membership.} This just tests if $X=Y$ is contained in
the caller.

@p
function IntRel.IsMember(X,Y:integer): boolean;
var I: integer;
begin
   IsMember:=Search(X,Y, I); @+
end;

@ @p
procedure IntRel.AssignPair(X,Y:integer);
begin
   if IsMember(X,Y) then exit;
   inherited AssignPair(X,Y);
end;

@* [S] Partial integers functions.

@<Public interface for \texttt{mobjects.pas}@>=
   NatSetPtr = ^NatSet; @/
   NatSet = object(IntRel) @t\1@> @/
      Delta: integer;
      Duplicates: boolean;
      constructor Init(aLimit, aDelta: integer); @t\2@>
      constructor InitWithElement(X:integer); @t\2@>
      destructor Done; virtual; @t\2@>
      procedure Insert(const aItem: IntPair); virtual; @t\2@>
      function SearchPair(X: integer; var Index: integer): boolean; virtual; @t\2@>
      function ElemNr(X:integer): integer; @t\2@> @/
      {********************************************}
      constructor CopyNatSet(const fFunc: NatSet); @t\2@>
      procedure InsertElem(X:integer); virtual; @t\2@>
      procedure DeleteElem(fElem:integer); virtual; @t\2@>
      procedure EnlargeBy(const fAnother: NatSet); {? virtual;?} @t\2@>
      procedure ComplementOf(const fAnother: NatSet); @t\2@>
      procedure IntersectWith(const fAnother: NatSet); @t\2@> @/
      {********************************************}
      function HasInDom(fElem:integer): boolean; virtual; @t\2@>
      function IsEqualTo(const fFunc: NatSet): boolean; @t\2@>
      function IsSubsetOf(const fFunc: NatSet): boolean; @t\2@>
      function IsSupersetOf(const fFunc: NatSet): boolean; @t\2@>
      function Misses(const fFunc: NatSet): boolean; @t\2@>
      constructor MoveNatSet(var fFunc: NatSet); @t\2\2\2@>
   end;

@ \node{Constructor.}
The empty |NatSet| can be constructed with the usual initialization.

@<Partial integer function implementation@>=
{Partial integers Functions}

constructor NatSet.Init(aLimit, aDelta: integer);
begin
   MObject.Init;
   Items := nil;
   Count := 0;
   Limit := 0;
   Delta := ADelta;
   SetLimit(ALimit);
   Duplicates := False;
end;

@ \node{Singleton constructor.}
This initializes the |Delta| set to 4, and the |aLimit| set to 0. Then
insert the given integer.

@p
constructor NatSet.InitWithElement(X:integer);
begin
   Init(0,4);
   InsertElem(X);
end;

@ \node{Destructor.} This delegates the heavy work to |SetLimit(0)|.

@p
destructor NatSet.Done;
begin
   Count := 0;
   SetLimit(0);
end;

@ \node{Inserting a pair of integers.}
Using |Search| to find where to insert $X=Y$, possibly growing the
underlying array if needed.

@p
procedure NatSet.Insert(const aItem: IntPair);
var
   I: integer;
begin
   if not SearchPair(aItem.X, I) or Duplicates then
   begin
      if (I < 0) or ( I > Count) then {Out of bounds, raise an error}
      begin
         NatSetError(coIndexError,0);
         exit; @+
      end;
      if Limit = Count then {Grow the capacity, if possible}
      begin
         if Delta = 0 then
         begin
            NatSetError(coOverFlow,0);
            exit; @+
         end;
         SetLimit(Limit+Delta);
      end;
      if I <> Count then  
         Move(Items^[I], Items^[I+1],(Count - I)*SizeOf(IntPair));
      Items^[I] := aItem;
      inc(Count);
   end;
end;

@ \node{Equality of IntPair objects.}
This just tests the componentwise equality of two |IntPair| objects.

@p
function Equals(Key1, Key2: IntPair): boolean;
begin
   Equals := (Key1.X = Key2.X) and (Key1.Y = Key2.Y);
end;

@ \node{Search.} This is a bisection search for any relation of the
form $X = Y$ for some $Y$.

\label{NatSet.SearchPair}

@p
function NatSet.SearchPair(X: integer; var Index: integer): boolean;
var
   L, H, I, C: integer;
begin
   SearchPair := False;
   L := 0;
   H := Count - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareInt(Items^[I].X, X);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            SearchPair := True;
            if not Duplicates then L := I;
         end;
      end;
   end;
   Index := L;
end;

@ \node{Copy constructor.}
We can copy the contents of another |NatSet| into the caller. This
mutates the caller, but leaves the given |NatSet| unchanged.

@p
constructor NatSet.CopyNatSet(const fFunc: NatSet);
begin
   Init(fFunc.Limit,fFunc.Delta);
   Move(fFunc.Items^,Items^,fFunc.Limit*SizeOf(IntPair));
   Count:=fFunc.Count;
end;

@ \node{Move constructor.}
We can also \emph{move} the contents of another |NatSet| into the
caller. This will mutate the other |NatSet| to have |nil| items and 0 capacity.
 
@p
constructor NatSet.MoveNatSet(var fFunc: NatSet);
begin
   Init(fFunc.Limit,fFunc.Delta);
   Self:=fFunc;
   fFunc.DeleteAll;
   fFunc.Limit:=0;
   fFunc.Items:=nil;
end;

@ \node{Union operation.}
We can merge another |NatSet| into the caller.

@p
procedure NatSet.EnlargeBy(const fAnother: NatSet);
var I: integer;
begin
   for I:=0 to fAnother.Count-1 do
      InsertElem(fAnother.Items^[i].X);
end;

@ \node{Set complement.}
We can destructively remove from the caller all elements appearing in
|fAnother| nat set.

@p
procedure NatSet.ComplementOf(const fAnother: NatSet);
var I: integer;
begin
   for I:=0 to fAnother.Count-1 do
      DeleteElem(fAnother.Items^[i].X);
end;

@ \node{Take intersection.} This computes |Self := Self @t$\cap$@> Other|

@p
procedure NatSet.IntersectWith(const fAnother: NatSet);
var k: integer;
begin
   k:=0;
   while k < Count do
      if not fAnother.HasInDom(Items^[k].X) then
         AtDelete(k)
      else inc(k);
end;

@ \node{Insert an element.} We can insert $X = 0$ into the caller.

@p
procedure NatSet.InsertElem(X:integer);
var lIntPair: IntPair;
begin
   lIntPair.X:=X;
   lIntPair.Y:=0;
   Insert(lIntPair);
end;

@ \node{Deleting an element.} Similarly, we can delete the first
element of the form $X=Y$ for some $Y$.

@p
procedure NatSet.DeleteElem(fElem:integer);
var I: integer;
begin
   if SearchPair(fElem, I) then AtDelete(I);
end;

@ We can test if an element $X$ is in the domain of the caller.

\label{NatSet.HasInDom}

@p
function NatSet.HasInDom(fElem:integer): boolean;
var I: integer;
begin
   HasInDom:=SearchPair(fElem, I);
end;

@ \node{Set equality predicate.} This assumes that there are no
duplicate entries in a |NatSet| data structure.

@p
function NatSet.IsEqualTo(const fFunc: NatSet): boolean;
var I: integer;
begin
   IsEqualTo:=false;
   if Count <> fFunc.Count then exit;
   for I:=0 to Count-1 do if not Equals(Items^[I],fFunc.Items^[I]) then exit;
   IsEqualTo:=true;
end;

@ \node{Subset predicate.}
The comment is Polish for (according to Google translate): ``If we're
checking if a small function is contained within a large one,
commenting it out might be better.'' There is a commented out function
which I removed.

@p
function NatSet.IsSubsetOf(const fFunc: NatSet): boolean;
var i,j,k,c: integer;
 {Jezeli sprawdzamy, czy mala funkcja jest zawarta w duzej, to to wykomentowane
   moze byc lepsze}
begin
   IsSubsetOf:=false;
   c:=fFunc.Count;
   if c < Count then exit;
   j:=0;
   for i:=0 to Count-1 do
   begin
      k:=Items^[i].X;
      while (j < c) and (fFunc.Items^[j].X < k) do inc(j);
      if (j = c) or not Equals(fFunc.Items^[j],Items^[i]) then exit;
   end;
   IsSubsetOf:=true;
end;

@ \node{Superset predicate.} This just takes advantage of the fact
that $Y\supseteq X$ is the same as $X\subseteq Y$, then use the subset
predicate. 

@p
function NatSet.IsSupersetOf(const fFunc: NatSet): boolean;
begin
   IsSupersetOf:=fFunc.IsSubsetOf(Self);
end;

@ \node{Test if two sets are disjoint.}
This iterates over the smaller of the two sets, checking if every
element in the smaller set \emph{does not} appear in the larger set.

@p
function NatSet.Misses(const fFunc: NatSet): boolean;
var I,k: integer;
begin
   if Count > fFunc.Count then
   begin
      for k:=0 to fFunc.Count-1 do
         if SearchPair(fFunc.Items^[k].X,I) then begin Misses:=false; exit @+ end
   end
   else
   begin
      for k:=0 to Count-1 do
         if fFunc.SearchPair(Items^[k].X,I) then begin Misses:=false; exit @+ end;
   end;
   Misses:=true;
end;

@ \node{Index for an element.} This searches for the index associated
with relations of the form $X = Y$. If any such relation appears,
return its index. Otherwise, return $-1$.

It leaves the caller unmodified, so it is a pure function.

@p
function NatSet.ElemNr(X:integer): integer;
var I: integer;
begin
   ElemNr:=-1;
   if SearchPair(X, I) then ElemNr:=I;
end;

@* [S] Function of natural numbers.
The |NatFunc| is used in the analyzer, equalizer, unifier,
and elsewhere. Its destructor is the only place where |nConsistent := false|.

@<Public interface for \texttt{mobjects.pas}@>=
   NatFuncPtr = ^NatFunc; @/
   NatFunc = object(NatSet) @t\1@> @/
      nConsistent: boolean;
      constructor InitNatFunc(ALimit, ADelta: integer); @t\2@>
      constructor CopyNatFunc(const fFunc: NatFunc); @t\2@>
      constructor MoveNatFunc(var fFunc: NatFunc); @t\2@>
      constructor LCM(const aFunc1,aFunc2: NatFunc); @t\2@>
      procedure Assign(X,Y:integer); virtual; @t\2@>
      procedure Up(X: integer); virtual; @t\2@>
      procedure Down(X: integer); virtual; @t\2@>
      function Value(fElem: integer): integer; virtual; @t\2@>
      procedure Join(const fFunc: NatFunc); @t\2@>
      destructor Refuted; virtual; @t\2@>
      procedure EnlargeBy(fAnother:NatFuncPtr); {? virtual;?} @t\2@>
      function JoinAtom(fLatAtom:NatFuncPtr): NatFuncPtr; @t\2@>
      function CompareWith(const fNatFunc:NatFunc): integer; @t\2@>
      function WeakerThan(const fNatFunc:NatFunc): boolean; @t\2@>
      function IsMultipleOf(const fNatFunc:NatFunc): boolean; @t\2@>
      procedure Add(const aFunc:NatFunc); @t\2@>
      function CountAll: integer; virtual; @t\2\2\2@>
   end;

@ \node{Constructors.} We have the basic constructors for an empty
|NatFunc|, a copy constructor, and a move constructor. The move
constructor is destructive on the supplied argument.

@<|NatFunc| implementation@>=
constructor NatFunc.InitNatFunc(ALimit, ADelta: integer);
begin
   inherited Init(ALimit, ADelta);
   nConsistent:=true;
end; @#

constructor NatFunc.CopyNatFunc(const fFunc: NatFunc);
begin
   Init(fFunc.Limit,fFunc.Delta);
   Move(fFunc.Items^,Items^,fFunc.Limit*SizeOf(IntPair));
   Count:=fFunc.Count;
   nConsistent:=fFunc.nConsistent;
end; @#

constructor NatFunc.MoveNatFunc(var fFunc: NatFunc);
begin
   Init(fFunc.Limit,fFunc.Delta);
   Self:=fFunc;
   fFunc.DeleteAll;
   fFunc.Limit:=0;
   fFunc.Items:=nil;
end;

@ \node{Constructor (LCM).}
The least common multiple between two |NatFunc| objects is another way
to construct a |NatFunc| instance. This seems to be the LCM in the
sense of commutative rings (if $x$ and $y$ are elements of a
commutative ring $R$, then $\lcm(x,y)$ is such that $x$ divides
$\lcm(x,y)$ and $y$ divides $\lcm(x,y)$ --- moreover, $\lcm(x,y)$ is
the smallest such quantity, in the sense that $\lcm(x,y)$ divides any
other such quantity).

For the ring (or ringoid) $\NN^{\NN}$, this amounts to
$$\lcm(f,g)=\{\,(x,y)\mid \exists y_{1},y_{2}, (x,y_{1})\in f, (x,y_{2})\in g, y=\lcm(y_{1},y_{2})\,\},$$
with the condition that when $y_{1}=0$, $y=y_{2}$ (and similarly
$y_{2}=0$ implies $y=y_{1}$).

@p
constructor NatFunc.LCM(const aFunc1,aFunc2: NatFunc);
var i,j,m: integer;
begin
   m:=aFunc2.Delta;
   if aFunc1.Delta > m then m:=aFunc1.Delta;
   InitNatFunc(aFunc1.Limit+aFunc2.Limit,m);
   i:=0; j:=0;
   while (i < aFunc1.Count) and (j < aFunc2.Count) do
      case CompareInt(aFunc1.Items^[i].X,aFunc2.Items^[j].X) of
         -1: begin Insert(aFunc1.Items^[i]); inc(i) @+ end;
         0:
            begin {$m = \max(f(i), g(i)$}
               m:=aFunc1.Items^[i].Y; 
               if aFunc2.Items^[j].Y > m then m:=aFunc2.Items^[j].Y;
               Assign(aFunc1.Items^[i].X,m); {destructively set $f(i)\gets m$}
               inc(i); inc(j);
            end;
         1: begin Insert(aFunc2.Items^[j]); inc(j) @+ end;
      endcases;
   if i >= aFunc1.Count then
      for j:=j to aFunc2.Count-1 do Insert(aFunc2.Items^[j])
   else
      for i:=i to aFunc1.Count-1 do Insert(aFunc1.Items^[i]);
end;

@ \node{Extend a natural function.} We can extend a natural function
to assign a value $y$ to a place where it is not yet defined $x\notin\dom(f)$.

We should recall |HasInDom| (\section\xref{NatSet.HasInDom}) which
depends on |SearchPair| (\section\xref{NatSet.SearchPair}) is relevant.
When trying to assign a different value $y$ to an already defined
$f(x)\neq y$, then we have refuted something.

@p
procedure NatFunc.Assign(X,Y:integer);
var lIntPair: IntPair;
begin
   if nConsistent then
   begin
      if HasInDom(X) and (Value(X) <> Y) then begin Refuted; exit @+ end;
      lIntPair.X:=X; lIntPair.Y:=Y;
      Insert(lIntPair);
   end;
end;

@ \node{Increment $f(x)$.}
Given a |NatFunc| object $f$, and an integer $x$, |f.Up(x)| will
\enumerate
\item If $x\in\dom(f)$, then update the value $f(x)\geq f(x)+1$
\item Otherwise, $x\notin\dom(f)$, so this corresponds to $f(x)=0$,
  then we mutate $f(x)\gets 1$.
\endenumerate

@p
procedure NatFunc.Up(X: integer);
var I: integer; lIntPair: IntPair;
begin
   if nConsistent then
   begin
      if SearchPair(X, I) then
         inc(Items^[I].Y)
      else
      begin lIntPair.X:=X; lIntPair.Y:=1;
      Insert(lIntPair);
      end;
   end;
end;

@ \node{Decrement $f(x)$.}
Given a |NatFunc| object $f$, and an integer $x$, |f.Down(x)| will
\enumerate
\item If $x\in\dom(f)$, then update the value $f(x)\geq f(x)-1$
      and if this is then zero, remove it from the function.
\item Otherwise, $x\notin\dom(f)$, so this corresponds to $f(x)=0$,
  and we cannot mutate $f(x)\gets-1$ without making it no longer
  natural-valued. So we raise an error.
\endenumerate

@p
procedure NatFunc.Down(X: integer);
var I: integer;
begin
   if nConsistent then
   begin
      if SearchPair(X, I) then
      begin
         dec(Items^[I].Y);
         if Items^[I].Y = 0 then AtDelete(I);
      end
      else NatSetError(coConsistentError,0);
   end;
end;

@ Getting the value of $f(x)$ when $x\in\dom(f)$.
When $x\notin\dom(f)$, raise an error.

@p
function NatFunc.Value(fElem: integer): integer;
var I: integer;
begin
   if SearchPair(fElem, I) then Value:=Items^[I].Y
   else NatSetError(coDuplicate,0);
end;

@ \node{Destructor.} We usually try to extend partial functions on
$\NN$, but if we end up trying to extend where it is already defined
to a different value, then we arrive at an inconsistent extension. It
is referred to as a ``refuted'' situation.

@p
destructor NatFunc.Refuted;
begin inherited Done; nConsistent:=false end;

@ \node{Join.} For two partial functions $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$, we form $f\cup g$ provided
$$f\cap g=f\vert_{\dom(f\cap g)}=g\vert_{\dom(f\cap g)}.$$
That is to say, for all $x\in\dom(f)\cap\dom(g)$, we have $f(x)=g(x)$.

The comment is in Polish, which Google translates as:
``It seems that the |Join| and |EnlargeBy| procedures below do the
same thing. |EnlargeBy| should be faster for small collections. If
not, it's not worth the code waste and can be discarded. On the other
hand, these procedures are primarily intended for (very) small
collections.''

Also worth observing, this tests for consistency in the other |NatFunc|.


@p
{Wyglada na to, ze ponizej podane procedury "Join" i "EnlargeBy"
  robia to samo, "EnlargeBy" powinna byc szybsza dla malych kolekcji.
  Jezeli tak nie jest nie warto tracic kodu i mozna ja wyrzucic.
  Z drugiej strony procedury te maja byc glownie stosowane do
  (bardzo) malych kolekcji.
}

procedure NatFunc.Join(const fFunc: NatFunc);
var I,k: integer;
begin
   if nConsistent then
   begin
      if not fFunc.nConsistent then begin Refuted; exit @+ end;
      for k:=0 to fFunc.Count-1 do
         if SearchPair(fFunc.Items^[k].X,I) then
         begin
            if not Equals(Items^[I],fFunc.Items^[k]) then
            begin Refuted; exit @+ end;
         end
         else Insert(fFunc.Items^[k]);
   end;
end;
@ This function performs the same task as the previous one (i.e., it
merges another partial function into the caller, provided it is
consistent on overlap).

@p
procedure NatFunc.EnlargeBy(fAnother:NatFuncPtr); {? virtual;?}
var i,j,lCount,lLimit:integer; lItems:IntPairListPtr;
begin
   if nConsistent then
   begin if not fAnother^.nConsistent then begin Refuted; exit @+ end;
   if fAnother^.Count = 0 then exit;
   lCount:=Count;
   lItems:=Items;
   lLimit:=Limit;
   Limit:=0;
   Count:=0;
   SetLimit(lCount+fAnother^.Count);
   i:=0;
   j:=0;
   while (i < lCount) and (j < fAnother^.Count) do
      case CompareInt(lItems^[i].X,fAnother^.Items^[j].X) of
         -1: begin Insert(lItems^[i]); inc(i) @+ end;
         0: begin
               if Equals(lItems^[i],fAnother^.Items^[j]) then Insert(lItems^[i])
               else begin Refuted; FreeMem(lItems,lLimit*SizeOf(IntPair)); exit @+ end;
               inc(i);
               inc(j);
            end;
         1: begin Insert(fAnother^.Items^[j]); inc(j) @+ end;
      endcases;
   if i >= lCount then
      for j:=j to fAnother^.Count-1 do Insert(fAnother^.Items^[j])
   else for i:=i to lCount-1 do Insert(lItems^[i]);
   SetLimit(0); FreeMem(lItems,lLimit*SizeOf(IntPair));
   end;
end;

@ We want to join two partial functions $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$ without accidentally mutating either $f$ or $g$ to
be refuted. To do this, we copy the caller, then enlarge it with the
other partial function. If the result is consistent, then return
it. Otherwise, return |nil|.

This leaves both the caller and |fLatAtom| unchanged, so it's a pure
function. 

@p
function NatFunc.JoinAtom(fLatAtom:NatFuncPtr): NatFuncPtr;
var lEval: NatFunc;
begin
   JoinAtom:=nil;
   lEval.CopyNatFunc(Self);
   lEval.EnlargeBy(fLatAtom);
   if lEval.nConsistent then JoinAtom:=NatFuncPtr(lEval.CopyObject);
end;

@ \node{Comparing partial functions.}
Given two partial functions, $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$, we want to compare them. We first start with
comparing $\magnitude{f}$ against $\magnitude{g}$. If they are not
equal, then this is the result.

When $\magnitude{f}=\magnitude{g}$, iterate through each
$x\in\dom(f)$, and then compare $f(x)$ against $g(x)$. If $f(x)<g(x)$,
then return $-1$. If $f(x)>g(x)$, then return $+1$. Otherwise keep
iterating until we have examined all of $\dom(f)$, and then we return
$0$.

\label{CompareNatFunc}

@p
function CompareNatFunc(aKey1, aKey2: Pointer): integer;
var i,lInt: integer;
begin
   with NatFuncPtr(aKey1)^ do
   begin
      lInt:=CompareInt(Count,NatFuncPtr(aKey2)^.Count);
      if lInt <> 0 then begin CompareNatFunc:=lInt; exit @+ end;
      for i:=0 to Count-1 do
      begin
         lInt:=CompareInt(Items^[i].X,NatFuncPtr(aKey2)^.Items^[i].X);
         if lInt <> 0 then begin CompareNatFunc:=lInt; exit @+ end;
         lInt:=CompareInt(Items^[i].Y,NatFuncPtr(aKey2)^.Items^[i].Y);
         if lInt <> 0 then begin CompareNatFunc:=lInt; exit @+ end;
      end;
   end;
   CompareNatFunc:=0;
end;

@ Let $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$ be partial functions. We say that $f$ is
``weaker'' than $g$ when $\magnitude{f}\leq\magnitude{g}$ and for each
$x\in\dom(f)$ we have $f(x)=g(x)$. If there is some $x\in\dom(f)$ such
that $x\notin\dom(g)$, then $f$ is not weaker than $g$.

If there is some $x\in\dom(f)$ such that $x\in\dom(g)$ and $f(x)\neq g(x)$,
then $f$ is not weaker than $g$.

@p
function NatFunc.WeakerThan(const fNatFunc:NatFunc): boolean;
var i,k:integer;
begin
   WeakerThan:=false;
   if Count <= fNatFunc.Count then
   begin
      for k:=0 to Count-1 do
      begin
         i:=Items^[k].X;
         if not fNatFunc.HasInDom(i) then exit;
         if Items^[k].Y <> fNatFunc.Value(i) then exit;
      end;
      WeakerThan:=true;
   end;
end;

@ Let $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$ be partial functions. We will say that $f$ is a
``multiple'' of $g$ if $\magnitude{g}\leq\magnitude{f}$ and for each
$x\in\dom(g)$ we have $x\in\dom(f)$ and $g(x)\leq f(x)$.

There was some commented code for this function, which I removed.

@p
function NatFunc.IsMultipleOf(const fNatFunc:NatFunc): boolean;
var k,l: integer;
begin
   IsMultipleOf:=false;
   if fNatFunc.Count <= Count then
   begin
      for k:=0 to fNatFunc.Count-1 do
	     if not HasInDom(fNatFunc.Items^[k].X) then exit
	     else
	        if Value(fNatFunc.Items^[k].X)<fNatFunc.Items^[k].Y then exit;
     
      IsMultipleOf:=true;
   end;
end;

@ \node{Comparing partial functions.} Let $f\colon\NN\pto\NN$ and
$g\colon\NN\pto\NN$ be partial functions.

If $\magnitude{f}\leq\magnitude{g}$, for each $x\in\dom(f)$ if
$x\notin\dom(g)$, then return 0.
If $f(x)\neq g(x)$, then return 0. Otherwise return $-1$.

Else if $\magnitude{g}\leq\magnitude{f}$, for each $x\in\dom(g)$ if
$x\notin\dom(f)$, then return 0.
If $f(x)\neq g(x)$, then return 0. Otherwise return $+1$.

This is difficult for me to grasp. It does not seem to adequately
satisfy |compare(f,g) = -compare(g,f)|, which is catastrophic. It is
also unclear to me that this is transitive or reflexive. So it seems
like it has no desirable properties.

I am confused why there is this function and also another similarly
named function (\section\xref{CompareNatFunc}).

The comment in Polish translates as, ``Using |WeakerThan| you can shorten |CompareWith|!!!''
At least, according to Google, that's the translation.

@p
{Uzywajac WeakerThan mozna skrocic CompareWith !!!}

function NatFunc.CompareWith(const fNatFunc:NatFunc): integer;
var i,k:integer;
begin
   CompareWith:=0;
   if Count <= fNatFunc.Count then
   begin
      for k:=0 to Count-1 do
      begin
         i:=Items^[k].X;
         if not fNatFunc.HasInDom(i) then exit;
         if Items^[k].Y <> fNatFunc.Value(i) then exit;
      end;
      CompareWith:=-1; exit;
   end;
   if fNatFunc.Count <= Count then
   begin
      for k:=0 to fNatFunc.Count-1 do
      begin
         i:=fNatFunc.Items^[k].X;
         if not HasInDom(i) then exit;
         if fNatFunc.Items^[k].Y <> Value(i) then exit;
      end;
      CompareWith:=1; exit;
   end;
end;

@ Let $f\colon\NN\pto\NN$ and $g\colon\NN\pto\NN$ be partial
functions. Then we define $f+g\colon\NN\pto\NN$ to be the partial
function defined on $\dom(f+g)=\dom(f)\cup\dom(g)$ such that for each
$x\in\dom(f\cap g)$ we have $(f+g)(x)=f(x)+g(x)$, and for each
$x\in\dom(f)\setminus\dom(g)$ we have $(f+g)(x)=f(x)$, and for each
$x\in\dom(g)\setminus\dom(f)$ we have $(f+g)(x)=g(x)$.

There is some subtlety in the implementation because we have to check
for overflows, i.e., when
$$g(x)\geq\\{High}(\\{integer})-f(x)$$
for each $x\in\dom(f)\cap\dom(g)$. 

@p
procedure NatFunc.Add(const aFunc:NatFunc);
var k,l:integer;
begin
   l:=0;
   for k:=0 to aFunc.Count-1 do
   begin
      while (l < Count) and (Items^[l].X < aFunc.Items^[k].X) do inc(l);
      if (l < Count) and (Items^[l].X = aFunc.Items^[k].X) then
      begin
         if @<Has overflow occurred in |NatFunc.Add|?@> then RunError(215);
         inc(Items^[l].Y,aFunc.Items^[k].Y);
      end
      else AtInsert(l,aFunc.Items^[k]);
   end;
end;

@ An overflow occurs if $f(x)+g(x)$ is greater than |High(integer)|
(the maximum value for an integer).

@<Has overflow occurred in |NatFunc.Add|?@>=
Items^[l].Y > (High(integer)-aFunc.Items^[k].Y)

@ \node{Sum values of partial function.} For a partial function
$f\colon\NN\pto\NN$, we have
$$\\{CountAll}(f) = \sum_{n\in\dom(f)}f(n).$$

@<|NatFunc| implementation@>=
function NatFunc.CountAll: integer;
var k,l: integer;
begin
   l:= 0;
   for k:=0 to Count-1 do inc(l,Items^[k].Y);
   CountAll:=l;
end;

@* [S] Sequences of natural numbers.

@<Public interface for \texttt{mobjects.pas}@>=   
   NatSeq = object(NatFunc) @t\1@> @/
      constructor InitNatSeq(ALimit, ADelta: integer); @t\2@>
      procedure InsertElem(X:integer); virtual; @t\2@>
      function Value(fElem: integer): integer; virtual; @t\2@>
      function IndexOf(Y: integer): integer; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<NatSeq implementation@>=
constructor NatSeq.InitNatSeq(ALimit, ADelta: integer);
begin
   inherited Init(ALimit, ADelta);
   nConsistent:=true;
end;

@ If we have a finite sequence $(a_{0},\dots,a_{n-1})$, then inserting
an element $x$ into it will yield the finite sequence $(a_{0},\dots,a_{n-1},x)$.

@p
procedure NatSeq.InsertElem(X:integer);
var lPair: IntPair;
begin
   lPair.X:=Count;
   lPair.Y:=X;
   inherited Insert(lPair);
end;

@ The value for the $k^{th}$ element in a sequence
$(a_{0},\dots,a_{n-1})$ is $a_{k}$ when $0\leq k<n$, and we take it to
be $0$ otherwise.

@p
function NatSeq.Value(fElem: integer): integer;
begin
   if {(0<=ind) and}(fElem<count) then
      Value:=Items^[fElem].Y
   else Value:=0;
end;

@ The index for $a_{i}$ in the sequence $(a_{0},\dots,a_{n-1})$ is $i$
when $a_{i}$ is in the sequence. Otherwise, we return $-1$.

@p
function NatSeq.IndexOf(Y: integer): integer;
var lResult: integer;
begin
   for lResult :=Count-1 downto 0 do
      if Items^[lResult].Y = Y then
      begin IndexOf:=lResult; exit end;
   IndexOf:=-1;
end;

@* [S] Integer sequences.

@<Public interface for \texttt{mobjects.pas}@>=
   IntegerListPtr = ^IntegerList; @/
   IntegerList = array[0..MaxIntegerListSize- 1] of integer; @#
   
   PIntSequence = ^IntSequence; @/
   IntSequencePtr = PIntSequence; @/
   IntSequence = object(MObject)  @t\1@> @/
      fList: IntegerListPtr;
      fCount: integer;
      fCapacity: integer;
      constructor Init(aCapacity: integer); @t\2@>
      constructor CopySequence(const aSeq: IntSequence); @t\2@>
      constructor MoveSequence(var aSeq: IntSequence); @t\2@>
      destructor Done; virtual; @t\2@>
      procedure IntListError(Code, Info: integer); virtual; @t\2@>
      procedure SetCapacity(aCapacity: integer); virtual; @t\2@>
      procedure Clear; virtual; @t\2@>
      function Insert(aInt: integer): integer; virtual; @t\2@>
      procedure AddSequence(const aSeq: IntSequence); virtual; @t\2@>
      function IndexOf(aInt: integer): integer; virtual; @t\2@>
      procedure AtDelete(aIndex: integer); virtual; @t\2@>
      function Value(aIndex:integer): integer; virtual; @t\2@>
      procedure AtInsert(aIndex,aInt: integer); virtual; @t\2@>
      procedure AtPut(aIndex,aInt: integer); virtual; @t\2\2\2@>
   end; @#

@ We will need to quicksort lists of integers. This will mutate the
|aList| argument, making it sorted. See also \section\xref{ListQuickSort}
and \section\xref{MStringList.QuickSort}.

This procedure does not appear to be used anywhere in Mizar.

\label{IntQuickSort}

@^Quicksort@>

@<|IntSequence| implementation@>=
{integer Sequences \AM\ Sets}

procedure IntQuickSort(aList: IntegerListPtr; L, R: integer);
var I, J,P,lTemp: integer;
begin
   repeat
      I := L;
      J := R;
      P := aList^[(L + R) shr 1];
      repeat
         while CompareInt(aList^[I], P) < 0 do inc(I);
         while CompareInt(aList^[J], P) > 0 do Dec(J);
         if I <= J then
         begin
            lTemp := aList^[I];
            aList^[I] := aList^[J];
            aList^[J] := lTemp;
            inc(I);
            Dec(J);
         end;
      until I > J;
      if L < J then IntQuickSort(aList, L, J);
      L := I;
   until I >= R;
end;

@ \node{Constructor.} We can create an empty sequence of integers,
with a given capacity.

@p
constructor IntSequence.Init(aCapacity: integer);
begin
   inherited Init;
   fList := nil;
   fCount := 0;
   fCapacity := 0;
   SetCapacity(aCapacity);
end;

@ \node{Copy constructor.} We can copy an existing sequence.

@p
constructor IntSequence.CopySequence(const aSeq: IntSequence);
begin
   Init(aSeq.fCapacity);
   AddSequence(aSeq);
end;

@ \node{Move constructor.} We can create a new array in heap, and move
all the elements from a given sequence over, then free up the given sequence.

@p
constructor IntSequence.MoveSequence(var aSeq: IntSequence);
begin
   inherited Init;
   fCount := aSeq.fCount;
   fCapacity := aSeq.fCapacity;
   fList := aSeq.fList;
   aSeq.fCount := 0;
   aSeq.fCapacity:=0;
   aSeq.fList:=nil;
end;

@ \node{Destructor.}

@p
destructor IntSequence.Done;
begin
   inherited Done;
   fCount := 0;
   SetCapacity(0);
end;

@ \node{Appending an element.}
Given a finite sequence of integers $(a_{0},\dots,a_{n-1})$, we can
append a value $x$ to produce the finite sequence $(a_{0},\dots,a_{n-1},x)$.
This will mutate the caller.

@p
function IntSequence.Insert(aInt: integer): integer;
begin
   if fCount = fCapacity then
      SetCapacity(fCapacity + GrowLimit(fCapacity));
   fList^[fCount]:=aInt;
   Insert:=fCount;
   inc(fCount);
end;

@ \node{Appending a sequence.}
This takes a finite sequence $(a_{0},\dots,a_{n-1})$ and another
finite sequence $(b_{0},\dots,b_{m-1})$, then forms a new finite
sequence
$(a_{0},\dots,a_{n-1},b_{0},\dots,b_{m-1})$. It mutates the caller.

@p
procedure IntSequence.AddSequence(const aSeq: IntSequence);
var I,r: integer;
begin
   for I := 0 to aSeq.fCount - 1 do
      r:=Insert(aSeq.fList^[I]);
end;

@ \node{Clearing a sequence.}

@p
procedure IntSequence.Clear;
begin
   if fCount <> 0 then
   begin
      fCount := 0;
      SetCapacity(0);
   end;
end;

@ \node{Delete entry in sequence.}
Removing the $i^{th}$ entry in the sequence
$(a_{0},\dots,a_{i-1},a_{i},a_{i+1},\dots,a_{n-1})$ yields the finite
sequence $(a_{0},\dots,a_{i-1},a_{i+1},\dots,a_{n-1})$.
If $i<0$ or $n-1<i$, then we raise an error.

@p
procedure IntSequence.AtDelete(aIndex: integer);
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      IntListError(coIndexError, aIndex);
   Dec(fCount);
   if aIndex < fCount then
      Move(fList^[aIndex+1], fList^[aIndex], (fCount-aIndex)*SizeOf(integer));
end;

@ We report errors using this helper function.

@p
procedure IntSequence.IntListError(Code, Info: integer);
begin
   RunError(212 - Code); {! poprawic bledy}
end;

@ Let $(a_{0},\dots,a_{n-1})$ be a finite sequence. The value at index
$i$ is $a_{i}$ when $0\leq i\leq n-1$, otherwise it raises an error.

@p
function IntSequence.Value(aIndex: integer): integer;
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      IntListError(coIndexError, aIndex);
   Value := fList^[aIndex];
end;

@ For a finite sequence $(a_{0},\dots,a_{n-1})$ and a value $x$, if
there is some entry $a_{i}=x$ with $a_{j}\neq x$ for $j<i$, then
return $i$. Otherwise return $-1$.

@p
function IntSequence.IndexOf(aInt: integer): integer;
var lResult: integer;
begin
   for lResult :=fCount-1 downto 0 do
      if fList^[lResult] = aInt then
      begin IndexOf:=lResult; exit end;
   IndexOf:=-1;
end;

@ Given a finite sequence $(a_{0},\dots,a_{n-1})$, an index $i$, and a
value $x$:
\enumerate
\item If $i<0$ or $i$ is too big, raise an error.
\item If the logical size of the sequence equals its capacity,
then grow the underlying array.
\item If $i$ is less than the logical size $i<n-1$, then shift
all the entries to the right by 1 so we have $(a_{0},\dots,a_{i-1},0,a_{i},\dots,a_{n-1})$
\item Set the $i^{th}$ entry to $x$, so we end up with the caller becoming
$(a_{0},\dots,a_{i-1},x,a_{i},\dots,a_{n-1})$.
\endenumerate

@p
procedure IntSequence.AtInsert(aIndex,aInt: integer);
begin
   if (aIndex < 0) or (aIndex > fCount) then
      IntListError(coIndexError, aIndex);
   if fCount = fCapacity then
      SetCapacity(fCapacity + GrowLimit(fCapacity));
   if aIndex < fCount then
      Move(fList^[aIndex], fList^[aIndex+1],(fCount-aIndex)*SizeOf(integer));
   fList^[aIndex]:=aInt;
   inc(fCount);
end;

@ \node{Update entry of sequence.}
For a sequence $(a_{0},\dots,a_{n-1})$, an index $i$, and a new value
$x$, if $0\leq i\leq n-1$ then we set $a_{i}\gets x$. Otherwise we
have the index be out of bounds ($0<i$ or $n-1<i$), and we should
raise an error.

@p
procedure IntSequence.AtPut(aIndex,aInt: integer);
begin
   if (aIndex < 0) or (aIndex >= fCount) then
      IntListError(coIndexError, aIndex);
   fList^[aIndex]:=aInt;
end;

@ \node{Grow the underlying array.}
When we want to increase (or decrease) the capacity of the underlying
array, we invoke this function. It will copy over the relevant contents.

@p
procedure IntSequence.SetCapacity(aCapacity: integer);
var lList: IntegerListPtr;
begin
   if aCapacity < fCount then aCapacity := fCount;
   if aCapacity > MaxListSize then aCapacity := MaxListSize;
   if aCapacity <> fCapacity then
   begin
      if aCapacity = 0 then lList := nil else
      begin
         GetMem(lList, aCapacity * SizeOf(integer));
         if (fCount <> 0) and (fList <> nil) then
            Move(fList^, lList^, fCount * SizeOf(integer));
      end;
      if fCapacity <> 0 then
         FreeMem(fList, fCapacity * SizeOf(integer));
      fList := lList;
      fCapacity := aCapacity;
   end;
end;

@* [S] Integer sets.

@<Public interface for \texttt{mobjects.pas}@>=
   PIntSet = ^IntSet; @/
   IntSetPtr = pIntSet;  @/
   IntSet = object(IntSequence)  @t\1@> @/
      function Insert(aInt: integer): integer; virtual; @t\2@>
      function DeleteInt(aInt: integer): integer; virtual; @t\2@>
      function Find(aInt: integer; var aIndex: integer): boolean; virtual; @t\2@>
      function IndexOf(aInt: integer): integer; virtual; @t\2@>
      procedure AtInsert(aIndex,aInt: integer); virtual; @t\2@>
      function IsInSet(aInt:integer): boolean; virtual; @t\2@>
      function IsEqualTo(const aSet: IntSet): boolean; virtual; @t\2@>
      function IsSubsetOf(const aSet: IntSet): boolean; virtual; @t\2@>
      function IsSupersetOf(var aSet: IntSet): boolean; virtual; @t\2@>
      function Misses(var aSet: IntSet): boolean; virtual; @t\2\2\2@>
   end;

@ When inserting an element $x$ into a set $A$, we check if $x\in A$
is already a member. If so, then we're done.

Otherwise, we ensure the capacity of the set can handle adding another
element. Then we shift all elements greater than $x$ over to the right
by 1. We finally insert $x$ into the underlying array.

@<|IntSet| Implementation@>=
function IntSet.Insert(aInt: integer): integer;
var lIndex: integer;
begin
   if Find(aInt, lIndex) then {already contains the element?}
   begin Insert:=lIndex; exit @+ end;
   if fCount = fCapacity then
      SetCapacity(fCapacity + GrowLimit(fCapacity));
   if lIndex < fCount then
      Move(fList^[lIndex], fList^[lIndex+1],(fCount-lIndex)*SizeOf(integer));
   fList^[lIndex]:=aInt;
   inc(fCount);
   Insert:=lIndex;
end;

@ Removing an element from a set. This will return the former index of
the element in the underlying array.

@p
function IntSet.DeleteInt(aInt: integer): integer;
var lIndex: integer;
begin
   DeleteInt:=-1;
   if Find(aInt, lIndex) then
   begin DeleteInt:=lIndex; AtDelete(lIndex) @+ end
end;

@ We can use bisection search to find an element |aInt| in the
underlying array. It will mutate |aIndex| to be where the entry should
be, and return |true| if the element is a member of the set (and
|false| otherwise).

@p
function IntSet.Find(aInt: integer; var aIndex: integer): boolean;
var L, H, I, C: integer;
begin
   Find := False;
   L := 0;
   H := fCount - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareInt(fList^[I], aInt);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Find := True;
            L := I; @+
         end;
      end;
   end;
   aIndex := L;
end;

@ We can find the index of an element (if it is present) by using
bisection search.

@p
function IntSet.IndexOf(aInt: integer): integer;
var lResult: integer;
begin
   if not Find(aInt, lResult) then lResult := -1;
   IndexOf:=lResult;
end;

@ The |AtInsert| method is ``grandfathered in'', but not supported, so
we raise an error if anyone tries using it.

@p
procedure IntSet.AtInsert(aIndex,aInt: integer);
begin
   IntListError(coSortedListError, 0);
end;

@ We can test if an integer is an element of the set, again just
piggie-backing off bisection search.

@p
function IntSet.IsInSet(aInt: integer): boolean;
var I: integer;
begin
   IsInSet:=Find(aInt, I);
end;

@ Testing if two finite sets $A$ and $B$ of integers are equal
requires $\card{A}=\card{B}$ and for each $x\in A$ we have $x\in B$.
If these conditions are not both met, then $A\neq B$.

@p
function IntSet.IsEqualTo(const aSet: IntSet): boolean;
var I: integer;
begin
   IsEqualTo:=false;
   if fCount <> aSet.fCount then exit;
   for I:=0 to fCount-1 do
      if fList^[I]<>aSet.fList^[I] then exit;
   IsEqualTo:=true;
end;

@ \node{Subset predicate.}
We can test $A\subset B$ by $\card{A}\leq\card{B}$ and for each $a\in A$
we have $a\in B$. 

@p
function IntSet.IsSubsetOf(const aSet: IntSet): boolean;
var i,j,lInt: integer;
begin
   IsSubsetOf:=false;
   if aSet.fCount < fCount then exit;
   j:=0; {index of $B$}
   for i:=0 to fCount-1 do {loop over $a\in A$}
   begin
      lInt:=fList^[i];
      while (j < aSet.fCount) and (aSet.fList^[j] < lInt) do inc(j);
      if (j = aSet.fCount) or (aSet.fList^[j]<>fList^[i]) then exit;
   end;
   IsSubsetOf:=true;
end;

@ \node{Superset predicate.} We have $A\supset B$ if $B\subset A$.

@p
function IntSet.IsSupersetOf(var aSet: IntSet): boolean;
begin
   IsSupersetOf:=aSet.IsSubsetOf(Self);
end;

@ \node{Test for disjointness.} We have $A\cap B=\emptyset$ if every
$a\in A$ is such that $a\notin B$.

@p
function IntSet.Misses(var aSet: IntSet): boolean;
var k: integer;
begin
   if fCount > aSet.fCount then
   begin
      for k:=0 to aSet.fCount-1 do
         if IsInSet(aSet.fList^[k]) then begin Misses:=false; exit @+ end
   end
   else
   begin
      for k:=0 to fCount-1 do
         if aSet.IsInSet(fList^[k]) then begin Misses:=false; exit @+ end;
   end;
   Misses:=true;
end;

@* [S] Partial Binary integer Functions.
We want to describe partial functions like $f\colon\ZZ\times\ZZ\pto\ZZ$.
These are encoded as finite sets of triples
$\{(x,y,f(x,y))\in\ZZ\times\ZZ\times\ZZ\}$. So we need to introduce
triples of integers.

@<Public interface for \texttt{mobjects.pas}@>=
   IntTripletListPtr = ^IntTripletList; @/
   IntTripletList = array[0..MaxIntTripletSize- 1] of IntTriplet; @#
   BinIntFuncPtr = ^BinIntFunc; @/
   BinIntFunc = object(MObject)  @t\1@> @/
      fList: IntTripletListPtr;
      fCount: integer;
      fCapacity: integer;
      constructor Init(aLimit: integer); @t\2@>
      procedure BinIntFuncError(aCode, aInfo: integer); virtual; @t\2@>
      destructor Done; virtual; @t\2@>@#
      
      procedure Insert(const aItem: IntTriplet); virtual; @t\2@>
      procedure AtDelete(aIndex: integer); @t\2@>
      procedure SetCapacity(aLimit: integer); virtual; @t\2@>
      procedure DeleteAll; @t\2@>
      function Search(X1,X2: integer; var aIndex: integer): boolean; virtual; @t\2@>
      function IndexOf(X1,X2:integer): integer; @t\2@>
      constructor CopyBinIntFunc(var aFunc: BinIntFunc); @t\2@> @#
      
      function HasInDom(X1,X2:integer): boolean; virtual; @t\2@>
      procedure Assign(X1,X2,Y:integer); virtual; @t\2@>
      procedure Up(X1,X2:integer); virtual; @t\2@>
      procedure Down(X1,X2:integer); virtual; @t\2@>
      function Value(X1,X2:integer): integer; virtual; @t\2@>
      procedure Add(const aFunc: BinIntFunc); virtual; @t\2@>
      function CountAll: integer; virtual; @t\2\2\2@>
   end;

@ We have a convenience function for reporting errors.

@<Partial Binary integer Functions@>=
procedure BinIntFunc.BinIntFuncError(aCode, aInfo: integer);
begin
   RunError(212 - aCode); @+
end;

@ \node{Constructor.} We initialize the empty partial function.

@p
constructor BinIntFunc.Init(aLimit: integer);
begin
   MObject.Init;
   fList := nil;
   fCount := 0;
   fCapacity := 0;
   SetCapacity(aLimit);
end;

@ \node{Destructor.}

@p
destructor BinIntFunc.Done;
begin
   fCount := 0;
   SetCapacity(0);
end;

@ If we have a partial function $f\colon\ZZ\times\ZZ\pto\ZZ$ and a
triple $(x,y,z)$, then check if $(x,y)\in\dom(f)$. If so, we're done.

Otherwise we add $f(x,y)=z$ to the partial function.

@p
procedure BinIntFunc.Insert(const aItem: IntTriplet);
var I: integer;
begin
   if not Search(aItem.X1,aItem.X2, I) then
   begin
      if (I < 0) or ( I > fCount) then
      begin
         BinIntFuncError(coIndexError,0);
         exit; @+
      end;
      if fCapacity = fCount then
         SetCapacity(fCapacity+ GrowLimit(fCapacity));
      if I <> fCount then
         Move(fList^[I], fList^[I+1],(fCount - I)*SizeOf(IntTriplet));
      fList^[I] := aItem;
      inc(fCount);
   end;
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$, we represent it as an array of
$\ZZ\times\ZZ\times\ZZ$. So we can remove the entry at index $i$ when
$0\leq i<\magnitude{f}$. Otherwise when $i<0$ or $\magnitude{f}\leq i$,
raise an error.

@p
procedure BinIntFunc.AtDelete(aIndex: integer);
var i: integer;
begin
   if (aIndex < 0) or (aIndex >= fCount) then
   begin
      BinIntFuncError(coIndexError,0);
      exit; @+
   end;
   if aIndex < fCount-1 then
      for i:=aIndex to fCount-2 do fList^[i]:=fList^[i+1];
   Dec(fCount);
end;

@ \node{Ensure capacity.}

@p
procedure BinIntFunc.SetCapacity(aLimit: integer);
var aItems: IntTripletListPtr;
begin
   if aLimit < fCount then aLimit := fCount;
   if aLimit > MaxIntTripletSize then ALimit := MaxIntTripletSize;
   if aLimit <> fCapacity then
   begin
      if ALimit = 0 then AItems := nil else
      begin
         GetMem(AItems, ALimit * SizeOf(IntTriplet));
         if (fCount <> 0) and (fList <> nil) then
            Move(fList^, aItems^, fCount * SizeOf(IntTriplet));
      end;
      if fCapacity <> 0 then FreeMem(fList, fCapacity * SizeOf(IntTriplet));
      fList := aItems;
      fCapacity := aLimit;
   end;
end;

@ Deleting all entries in a partial function $\ZZ\times\ZZ\pto\ZZ$
amounts to setting the logical size of the underlying dynamic array to zero.

@p
procedure BinIntFunc.DeleteAll;
begin
   fCount := 0; @+
end;

@ We can use bisection search to find an entry $(x_{1},x_{2})$ such
that $(x_{1},x_{2})\in\dom(f)$.

@p
function BinIntFunc.Search(X1,X2: integer; var aIndex: integer): boolean;
var
   L, H, I, C: integer;
begin
   Search := False;
   L := 0;
   H := fCount - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareIntPairs(fList^[I].X1, fList^[I].X2, X1, X2);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Search := True;
            L := I; @+
         end;
      end;
   end;
   aIndex := L;
end;

@ \node{Copy constructor.} This leaves |aFunc| unchanged, and clones
|aFunc|.

@p
constructor BinIntFunc.CopyBinIntFunc(var aFunc: BinIntFunc);
begin
   Init(aFunc.fCapacity);
   Move(aFunc.fList^,fList^,aFunc.fCapacity*SizeOf(IntTriplet));
   fCount:=aFunc.fCount;
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$ and $(x_{1},x_{2})$, find the
index for the underlying dynamic array $i$ such that it contains
$(x_{1},x_{2},f(x_{1},x_{2}))$. If there is no such entry, $i=-1$ is returned.

@p
function BinIntFunc.IndexOf(X1,X2:integer): integer;
var I: integer;
begin
   IndexOf:=-1;
   if Search(X1,X2, I) then IndexOf:=I;
end;

@ Test if $(x_{1},x_{2})\in\dom(f)$.

@p
function BinIntFunc.HasInDom(X1,X2:integer): boolean;
var I: integer;
begin
   HasInDom:=Search(X1,X2, I);
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$, and
$(x_{1},x_{2})\in\ZZ\times\ZZ$ and $y\in\ZZ$, try setting
$f(x_{1},x_{2})=y$ provided $(x_{1},x_{2})\notin\dom(f)$ or if
$(x_{1},x_{2},y)\in f$ already. If $f(x_{1},x_{2})\neq y$ already
exists, then raise an error.

@p
procedure BinIntFunc.Assign(X1,X2, Y:integer);
var lIntTriplet: IntTriplet;
begin
   if HasInDom(X1,X2) and (Value(X1,X2) <> Y) then
   begin
      BinIntFuncError(coDuplicate,0);
      exit
   end;
   lIntTriplet.X1:=X1;
   lIntTriplet.X2:=X2;
   lIntTriplet.Y:=Y;
   Insert(lIntTriplet);
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$ and $(x_{1},x_{2})\in\ZZ\times\ZZ$.
If $(x_{1},x_{2})\in\dom(f)$, then set $f(x_{1},x_{2})\gets f(x_{1},x_{2})+1$.
Otherwise set $f(x_{1},x_{2})\gets1$.

@p
procedure BinIntFunc.Up(X1,X2:integer);
var I: integer; lIntTriplet: IntTriplet;
begin
   if Search(X1,X2, I) then
      inc(fList^[I].Y)
   else
   begin
      lIntTriplet.X1:=X1;
      lIntTriplet.X2:=X2;
      lIntTriplet.Y:=1;
      Insert(lIntTriplet);
   end;
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$ and $(x_{1},x_{2})\in\ZZ\times\ZZ$.
If $(x_{1},x_{2})\in\dom(f)$, then set $f(x_{1},x_{2})\gets f(x_{1},x_{2})-1$.
Further, if $f(x_{1},x_{2})=0$, then remove it from the underlying
dynamic array.

Otherwise for $(x_{1},x_{2})\notin\dom(f)$, raise an error.

@p
procedure BinIntFunc.Down(X1,X2:integer);
var I: integer;
begin
   if Search(X1,X2, I) then
   begin
      dec(fList^[I].Y);
      if fList^[I].Y = 0 then AtDelete(I);
   end
   else BinIntFuncError(coConsistentError,0);
end;

@ Given $f\colon\ZZ\times\ZZ\pto\ZZ$, and $(x_{1},x_{2})\in\ZZ\times\ZZ$,
if $(x_{1},x_{2})\notin\dom(f)$ then raise an error.
Otherwise when $(x_{1},x_{2})\in\dom(f)$, return $f(x_{1},x_{2})$.

@p
function BinIntFunc.Value(X1,X2: integer): integer;
var I: integer;
begin
   if Search(X1,X2, I) then Value:=fList^[I].Y
   else BinIntFuncError(coDuplicate,0);
end;

@ Given two partial functions $f,g\colon\ZZ\times\ZZ\pto\ZZ$, compute
$f+g\colon\ZZ\times\ZZ\pto\ZZ$. This is defines by:
\enumerate
\item For $(x_{1},x_{2})\in\dom(f)\cap\dom(g)$, set $(f+g)(x_{1},x_{2})=f(x_{1},x_{2})+g(x_{1},x_{2})$
\item For $(x_{1},x_{2})\in\dom(f)\setminus\dom(g)$, set $(f+g)(x_{1},x_{2})=f(x_{1},x_{2})$
\item For $(x_{1},x_{2})\in\dom(g)\setminus\dom(f)$, set $(f+g)(x_{1},x_{2})=g(x_{1},x_{2})$.
\endenumerate

@p
{\textbf{TODO}: this is inefficient, since the search is repeated
         in the |Assign| method; fix this both here and in
         other similar methods}
procedure BinIntFunc.Add(const aFunc: BinIntFunc);
var k,l:integer;
begin
   for k:=0 to aFunc.fCount-1 do
      if Search( aFunc.fList^[k].X1, aFunc.fList^[k].X2, l) then
         inc( fList^[l].Y, aFunc.fList^[k].Y)
      else Assign( aFunc.fList^[k].X1, aFunc.fList^[k].X2, aFunc.fList^[k].Y);
end;

@ \node{Sum.} For $f\colon\ZZ\times\ZZ\pto\ZZ$, we compute
$$\\{CountAll}(f)=\sum_{(m,n)\in\dom(f)}f(m,n).$$

@p
function BinIntFunc.CountAll: integer;
var k,l: integer;
begin
   l:= 0;
   for k:=0 to fCount-1 do inc( l, fList^[k].Y);
   CountAll:= l;
end;

@* [S] Partial integers to Pair of integers Functions.

@<Public interface for \texttt{mobjects.pas}@>=
   Int2PairOfInt = record X,Y1,Y2: integer; end; @#
   
   Int2PairOfIntFuncPtr = ^Int2PairOfIntFunc; @/
   Int2PairOfIntFunc = object(MObject) @t\1@> @/
      fList: array of Int2PairOfInt;
      fCount: integer;
      fCapacity: integer;
      constructor Init(aLimit: integer); @t\2@>
      procedure Int2PairOfIntFuncError(aCode, aInfo: integer); virtual; @t\2@>
      destructor Done; virtual; @t\2@> @#
      
      procedure Insert(const aItem: Int2PairOfInt); virtual; @t\2@>
      procedure AtDelete(aIndex: integer); @t\2@>
      procedure SetCapacity(aLimit: integer); virtual; @t\2@>
      procedure DeleteAll; @t\2@>
      function Search(X: integer; var aIndex: integer): boolean; virtual; @t\2@>
      function IndexOf(X:integer): integer; @t\2@>
      constructor CopyInt2PairOfIntFunc(var aFunc: Int2PairOfIntFunc); @t\2@> @#
      
      function HasInDom(X:integer): boolean; virtual; @t\2@>
      procedure Assign(X,Y1,Y2:integer); virtual; @t\2@>
      function Value(X:integer): IntPair; virtual; @t\2\2\2@>
   end;

@ We have a helper function for raising errors.

@<Partial integers to Pair of integers Functions@>=
{Partial integers to Pair of integers Functions}

procedure Int2PairOfIntFunc.Int2PairOfIntFuncError(aCode, aInfo: integer);
begin
   RunError(212 - aCode);
end;

@ \node{Constructor.} Creates an empty $f\colon\ZZ\pto\ZZ\times\ZZ$
with an underlying dynamic array whose capacity is given as the
argument |aLimit|.

@p
constructor Int2PairOfIntFunc.Init(aLimit: integer);
begin
   MObject.Init;
   fList := nil;
   fCount := 0;
   fCapacity := 0;
   SetCapacity(aLimit);
end;

@ \node{Destructor.}

@p
destructor Int2PairOfIntFunc.Done;
begin
   fCount := 0;
   SetCapacity(0);
end;

@ Inserting $(x,y_{1},y_{2})$ into $f\colon\ZZ\pto\ZZ\times\ZZ$
amounts to checking if $(x,y_{1},y_{2})\in f$. If not, then insert the
entry.

Otherwise, if $(x,y_{1},y_{2})\notin f$ but $x\in\dom(f)$, then raise
an error.

Otherwise do nothing.

@p
procedure Int2PairOfIntFunc.Insert(const aItem: Int2PairOfInt);
var I: integer;
begin
   if not Search(aItem.X, I) then
   begin
      if (I < 0) or ( I > fCount) then
      begin
         Int2PairOfIntFuncError(coIndexError,0);
         exit; @+
      end;
      if fCapacity = fCount then
         SetCapacity(fCapacity+ GrowLimit(fCapacity));
      if I <> fCount then
         Move(fList[I], fList[I+1],(fCount - I)*SizeOf(Int2PairOfInt));
      fList[I] := aItem;
      inc(fCount);
   end
   else if (fList[I].Y1 <> aItem.Y1) or (fList[I].Y2 <> aItem.Y2) then
   begin
      Int2PairOfIntFuncError(coDuplicate,0);
      exit; @+
   end;
end;

@ Delete an entry from the underlying dynamic array. Raise an error if
the index given is out of bounds.

@p
procedure Int2PairOfIntFunc.AtDelete(aIndex: integer);
var i: integer;
begin
   if (aIndex < 0) or (aIndex >= fCount) then
   begin
      Int2PairOfIntFuncError(coIndexError,0);
      exit;
   end;
   if aIndex < fCount-1 then
      for i:=aIndex to fCount-2 do fList[i]:=fList[i+1];
   dec(fCount);
end;

@ 

@p
procedure Int2PairOfIntFunc.SetCapacity(aLimit: integer);
begin
   if aLimit < fCount then aLimit := fCount;
   setlength(fList,aLimit);
   fCapacity := aLimit;
end;

@ We can ``soft delete'' all entries in the partial function.

@p
procedure Int2PairOfIntFunc.DeleteAll;
begin
   fCount := 0;
end;

@ We can bisection search on the domain.

@p
function Int2PairOfIntFunc.Search(X: integer; var aIndex: integer): boolean;
var
   L, H, I, C: integer;
begin
   Search := False;
   L := 0;
   H := fCount - 1;
   while L <= H do
   begin
      I := (L + H) shr 1;
      C := CompareInt(fList[I].X, X);
      if C < 0 then L := I + 1 else
      begin
         H := I - 1;
         if C = 0 then
         begin
            Search := True;
            L := I;
         end;
      end;
   end;
   aIndex := L;
end;

@ \node{Copy constructor.} This leaves the argument |aFunc| unchanged.

@p
constructor Int2PairOfIntFunc.CopyInt2PairOfIntFunc(var aFunc: Int2PairOfIntFunc);
begin
   Init(aFunc.fCapacity);
   Move(aFunc.fList[0],fList[0],aFunc.fCapacity*SizeOf(Int2PairOfInt));
   fCount:=aFunc.fCount;
end;

@ Find the index in the underlying dynamic array for $x\in\dom(f)$.
If $x\notin\dom(f)$, then return $-1$.

@p
function Int2PairOfIntFunc.IndexOf(X:integer): integer;
var I: integer;
begin
   IndexOf:=-1;
   if Search(X, I) then IndexOf:=I;
end;

@ Test if $x\in\dom(f)$.

@p
function Int2PairOfIntFunc.HasInDom(X:integer): boolean;
var I: integer;
begin
   HasInDom:=Search(X, I);
end;

@ Attempt to insert $(x,y_{1},y_{2})$ into $f\colon\ZZ\pto\ZZ\times\ZZ$.

@p
procedure Int2PairOfIntFunc.Assign(X, Y1,Y2:integer);
var lInt2PairOfInt: Int2PairOfInt;
begin
   lInt2PairOfInt.X:=X;
   lInt2PairOfInt.Y1:=Y1;
   lInt2PairOfInt.Y2:=Y2;
   Insert(lInt2PairOfInt);
end;

@ Given $f\colon\ZZ\pto\ZZ\times\ZZ$ and $x\in\ZZ$, if $x\in\dom(f)$
return $f(x)$. Otherwise raise an error.

@p
function Int2PairOfIntFunc.Value(X: integer): IntPair;
var I: integer;
begin
   if Search(X, I) then
   begin
      Result.X:=fList[I].Y1;
      Result.Y:=fList[I].Y2;
   end
   else Int2PairOfIntFuncError(coDuplicate,0);
end;

@ We have a myriad of random declarations, so we just stick them all here.

@<Public interface for \texttt{mobjects.pas}@>=
   {Comparing Strings wrt MStrObj}

   function CompareStringPtr(aKey1, aKey2: Pointer): integer; @t\2@> @#

   {Comparing Strings and integers}
   function CompareStr(aStr1, aStr2: String): integer; @t\2@>
   function CompareIntPairs(X1, Y1, X2,Y2: Longint): integer; @t\2@> @#
   
   {Dynamic String handling routines}

   function NewStr(const S: String): PString; @t\2@>
   procedure DisposeStr(P: PString); @t\2@> @#
   
   function GrowLimit(aLimit: integer): integer; @t\2@>
   
   {Abstract notification procedure}
   function CompareNatFunc(aKey1, aKey2: Pointer): integer; @t\2@>
   
   procedure Abstract1; @t\2@>
   
   var EmptyNatFunc: NatFunc;

@* [F] XML Dictionary.
We have several types declared in the \texttt{xml\_dict.pas} file.
These are enumerated types, and string constants for their names.

\label{XMLDictionary}

@<xml\_dict.pas@>=
  @<GNU License@>

unit xml_dict;

interface @|@#

uses mobjects; @|@#

@t\4\4@> {known (and only allowed) \XML/ elements}
type
   XMLElemKind =
   (
    elUnknown,
    elAdjective,
    elAdjectiveCluster,
    elArticleID,
    elAncestors,
    elArguments,
    elBlock,
    elConditions,
    elCorrectnessConditions,
    elDefiniens,
    elDirective,
    elEnviron,
    elEquality,
    elFieldSegment,
    elFormat,
    elFormats,
    elIdent,
    elItem,
    elIterativeStep,
    elLabel,
    elLink,
    elLoci,
    elLociEquality,
    elLocus,
    elNegatedAdjective,
    elPartialDefiniens,
    elPriority,
    elProposition,
    elProvisionalFormulas,
    elRedefine,
    elRightCircumflexSymbol,
    elSchematicVariables,
    elScheme,
    elSelector,
    elSetMember,
    elSkippedProof,
    elSymbol,
    elSymbolCount,
    elSymbols,
    elSubstitution,
    elTypeSpecification,
    elTypeList,
    elVariable,
    elVariables,
    elVocabularies,
    elVocabulary
    ); @#

@t\4\4@> {known \XML/ attributes}
   XMLAttrKind =
   (
    atUnknown,
    atAid,
    atArgNr,
    atArticleId,
    atArticleExt,
    atCol,
    atCondition,
    atConstrNr,
    atIdNr,
    atInfinitive,
    atKind,
    atLabelNr,
    atLeftArgNr,
    atLine,
    atMizfiles,
    atName,
    atNegated,
    atNr,
    atNumber,
    atOrigin,
    atPosLine,
    atPosCol,
    atPriority,
    atProperty,
    atRightSymbolNr,
    atSchNr,
    atSerialNr,
    atShape,
    atSpelling,
    atSymbolNr,
    atValue,
    atVarNr,
    atVarSort,
    atX,
    atX1,
    atX2,
    atY,
    atY1,
    atY2
    );

const
   XMLElemName: array[XMLElemKind] of string =
   (
    'Unknown',
    'Adjective',
    'Adjective-Cluster',
    'ArticleID',
    'Ancestors',
    'Arguments',
    'Block',
    'Conditions',
    'CorrectnessConditions',
    'Definiens',
    'Directive',
    'Environ',
    'Equality',
    'Field-Segment',
    'Format',
    'Formats',
    'Ident',
    'Item',
    'Iterative-Step',
    'Label',
    'Link',
    'Loci',
    'LociEquality',
    'Locus',
    'NegatedAdjective',
    'Partial-Definiens',
    'Priority',
    'Proposition',
    'Provisional-Formulas',
    'Redefine',
    'Right-Circumflex-Symbol',
    'Schematic-Variables',
    'Scheme',
    'Selector',
    'SetMember',
    'elSkippedProof',
    'Symbol',
    'SymbolCount',
    'Symbols',
    'Substitution',
    'Type-Specification',
    'Type-List',
    'Variable',
    'Variables',
    'Vocabularies',
    'Vocabulary'
    );

XMLAttrName:array[XMLAttrKind] of string =
   (
    'unknown',
    'aid',
    'argnr',
    'articleid',
    'articleext',
    'col',
    'condition',
    'constrnr',
    'idnr',
    'infinitive',
    'kind',
    'labelnr',
    'leftargnr',
    'line',
    'mizfiles',
    'name',
    'negated',
    'nr',
    'number',
    'origin',
    'posline',
    'poscol',
    'priority',
    'property',
    'rightsymbolnr',
    'schnr',
    'serialnr',
    'shape',
    'spelling',
    'symbolnr',
    'value',
    'varnr',
    'varsort',
    'x',
    'x1',
    'x2',
    'y',
    'y1',
    'y2'
    ); @#

implementation @t\2@> @|@/

end.

@* [F] Environment library.
We have a library to handle accessing the Mizar mathematical library
files. This is used in \texttt{makeenv.dpr} and using
local \texttt{prel/} directories.

This will execute |InitLibrEnv| (\section\xref{InitLibrEnv}) and
|CheckCompatibility| (\section\xref{CheckCompatibility}).

@<librenv.pas@>=
  @<GNU License@>

unit librenv;

interface @|@#

uses mobjects; @|@#

@<Interface for \.{MIZFILES} library@>@; @#

implementation @|@#

uses @|@/
   @{@&$IFDEF WIN32@}
   windows, @/
   @{@&$ENDIF@}
   mizenv,pcmizver,mconsole; @#

@<Implementation for \texttt{librenv.pas}@>@; @#

begin
   InitLibrEnv;
   CheckCompatibility; @t\2@>
end.

@ @<Interface for \.{MIZFILES} library@>=
const
   MML = 'mml';
   EnvMizFiles = 'MIZFILES';

var MizPath, MizFiles: string;

function LibraryPath(fName,fExt: string): string; @t\2@>@#

procedure GetSortedNames(fParam:byte; var fList:MStringCollection); @t\2@>
procedure GetNames(fParam:byte; var fList: StringColl); @t\2@>@#

procedure ReadSortedNames(fName:string; var fList:MStringCollection); @t\2@>
procedure ReadNames(fName:string; var fList: StringColl); @t\2@>

@ There are two public-facing classes.

@<Interface for \.{MIZFILES} library@>=
type
   @<Declare \\{FileDescr} data type@>@;
   @<Declare \\{FileDescrCollection} data type@>@;@#

var LocFilesCollection: FileDescrCollection;

@ \node{File descriptors.} We use file descriptors for things. These
are just ``a file name'' and ``a timestamp''.

@<Declare \\{FileDescr} data type@>=
   PFileDescr = ^FileDescr; @/
   FileDescr = object(MObject) @t\1@> @/
      nName: PString;
      Time: LongInt;
      constructor Init(fIdent:string; fTime:LongInt); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementation for \texttt{librenv.pas}@>=
constructor FileDescr.Init(fIdent:string; fTime:LongInt);
begin
   nName:=NewStr(fIdent); Time:=fTime;
end;

@ \node{Destructor.}

@p
destructor FileDescr.Done;
begin
   DisposeStr(nName);
end;

@ \node{Collection of file descriptions.}

@<Declare \\{FileDescrCollection} data type@>=
   PFileDescrCollection = ^FileDescrCollection; @/
   FileDescrCollection = object(MSortedCollection) @t\1@>
      function Compare(Key1, Key2: Pointer): integer; virtual; @t\2@>
      procedure StoreFIL(fName:string); @t\2@>
      constructor LoadFIL(fName:string); @t\2@>
      procedure InsertTimes; @t\2\2\2@>
   end;

@ Comparing two entries in a file descriptor collection amounts to
comparing the names for the file descriptors.

@<Implementation for \texttt{librenv.pas}@>=
function FileDescrCollection.Compare(Key1, Key2: Pointer): integer;
begin
   if PFileDescr(Key1)^.nName^ < PFileDescr(Key2)^.nName^ then Compare:=-1
   else if PFileDescr(Key1)^.nName^ = PFileDescr(Key2)^.nName^ then Compare:=0
   else Compare:=1;
end;

@ Inserting file times into the file descriptors relies
upon \texttt{mizenv.pas}'s |GetFileTime| (\section\xref{GetFileTime})
function.

@p
procedure FileDescrCollection.InsertTimes;
var z: integer;
begin
   for z:=0 to Count-1 do
      with PFileDescr(Items^[z])^ do Time:=GetFileTime(nName^);
end;

@ \node{Constructor.} This leverages a few primitive \PASCAL/
functions: \\{assign}(\\{file},\\{name}) assigns \\{name} to a file
but does not open the file (it is still considered closed).
Then \\{reset}(\\{file}) opens the file for reading.

Specifically, this will load a \texttt{.fil} file produced by Mizar.
These contain $2N$ lines: a file path on line $2n-1$, then a timestamp
on line $2n$ for $n=1,\dots,N$. This appears to be used for
local \texttt{prel/} files.
@:File, .fil}{File, \texttt{.fil}@>
@^Prel directory@>

@p
constructor FileDescrCollection.LoadFIL(fName:string);
var FIL: text; lName: string; lTime: longint;
begin
   Assign(FIL,fName); Reset(FIL);
   Init(0,10);
   while not eof(FIL) do
   begin
      ReadLn(FIL,lName);
      ReadLn(FIL,lTime);
      Insert(new(PFileDescr,Init(lName,lTime)));
   end;
   close(FIL);
end;

@ \node{Repopulate .fil file.}
This will erase the file named \\{fName}, then assign to \\{FIL} that
file, and $\\{rewrite}(\\{FIL})$ will open it for writing.

This will loop through every item in the caller's underlying
collection, writing the file names and times to the \texttt{.fil} file.

@p
procedure FileDescrCollection.StoreFIL(fName:string);
var FIL: text; i: integer;
begin
   EraseFile(fName);
   Assign(FIL,fName); Rewrite(FIL);
   InsertTimes;
   for i:=0 to Count-1 do
      with PFileDescr(Items^[i])^ do
         begin WriteLn(FIL,nName^); WriteLn(FIL,Time) end;
   Close(FIL);
end;

@ The library path tries to use the local version of a file, if it
exists as tested with |MFileExists| (\section\xref{MFileExists}).
Otherwise it looks at the Mizar MML version of a file, if it exists.

This returns the path to the file, as a string.
If the file cannot be found either in the local prel directory or the
MML prel directory, then it returns the empty string.

@p
function LibraryPath(fName,fExt: string): string;
begin
   LibraryPath:='';
   if MFileExists('prel'+DirSeparator+fName+fExt) then
   begin
      LocFilesCollection.Insert(New(PFileDescr,Init('prel'+DirSeparator+fName+fExt,0)));
      LibraryPath:='prel'+DirSeparator+fName+fExt; exit
   end;
   if MFileExists(MizFiles+'prel'+DirSeparator+fName[1]+DirSeparator+fName+fExt) then
      LibraryPath:=MizFiles+'prel'+DirSeparator+fName[1]+DirSeparator+fName+fExt;
end;

@ This function actually is not used anywhere, so I am not sure why we
have it.

@p
procedure ReadSortedNames(fName:string; var fList:MStringCollection);
var NamesFile: text;
begin
   if fName[1]='@@' then
   begin
      Delete(fName,1,1);
      FileExam(fName);
      Assign(NamesFile,fName);
      Reset(NamesFile);
      fList.Init(100,100);
      while not seekEof(NamesFile) do
      begin
         ReadLn(NamesFile,fName);
         fList.Insert(NewStr(fName));
      end;
      exit;
   end;
   fList.Init(2,10);
   fList.Insert(NewStr(fName));
end;

@ Again, this function is not used anywhere, so I am not sure why we
have it.

@p
procedure ReadNames(fName:string; var fList: StringColl);
var NamesFile: text;
begin
   if fName[1]='@@' then
   begin
      Delete(fName,1,1);
      FileExam(fName);
      Assign(NamesFile,fName);
      Reset(NamesFile);
      fList.Init(10,10);
      while not seekEof(NamesFile) do
      begin
         ReadLn(NamesFile,fName);
         fList.Insert(NewStr(fName));
      end;
      exit;
   end;
   fList.Init(2,10);
   fList.Insert(NewStr(fName));
end;

@ This function is used in \texttt{lisvoc.dpr}

@p
procedure GetSortedNames(fParam:byte; var fList:MStringCollection);
var FileName:string;
NamesFile: text;
i: integer;
begin
   if ParamCount < fParam then  begin fList.Init(0,0); exit end;
   FileName:=ParamStr(fParam);
   if FileName[1]='@@' then
   begin
      Delete(FileName,1,1);
      FileExam(FileName);
      Assign(NamesFile,FileName);
      Reset(NamesFile);
      fList.Init(10,10);
      while not seekEof(NamesFile) do
      begin
         ReadLn(NamesFile,FileName);
         fList.Insert(NewStr(TrimString(FileName)));
      end;
      exit;
   end;
   fList.Init(2,8);
   fList.Insert(NewStr(FileName));
   for i:=fParam+1 to ParamCount do
   begin
      FileName:=ParamStr(i);
      fList.Insert(NewStr(FileName));
   end;
end;

@ Continuing with the ``this is not used anywhere'' theme, this
function is not used anywhere.

@p
procedure GetNames(fParam:byte; var fList: StringColl);
var FileName:string;
NamesFile: text;
i: integer;
begin
   if ParamCount < fParam then  begin fList.Init(0,0); exit end;
   FileName:=ParamStr(fParam);
   if FileName[1]='@@' then
   begin
      Delete(FileName,1,1);
      FileExam(FileName);
      Assign(NamesFile,FileName);
      Reset(NamesFile);
      fList.Init(10,10);
      while not seekEof(NamesFile) do
      begin
         ReadLn(NamesFile,FileName);
         fList.Insert(NewStr(TrimString(FileName)));
      end;
      exit;
   end;
   fList.Init(2,8);
   fList.Insert(NewStr(FileName));
   for i:=fParam+1 to ParamCount do
   begin
      FileName:=ParamStr(i);
      fList.Insert(NewStr(FileName));
   end;
end;

@ \node{Check compatibility of Mizar with MML.}
We will load the \texttt{mml.ini} file for the MML version number, and
we check it against the Mizar version. If they are not compatible,
print a message to the screen, and halt as an error has occurred.

\label{CheckCompatibility}
The \texttt{mml.ini} file looks something like:

\medbreak
{\obeylines\tt
[Mizar verifier]
MizarReleaseNbr=8
MizarVersionNbr=1
MizarVariantNbr=15
[MML]
NumberOfArticles=1493
MMLVersion=5.94
\par}

\medbreak\noindent%
We will read line-by-line the \texttt{mml.ini} file to initialize
several variables. This motivates the \\{Try\_read\_ini\_var} macro.

@d init_val_and_end(#)==val(lLine,#,lCode);
    end
@d Try_read_ini_var(#)==@+
  lPos:=Pos(#,lLine);
  if lPos > 0 then
    begin delete(lLine,1,lPos+15);
    init_val_and_end

@<Implementation for \texttt{librenv.pas}@>=
procedure CheckCompatibility;
var lFile: text;
lLine,lVer1,lVer2,l: string;
lPos,lCode: integer;
lMizarReleaseNbr,lMizarVersionNbr,lMizarVariantNbr: integer;
begin
   @<Open \texttt{mml.ini} file@>@;
   lMizarReleaseNbr:=-1;
   lMizarVersionNbr:=-1;
   lMizarVariantNbr:=-1;
   while not seekEof(lFile) do
   begin
      ReadLn(lFile,lLine);
      Try_read_ini_var('MizarReleaseNbr=')(lMizarReleaseNbr);
      Try_read_ini_var('MizarVersionNbr=')(lMizarVersionNbr);
      Try_read_ini_var('MizarVariantNbr=')(lMizarVariantNbr);
   end;
   close(lFile); @/
   @<Assert MML version is compatible with Mizar version@>@;
end;

@ We open the \texttt{\$MIZFILES/mml.ini} file for reading.

@<Open \texttt{mml.ini} file@>=
   FileExam(MizFiles+MML+'.ini');
   Assign(lFile,MizFiles+MML+'.ini');
   Reset(lFile);

@ We need to check the MML version is compatible with the Mizar
version. If they are not compatible, raise an error, print a warning
to the user, and halt here.

@<Assert MML version is compatible with Mizar version@>=
   if not ((lMizarReleaseNbr=PCMizarReleaseNbr) and
         (lMizarVersionNbr=PCMizarVersionNbr)) then
   begin
      Str(PCMizarReleaseNbr,l); lVer1:=l;
      Str(PCMizarVersionNbr,l); lVer1:=lVer1+'.'+l;
      Str(PCMizarVariantNbr,l); lVer1:=lVer1+'.'+l;
      Str(lMizarReleaseNbr,l); lVer2:=l;
      Str(lMizarVersionNbr,l); lVer2:=lVer2+'.'+l;
      Str(lMizarVariantNbr,l); lVer2:=lVer2+'.'+l;
      DrawMessage('Mizar System ver. '+lVer1+' is incompatible with the MML version imported ('+lVer2+')','Please check '+MizFiles+'mml.ini');
      halt(1);
   end;

@ \node{Initialize library environment.}
This will try to initialize the |MizFiles| variable to be equal to
the \texttt{\$MIZFILES} environment variable (if that environment
variable exists) or the directory of the program being executed. This
|MizFiles| will always end in a directory separator.

We also initalize |MizFileName|, |EnvFileName|, |ArticleName|,
|ArticleExt| to be empty strings.

\label{InitLibrEnv}

@d append_dir_separator(#)==@+if #[length(#)]<>DirSeparator then
  #:=#+DirSeparator;

@<Implementation for \texttt{librenv.pas}@>=
procedure InitLibrEnv;
begin
   LocFilesCollection.Init(0,20);
   MizPath:=ExtractFileDir(ParamStr(0));
   @<Initialize |Mizfiles|@>@;
   MizFileName:=''; EnvFileName:=''; ArticleName:=''; ArticleExt:='';
end;

@ Initalizing |Mizfiles| requires a bit of work. We first guess it
based on environment variables. Then we need to ensure it is a
directory path.

@<Initialize |Mizfiles|@>=
   @<Guess |MizFiles| from environment variables or executable path@>@;
   if MizFiles<>'' then append_dir_separator(MizFiles);
   if MizFiles='' then Mizfiles:=DirSeparator;

@ When the \texttt{\$MIZFILES} environment variable is set, we just
use it. When it is empty or missing, then we guess the path of the
executable invoked.

@<Guess |MizFiles| from environment variables or executable path@>=
   MizFiles:=GetEnvStr(EnvMizFiles);
   if MizFiles='' then MizFiles:=MizPath;

@* [F] XML Parser.
The \XML/ parser module is used for extracting information from XML
files. It does not ``validate'' the \XML/ (it's assumed to already be
valid). The scanner chops up the input stream into tokens, then the
parser makes this available as tokens for the user.

Just to review some terminology from \XML/:
\enumerate
\item A \define{tag} is a markup construct that begins with a
``\texttt{<}'' and ends with a ``\texttt{>}''. There are three types
of tags:
\itemitem{(i)} Start-tags: like ``\texttt{<foo>}''
\itemitem{(ii)} End-tags: like ``\texttt{</foo>}''
\itemitem{(iii)} Empty-element tags: like ``\texttt{<br~/>}''
\item A \define{Element} is a logical document component that either
(a) begins with a start-tag and ends with an end-tag, or (b) consists
of an empty-element tag. The characters between the start-tag and
end-tag (if any) are called its \define{Contents}, and may contain
markup including other elements which are called \define{Child Elements}.
\item An \define{Attribute} is a markup construct consisting of a
name-value pair which can exist in a start-tag or an empty-element tag. For example ``\texttt{<img src="madonna.jpg" alt="Madonna"~/>}''
has two attributes: one named ``src'' whose value is ``madonna.jpg'',
and the other named ``alt'' whose value is ``Madonna''.
\item \XML/ documents may start with an \define{XML declaration} which looks
something like (after some optional whitespace) ``\texttt{<?xml version="1.0" encoding="UTF-8"?>}''
\endenumerate

@<xml\_parser.pas@>=
  @<GNU License@>

unit xml_parser;

interface

uses mobjects,errhan; @#

@t\4@> @<Constants for \texttt{xml\_parser.pas}@>@; @#

@t\4@> @<Type declarations for \texttt{xml\_parser.pas}@>@; @#

   procedure XMLASSERT(aCond: boolean); @t\2@>

   procedure UnexpectedXMLElem(const aElem:string; aErr:integer); @t\2@>

implementation @|@/
mdebug; uses info; end_mdebug; @#

@t\4@> @<Implementation of XML Parser@> @t\2@>

end.

@ \node{Constant parameters.} We have a few constant parameters for
the error codes.

@<Constants for \texttt{xml\_parser.pas}@>=
const InOutFileBuffSize = $4000; @#

@t\4\4@> {for xml attribute tables}
const errElRedundant = 7500; {End of element expected, but child element found}
const errElMissing = 7501; {Child element expected, but end of element found}
const errMissingXMLAttribute = 7502; {Required \XML/ attribute not found}
const errWrongXMLElement = 7503; {Different \XML/ element expected}
const errBadXMLToken = 7506; {Unexpected \XML/ token}

@ \node{Public type declarations.} We will defer the ``\PASCAL/ classes'' until
we start implementing them. Right now, we have syntactic classes for
the tokens. Specifically we have the start of an XML declaration
``\texttt{<?}'', the end of an XML declaration ``\texttt{?>}'', the
start of a character data section ``\texttt{<!}'', the start and end
of tags, quotation marks, equalities, entities, identifiers, and end
of text.

\label{xmlparser:types}

@<Type declarations for \texttt{xml\_parser.pas}@>=
type
   XMLTokenKind = (Err,  {an error symbol}
                   BI,     {{\tt <?}}
                   EI,     {{\tt ?>}}
                   DT,     {{\tt <!}}
                   LT,     {{\tt <}}
                   GT,     {{\tt >}}
                   ET,     {{\tt </}}
                   EE,     {{\tt />}}
                   QT,     {{\tt "}}
                   EQ,     {=}
                   EN,     {Entity}
                   ID,     {Identifier, Name}
                   EOTX);   {End of text}
   TokensSet = set of XMLTokenKind; @#

   @<Declare XML Scanner Object type@>@; @#

   TElementState = ( eStart, eEnd); {high-level parser states, 
    see procedure NextElementState} 

   @<Declare XML Attribute Object@>@; @#

   @<Declare XML Parser object@>@;

@ \node{XML Attribute Object.} An \XML/ attribute contains the attribute
name and its value. We can represent it as ``just'' an |MStrObj|
(\section\xref{MStrObj}) with an additional ``value'' field.

\label{XMLAttrPtr}

@<Declare XML Attribute Object@>=
   XMLAttrPtr = ^XMLAttrObj; @/
   XMLAttrObj = object(MStrObj) @t\1@> @/
      nValue: string; @/
      constructor Init(const aName,aValue: string); @t\2\2\2@>
   end;

@ \node{Constructor.} This uses the |MStrObj.Init| constructor to
initialize the name, then it sets the value.

@<Implementation of XML Parser@>=
constructor XMLAttrObj.Init(const aName,aValue: string);
begin
   inherited Init(aName);
   nValue:=aValue;
end;

@ \node{Assertion.} We have a helper function for asserting things
about \XML/. This is just a wrapper around |MizAssert|
(\section\xref{MizAssert}).

@<Implementation of XML Parser@>=
procedure XMLASSERT(aCond: boolean);
begin
   MizAssert(errWrongXMLElement, aCond);
end;

@ \node{Unexpected XML Element.} Another helper function for checking
\XML/ parsing.

@<Implementation of XML Parser@>=
procedure UnexpectedXMLElem( const aElem:string; aErr:integer); @|@/
mdebug;
var lEl:string; @/
end_mdebug; @t\2@>
begin @|@/
   mdebug;
   InfoNewLine; @+
   end_mdebug; @/
   RunTimeError(aErr);
end;

@ \node{XML Scanner Object.} The scanner produces a stream of tokens,
which is then consumed by the XML parser. Hence, besides the
constructor and destructor, there is only one public facing method:
get the next token.

@<Declare XML Scanner Object type@>=
   XMLScannObj = object(MObject) @t\1@> @/
      nSourceFile: text; @/
      nSourceFileBuff: pointer; @/
      nCurTokenKind: XMLTokenKind; @/
      nSpelling: string; @/
      nPos: Position; @/
      nCurCol: integer; @/
      nLine: string; @/
      constructor InitScanning(const aFileName:string); @t\2@>
      destructor Done; virtual; @t\2@>
      procedure GetToken; @t\2\2@>
      private @t\1@>
      procedure GetAttrValue; @t\2\2\2@>
   end; 

@ \node{Constructor.} We open the file (doing all the boilerplate file
IO stuff), then initialize the fields of the scanner to prepare to
read the first line from the file.

@<Implementation of XML Parser@>=
constructor XMLScannObj.InitScanning(const aFileName:string);
begin
   inherited Init;
   @<Prepare to read in the contents of XML file@>;
   nSpelling:='';
   nLine:='';
   nCurCol:=0;
   nPos.Line:=0;
   nPos.Col:=0; @/
   GetToken;
end;

@ This prepares to read in from an \XML/ file, setting up a text buffer,
and opening the file in ``read mode''.

@<Prepare to read in the contents of XML file@>=
Assign(nSourceFile,aFileName);
GetMem(nSourceFileBuff,InOutFileBuffSize);
SetTextBuf(nSourceFile,nSourceFileBuff^,InOutFileBuffSize);
Reset(nSourceFile) {open for reading}
   
@ \node{Destructor.} We need to close the \XML/ file, as well as free up
the input buffer.

@<Implementation of XML Parser@>=
destructor XMLScannObj.Done;
begin
   close(nSourceFile);
   FreeMem(nSourceFileBuff,InOutFileBuffSize); @/
   nLine:='';
   nSpelling:=''; @/
   inherited Done;
end;

@ \node{Getting the token.} The scanner produces tokens on
demand. They are assembled into a tree data structure by the parser.
This method may look a bit foreign, since it's a procedure and not a function.
The current token is stored in several fields in the scanner.
The token's lexeme is stored into the \\{nSpelling} field.

\label{XMLScannObj.GetToken}
\def\thickskip{\hskip3pt}

@d update_lexeme == nSpelling:=Copy(nLine,nPos.Col,nCurCol-nPos.Col)

@<Implementation of XML Parser@>=
procedure XMLScannObj.GetToken;
const CharKind: array[chr(0)..chr(255)] of byte = 
   (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
@t\hskip-1.5em @> {\hphantom{0,0,0,}{\tt\#}\hphantom{,0,0,0}{\tt\AM}\hphantom{,0,0,0,0,0,0,0,0}{\tt-\thickskip{\kern2pt}.\thickskip{}/\hphantom{\rm,\kern2pt}0\hphantom{\rm,\kern2pt}1\thickskip{\kern1pt}2\thickskip{\kern1pt}3\thickskip{\kern1pt}4\thickskip{\kern2pt}5\thickskip{\kern1pt}6\thickskip{\kern1pt}7\hphantom{\rm l,}8\hphantom{\rm,}9 {:}\thickskip{}{;}}}
    0,0,0,3,0,0,3,0,0,0,0,0,0,3,3,0,2,2,2,2,2,2,2,2,2,2,3,3,0,0,0,0,@/
@t\hskip-1.5em @> {\hphantom{0,}{\tt A\hphantom{,}B\thickskip{}C\hphantom{,}D\hphantom{,}E\thickskip{}F\thickskip{}G\thickskip{}H\hphantom{,}I\thickskip{}J\hphantom{,}K\hphantom{,}L\thickskip{}M\hphantom{,}N\thickskip{}O\hphantom{,}P\hphantom{,}Q\thickskip{}R\hphantom{,}S\thickskip{}T\thickskip{}U\hphantom{,}V\thickskip{}W\hphantom{,}X\hphantom{,}Y\thickskip{}Z\hphantom{0,0,0,0,}\_}}
    0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,3,@/
@t\hskip-1.5em @> {{\hphantom{0,}{\tt a\thickskip{}b\hphantom{,}c\thickskip{}d\hphantom{,}e\thickskip{}f\hphantom{,}g\hphantom{,}h\thickskip{}i\thickskip{}j\hphantom{,}k\hphantom{,}l\thickskip{}m\hphantom{,}n\thickskip{}o\hphantom{,}p\thickskip{}q\hphantom{,}r\thickskip{}s\hphantom{,}t\thickskip{}u\hphantom{,}v\hphantom{,}w\thickskip{}x\hphantom{,}y\thickskip{}z}}}
    0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,@/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0);
begin
   @<Skip whitespace for XML parser@>;
   nPos.Col := nCurCol; @/
   @<Get token kind based off of leading character@>;
   update_lexeme;
   while (nCurCol<length(nLine)) and (nLine[nCurCol] in [' ','	'])
   do inc(nCurCol);
end;

@ If we're done in the file, then we've arrived at the ``end-of-file''
--- i.e., $\\{eof}(\\{nSourceFile})$ is true. In this case, the token
returned should be an \texttt{EOTX} (end of text). We also end the
function here.

On the other hand, if there is still more left in the file, we should
read in a line, increment the line number, reset the column to 1, and
skip over any whitespace (specifically, ``\texttt{SP}'' are skipped
over --- tabs or newlines are not skipped).

@<Skip whitespace for XML parser@>=
   while nCurCol = length(nLine) do
   begin
      if eof(nSourceFile) then
      begin
         nCurTokenKind:=EOTX;
         nSpelling:='';
         exit @+
      end;
      ReadLn(nSourceFile,nLine);
      inc(nPos.Line);
      nLine:=nLine+' ';
      nCurCol:=1;
      while (nCurCol<length(nLine)) and (nLine[nCurCol]=' ') do inc(nCurCol);
   end

@ There are several situations when determining tokens. We will often
want to keep accumulating alphanumeric characters, so we describe this
in the ``keep eating alphadigits'' macro.

When we encounter a ``\texttt{<}'' character, this could begin or end
a tag, or it could be something special if the next character is
``\texttt{?}'' or ``\texttt{!}''. We determine the type in the ``get
tag kind'' macro.

@d keep_eating_alphadigits==begin
  nCurTokenKind:=ID;
  repeat inc(nCurCol) until CharKind[nLine[nCurCol]] = 0;
  end
@d get_tag_kind==inc(nCurCol);
  case nLine[nCurCol] of
  '/': begin nCurTokenKind:=ET; inc(nCurCol); @+ end;
  '?': begin nCurTokenKind:=BI; inc(nCurCol); @+ end ;
  '!': begin nCurTokenKind:=DT; inc(nCurCol); @+ end ;
  othercases nCurTokenKind:=LT;
  endcases
@d keep_getting_until_end_of_tag(#)==@+
         begin
            inc(nCurCol);
            if nLine[nCurCol] = '>' then
            begin
               nCurTokenKind:=#;
               inc(nCurCol); @+
            end
            else nCurTokenKind:=Err;
         end;

@<Get token kind based off of leading character@>=
   case nLine[nCurCol] of
      'a'..'z', 'A'..'Z', '0'..'9','_','-','&': keep_eating_alphadigits;
      '"':
         begin
            nCurTokenKind:=QT;
            inc(nCurCol) @+
         end;
      '=':
         begin
            nCurTokenKind:=EQ;
            inc(nCurCol) @+
         end;
      '<':
         begin
            get_tag_kind; @+
         end;
      '>':
         begin
            nCurTokenKind:=GT;
            inc(nCurCol) @+
         end;
      '/': keep_getting_until_end_of_tag(EE);
      '?': keep_getting_until_end_of_tag(EI);
   othercases
   begin
      nCurTokenKind:=Err;
      inc(nCurCol) @+
   end;
   endcases

@ Scanners can obtain attribute values as tokens.
This is used by the XML parser
(\section\section\xref{XMLParserObj.NextTag}, \xref{XMLParserObj.NextElementState}).
I think one possible source of bugs is that this does not handle
escaped quotes (e.g., ``\texttt{\BS"}'' is traditionally parsed as a
quotation mark character).

This will not include the delimiting quotation marks, and it will also
skip all whitespace \emph{after} the attribute.

\label{XMLScannObj.GetAttrValue}

@d skip_to_quotes == @+ while (nCurCol < length(nLine)) and (nLine[nCurCol] <> '"') do
      inc(nCurCol)
@d is_space == @+ (nCurCol<length(nLine)) and (nLine[nCurCol] in [' ','	'])
@d skip_spaces == @+ while is_space
   do inc(nCurCol)

@<Implementation of XML Parser@>=
procedure XMLScannObj.GetAttrValue;
var lCol: integer;
begin
   lCol:=nCurCol;
   skip_to_quotes; @/
   nSpelling:=Copy(nLine,lCol,nCurCol-lCol); { save the lexeme }
   if nLine[nCurCol] = '"' then
      inc(nCurCol);
   skip_spaces;
end;

@ \node{XML Parser.} We recall (\section\xref{xmlparser:types}) the
type for element states (it's an enumerated type with two
values, \\{eStart} and \\{eEnd}).

\label{XMLParserObj}

@<Declare XML Parser object@>=
   XMLParserObj = object(XMLScannObj) @t\1@> @/
      nElName	: string;   {name of the current element}
      nState	: TElementState;
      nAttrVals	: MSortedStrList; @#

      constructor InitParsing(const aFileName:string); @t\2@>
      destructor Done; virtual; @t\2@>
      procedure ErrorRecovery(aErr: integer; aSym: TokensSet); @t\2@>  @#

      procedure NextTag; virtual; @t\2@>
      procedure NextElementState; virtual; @t\2@>
      procedure AcceptEndState; virtual; @t\2@>
      procedure AcceptStartState; virtual; @t\2@>
      procedure OpenStartTag; virtual; @t\2@>
      procedure CloseStartTag; virtual; @t\2@>
      procedure CloseEmptyElementTag; virtual; @t\2@>
      procedure ProcessEndTag; virtual; @t\2@>
      procedure ProcessAttributeName; virtual; @t\2@>
      procedure ProcessAttributeValue; virtual; @t\2@>
      procedure SetAttributeValue(const aVal:string); @t\2\2\2@>
   end;

@ \node{Constructor.} The parser expects an XML file to start with 
``\texttt{<?xml \dots?>}'' (everything after the ``xml'' is ignored).
If this is not the first non-whitespace entry, an error will be
raised.

The constructor will then skip all other ``\texttt{<?\dots?>}'' entities.

\label{XMLParserObj.InitParsing}

@d skip_xml_prolog == @+ while (nCurTokenKind <> EOTX) and (nCurTokenKind <> EI) do GetToken;
      if nCurTokenKind = EI then GetToken
@d skip_all_other_ids == @+ while nCurTokenKind = BI do
      begin
         GetToken;
         while (nCurTokenKind <> EOTX) and (nCurTokenKind <> EI) do GetToken;
         if nCurTokenKind = EI then GetToken;
      end

@<Implementation of XML Parser@>=
constructor XMLParserObj.InitParsing(const aFileName:string);
begin
   inherited InitScanning(aFileName);
   nElName:= '';
   nAttrVals.Init(0);
   if nCurTokenKind = BI then
   begin
      GetToken;
      if (nCurTokenKind = ID) and (nSpelling = 'xml') then
         GetToken
      else ErrorRecovery(10,[EI,LT]);
      skip_xml_prolog;
      skip_all_other_ids; {skip all other initial processing instructions}
   end;
end;

@ \node{Destructor.} We will set the element name to the empty string,
and invoke the destructor for the attribute values.

@p 
destructor XMLParserObj.Done;
begin
   inherited Done;
   nAttrVals.Done;
   nElName:='';
end;

@ \node{Error recovery.} We just raise a runtime error. In fact, this
is often used in situations like:

\medbreak
{\advance\leftskip4em\obeylines
\&{if} $\\{nCurTokenKind}=\\{ID}$ \&{then}\C{success}
\&{else} $\\{ErrorRecovery}(5, [\\{LT}, \\{ET}])$;
}
\medbreak\noindent%
Consequently, it is probably more idiomatic to introduce a macro
$\\{xml\_match}(\\{tokenKind})(\\{aErr}, \\{aSym})$ to assert the match and
raise an error for mismatch. Unfortunately, \WEB/ macros allow
for only one argument, so we need two macros.

@d report_mismatch(#) == ErrorRecovery(#)
@d xml_match(#) == @+ if nCurTokenKind<># then report_mismatch

@p
{ErrorRecovery is no longer allowed for \XML/, bad \XML/ is just RTE}
procedure XMLParserObj.ErrorRecovery(aErr: integer; aSym: TokensSet);
begin
   Mizassert(errBadXMLToken, false);
end;

@ The parser will the consume the next tag or element.
It's useful to recall the token kinds (\section\xref{xmlparser:types}).

Curiously, the attributes are skipped during this parsing function.

This will be using the
inherited procedure \\{GetToken} (\section\xref{XMLScannObj.GetToken}).
\label{XMLParserObj.NextTag}

@p
{Parses next part of \XML/, used for skipping some part of \XML/}

    {setting the \\{nState} to \\{eStart} or \\{eEnd}.}
    {\\{nElName} is set properly}
    {\\{nAttrVals} are omitted (skiped).}
    procedure XMLParserObj.NextTag;
    begin
       case nCurTokenKind of
          EOTX: nState:= eEnd;  {sometimes we need this}
          LT:
             begin
                nState := eStart;
                GetToken;
                xml_match(ID)(6, [LT, ET]);
                OpenStartTag;
                GetToken;
                @<Get contents of \XML/ start tag @>;
             end;
          EE:
             begin
                nState := eEnd;
                GetToken; @+
             end;
          ET:
             begin
                nState := eEnd;
                GetToken;
                xml_match(ID)(8, [LT, ET]);
                OpenStartTag;
                GetToken;
                xml_match(GT)(7, [LT, ET]);
                GetToken
             end;
       othercases ErrorRecovery(9,[LT,ET]);
       endcases;
    end;

@ When getting the contents of an \XML/ start tag (or possibly an
element), we keep going until we get to either ``\texttt{\BS>}'' (for
an element) or ``\texttt{>}'' (for a tag). This will be using the
inherited procedure \\{GetToken} (\section\xref{XMLScannObj.GetToken}).

@d get_attribute == @+ begin GetToken;
                       xml_match(EQ)(4, [ID,GT,LT,ET]);
                       GetToken;
                       xml_match(QT)(3, [ID,GT,LT,ET]);
                       GetAttrValue;
                       GetToken; end
@<Get contents of \XML/ start tag @>=
                   repeat
                      case nCurTokenKind of
                         GT:
                            begin
                               GetToken;
                               break @+
                            end;
                         EE:
                            begin
                               break @+
                            end;
                         ID: get_attribute;
                      othercases
                      begin
                         ErrorRecovery(5,[GT,LT,ET]);
                         break @+
                      end;
                      endcases;
                   until nCurTokenKind = EOTX

@ For Mizar, \emph{everything} will be encoded as an element or an
attribute on an element. So we do not really need to consider the case
where we would encounter text in the body of an element.

\label{XMLParserObj.NextElementState}

@<Implementation of XML Parser@>=
    {Parses next part of \XML/, setting the \\{nState} to \\{eStart} or \\{eEnd}.
    If $\\{nState}=\\{eStart}$, then \\{nElName}, \\{nAttrVals} are set properly.
    It is possible to go from $\\{nState}=\\{eStart}$ to $\\{nState}=\\{eStart}$
    (when the element is non empty), and similarily from \\{eEnd} to \\{eEnd}.}
    procedure XMLParserObj.NextElementState;
    begin
       case nCurTokenKind of
          EOTX: nState:= eEnd;  {sometimes we need this}
          LT: @< Parse start of \XML/ tag @>;
          EE: begin
                 nState := eEnd;
                 GetToken; @+
              end;
          ET: begin
                 nState := eEnd;
                 GetToken;
                 xml_match(ID)(8, [LT, ET]);
                 ProcessEndTag;
                 GetToken;
                 xml_match(GT)(7, [LT, ET]);
                 GetToken; @+
              end;
       othercases ErrorRecovery(9,[LT,ET]);
       endcases;
    end;

@ We start parsing a start-tag because we have encountered an LT token.
So at this point, the next token should be an identifier of some kind.
A start-tag may actually be an empty-element tag, so we need to look
out for the \\{EE} token kind.

Note: the \XML/ parser does not handle comments, otherwise we would
need to consider that situation here.

@d end_start_tag == @+ begin
                               GetToken;
                               CloseStartTag;
                               break @+
                            end
@d end_empty_tag == @+ begin
                               CloseEmptyElementTag;
                               break @+
                            end

@< Parse start of \XML/ tag @>=
             begin
                nState := eStart;
                GetToken;
                xml_match(ID)(6,[LT,ET]);
                OpenStartTag;
                {Start-Tag or Empty-Element-Tag Name = nSpelling}
                GetToken;
                repeat
                   case nCurTokenKind of
                      GT: end_start_tag; {End of a Start-Tag}
                      EE: end_empty_tag; {End of a Empty-Element-Tag}
                      ID:
                         begin
                            ProcessAttributeName;
                            GetToken;
                            xml_match(EQ)(4, [ID,GT,LT,ET]);
                            GetToken;
                            xml_match(QT)(3, [ID,GT,LT,ET]);
                            GetAttrValue;
                            ProcessAttributeValue;
                            GetToken;
                         end;
                      othercases
                      begin
                         ErrorRecovery(5,[GT,LT,ET]);
                         break @+
                      end;
                   endcases;
                until nCurTokenKind = EOTX;
             end

@ We will want assertions reflecting the parser is in a ``start''
state or an ``end'' state.

@<Implementation of XML Parser@>=
    procedure XMLParserObj.AcceptEndState;
    begin
       NextElementState;
       MizAssert( errElRedundant, nState = eEnd);
    end; @#

    procedure XMLParserObj.AcceptStartState;
    begin
       NextElementState;
       MizAssert( errElMissing, nState = eStart);
    end;

@ @p
    procedure XMLParserObj.OpenStartTag;
    begin
       nElName:= nSpelling;
       nAttrVals.FreeAll;
    end;

@ We have a few procedures which are, well, empty. I am not sure why
we have them. Regardless, here they are!

@p
    procedure XMLParserObj.CloseStartTag;
    begin
    end; @#
    
    procedure XMLParserObj.CloseEmptyElementTag;
    begin
    end; @#
    
    procedure XMLParserObj.ProcessEndTag;
    begin
    end;

@ We have a list of attributes. When the parser \\{ProcessAttributeName},
it will merely push a new |XMLAttrPtr| to the list with the given
name. Then \\{ProcessAttributeValue} will associate to it the value
which has been parsed. We can, of course, \emph{manually} set the
value for an attribute using \\{SetAttributeValue}.

@p
    procedure XMLParserObj.ProcessAttributeName;
    begin
       nAttrVals.Insert(new(XMLAttrPtr,Init(nSpelling,'')));
    end; @#

    procedure XMLParserObj.ProcessAttributeValue;
    begin
       SetAttributeValue(nSpelling);
    end; @#

    procedure XMLParserObj.SetAttributeValue(const aVal:string);
    begin
       with nAttrVals do
          XMLAttrPtr(Items^[Count-1])^.nValue := aVal;
    end;

@* [F] I/O with XML. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We will want to print some \XML/ to a buffer or stream.

Note that \XML/ seems to be frozen at version 1.0 (first published in
1998, last revised in its fifth edition released November 26, 2008).

@<xml\_inout.pas@>=
  @<GNU License@>

unit xml_inout;

interface @|@#

uses errhan,mobjects,xml_parser;@#

@t\4@> @<Type declarations for XML I/O@>@;

   function QuoteStrForXML(const aStr:string):string; @t\2@>
   function XMLToStr(const aXMLStr:string): string; @t\2@>
   function QuoteXMLAttr( aStr:string): string; @t\2@> @#

   const gXMLHeader = '<?xml version="1.0"?>' + #10; @#

implementation @|@#

uses SysUtils,mizenv,pcmizver,librenv,xml_dict @/
mdebug, info @+ end_mdebug; @#

@t\4@> @<Implementation for I/O of XML@> @t\2@>

end.

@ There are only 4 types of streams we care about: Streams, Text
Streams, \XML/ Input Streams, and \XML/ Output Streams.

@<Type declarations for XML I/O@>=
   @<Public interface for XML Input Stream@>; @#

   @<Public declaration for Stream Object@>; @#

   @<Public declaration for Text Stream Object@>; @#

   @<Public declaration for XML Output Stream@>;

@ \node{Escape for quote string.}
We want to allow only alphanumerics [a-zA-Z0-9] as well as dashes
(``-''), spaces (``\.{}''), commas (``,'') periods (``.''),
apostrophes (``\texttt{'}''), forward slashes (``\texttt{/}''),
underscores (``\_''), brackets (``\texttt{[}'' and ``\texttt{]}''),
exclamation points (``!''), semicolons and colons (``;'' and ``:''),
and equal signs (``=''). Everything else we transform into an \XML/
entity of the form ``{\tt\AM{}xx}'' where {\tt x} is a hexadecimal digit.

\label{QuoteStrForXML}

@<Implementation for I/O of XML@>=
function QuoteStrForXML(const aStr:string): string;
const
   ValidCharTable = (['a'..'z','A'..'Z','0'..'9','-',' ',',','.','\','/','_',
                      '[',']','!',';',':','=']);
var c : char;
i : integer;
begin
   result := aStr;
   for i := length(result) downto 1 do
   begin
      c := result[i];
      if not (c in ValidCharTable)  then
      begin
         result[i] := '&';
         Insert('#x' + IntToHex(Ord(c),2) + ';', result,i+1);
      end;
   end;
end;

@ This appears to ``undo'' the previous function, transforming \XML/
entities of the form ``{\tt\AM xx}'' into characters.

@p
function XMLToStr(const aXMLStr:string): string;
var i, h : integer;
lHexNr: string;
begin
   result := aXMLStr;
   for i := length(result)-5 downto 1 do begin
      @<Transform XML entity into character, if encountering an XML entity at |i|@>;
   end;
   result := Trim(result);
end;

@ Transforming an \XML/ entity into a character. This specifically
checks for \emph{hexadecimal} entities of the form
``\texttt{\AM\#x}$XX$'' for some hexadecimal digits $X$. Note we must prepend
``\texttt{0x}'' to a numeric string for \PASCAL/ to parse it as hexadecimal.

Since \PASCAL/ does not have shortcircuiting Boolean operations, we
need to make this a nested \&{if} statement.

@<Transform XML entity into character, if encountering an XML entity at |i|@>=
   if (result[i] = '&') and (length(result) >= i+5) then
   begin
      if (result[i+1] = '#') and (result[i+2] = 'x') then
      begin
         lHexNr := result[i+3]+result[i+4];
         h := StrToInt('0x' + lHexNr);
         Delete(result, i, 5);
         result[i] := chr(h);
      end;
   end

@ We can quote an \XML/ attribute, escaping quotes, ampersands, and
angled brackets. For non-\ASCII/ characters, we escape it to a
hexadecimal \XML/ entity.

@<Implementation for I/O of XML@>=
function QuoteXMLAttr(aStr:string): string;
var i:integer;
begin
   result:= '';
   for i:=1 to length(aStr) do
      case aStr[i] of
         '"':  result:= result + '&quot;';
         '&':  result:= result + '&amp;';
         '<':  result:= result + '&lt;';
         '>':  result:= result + '&gt;';
      othercases if integer(aStr[i]) > 127 then
         result:= result + '&#x' + IntToHex(Ord(aStr[i]),2) + ';'
      else result:= result + aStr[i];
      endcases;
end;

@ \node{Stream object class.}
A stream consists of a file, a character buffer, as well as integers
tracking the size of the buffer and (I think) the position in the buffer.
This is the parent class to \XML/ output buffers.



\label{StreamObj}

@<Public declaration for Stream Object@>=
   StreamObj = object(MObject) @t\1@> @/
         nFile: File; @/
         fFileBuff: ^BuffChar; @/
         fBuffCount,fBuffInd: longint; @/
         constructor InitFile(const AFileName:string); @t\2@>
         procedure Error(Code,Info:integer); virtual; @t\2@>
         destructor Done; virtual; @t\2\2\2@> 
      end

@ We will have a wrapper function for conveniently reporting errors.

@<Implementation for I/O of XML@>=
procedure StreamObj.Error(Code,Info:integer);
begin
   RunError(2000+Code);
end;

@ \node{Constructor.} We begin by |Assign|-ing a name to a file,
allocating a file buffer, then initializing the buffer size to zero,
and the buffor position to zero. (The buffer position |fBuffInd| is
needed only when writing to an output \XML/ stream.)

@p
constructor StreamObj.InitFile(const AFileName:string);
begin
   Assign(nFile,AFileName);
   new(fFileBuff);
   fBuffCount:=0; fBuffInd:=0;
end;

@ \node{Destructor.} We close the file, and free up the file buffer.

@p
destructor StreamObj.Done;
begin
   Close(nFile);
   dispose(fFileBuff);
end;

@ \node{Text Stream Object.} A text stream is very similar to a Stream
Object, except it is specifically for text.

@<Public declaration for Text Stream Object@>=
   TXTStreamObj = object(MObject) @t\1@> @/
         nFile: text; @/
         nFileBuff: pointer; @/
         constructor InitFile(const AFileName:string); @t\2@>
         procedure Error(Code,Info:integer); virtual; @t\2@>
         destructor Done; virtual; @t\2\2\2@> 
      end

@ We have the convenience function for reporting errors.

@<Implementation for I/O of XML@>=
procedure TXTStreamObj.Error(Code,Info:integer);
begin
   RunError(2000+Code);
end;

@ \node{Constructor.} Assign a name to the file, allocate an input
buffer, then initialize the buffer.

@p
constructor TXTStreamObj.InitFile(const AFileName:string);
begin
   Assign(nFile,AFileName);
   GetMem(nFileBuff,InOutFileBuffSize);
   SetTextBuf(nFile,nFileBuff^,InOutFileBuffSize);
end;

@ \node{Destructor.} Simply free the underlying file buffer.

\label{TXTStreamObj.Done}

@p
destructor TXTStreamObj.Done;
begin
   FreeMem(nFileBuff,InOutFileBuffSize);
end;

@ \node{XML Input Streams.}
An input stream reads an \XML/ file and produces an abstract syntax
tree for its contents. This extends this \XML/ parser class
(\section\xref{XMLParserObj}). It may be tempting to draw similarities
with, e.g., the StAX library (in Java), but the truth is there's only
finitely many ways to parse \XML/, and some ways are just more natural.

@^StAX, Java@>

\label{XMLInStreamObj}

@<Public interface for XML Input Stream@>=
   XMLInStreamPtr = ^XMLInStreamObj; @/
   XMLInStreamObj = object(XMLParserObj) @t\1@>
      constructor OpenFile(const AFileName:string); @t\2@> 
      function GetOptAttr(@t\hskip-1em@>@+@+const aAttrName: string;@+
         var aVal:string@t\hskip-0.45em@>): boolean; @t\2@>
      function GetAttr( const aAttrName: string): string; @t\2@>
      function GetIntAttr( const aAttrName: string): integer; @t\2\2\2@> 
   end

@ \node{Constructor.} The non-debugging code just invokes the XML
Parser's constructor (\section\xref{XMLParserObj.InitParsing}).

@<Implementation for I/O of XML@>=
constructor XMLInStreamObj.OpenFile(const AFileName:string);
begin @|@/
   mdebug;
   write(InfoFile, AFileName); @+
   end_mdebug; @/
   InitParsing(AFileName); @/
   mdebug;
   WriteLn(InfoFile,' reset'); @+
   end_mdebug;
end;

@ We use the inherited |XMLParserObj|'s |nAttrVals : MSortedStrList|
to track the XML attributes. If |aAttrName| is stored there, this will
mutate |aVal| to store the associated value and the function will
return |true|. Otherwise, this will return |false|.

This is useful for getting the value of an \emph{optional} \XML/
attribute. 

@p
@t\4\4@> {get string denoted by optional \XML/ attribute aAttrName}
function XMLInStreamObj.GetOptAttr(@t\hskip-0.5em@>@+const aAttrName: string; @+
                                    var aVal:string@t\hskip-0.3333em@>): boolean;
var lAtt: XMLAttrPtr;
begin
   lAtt:=XMLAttrPtr(nAttrVals.ObjectOf(aAttrName));
   if lAtt<>nil then
   begin
      aVal:=lAtt^.nValue;
      GetOptAttr:= true;
      exit;
   end;
   GetOptAttr:= false;
end;

@ When we know an \XML/ attribute is \emph{required}, we can just get
the associated value directly (and raise an error if it is missing).

@p
@t\4\4@> {get string denoted by  required \XML/ attribute aAttrName}
function XMLInStreamObj.GetAttr( const aAttrName: string): string;
var lAtt: XMLAttrPtr;
begin
   lAtt:=XMLAttrPtr(nAttrVals.ObjectOf(aAttrName));
   if Latt<>nil then
   begin
      GetAttr:=lAtt^.nValue;
      exit;
   end;
   MizAssert(errMissingXMLAttribute, false);
end;

@ When the required attribute has an integer value, we should return
the integer-value of it. Does this ever happen? Yes! For example, when
writing an article named \texttt{article.miz}, then we run the
verifier on it, we shall obtain \texttt{article.xml} which will
contain tags of the form ``\texttt{<Adjective nr="5">}''. 

@p
@t\4\4@> {get integer denoted by required \XML/ attribute aAttrName}
function XMLInStreamObj.GetIntAttr(const aAttrName: string): integer;
var lInt,ec:integer;
begin
   val(GetAttr(aAttrName), lInt, ec);
   GetIntAttr:= lInt;
end;

@ \node{XML Output Streams.}
We will want to write data to an \XML/ file. This gives us an
abstraction for doing so.

\label{XmlOutStreamObj}

@<Public declaration for XML Output Stream@>=
   XMLOutStreamPtr = ^XMLOutStreamObj; @/
   XMLOutStreamObj = object(StreamObj) @t\1@> @/
      nIndent:	integer; 	{indenting}
      constructor OpenFile(const AFileName:string); @t\2@>
      constructor OpenFileWithXSL(const AFileName:string); @t\2@>
      destructor EraseFile; @t\2@> @#

      procedure OutChar(AChar: char); @t\2@>
      procedure OutNewLine; @t\2@>
      procedure OutString(const AString: string); @t\2@>@#

      procedure OutIndent; @t\2@>
      procedure Out_XElStart(const fEl: string); @t\2@>
      procedure Out_XAttrEnd; @t\2@>
      procedure Out_XElStart0(const fEl: string); @t\2@>
      procedure Out_XElEnd0; @t\2@>
      procedure Out_XEl1(const fEl: string); @t\2@>
      procedure Out_XElEnd(const fEl: string); @t\2@>
      procedure Out_XAttr(const fAt, fVal: string); @t\2@>
      procedure Out_XIntAttr(const fAt: string; fVal: integer); @t\2@>
      procedure Out_PosAsAttrs(const fPos: Position); @t\2@>
      procedure Out_XElWithPos(const fEl: string; const fPos: Position); @t\2@>
      procedure Out_XQuotedAttr(const fAt,fVal: string); @t\2@>
      destructor Done; virtual; @t\2\2\2@> 
   end

@ \node{Constructor.}
We initialize a file, open it for writing, set the initial indentation
amount to zero, and then print the \XML/ header declaration.

@<Implementation for I/O of XML@>=
constructor XMLOutStreamObj.OpenFile(const AFileName:string);
begin @|@/
   mdebug
   write(InfoFile,MizFileName+'.'+copy(AFileName, length(AFilename)-2,3)); @+
   end_mdebug @/
   InitFile(AFileName);
   Rewrite(nFile,1); @/
   mdebug
   WriteLn(InfoFile,' rewritten'); @+
   end_mdebug @/
   nIndent := 0;
   OutString( gXMLHeader);
end;

@ \node{Constructor.} Since \XML/ supports custom style declarations
(think of \XSLT/),
we can also support writing an \XML/ file which uses them. This
specifically needs to adjust the \XML/ declaration.

@p
{add the stylesheet procesing info}
constructor XMLOutStreamObj.OpenFileWithXSL(const AFileName:string);
begin
   OpenFile(AFileName);
   OutString('<?xml-stylesheet type="text/xml" href="file://' +
                MizFiles + 'miz.xml"?>'+ #10);
end;

@ \node{Destructor.} We need to flush the buffer to the file before
freeing up the buffer.

@p
destructor XMLOutStreamObj.Done;
begin
   if (fBuffInd > 0) and (fBuffInd < InOutFileBuffSize) then
      BlockWrite(nFile,fFileBuff^,fBuffInd,fBuffCount);
   inherited Done;
end;

@ \node{Destructor.} Some times we want to further erase the output
file (which seems, at first glance, like \emph{a really bad idea}\dots).

@p
destructor XMLOutStreamObj.EraseFile;
begin Done;
Erase(nFile);
end;

@ Writing a character to the buffer. When the buffer is full, we flush it.

@p
procedure XMLOutStreamObj.OutChar (aChar: char);
begin
   fFileBuff^[fBuffInd]:=AnsiChar(aChar);
   inc(fBuffInd);
   @<Flush \XML/ output buffer, if full@>;
end;

@ The \XML/ output buffer is full when the logical size (\\{fBuffInd})
is equal to the \\{InOutFileBuffSize}. When this happens, we should
write everything to the file, then reset the logical size parameter to
zero. 

@<Flush \XML/ output buffer, if full@>=
   if fBuffInd = InOutFileBuffSize then
   begin BlockWrite(nFile,fFileBuff^,InOutFileBuffSize,fBuffCount);
   fBuffInd:=0;
   end

@ Print a newline (\texttt{"\BS n"}) to the XML output stream.

@<Implementation for I/O of XML@>=
procedure XMLOutStreamObj.OutNewLine;
begin
   OutChar(#10);
end;

@ Printing a string to the output buffer.

@p
procedure XMLOutStreamObj.OutString (const aString: string);
var i: integer;
begin
   for i:=1 to length(aString) do
      OutChar(aString[i]);
end;

@ Printing |nIndent| spaces (``\texttt{\SP}'') to the output buffer.

@p
@t\4\4@> {print \\{nIndent} spaces}
procedure XMLOutStreamObj.OutIndent;
var i:integer;
begin
   for i:=1 to nIndent do OutChar(' ');
end;

@ When printing a start-tag to the file, we start by printing the
indentation, then we increment the indentation, then we print the
``\texttt{<}'' followed by the name of the tag.

\label{XMLOutStreamObj.Out_XElStart}

@p
@t\4\4@>{print '\texttt{<}' and the representation of \\{fEl} with indenting}
procedure XMLOutStreamObj.Out_XElStart(const fEl: string);
begin
   OutIndent;
   inc(nIndent);
   OutChar('<');
   OutString(fEl);
end;

@ When we are done writing the attributes of a tag, we print the
``\texttt{>}'' to the file, and we also print a newline to the file.

@p
@t\4\4@> {close the attributes with '\texttt{>}'}
procedure  XMLOutStreamObj.Out_XAttrEnd;
begin
   OutChar('>');
   OutNewLine;
end;

@ When we want to write the tag, but omit the attributes, we can do so.

@p
@t\4\4@> {no attributes expected}
procedure XMLOutStreamObj.Out_XElStart0( const fEl: string);
begin
   Out_XElStart(fEl);
   Out_XAttrEnd;
end;

@ For empty-element tags, we should close the tag with
``\texttt{/>}'', print a new line, then \emph{decrement} the
indentation since there are no children to the tag.

\label{XMLOutStreamObj.Out_XElEnd0}

@p
@t\4\4@> {print '\texttt{/>}' with indenting}
procedure XMLOutStreamObj.Out_XElEnd0;
begin
   OutString('/>');
   OutNewLine;
   dec(nIndent);
end;

@ When printing an empty-element tag without any attributes, we can
combine the preceding functions together.

@p
@t\4\4@> {no attributes and elements expected}
procedure XMLOutStreamObj.Out_XEl1(const fEl: string);
begin
   Out_XElStart( fEl);
   Out_XElEnd0;
end;

@ Printing end-tags should first decrement the
indentation \emph{before} printing the indentation to the file (so
that the end-tag vertically aligns with the associated
start-tag). Then we print ``\texttt{</}'' followed by the tag name and
then ``\texttt{>}''. We should print a newline to the file, too.

@p
@t\4\4@> {close the \\{fEl} element using '\texttt{</}'}
procedure XMLOutStreamObj.Out_XElEnd( const fEl: string);
begin
   dec(nIndent);
   OutIndent;
   OutString('</');
   OutString( fEl);
   OutChar('>');
   OutNewLine;
end;

@ When printing one attribute to a tag, we need a whitespace printed
(to separate the tag's name --- or preceding attribute --- from the
current attribute being printed), followed by the attribute's name
printed with an equality symbol, then enquoted the value of the
attribute.

\label{XMLOutStreamObj.Out_XAttr}

@p 
@t\4\4@> {print one attribute key-value pair}
procedure XMLOutStreamObj.Out_XAttr(const fAt,fVal: string);
begin
   OutChar(' ');
   OutString( fAt);
   OutString('="');
   OutString(fVal);
   OutChar('"');
end;

@ When the value of an attribute is an integer, invoke
$\\{IntToStr}(\\{fVal})$ to pretend it is a string value. Then printing
out to a file an attribute with an integer value boils down to
printing out the attribute with a string value.

@p
@t\4\4@> {print one attribute key-value pair, where value is integer}
procedure XMLOutStreamObj.Out_XIntAttr(const fAt: string; @+ fVal: integer);
begin
   Out_XAttr(fAt, IntToStr(fVal));
end;

@ We can now just compose writing the start of a tag
(\section\xref{XMLOutStreamObj.Out_XElStart}), followed by its
attributes (\section\xref{XMLOutStreamObj.Out_PosAsAttrs}), and then
close the empty-element tag (\section\xref{XMLOutStreamObj.Out_XElEnd0}).

@p
procedure XMLOutStreamObj.Out_XElWithPos(const fEl: string;@+ const fPos: Position);
begin
   Out_XElStart(fEl);
   Out_PosAsAttrs(fPos);
   Out_XElEnd0;
end;

@ We will want to treat a \emph{position} (i.e., the line and
column) as two attributes. We print this out using \\{Out\_PosAsAttrs}.
We rely on the \\{XMLDict}'s \\{XMLAttrName} for standardizing the
name for the line and column.

\label{XMLOutStreamObj.Out_PosAsAttrs}

@p
procedure XMLOutStreamObj.Out_PosAsAttrs(const fPos: Position);
begin
   Out_XIntAttr(XMLAttrName[atLine], fPos.Line);
   Out_XIntAttr(XMLAttrName[atCol], fPos.Col);
end;

@ We print a quoted attribute, leveraging printing attributes out to
the file (\section\xref{XMLOutStreamObj.Out_XAttr}). We just need to
escape the \XML/ string (\section\xref{QuoteStrForXML}).

@p
procedure XMLOutStreamObj.Out_XQuotedAttr(const fAt, fVal: string);
begin
   Out_XAttr(fAt, QuoteStrForXML( fVal) );
end;

@* [F] Vocabulary file dictionaries.
Mizar works with vocabulary files (suffixed with \texttt{.voc})
for introducing new identifiers.

\label{dicthan.pas}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%
%%%
@<dicthan.pas@>=
  @<GNU License@>

unit dicthan;

interface @|@#

uses mobjects; @|@#

@t\4@> @<Public constants for \texttt{dicthan.pas}@>@; @#

type
   SymbolCounters = array['A'..'Z'] of word;
   SymbolIntSeqArr = array['A'..'Z'] of IntSequence; @#

@<Class declarations for \texttt{dicthan.pas}@>@;

@<Public function declarations for \texttt{dicthan.pas}@>@; @#

implementation @|@#

uses mizenv,xml_inout,xml_dict; @#

@t\4@> @<Implementation for \texttt{dicthan.pas}@>@t\2@> @#

end.

@ We recall from  Adam Grabowski,
Artur Korni\l{}owicz, and
Adam Naumowicz's ``Mizar in a Nutshell'' (\section4.3, \doi{10.6092/issn.1972-5787/1980}), the various
prefixes for vocabulary file entries:
@^Grabowski, Adam@>
@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>
@^Naumowicz, Adam@>

\label{dicthan.pas:constants}

{-- G} for structures

{-- K} for left-functor brackets

{-- L} for right-functor brackets

{-- M} for modes

{-- O} for functors

{-- R} for predicates

{-- U} for selectors

{-- V} for attributes

@<Public constants for \texttt{dicthan.pas}@>=
const @|@/
   StandardPriority = 64; @/
   AvailableSymbols = ['G','K','L','M','O','R','U','V'];

@ There are only three classes in the dictionary handling module. We
have an abstraction for a symbol appearing in a vocabulary file, a
sort of ``checksum'' for the counts of symbols appearing in a
vocabulary file, and a dictionary associating to each article name
(string) a collection of symbols.

@<Class declarations for \texttt{dicthan.pas}@>=
   @<Symbol for vocabulary@>; @#
   @<Abstract vocabulary object declaration@>; @#
   @<Vocabulary object declaration@>;

@ @<Public function declarations for \texttt{dicthan.pas}@>=
   function GetPrivateVoc(const fName:string):PVocabulary; @t\2@>
   function GetPublicVoc(@t\hskip-0.6667em@>@+const fName:string;@+ var fVocFile:text):PVocabulary; @t\2@>@#
   
   procedure LoadMmlVcb(@t\hskip-0.6667em@>@+const aFileName: string;@+ var aMmlVcb: MStringList); @t\2@>
   procedure StoreMmlVcb(const aFileName: string;@+ const aMmlVcb: MStringList); @t\2@>
   procedure StoreMmlVcbX(const aFileName: string;@+ const aMmlVcb: MStringList); @t\2@>


@ We can test if an entry in the dictionary is valid. Remember, only
functor symbols can have a priority associated with it (and a priority
is a number between 0 and $255=2^{8}-1$, inclusive).

Also remember, that a symbol in a dictionary entry \textbf{cannot}
have whitespaces in it.

\label{IsValidSymbol}

@d delete_prefix == Delete(lLine,1,1)

@<Implementation for \texttt{dicthan.pas}@>=
function IsValidSymbol(const aLine: string): boolean;
var lLine: string;
lKind: char;
lPriority,lPos,lCode: integer;
begin
   IsValidSymbol:=false;
   lLine:=TrimString(aLine);
   @<Initialize \\{lKind}, but exit if dictionary line contains invalid symbol@>;
   delete_prefix;
   case lKind of
      'O': @<Check if functor symbol is valid@>;
      'R': @<Check if predicate symbol is valid@>;
   othercases
   begin
      if Pos(' ',lLine) > 0 then exit;
      IsValidSymbol:=true;
   end;
   endcases;
end;

@ An ``invalid'' line in the dictionary file would be empty lines
(whose length is less than one), and lines which do not start with a
valid prefix. At the end of this chunk, the \\{lKind} should be
initialized to the prefix of the line.

@<Initialize \\{lKind}, but exit if dictionary line contains invalid symbol@>=
   if length(lLine)<=1 then exit;
   lKind:=lLine[1];
   if not (lKind in AvailableSymbols) then exit

@ Recall the \href{https://wiki.freepascal.org/Val}{specification}
for \\{Val} sets \\{lCode} to zero for
success, and the nonzero values store the index where the string is
not a numeric value.

We copy the identifier (as determined from the start of the line
until, but not including, the index of the first space in the line)
and throw away everything after the first whitespace.

When the identifier for the functor symbol is not an empty
string \emph{and} the priority can be determined unambiguously, then
the functor symbol entry is valid. Otherwise it is invalid.

@<Check if functor symbol is valid@>=
         begin
            IsValidSymbol:=true;
            lPos:=Pos(' ',lLine);
            if lPos <> 0 then
            begin {Parse priority for symbol}
               val(TrimString(Copy(lLine,lPos,length(lLine))),lPriority,lCode);
               lLine:=TrimString(Copy(lLine,1,lPos-1));
               IsValidSymbol:=(lCode = 0) and (lLine<>'');
            end;
         end

@ A predicate entry in the dictionary file should not include a
priority, nor should it include any whitespaces. This is the criteria
for a valid predicate symbol entry in the dictionary.

We enforce this by finding the first ``\texttt{\SP}'' character in the
line. If there is one, then we trim both sides of the line (removing
leading and trailing whitespace). We should have no more spaces in the
line. If there is a space, then it is an invalid predicate symbol.

@<Check if predicate symbol is valid@>=
         begin
            lPos:=Pos(' ',lLine);
            if lPos <> 0 then {\\{lLine} contains a space}
            begin
               lLine:=TrimString(Copy(lLine,lPos,length(lLine)));
               if Pos(' ',lLine) > 0 then exit;
            end;
            IsValidSymbol:=true;
         end

@ \node{TSymbol.} These are used in \texttt{kernel/accdict.pas}.
The \\{Kind} is its one-letter kind (discussed
in \section\xref{dicthan.pas:constants}), and \\{Repr} is its lexeme.
For functors, its priority is stored as its \\{Prior}.

The ``infinitive'' appears to be only used for
predicates.

@<Symbol for vocabulary@>=
   PSymbol = ^TSymbol; @/
   TSymbol  = object(MObject) @t\1@>@/
      Kind: char; @/
      Repr,Infinitive: string; @/
      Prior: byte; @/
      constructor Init(fKind: char; fRepr,fInfinitive: string; fPriority:byte); @t\2@>
      constructor Extract(const aLine: string); @t\2@>
      function SymbolStr: string; @t\2@>
      constructor Load(var aText: text); @t\2@>
      procedure Store(var aText: text); @t\2@>
      destructor Done; virtual;  @t\2\2\2@>
   end

@ \node{Constructor.} Given the ``kind'', its ``representation'' and
``infinitive'', and its priority (as a number between 0 and 255), we
can construct a symbol.

\label{TSymbol.Init}

@<Implementation for \texttt{dicthan.pas}@>=
constructor TSymbol.Init(fKind: char; fRepr,fInfinitive: string; fPriority:byte);
begin
   Kind:=fKind; Repr:=fRepr;
   Prior:=fPriority;
   Infinitive:='';
end;

@ \node{Constructor.} When we want to extract a symbol from a line in
the dictionary file, care must be taken for functors (since they may
contain an explicit priority) and for predicates. Predicates have an
undocumented feature to allow ``infinitives'', so an acceptable
predicate line in a dictionary may look like
{\smallbreak\tt\narrower
Rpredicate infinitive\smallbreak}
\noindent%
Although what Mizar does with infinitives, I do not know\dots

@p
constructor TSymbol.Extract(const aLine: string);
var lPos,lCode:integer; lRepr: string;
begin
   Kind:=aLine[1];
   Repr:=TrimString(Copy(aLine,2,length(aLine)));
   Prior:=0;
   Infinitive:='';
   case Kind of
      'O':
         begin
            lPos:=Pos(' ',Repr);
            Prior:=StandardPriority;
            if lPos <> 0 then
               @<Initialize explicit priority for functor entry in dictionary@>;
         end;
      'R':
         begin
            lPos:=Pos(' ',Repr);
            if lPos <> 0 then
            @<Initilize explicit infinitive for a predicate entry in dictionary@>;
         end;
   endcases;
end;

@ Predicates can have an optional infinitive, separated from the
lexeme by a single whitespace. It remains unclear what Mizar uses
predicate infinitives for, but it is a feature. This is written out to
the \texttt{.vcx} file, according to \texttt{xml\_dict.pas}.

Note that there are 4 predicates with infinitives in Mizar:
\enumerate
\item \texttt{jumps\_in} (infinitive: \texttt{jump\_in}) occurs in the
article \texttt{AMISTD\_1}
\item \texttt{halts\_in} (infinitive: \texttt{halt\_in}) occurs in the
article \texttt{EXTPRO\_1}
\item \texttt{refers} (infinitive: \texttt{refer}) occurs in the
article \texttt{SCMFSA7B}
\item \texttt{destroys} (infinitive: \texttt{destroy}) occurs in the
article \texttt{SCMFSA7B}
\endenumerate

@<Initilize explicit infinitive for a predicate entry in dictionary@>=
begin
   lRepr:=Repr; Repr:='';
   Repr:=TrimString(Copy(lRepr,1,lPos-1));
   Infinitive:=TrimString(Copy(lRepr,lPos+1,length(lRepr)));
end

@ Functors with explicit priorities require parsing that priority. It
is assumed that a single whitespace separates the lexeme from the priority.

@<Initialize explicit priority for functor entry in dictionary@>=
begin
   lRepr:=Repr;
   Repr:=''; @/
   val(TrimString(Copy(lRepr,lPos+1,length(lRepr))),Prior,lCode); {Store the priority}
   Repr:=TrimString(Copy(lRepr,1,lPos-1)); {Store the lexeme}
end

@ \node{Serialize symbols.} We can serialize a \\{TSymbol} object,
which produces the sort of entry we'd expect to find in a
dictionary. So we would have the symbol kind, the lexeme, and optional
data (non-default priorities for functors, infinitives for predicates).

\label{TSymbol.SymbolStr}

@<Implementation for \texttt{dicthan.pas}@>=
function TSymbol.SymbolStr: string;
var lStr,lIntStr: string;
begin
   lStr:=Kind+Repr;
   case Kind of
      'O':
         if Prior <> StandardPriority then
         begin
            Str(Prior,lIntStr);
            lStr:=lStr+' '+lIntStr;
         end;
      'R':
         if Infinitive <> '' then
            lStr:=lStr+' '+Infinitive;
   endcases; @/
   SymbolStr:=lStr;
end;

@ Given a text (usually the contents of a vocabulary file), we read in
a line. When the line is a nonempty string, we initialize the lexeme
representation, priority, and infinitives.
Then, when the dictionary entry describes a valid symbol (\section\xref{IsValidSymbol}),
we populate the fields of the \\{TSymbol}.

@p
constructor TSymbol.Load(var aText: text);
var lDictLine: string;
begin
   ReadLn(aText,lDictLine);
   lDictLine:=TrimString(lDictLine);
   if length(lDictLine) = 0 then exit;
   Repr:=''; Prior:=0; Infinitive:='';
   if IsValidSymbol(lDictLine) then
      Extract(lDictLine);
end;

@ Storing a \\{TSymbol} in a file amounts to writing its serialization
(\section\xref{TSymbol.SymbolStr}) to the file.

@p
procedure TSymbol.Store(var aText: text);
begin
   WriteLn(aText,SymbolStr);
end;

@ \node{Destructor.} We just reset the lexeme and infinitive strings
to be empty strings.

@p
destructor TSymbol.Done;
begin
   Repr:='';
   Infinitive:='';
end;

@ \node{Abstract vocabulary objects.}
This is used in \texttt{kernel/impobjs.pas}.
We recall (\section\xref{dicthan.pas}) that the \\{SymbolCounters} are just
an enumerated type consisting of a single uppercase Latin Letter. 

@<Abstract vocabulary object declaration@>=
   AbsVocabularyPtr = ^AbsVocabularyObj; @/
   AbsVocabularyObj = object(MObject) @t\1@> @/
      fSymbolCnt: SymbolCounters;
      constructor Init; @t\2@>
      destructor Done; virtual;  @t\2\2\2@>
   end

@ We only have the constructor and destructor for abstract vocabulary
objects. 

@<Implementation for \texttt{dicthan.pas}@>=
constructor AbsVocabularyObj.Init;
begin
   FillChar(fSymbolCnt,SizeOf(fSymbolCnt),0);
end;

destructor AbsVocabularyObj.Done;
begin
end;

@ \node{Vocabulary objects.} A ``vocabulary object'' is just a
collection of \\{PSymbol}s read in from a vocabulary file.

These are also used in \texttt{kernel/accdict.pas}. 

@<Vocabulary object declaration@>=
   PVocabulary = ^TVocabulary; @/
   TVocabulary = object(AbsVocabularyObj) @t\1@> @/
      Reprs: MCollection; @/
      constructor Init; @t\2@>
      constructor ReadPrivateVoc(const aFileName: string); @t\2@>
      constructor LoadVoc(var aText: text); @t\2@>
      procedure StoreVoc(@t\hskip-0.6667em@>@+const aFileName: string;@+ var aText: text); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor (Empty vocabulary).} We can construct the empty
vocabulary by just initializing the underlying collection.

@<Implementation for \texttt{dicthan.pas}@>=
constructor TVocabulary.Init;
begin
   FillChar(fSymbolCnt,SizeOf(fSymbolCnt),0);
   Reprs.Init(10,10);
end;

@ \node{Destructor.} We only need to free up the underlying collection.

@p
destructor TVocabulary.Done;
begin
   Reprs.Done;
end;

@ \node{Constructor.} We can read from a private vocabulary file.

@p
constructor TVocabulary.ReadPrivateVoc(const aFileName: string);
 var lDict: text;
     lDictLine: string;
     lSymbol: PSymbol;
begin
    Init;
    Assign(lDict,aFileName); @/
    without_io_checking(reset(lDict)); @/
    if ioresult <> 0 then exit; {file is not ready to be read, bail out!}
    while not seekEOF(lDict) do
    @<Read line into vocabulary from dictionary file@>;
   Close(lDict);
end;

@ When reading dictionary lines into a vocabulary file, we skip over
blank lines. Further, we only read \emph{valid} entries into the
vocabulary. 

@<Read line into vocabulary from dictionary file@>=
begin
   readln(lDict,lDictLine);
   lDictLine:=TrimString(lDictLine);
   if length(lDictLine) > 1 then {if dictionary line is not blank}
   begin
      lSymbol:=new(PSymbol,Extract(lDictLine));
      if IsValidSymbol(lDictLine) then {add the symbol}
      begin
         inc(fSymbolCnt[lSymbol^.Kind]);
         Reprs.Insert(lSymbol); @+
      end;
   end;
end

@ \node{Constructor.}
We can read in the vocabulary from a file. If I am not mistaken, this
is usually from \texttt{mml.vct}. We have the first line look like
``\texttt{G3 K0 L0 M1 O7 R2 U4 V6}'', which enumerates the number of
different types of definitions appearing in an article.

\label{TVocabulary.LoadVoc}

@<Implementation for \texttt{dicthan.pas}@>=
constructor TVocabulary.LoadVoc(var aText: text);
var i, lSymbNbr, lNbr: integer;
    lKind,lDummy,c: Char;
begin
   lSymbNbr:=0;
   @<Count \\{lNbr} the number of dictionary entries for an article@>;
   ReadLn(aText);
   Reprs.Init(10,10);
   for i:=1 to lSymbNbr do
   begin
      Reprs.Insert(new(PSymbol,Load(aText)));
   end;
end;

@ Since the first line counts the different sorts of definitions
appearing in the article, we can parse the numbers, then add them
up. This initializes the \\{fSymbolcCnt} entry for $c$.

@<Count \\{lNbr} the number of dictionary entries for an article@>=
   for c:='A' to 'Z' do if c in AvailableSymbols then
   begin
      Read(aText, lKind, lNbr, lDummy);
      fSymbolCnt[c]:=lNbr;
      Inc(lSymbNbr, fSymbolCnt[c]);
   end

@ \node{Storing a dictionary entry.} This appends to a \texttt{.vct}
file the entries for an article. Specifically, this is just the
``\texttt{\#}ARTICLE'' and then the counts of the different kinds of
definitions.

\label{TVocabulary.StoreVoc}

@<Implementation for \texttt{dicthan.pas}@>=
procedure TVocabulary.StoreVoc(@t\hskip-0.5em@> @+const aFileName: string;@+ var aText: text);
var i: Byte; c: Char;
begin
   WriteLn(aText, '#', aFileName);
   for c:='A' to 'Z' do
      if c in AvailableSymbols then Write(aText, c,fSymbolCnt[c], ' ');
   WriteLn(aText);
   for i:=0 to Reprs.Count - 1 do PSymbol(Reprs.Items^[i])^.Store(aText);
end;

@ \node{Miscellaneous public-facing functions.}


@<Implementation for \texttt{dicthan.pas}@>=
function GetPrivateVoc(const fName:string):PVocabulary;
var lName: string;
begin
   lName:=fName;
   if ExtractFileExt(lName) = '' then lName:=lName+'.voc';
   if not MFileExists(lName) then
   begin
      GetPrivateVoc:=nil;
      exit;
   end;
   GetPrivateVoc:=new(PVocabulary,ReadPrivateVoc(lName));
end;

@ \node{Reading mml.vct entries.}
The \texttt{\$MIZFILES/mml.vct} file contains all the vocabularies
concatenated together into one giant vocabulary file. It uses lines
prefixed with ``\#'' followed by the article name to separate the
vocabularies from different files. We search for the given article
name (stored in the \\{fName} argument). When we find it, we construct
the Vocabulary object (\section\xref{TVocabulary.LoadVoc}).

@p
function GetPublicVoc(@t\hskip-0.6667em@> @+const fName:string;@+ var fVocFile:text): PVocabulary;
var lLine: string;
begin
   GetPublicVoc:=nil;
   reset(fVocFile);
   while not eof(fVocFile) do
   begin
      readln(fVocFile,lLine);
      if (length(lLIne)>0) and (lLine[1]='#') and
            (copy(lLine,2,length(lLine)) = fName) then
      begin
         GetPublicVoc:=new(PVocabulary,LoadVoc(fVocFile));
         exit;
      end;
   end;
end;

@ \node{Reading from mml.vct.}
This function is used by \texttt{libtools/checkvoc.dpr} and in a
couple user tools. In those other functions, they
pass \texttt{\$MIZFILES/mml.vct} as the value for \\{aFileName}.
This procedure will then populate the \\{aMmlVcb} file associating to
each article name its vocabulary.

@p
procedure LoadMmlVcb(@t\hskip-0.6667em@> @+const aFileName: string;@+ var aMmlVcb: MStringList);
var lFile: text;
lDummy: char;
lDictName: string;
r:Integer;
begin
   FileExam(aFileName);
   Assign(lFile, aFileName);
   Reset(lFile); {initialize file for reading}
   aMmlVcb.Init(1000);
   aMmlVcb.fSorted:=true;
   while not eof (lFile) do
   begin
      ReadLn(lFile, lDummy, lDictName);
      r:=aMmlVcb.AddObject(lDictName,new(PVocabulary,LoadVoc(lFile)));
   end;
   Close(lFile);
end;

@ Storing a vocabulary delegates much work
(\section\xref{TVocabulary.StoreVoc}). However, since \\{fCount} is
not initialized, I am uncertain how this works, exactly\dots
Furthermore, this function is not used anywhere in Mizar.

@p
procedure StoreMmlVcb(const aFileName: string;@+ const aMmlVcb: MStringList);
var lFile: text;
i: Integer;
begin
   Assign(lFile, aFileName);
   Rewrite(lFile);
   with aMmlVcb do
      for i:=0 to fCount - 1 do
         PVocabulary(fList^[i].fObject)^.StoreVoc(fList^[i].fString^,lFile);
   Close(lFile);
end;

@ Like \\{StoreMmlVcb}, this function is not used anywhere in Mizar.
This appears to produce the \XML/-equivalent to the previous function.

@p
procedure StoreMmlVcbX(const aFileName: string;@+ const aMmlVcb: MStringList);
var i,s: Integer;
c: char;
VCXfile: XMLOutStreamPtr;
begin
   VCXfile:=new(XMLOutStreamPtr,OpenFile(aFileName));
   VCXfile.Out_XElStart0(XMLElemName[elVocabularies]);
   with aMmlVcb do
      for i:=0 to fCount - 1 do
         with PVocabulary(fList^[i].fObject)^ do
      begin
         VCXfile.Out_XElStart(XMLElemName[elVocabulary]);
         VCXfile.Out_XAttr(XMLAttrName[atName],fList^[i].fString^);
         VCXfile.Out_XAttrEnd;
         @<Write vocabulary counts to \XML/ file@>;
         @<Write symbols to vocabulary \XML/ file@>;
         VCXfile.Out_XElEnd(XMLElemName[elVocabulary]);
      end;
   VCXfile.Out_XElEnd(XMLElemName[elVocabularies]);
   dispose(VCXfile,Done);
end;

@ We write out the counts of each kind of definition appearing in the
article.
 
@<Write vocabulary counts to \XML/ file@>=
         {Kinds}
         for c:='A' to 'Z' do
            if c in AvailableSymbols then
            begin
               VCXfile.Out_XElStart(XMLElemName[elSymbolCount]);
               VCXfile.Out_XAttr(XMLAttrName[atKind],c);
               VCXfile.Out_XIntAttr(XMLAttrName[atNr],fSymbolCnt[c]);
               VCXfile.Out_XElEnd0;
            end

@ We write out each symbol appearing in the article's vocabulary.

@<Write symbols to vocabulary \XML/ file@>=
         {Symbols}
         VCXfile.Out_XElStart0(XMLElemName[elSymbols]);
         for s:=0 to Reprs.Count - 1 do
            with PSymbol(Reprs.Items[s])^ do
         begin
            VCXfile.Out_XElStart(XMLElemName[elSymbol]);
            VCXfile.Out_XAttr(XMLAttrName[atKind],Kind);
            VCXfile.Out_XAttr(XMLAttrName[atName],QuoteStrForXML(Repr));
            case Kind of
               'O': VCXfile.Out_XIntAttr(XMLAttrName[atPriority],Prior);
               'R': if Infinitive <> '' then VCXfile.Out_XAttr(XMLAttrName[atInfinitive],Infinitive);
            end;
            VCXfile.Out_XElEnd0;
         end;
         VCXfile.Out_XElEnd(XMLElemName[elSymbols])


@* [F] Scanner.
The \texttt{scanner.pas} file contains the \\{MTokeniser} and
the \\{MScanner}. 

It is worth noting: if we want to extend Mizar to support Unicode,
then we would want to hack this file accordingly. Or create
a \texttt{utf8scanner} module, whichever. This scanner class is built
specifically to work with \ASCII/ characters, specifically accepting
printable characters and the space (``{\tt\SP}'') characters as valid
input.

\label{scanner.pas}

@<scanner.pas@>=
@<GNU License@>

unit scanner;

interface;

uses errhan,mobjects;

const
   MaxLineLength  = 80; @/
   MaxConstInt = 2147483647; {$= 2^{31}-1$, maximal signed 32-bit integer} @#

@t\4@> @<Type declarations for scanner@>@; @#

implementation @|@#

uses
   mizenv,librenv,mconsole,xml_dict,xml_inout; @#

@t\4@> @<Implementation for scanner.pas@>  @t\2@> @#

end.

@ Note that a \\{LexemRec} is really a standardized token. I was
always raised to believe that a ``lexeme'' refers to the literal text
underlying a token.

\label{LexemRec}

@<Type declarations for scanner@>=
type
   ASCIIArr = array[chr(0)..chr(255)] of byte; @#

   LexemRec = record Kind: char; Nr: integer; end; @#

   @<Token object class@>; @#

   @<Tokens collection class@>; @#

   @<MToken object class@>; @#

   @<MTokeniser class@>; @#

   @<MScanner object class@>;

@ The ``default allowed'' characters are the 10 decimal digits, the 26
uppercase Latin letters, the 26 lowercase Latin letters, and the
underscore (``\_'') character.

@<Implementation for scanner.pas@>=
var DefaultAllowed:AsciiArr = @/
       (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0, @/
        0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1, {'\_' allowed in identifiers by default!}
        0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0, @/
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, @/
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0);

@ \node{Tokens object.} A token contains a lexeme, but it extends
an \\{MStr} object.

\label{TokenObj}

@<Token object class@>=
   TokenPtr = ^TokenObj; @/
   TokenObj = object(MStrObj)  @t\1@> @/
      fLexem: LexemRec; @/
      constructor Init(aKind:char; aNr:integer@+;@+ const aSpelling: string); @t\2\2\2@>
   end

@ The constructor for a token requires its kind (functor, mode,
predicate, etc.), and its internal ``number'', as well as its raw
lexeme \\{aSpelling}.

@<Implementation for scanner.pas@>=
constructor TokenObj.Init(aKind:char; aNr:integer@+;@+ const aSpelling: string);
begin
   fLexem.Kind:=aKind;
   fLexem.Nr:=aNr;
   fStr:=aSpelling;
end;

@* [S] Collections of tokens.
We can populate a token collection from a dictionary file, or we can
start with an empty collection. We can save our collection to a
file. We can also insert (or ``collect'') a new token into the
collection.

@<Tokens collection class@>=
   TokensCollection = object(MSortedStrList) @t\1@> @/
      fFirstChar: array [chr(30)..chr(255)] of integer; @/
      constructor InitTokens; @t\2@>
      constructor LoadDct(const aDctFileName:string); @t\2@>
      procedure SaveDct(const aDctFileName:string); @t\2@>
      procedure SaveXDct(const aDctFileName:string);  @t\2@>
      function CollectToken(const aLexem:LexemRec;@+ const aSpelling:string): boolean; @t\2\2\2@>
   end

@ \node{Construct empty token collection.}

\label{TokensCollection.InitTokens}

@<Implementation for scanner.pas@>=
constructor TokensCollection.InitTokens;
begin
   Init(100);
end;

@ \node{Insert.} If the collection already contains the token
described by \\{aLexem}, then we just free up the memory allocated for
the token (avoid duplicates). Otherwise, we insert the token.

@<Implementation for scanner.pas@>=
function TokensCollection.CollectToken(const aLexem:LexemRec;@+ const aSpelling:string): boolean;
var k:integer; lToken:TokenPtr;
begin
   lToken:=new(TokenPtr,Init(aLexem.Kind,aLexem.Nr,aSpelling));
   if Search(lToken,k)
   then {already contains token?}
   begin
      CollectToken:=false;
      dispose(lToken,Done)
   end
   else
   begin
      CollectToken:=true;
      Insert(lToken)
   end
end;

@ \node{Load a dictionary.} We open the dictionary ``\texttt{.dct}''
file (expects the file name to be lacking that extension), and construct
an empty token collection. Then we iterate through the dictionary,
reading each line, forming a new token, then inserting it into the
collection.

The ``\texttt{.dct}'' file contains all the identifiers from articles
referenced in the \texttt{environ} part of an article, and it will
always have the first 148 lines be for reserved keywords. The format
for a ``\texttt{.dct}'' file consists of lines of the form

\centerline{$\langle\textit{kind\/}\rangle\langle\textit{number\/}\rangle$\SP$\langle\textit{name\/}\rangle$}

\noindent The ``kind'' is a single byte, the \emph{number} is an integer
assigned for the identifier, and \textit{name} is the lexeme (string
literal) for the identifier. This also has an \XML/ file for this same
information, the ``\texttt{.dcx}'' file.

@:dct file}{\texttt{.dct} file@>
@:dcx file}{\texttt{.dcx} file@>

\label{TokensCollection.LoadDct}

@<Implementation for scanner.pas@>=
constructor TokensCollection.LoadDct(const aDctFileName:string);
var Dct: text;
lKind,lDummy:AnsiChar; lNr: integer; lString: string;
i: integer; c:char;
begin
   assign(Dct,aDctFileName+'.dct');
   reset(Dct);
   InitTokens;
   @<Load all tokens from the dictionary@>;
   close(Dct);
   @<Index first character appearances among definitions@>;
end;

@ We just iterate through the dictionary, constructing a new token for
each line we read.

@<Load all tokens from the dictionary@>=
   while not seekEof(Dct) do
   begin
      readln(Dct,lKind,lNr,lDummy,lString);
      Insert(new(TokenPtr,Init(char(lKind),lNr,lString)));
   end

@ We index the first appearance of each leading character in a token.

@<Index first character appearances among definitions@>=
   for c:=chr(30) to chr(255) do
      fFirstChar[c]:=-1;
   for i:=0 to Count-1 do
   begin
      c:=TokenPtr(Items^[fIndex^[i]])^.fStr[1];
      if fFirstChar[c] = -1 then
         fFirstChar[c]:=i;
   end

@ We save a token collection to a ``\texttt{.dct}'' file. This appears
to just produce the concatenation of the definition kind, the
identifier number, then a whitespace separating it from the
lexeme. \textbf{Caution:} this is \emph{not} an \XML/ format! For
that, see \\{SaveDctX}.

@:dct file}{\texttt{.dct} file@>

@<Implementation for scanner.pas@>=
procedure TokensCollection.SaveDct(const aDctFileName:string);
var i: integer; DctFile: text;
begin
   assign(DctFile,aDctFileName+'.dct'); rewrite(DctFile);
   for i:=0 to Count-1 do
      with TokenPtr(Items^[i])^, fLexem do
         writeln(DctFile,AnsiChar(Kind),Nr,' ',fStr);
      close(DctFile);
end;

@ \node{Save dictionary to XML file.} The RNC (compact Relax NG Schema):
Local dictionary for an article. The symbol kinds still use
very internal notation.

{\obeylines\tt
   elSymbols =
   attribute atAid \LB xsd:string\RB?,
   element elSymbols \LB
   \quad   element elSymbol \LB
   \qquad   attribute atKind \LB xsd:string\RB,
   \qquad   attribute atNr \LB xsd:integer\RB,
   \qquad   attribute atName \LB xsd:integer\RB
   \quad   \RB*
   \RB
}

\noindent %
This creates the \texttt{.dct} file for an article.

@:dct file}{\texttt{.dct} file@>

@<Implementation for scanner.pas@>=
procedure TokensCollection.SaveXDct(const aDctFileName:string);
var
   lEnvFile: XMLOutStreamObj; i: integer;
begin
   lEnvFile.OpenFile(aDctFileName);
   with lEnvFile do
   begin
      Out_XElStart(XMLElemName[elSymbols]);
      Out_XAttr(XMLAttrName[atAid], ArticleID);
      Out_XQuotedAttr(XMLAttrName[atMizfiles], MizFiles); @/
      Out_XAttrEnd; {print \texttt{elSymbols} start-tag}
      for i:=0 to Count-1 do {print children \texttt{elSymbol} elements}
         with TokenPtr(Items^[i])^, fLexem do
      begin
         Out_XElStart(XMLElemName[elSymbol]);
         Out_XQuotedAttr(XMLAttrName[atKind], Kind);
         Out_XIntAttr(XMLAttrName[atNr], Nr);
         Out_XQuotedAttr(XMLAttrName[atName], fStr);
         Out_XElEnd0;
      end;
         Out_XElEnd(XMLElemName[elSymbols]); {print \texttt{elSymbols} end-tag}
   end;
   lEnvFile.Done;
end;

@* [S] Mizar token objects.
This appears to be tokens for a specific file. An MToken extends a
Token (\section\xref{TokenObj}).

\label{MTokenObj}

@<MToken object class@>=
   MTokenPtr = ^MTokenObj; @/
   MTokenObj = object(TokenObj) @t\1@> @/
      fPos: Position; @/
      constructor Init(aKind:char; aNr:integer@+;@+@+ const aSpelling: string;@+ const aPos: Position); @t\2\2\2@>
   end

@ \node{Constructor.} Construct a token. This might be a tad
confusing, at least for me, because the lexeme is stored in
the \\{fStr} field, whereas the standardized token is stored in
the \\{fLexem} field.

We do not need to invoke the constructor for any ancestor class,
because we just construct everything here. This seems like a bug
waiting to happen\dots

\label{MTokenObj.Init}

% NOTE: the spacing for the function arguments cannot fit on one line

@<Implementation for scanner.pas@>=
constructor MTokenObj.Init(aKind:char; aNr:integer;
                           const aSpelling: string@t\1@>;
                           const aPos: Position@t\2@>);
begin
   fLexem.Kind:=aKind;
   fLexem.Nr:=aNr;
   fStr:=aSpelling;
   fPos:=aPos;
end;

@ \node{Token Kind constants.}
There are four kinds of tokens we want to distinguish:
all valid tokens are either (1) numerals, or (2) identifiers. Then we
also have (3) error tokens. But last, we have (4) end of text tokens.

These are for identifying everything which is neither an identifier
defined in the vocabulary files, nor a reserved keyword.

\label{scanner.pas:implementation:const}

@<Implementation for scanner.pas@>=
const
   Numeral = 'N';
   Identifier = 'I';
   ErrorSymbol = '?';
   EOT = '!';

@* [S] Tokeniser.
The first step in lexical analysis is to transform a character stream
into a token stream. The Tokeniser extends the MToken object
(\section\xref{MTokenObj}), which in turn extends the Token object
(\section\xref{TokenObj}).

In particular, we should take a moment to observe the new
fields. The \\{fPhrase} field is a segment of the input stream which
is expected to start at a non-whitespace character.

The \\{SliceIt} function populates the \\{TokensBuf} and
the \\{fIdents} fields from the \\{fPhrase} field.
I cannot find where \\{fTokens} is populated.

Note that the MTokeniser is not, itself, used anywhere \emph{directly}. It's extended
in the \\{MScannObj} class, which is used
in \texttt{base/mscanner.pas} (and in \texttt{kernel/envhan.pas}).

The contract for \\{GetPhrase} ensures the \\{fPhrase} will be
populated with a string ending with a space (``{\tt\SP}'') character
or it will be the empty string.
Any class extending \\{MTokeniser} must respect this contract.

\label{MTokeniser:class}

@<MTokeniser class@>=
   MTokeniser = object(MTokenObj)  @t\1@> @/

      fPhrase: string; @/
      fPhrasePos: Position; @/

      fTokensBuf: MCollection; @/

      fTokens,fIdents: TokensCollection; @/

      constructor Init; @t\2@>
      destructor Done; virtual;  @t\2@>

      procedure SliceIt; virtual;  @t\2@>
      procedure GetToken; virtual;  @t\2@>

      procedure GetPhrase;  virtual;  @t\2@>
      function EndOfText: boolean; virtual;  @t\2@>

      function IsIdentifierLetter(ch: char): boolean; virtual;  @t\2@>
      function IsIdentifierFirstLetter(ch: char): boolean; virtual; @t\2@>

      function Spelling(const aToken: LexemRec): string; virtual; @t\2\2\2@>
   end

@ Spelling boils down to three cases (c.f., types of tokens \section\xref{scanner.pas:implementation:const}): numerals, identifiers, and
everything else. Numerals spell out the base-10 decimal expansion.

The other two cases boil down to finding the first matching token in
the caller's collection of tokens with the same lexeme supplied as an
argument, provided certain `consistency' checks hold (the lexeme and
token have the same \\{Kind}).

@<Implementation for scanner.pas@>=
function MTokeniser.Spelling(const aToken: LexemRec): string;
var i: integer; s: string;
begin
   Spelling:='';
   if aToken.Kind = Numeral then
   begin
      Str(aToken.Nr,s);
      Spelling:=s; @+
   end else
      if aToken.Kind = Identifier then
      @<Spell an identifier for the MTokeniser@>
      else
      @<Spell an error or EOF for the MTokeniser@>;
end;

@ Spelling an identifier just needs to match the lexeme's number with
the token's number. This finds the first
matching token in the underlying collection, then terminates the function.

@<Spell an identifier for the MTokeniser@>=
      begin
         for i:=0 to fIdents.Count-1 do
            with TokenPtr(fIdents.Items^[i])^ do
               if fLexem.Nr = aToken.Nr then
               begin Spelling:=fStr; exit end;
      end

@ Spelling anything else for the tokeniser needs the kind and number
of the lexeme to match those of the token. Again, this finds the first
matching token in the underlying collection, then terminates the function.

@<Spell an error or EOF for the MTokeniser@>=
      begin
         for i:=0 to fTokens.Count-1 do
            with TokenPtr(fTokens.Items^[i])^ do
               if (fLexem.Kind = aToken.Kind) and (fLexem.Nr = aToken.Nr) then
               begin Spelling:=fStr; exit end;
      end

@ \node{Constructor.} Initialising a tokeniser starts with a blank
phrase and kind, with most fields set to zero.

@<Implementation for scanner.pas@>=
constructor MTokeniser.Init;
begin
   fPos.Line:=0;
   fLexem.Kind:=' ';
   fPhrase:='  ';
   fPhrasePos.Line:=0;
   fPhrasePos.Col:=0;
   fTokensBuf.Init(80,8);
   fTokens.Init(0);
   fIdents.Init(100);
end;

@ \node{Destructor.} This chains to free up several fields, just
invoking their destructors.

@<Implementation for scanner.pas@>=
destructor MTokeniser.Done;
begin
   fPhrase:='';
   fTokensBuf.Done;
   fTokens.Done;
   fIdents.Done;
end;

@ \node{Aside on ASCII separators.}
Note: \\{chr}(30) is the record separator in \ASCII/, and \\{chr}(31) is
the unit separator. Within a group (or table), the records are
separated with the ``RS'' (\\{chr}(30)). As far as unit separators,
Lammer Bies explains
(\href{https://www.lammertbies.nl/comm/info/ascii-characters}{{\tt lammertbies.nl/comm/info/ascii-characters}}):
\medbreak

{\narrower\narrower %advance\leftskip by3pc
The smallest data items to be stored in a database are called units in
the \ASCII/ definition. We would call them field now. The unit separator
separates these fields in a serial data storage environment. Most
current database implementations require that fields of most types
have a fixed length. Enough space in the record is allocated to store
the largest possible member of each field, even if this is not
necessary in most cases. This costs a large amount of space in many
situations. The US control code allows all fields to have a variable
length. If data storage space is limited---as in the sixties---this is
a good way to preserve valuable space. On the other hand is serial
storage far less efficient than the table driven RAM and disk
implementations of modern times. I can't imagine a situation where
modern \SQL/ databases are run with the data stored on paper tape or
magnetic reels\dots\par}

\medbreak\noindent%
We will introduce macros for the record separator and the unit
separator, because Mizar's front-end uses them specifically for the
following purposes:

(1) lines longer than 80 characters will contain a |record_separator|
character (\section\xref{replace-long-line-endings-with-record-separator});

(2) all other invalid characters are replaced with the
|unit_separator| character (c.f., \section\xref{replace-every-invalid-char-with-unit-char}).


@d record_separator == chr(30)
@d unit_separator == chr(31)

@ \node{Example of zeroeth step (``getting a phrase'') in tokenising.}
The \\{GetPhrase} function is left as an abstract method of the
tokeniser, so it is worth discussing ``What it is supposed to do''
before getting to the tokenisation of strings.

Suppose we have the following snippet of Mizar:

\medbreak
\centerline{\vbox{\offinterlineskip
\hrule\tt
\halign{\vrule# & \strut\quad #\quad\hfil &\vrule#\cr
&begin &\cr
&  &\cr
&theorem &\cr
&\quad  for x being object &\cr
&\quad  holds x= x; &\cr}
 \hrule}}

\medbreak\noindent%
This is ``sliced up'' into the following ``phrases'' (drawn in boxes) which
are clustered by lines:

\medbreak
{\obeylines\tt\def\SP{\raise0.25pt\hbox{{\tt\char`\ }}}

\setbox2=\hbox to 2.75pc{begin\SP}%
\boxit{1pt}{\box2}{7.5pt}{10pt}

\vskip2pt
\setbox0=\hbox to3.5pc{theorem\SP}%
%\boxit{1.5pt}{\box0}{9.5pt}{11pt}
\boxit{1.5pt}{\box0}{9.75pt}{11pt}

\setbox0=\hbox to2pc{for\SP}
\setbox1=\hbox to1pc{\vphantom{b}x\SP}
\setbox2=\hbox to2.75pc{being\SP}
\setbox3=\hbox to3.25pc{object\SP}
\quad\boxit{1pt}{\box0}{8.75pt}{10pt}\ \boxit{1pt}{\box1}{8.75pt}{10pt}\ \raise1pt\hbox{\boxit{1pt}{\box2}{7.3333pt}{10pt}}\ \raise1pt\hbox{\boxit{1pt}{\box3}{7.5pt}{10pt}}

\setbox0=\hbox to2.8333pc{holds\SP}
\setbox1=\hbox to1.5pc{\vphantom{b}x=\SP}
\setbox3=\hbox to1.5pc{\vphantom{b}x;\SP}
\quad\boxit{1pt}{\box0}{8.75pt}{10pt}\ \boxit{1pt}{\box1}{8.75pt}{10pt}\ \boxit{1pt}{\box3}{8.3333pt}{10pt}

\par}
\medbreak\noindent%
Observe that the ``phrases'' are demarcated by whitespaces
(``{\tt\SP}'') or linebreaks. This is the coarse ``first pass'' before
we carve a ``phrase'' up into a token. A phrase contains at least one
token, possibly multiple tokens (e.g., the phrase ``{\tt x=\SP}''
contains the two tokens ``{\tt x}'' and ``{\tt =}'').

What is the contract for a ``phrase''?
A phrase is \emph{guaranteed} to either be equal to ``\SP'', or it contains at
least one token and it is \emph{guaranteed} to end with a space
``\SP'' character (\ASCII/ code \H{32}).
Further, there are no other possible ``\SP'' characters in a
phrase \emph{except} at the very end. A phrase is never an empty string.

The task is then to \emph{slice up} each phrase into tokens.


@ \node{Tokenise a phrase.} When a ``phrase'' has been loaded into the
tokeniser (which is an abstract method implemented by its descendent
classes), we tokenise it --- ``slice it up'' into tokens, thereby
populating the \\{fTokensBuf} tokens buffer. This is invoked as
needed by the \\{GetToken} method (\section\xref{MTokeniser.GetToken}).

This function is superficially complex, but upon closer scrutiny it is
fairly straightforward.

Also note, despite being marked as ``virtual'', this is not overridden
anywhere in the Mizar program.

The contract ensures, barring catastrophe, the \\{fLexem}, \\{fStr},
and \\{fPos} be populated. \textbf{Importantly:} The \\{fLexem}'s
token type is one of the 
four kinds given in the constant section
(\section\xref{scanner.pas:implementation:const}): \texttt{Numeral}, \texttt{Identifier}, \texttt{ErrorSymbol},
or \texttt{EOT}. What about the ``reserved keywords'' of Mizar? They
are already present in the ``\texttt{.dct}'' file, which is loaded
into the \\{fTokens} dictionary. So they will be discovered in step (\section\xref{MTokeniser.SliceIt.reserved-words})
in this procedure.

\label{MTokeniser.SliceIt}


@<Variables for slicing a phrase@>=
   lCurrChar: integer; {index in \\{fPhrase} for current position}
   EndOfSymbol: integer;
   EndOfIdent: integer; {index in \\{fPhrase} for end of identifier}
   FoundToken : TokenPtr; {most recently found token temporary variable}
   lPos:Position; {position for debugging purposes}

@ @<Implementation for scanner.pas@>=
procedure MTokeniser.SliceIt;
var
   @<Variables for slicing...@>@;
begin
   MizAssert(2333,fTokensBuf.Count=0); {Requires: token buffer is empty}
   lCurrChar:=1;
   lPos:=fPhrasePos; @/
   @<Slice pragmas@>;
   while fPhrase[lCurrChar]<>' ' do
   begin
      @<Determine the ID@>; @/
      @<Try to find a dictionary symbol@>;
      if EndOfSymbol < EndOfIdent then
         @<Check identifier is not a number@>;
      if FoundToken <> nil then
         with FoundToken^ do
      begin
         lPos.Col:=fPhrasePos.Col+EndOfSymbol-1;
         fTokensBuf.Insert(new(MTokenPtr,Init(fLexem.Kind,fLexem.Nr,fStr,lPos)));
         lCurrChar:=EndOfSymbol+1;
         continue;
      end; @/
@t\4@>      {else |FoundToken = nil|}
      @<Whoops! We found an unknown token, insert a 203 error token@>;
   end;
end;

@ We begin by slicing pragmas. This will insert the pragma into the
tokens buffer.

Note that the ``\texttt{\$EOF}'' pragma indicates that we should treat
the file as ending here. So we comply with the request, inserting
the \\{EOT} (end of text) token as the next token to be offered
to the user.

@^\texttt{::\$EOF}@>
@^Pragma@>
@:Pragma, EOF}{Pragma, \texttt{::\$EOF}@>

@<Slice pragmas@>=
   if (lPos.Col = 1) and (Pos('::$',fPhrase) = 1) then
   begin
      fTokensBuf.Insert(new(MTokenPtr,Init(' ',0,
                                           copy(fPhrase,3,length(fPhrase)-3),lPos)));
      if copy(fPhrase,1,6)='::$EOF' then
         fTokensBuf.Insert(new(MTokenPtr,Init(EOT,0,fPhrase,lPos)));
      exit
   end

@ We take the longest possible substring consisting of identifier
characters as a possible identifier. The phrase is guaranteed to
contain at least one token, maybe more, so we just keep going until we
have exhausted the phrase or found a non-identifier character.

Note that all invalid characters are transformed into the ``unit
character'' (c.f., \section\xref{replace-every-invalid-char-with-unit-char}).
We should treat any occurrence of them as an error.

At the end of this stage of our tokenising journey, for valid tokens, we should
have \\{EndOfIdent} and \\{IdentLength} both initialized here.

@<Variables for slicing...@>=
   IdentLength: integer;

@ @<Determine the ID@>=
 @t\4@>     {1. attempt to determine the ID}
      EndOfIdent:=lCurrChar;
      if IsIdentifierFirstLetter(fPhrase[EndOfIdent]) then
         while (EndOfIdent< length(fPhrase)) and
                  IsIdentifierLetter(fPhrase[EndOfIdent]) do inc(EndOfIdent);
      IdentLength:=EndOfIdent-lCurrChar;
      if fPhrase[EndOfIdent] <= unit_separator then
      @<Whoops! ID turns out to be invalid, insert an error token, then continue@>;
      dec(EndOfIdent)

@ Recall (\section\xref{replace-long-line-endings-with-record-separator}),
we treat record separators as indicating the line is ``too long''
(i.e., more than 80 characters long). So we insert a 201 ``Too long source line'' error.
But anything else is treated as an invalid identifier error.

@^Error, 200@>
@^Error, 201@>

@<Whoops! ID turns out to be invalid, insert an error token, then continue@>=
      begin
         lPos.Col:=fPhrasePos.Col+EndOfIdent-1;
         if fPhrase[EndOfIdent] = record_separator then
            fTokensBuf.Insert(new(MTokenPtr,Init(ErrorSymbol,200,'',lPos)))
         else
            fTokensBuf.Insert(new(MTokenPtr,Init(ErrorSymbol,201,'',lPos)));
         lCurrChar:=EndOfIdent+1;
         continue;
      end

@ We look at the current phrase and try to match against tokens found
in the underlying dictionary. When we find a match, we check if there
are \emph{multiple} matches and return the last one (this reflects
Mizar's ``the last version of the notation is preferred''). We
implement this matching scheme using an infinite loop.
Note that this uses a ``\&{repeat}\dots\&{until} \\{false}'' loop, which
is identical to ``\&{while} \\{true} \&{do} \&{begin} \dots \&{end}'' loop.
(I am tempted to introduce a macro just to have this loop ``\&{repeat}\dots\&{until} \\{end\_of\_time}''\dots)
@^Nelson, Alexander M: great sense of humour@>

Recall (\section\xref{MSortedList:declarations}), sorted lists have a
field \\{fIndex} which is an array of indices (which are sorted while
leaving the underlying array \\{Items} of data untouched).

Also, \\{lToken}, \\{lIndex} are used only in this code
chunk. Here \\{lToken} is translated to an index of the underlying
dictionary, so for clarity we introduce a macro to refer to the token directly.
And \\{lIndex} is used as ``the current character'' index to compare
the phrase to the token (indexed by \\{lToken}) as a match or not.

At the end of this chunk, if successful, then |FoundToken| will be set
to a valid token pointer. Further, |EndOfPhrase| will be initialized.

A possible bug: what happens if we look through the entire phrase? We
can't ``look any farther'' down the phrase, so shouldn't we throw an
error? Or lazily read more characters? Or\dots something?

Never fear: this will never happen with Mizar's grammar. The
``reserved words'' are \emph{always} separated from the other stuff by
at least one whitespace.

Also we note the list of symbols is sorted lexicographically.
% {The index of the beginning of the list of symbols starting with a given letter. The symbols are sorted lexicographically.}

This appears to match the phrase with the longest possible matching
entry in the list of symbols (it is ``maximal munch'').

@d the_item(#) == Items^[fIndex^[#]]
@d the_token(#) == TokenPtr(the_item(#))^

@<Variables for slicing...@>=
   EndOfPhrase: integer; {index in \\{fPhrase} for candidate token}
   lIndex: integer; {index for \\{fIndex} entry}
   lToken: integer; {index for entries in dictionary starting with the
   first character of the current token}

@ Reserved keywords and defined terms are loaded into the \\{fTokens}
dictionary.

\label{MTokeniser.SliceIt.reserved-words}
@^Tokenise, reserved keywords@>
 
@<Try to find a dictionary symbol@>=
      EndOfPhrase:=lCurrChar; FoundToken:=nil;
      EndOfSymbol:=EndOfPhrase-1; {initialized for comparison}
      lToken:=fTokens.fFirstChar[fPhrase[EndOfPhrase]];
      inc(EndOfPhrase);
      if (lToken >= 0) then
         with fTokens do
      begin
         lIndex:=2;
         repeat {infinite loop}
            @<If we matched a dictionary entry, then initialize \\{FoundToken}@>;
            if fPhrase[EndOfPhrase] = ' ' then break; {we are done!}
            if (lIndex<=length(the_token(lToken).fStr)) and @|
                  (the_token(lToken).fStr[lIndex] = fPhrase[EndOfPhrase])
            then
            begin
               inc(lIndex);
               inc(EndOfPhrase) @+
            end {iterate, look at next character}
            else if (lToken < Count-1) then {try looking for the last matching item}
            begin
               if (copy(the_token(lToken).fStr,1,lIndex-1)=@|
                      copy(the_token(lToken+1).fStr,1,lIndex-1))
               then inc(lToken) {iterate}
               else break; {we are done!}
            end
 @t\2@>           else break@t\1@>; {we are done!}
         until false;
      end

@ If we have \\{lIndex} (the index of the current phrase) be longer
than the lexeme of the current dictionary entry's lexeme, then we
should populate \\{FoundItem}.

@<If we matched a dictionary entry, then initialize \\{FoundToken}@>=
if lIndex>length(the_token(lToken).fStr) then {we matched the token}
begin
   FoundToken:=the_item(lToken);
   EndOfSymbol:=EndOfPhrase-1;
end

@ When the identifier is not a number, we insert an ``identifier''
token into the tokens buffer.



@<Variables for slicing...@>=
   lFailed: integer; {index of first non-digit character}
   I: integer; {index ranging over the raw lexeme string}
   lSpelling: string; {raw lexeme as a string}

@ @<Check identifier is not a number@>=
      begin
         lSpelling:=copy(fPhrase,lCurrChar,IdentLength);
         lPos.Col:=fPhrasePos.Col+EndOfIdent-1;
         if (ord(fPhrase[lCurrChar])>ord('0')) and
               (ord(fPhrase[lCurrChar])<=ord('9')) then
         begin
            lFailed:=0; {location of non-digit character}
            for I:=1 to IdentLength-1 do
               if (ord(fPhrase[lCurrChar+I])<ord('0')) or
                     (ord(fPhrase[lCurrChar+I])>ord('9')) then
               begin
                  lFailed:=I+1;
                  break;
               end;
            if lFailed=0 then {if all characters are digits}
            @<Whoops! Identifier turned out to be a number!@>;
         end;
         @<Add token to tokens buffer and iterate@>;
      end

@ We add an \\{Identifier} token to the tokens buffer.

@<Variables for slicing...@>=
   lIdent: TokenPtr;

@ @<Add token to tokens buffer and iterate@>=
         lIdent:=new(TokenPtr,Init(Identifier,fIdents.Count+1,lSpelling));
         if fIdents.Search(lIdent,I)
         then dispose(lIdent,Done)
         else fIdents.Insert(lIdent);
         fTokensBuf.Insert(new(MTokenPtr,
                               Init(Identifier,TokenPtr(fIdents.Items^[I])^.fLexem.Nr,lSpelling,lPos)));@/
         lCurrChar:=EndOfIdent+1;
         continue

@ If we goofed and all the characters turned out to be digits (i.e.,
the identifier \emph{was} a numeral after all), we should clean things
up here. Observe we will end up \\{continue}-ing along the loop.

When the numeral token is larger than $\\{MaxConstInt} = 2^{31}-1$
(the largest 32-bit integer, \section\xref{scanner.pas}), then we
should raise a ``Too large numeral'' 202 error token. If we wanted to
support ``arbitrary precision'' numbers, then this should be modified.
@^Error, 202@>

We can either insert into the tokens buffer an error token (in two
possible outcomes) or a numeral token (in the third possible outcome).


@<Variables for slicing...@>=
   lNumber: longint;
   J: integer;

@ @<Whoops! Identifier turned out to be a number!@>=
begin
   if IdentLength > length(IntToStr(MaxConstInt)) then {insert error token}
   begin
      fTokensBuf.Insert(new(MTokenPtr,Init(ErrorSymbol,202,lSpelling,lPos)));
      lCurrChar:=EndOfIdent+1;
      continue;
   end;
   lNumber:=0;
   J:=1;
   for I:=IdentLength-1 downto 0 do
   begin
      lNumber:=lNumber+(ord(fPhrase[lCurrChar+I])-ord('0'))*J;
      J:=J*10;
   end;
   if lNumber > MaxConstInt then {insert error token}
   begin
      fTokensBuf.Insert(new(MTokenPtr,Init(ErrorSymbol,202,lSpelling,lPos)));
      lCurrChar:=EndOfIdent+1;
      continue;
   end;
   {insert numeral token}
   fTokensBuf.Insert(new(MTokenPtr,Init(Numeral,lNumber,lSpelling,lPos)));
   lCurrChar:=EndOfIdent+1;
   continue;
end


@ If we have tokenised the phrase, but the token is not contained in
the dictionary, then we should raise a 203 error.

@^Error, 203@>

@<Whoops! We found an unknown token, insert a 203 error token@>=
      lPos.Col:=fPhrasePos.Col+lCurrChar-1;
      fTokensBuf.Insert(new(MTokenPtr,Init(ErrorSymbol,203,fPhrase[lCurrChar],lPos)));
      inc(lCurrChar)

@ We have purely abstract methods which will invoke \\{Abstract1} (\section\xref{Abstract1}),
which raises a runtime error.

\label{MTokeniser.IsIdentifierLetter}

@<Implementation for scanner.pas@>=
procedure MTokeniser.GetPhrase;
begin Abstract1; end; @#

function MTokeniser.EndOfText: boolean;
begin Abstract1; EndOfText:= false; end; @#

function MTokeniser.IsIdentifierLetter(ch: char): boolean;
begin Abstract1; IsIdentifierLetter:= false; end;

@ \node{Get a token.} Getting a token from the tokeniser will check if
we've exhausted the input stream (which tests if the kind
of \\{fLexem} is \\{EOT}), and exit if we have.

Otherwise, it looks to see if we've got tokens left in the buffer. If
so, just pop one and exit.

But when the token buffer is empty, we invoke the abstract
method \\{GetPhrase} to read some of the input stream. If it turns out
there's nothing left to read, then update the tokeniser to be in the
``end of text'' state.

When we have some of the input stream read into the \\{fPhrase} field,
we tokenise it using the \\{SliceIt} function. Then we pop a token
from the buffer of tokens.

This will populate \\{fLexem}, \\{fStr}, and \\{fPos} with the new
token, lexeme, and position\dots but that's only
because \\{GetPhrase} (\section\xref{MScannObj.GetPhrase}) and \\{SliceIt} (\section\xref{MTokeniser.SliceIt}) do the actual work.

\label{MTokeniser.GetToken}

@<Implementation for scanner.pas@>=
procedure MTokeniser.GetToken;
begin
   if fLexem.Kind = EOT then exit;
   if fTokensBuf.Count > 0 then
   begin
      @<Pop a token from the underlying tokens stack@>;
      exit;
   end;
   GetPhrase;
   if EndOfText then
   begin
      fLexem.Kind:=EOT;
      fStr:='';
      fPos:=fPhrasePos;
      inc(fPos.Col); @/
      exit;
   end;
   SliceIt;
   @<Pop a token from the underlying tokens stack@>;
end;

@ Popping a token will update the lexeme, str, and position fields to
be populated from the first item in the tokens buffer. Then it will
free that item from the tokens buffer, shifting everything down by one.

@<Pop a token from the underlying tokens stack@>=
      fLexem:=MTokenPtr(fTokensBuf.Items^[0])^.fLexem;
      fStr:=MTokenPtr(fTokensBuf.Items^[0])^.fStr;
      fPos:=MTokenPtr(fTokensBuf.Items^[0])^.fPos;
      fTokensBuf.AtFree(0)

@ Testing if the given character is an identifier character or not
requires invoking the abstract method \\{IsIdentifierLetter}
(\section\xref{MTokeniser.IsIdentifierLetter}). 

@<Implementation for scanner.pas@>=
function MTokeniser.IsIdentifierFirstLetter(ch: char): boolean;
begin
   IsIdentifierFirstLetter:=IsIdentifierLetter(ch);
end;

@* [S] Scanner Object.
This extends the Tokeniser class (\section\xref{MTokeniser:class}).
It is the only class extending the Tokeniser class.

@<MScanner object class@>=
MScannPtr = ^MScannObj; @/
   MScannObj = object(MTokeniser)  @t\1@>@/
      Allowed: ASCIIArr; @/
      fSourceBuff: pointer; @/
      fSourceBuffSize: word; @/
      fSourceFile: text; @/
      fCurrentLine: string; @/

      constructor InitScanning(const aFileName,aDctFileName:string); @t\2@>
      destructor Done; virtual; @t\2@>

      procedure GetPhrase; virtual; @t\2@>
      procedure ProcessComment(fLine, fStart: integer; cmt: string); virtual; @t\2@>
      function EndOfText: boolean; virtual; @t\2@>

      function IsIdentifierLetter(ch: char): boolean; virtual; @t\2\2\2@>
   end

@ \node{Get a phrase.}
We search through the lines for the ``first phrase'' (i.e., first
non-whitespace character, which indicates the start of something
interesting). Comments are thrown away as are Mizar pragmas.

This will update \\{fCurrentLine} as needed, setting it to the next
line in the input stream buffer. It will assign a \emph{copy} of the
phrase to the field \\{fPhrase}, as well as update the \\{fPhrasePos}.

There is a comment in Polish, ``uzyskanie pierwszego znaczacego
znaku'', which Google translates as: ``obtaining the first significant sign''.
This seemed like a natural ``chunk'' of code to study in isolation.

The contract for \\{GetPhrase} ensures the \\{fPhrase} will be
populated with a string ending with a space (``{\tt\SP}'') character,
or it will be the empty string (when the end of text has been encountered).

\label{MScannObj.GetPhrase}

@<Implementation for scanner.pas@>=
procedure MScannObj.GetPhrase;
const
   Prohibited: ASCIIArr = @<Characters prohibited by \\{MScanner}@>;
var i,k: integer;
begin
   fPhrasePos.Col:=fPhrasePos.Col+length(fPhrase)-1; @/
   @<Find the first significant `sign'@>;
   for i:=fPhrasePos.Col to length(fCurrentLine) do
      if fCurrentLine[i] =  ' ' then break;
   fPhrase:=Copy(fCurrentLine,fPhrasePos.Col,i-fPhrasePos.Col+1);
end;

@ The prohibited \ASCII/ characters are
everything \emph{NOT} among the follow characters:
\def\lskip{\hskip6pc}\medbreak
{\tt\obeyspaces\obeylines%
\lskip \SP\ {!} " \#\ \$\ \%\ \AM\ ' ( ) * + , - {.} /  : ; < = > ? \AT!
\lskip [ \BS\ ]\ \shiftSix\ \_\ `\  \LB\ \pipe\ \RB\ \TL\ 0 1 2 3 4 5 6 7 8~9
\lskip A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
\lskip a b c d e f g h i j k l m n o p q r s t u v w x y z \par}
\medbreak\noindent%
The reader will observe these are all the ``graphic'' \ASCII/
characters, plus the space (``{\tt\SP}'') character.

@<Characters prohibited by \\{MScanner}@>=
      (1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,@/
       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,@/
       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,@/
       1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,@/
       1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,@/
       1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,@/
       1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)

@ Note that the \\{fCurrentLine} will end with a whitespace, when we
have not consumed the entire underlying input stream.

@<Find the first significant `sign'@>=
   while fCurrentLine[fPhrasePos.Col] = ' ' do
   begin
      if fPhrasePos.Col >= length(fCurrentLine) then
      @<Populate the current line@>;
      inc(fPhrasePos.Col);
   end

@ Now, populating the current line requires a bit of work. We ensure
the end of the current line will end with a space character (``{\tt\SP}''),
which will guarantee the loop iteratively consumes all empty lines in
the file.

Once we arrive at a non-space character, we will break the
loop containing this chunk of code.
If we have exhausted the underlying input stream, then we will
have \\{EndOfText} be true. Should that occur, we exit the function.

@<Populate the current line@>=
begin
   if EndOfText then exit;
   inc(fPos.Line);
   inc(fPhrasePos.Line);
   readln(fSourceFile,fCurrentLine);
   @<Scan for pragmas, and exit if we found one@>;
   @<Skip comments@>;
   @<Trim whitespace from the right of the current line@>;
   @<Replace every invalid character in current line with the unit character@>;
   fCurrentLine:=fCurrentLine+' ';
   if not LongLines then
      if length(fCurrentLine) > MaxLineLength then
      @<Replace end of long line with record separator@>; @/
 @t\4@>        {Assert: we have \\{fCurrentLine} end in ``\texttt{\SP}''}
   fPhrasePos.Col:=0;
   fPos.Col:=0; 
end


@ When we have excessively long lines, and we have not enabled ``long
line mode'', then we just delete everything after $\\{MaxLineLength}+1$
and set $\\{MaxLineLength}-1$ to the record separator (which is
rejected by the Mizar lexer) and the last character in the line to the
space character.

\label{replace-long-line-endings-with-record-separator}

@<Replace end of long line with record separator@>=
begin
   delete(fCurrentLine,MaxLineLength+1,length(fCurrentLine));
   fCurrentLine[MaxLineLength-1]:=record_separator; @/
   fCurrentLine[MaxLineLength]:=' ';
end

@ In particular, if we every encounter an ``invalid'' character, then
we just replace it with the ``unit separator'' character.

\label{replace-every-invalid-char-with-unit-char}

@<Replace every invalid character in current line with the unit character@>=
for k:=1 to length(fCurrentLine)-1 do
   if Prohibited[fCurrentLine[k]]>0 then fCurrentLine[k]:=unit_separator

@ We will trim whitespace from the right of the current line at least
twice. 

@<Trim whitespace from the right of the current line@>=
k:=length(fCurrentLine);
while (k > 0) and (fCurrentLine[k] = ' ') do dec(k);
delete(fCurrentLine,k+1,length(fCurrentLine))

@ Pragmas in Mizar are special comments which start a line with
``\texttt{::\$}''. They are useful for naming theorems
(``\texttt{::\$N} $\langle$\textit{name\/}$\rangle$''), or toggling
certain phases of the Mizar checker. This will process the comment
(\section\xref{MScannObj.ProcessComment}).

Since pragmas are important, we treat it as a token (and not a comment
to be thrown away).

Note: if you try to invoke a pragma, but do not place it at the start
of a line, then Mizar will treat it like a comment.

@<Scan for pragmas, and exit if we found one@>=
k:=Pos('::$',fCurrentLine); {Preprocessing directive}
if (k = 1) then
begin
   ProcessComment(fPhrasePos.Line, 1, copy(fCurrentLine, 1, length(fCurrentLine)));
   @<Trim whitespace from the right of the current line@>;
   fCurrentLine:=fCurrentLine+' ';
   fPhrase:=Copy(fCurrentLine,1,length(fCurrentLine));
   fPhrasePos.Col:=1;
   fPos.Col:=0;
   exit
end

@ Scanning a comment will effectively replace the start of the comment
(``\texttt{::}'') up to and including the end of the line, with a
single space. This will process the comment
(\section\xref{MScannObj.ProcessComment}). 

@<Skip comments@>=
k:=Pos('::',fCurrentLine); {Comment}
if (k <> 0) then
begin
   ProcessComment(fPhrasePos.Line, k, copy(fCurrentLine, k, length(fCurrentLine)));
   delete(fCurrentLine,k+1,length(fCurrentLine));
   fCurrentLine[k]:=' ';
end

@ ``Processing a comment'' really means skipping the comment.

\label{MScannObj.ProcessComment}

@<Implementation for scanner.pas@>=
procedure MScannObj.ProcessComment(fLine, fStart: integer; cmt: string);
begin end;

@ Testing if the scanner has exhausted the input stream amounts to
checking the current line has been completely read \emph{and} the
current source file has arrived at an \\texttt{eof} state.

@<Implementation for scanner.pas@>=
function MScannObj.EndOfText: boolean;
begin
   EndOfText := (fPhrasePos.Col >= length(fCurrentLine)) and eof(fSourceFile);
end;

@ Testing if a character is an identifier letter amounts to testing if
it is allowed (i.e., not disallowed).

@<Implementation for scanner.pas@>=
function MScannObj.IsIdentifierLetter(ch: char): boolean;
begin
   IsIdentifierLetter:=Allowed[ch]<>0;
end;

@ \node{Constructor.} The only way to construct a scanner. This
expects an article to be read in \\{aFileName} and a dictionary to
be loaded (\\{aDctFileName}, loaded with \section\xref{TokensCollection.LoadDct}). The buffer size for
reading \\{aFileName} is initially @"4000.

@<Implementation for scanner.pas@>=
constructor MScannObj.InitScanning(const aFileName,aDctFileName:string);
begin
   inherited Init;
   Allowed:=DefaultAllowed;
   fTokens.LoadDct(aDctFileName);
   assign(fSourceFile,aFileName);
   fSourceBuffSize:=@"4000;
   getmem(fSourceBuff,fSourceBuffSize);
   settextbuf(fSourceFile,fSourceBuff^,@"4000);
   reset(fSourceFile);
   fCurrentLine:=' ';
   GetToken;
end;

@ \node{Destructor.} We must remember to close the source file, free
the buffer, close the lights, and lock the doors.

@<Implementation for scanner.pas@>=
destructor MScannObj.Done;
begin
   close(fSourceFile);
   FreeMem(fSourceBuff,fSourceBuffSize);
   fCurrentLine:='';
   inherited Done;
end;


@* [F] Format.
The first step towards disambiguating the meaning of identifiers is to
use ``formats''.
Recall from, e.g., Andrzej Trybulec's ``Some Features of the Mizar Language''
(ESPRIT Workshop, Torino, 1993;
\href{https://mizar.uwb.edu.pl/project/trybulec93.pdf}{{\tt mizar.uwb.edu.pl/project/trybulec93.pdf}},
\section3) that the ``Format'' describes with how many arguments a
``Constructor Symbol'' may be used. The basic formats:
\item{$\bullet$} Predicates $\langle$lexeme, left arguments number,
right arguments number$\rangle$
\item{$\bullet$} Modes $\langle$lexeme, arguments number$\rangle$ for
``mode Foo of $T_{1},\dots,T_{n}$'' where $n$ is the arguments number
\item{$\bullet$} Functors $\langle$lexeme, left arguments number,
right arguments number$\rangle$
\item{$\bullet$} Bracket functors $\langle$left bracket lexeme, arguments number,
right bracket lexeme$\rangle$
\item{$\bullet$} Selector $\langle$lexeme, $1\rangle$
\item{$\bullet$} Structure $\langle$lexeme, arguments number$\rangle$
  for generic structures over [arguments number] parameters
\item{$\bullet$} Structure $\langle$lexeme, $1\rangle$ for situations
  where we write ``\texttt{the [structure] of [term]}''

\medbreak\noindent%
We store these format information in \XML/ files.
See also Adam Grabowski,
Artur Korni\l{}owicz, and
Adam Naumowicz's ``Mizar in a Nutshell''
(viz.\ \section2.3, \doi{10.6092/issn.1972-5787/1980}) for a little more
discussion about formats.
@^Grabowski, Adam@>
@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>
@^Naumowicz, Adam@>
@^Trybulec, Andrzej@>

@<\_format.pas@>=
@<GNU License@>
unit _formats;

interface @| @/

uses mobjects,scanner,dicthan,xml_inout; @#

@<Declare classes for \texttt{\_formats.pas}@>@#

   function CompareFormats(aItem1, aItem2: Pointer): Integer; @t\2@>

   function In_Format(fInFile: XMLInStreamPtr): MFormatPtr; @t\2@> @#


@<Global variables (\texttt{\_formats.pas})@>@; @#

implementation @|@#

uses errhan,xml_dict,xml_parser
mdebug ,info @+ end_mdebug;

@<Implementation for \texttt{\_formats.pas}@> @t\2@>@; @#

end.

@

\label{gFormatsColl}
@<Global variables (\texttt{\_formats.pas})@>=
var @!gFormatsColl: MFormatsList;
   @!gPriority: BinIntFunc;
   @!gFormatsBase: integer; @#

@ Broadly speaking, there are only 3 types of ``formats'': prefix
formats, infix formats, bracket-like formats. These are viewed as
``subclasses'' of a base \\{MFormat} object.

We will want to collect the formats from articles referenced by the
environment of an article being verified or parsed. This motivates
the \\{MFormatList} object.

@<Declare classes for \texttt{\_formats.pas}@>=
   @<Declare \\{MFormat} object@>; @#

   {\textbf{TODO}: add assertions that nr. of all format arguments is equal
   to the number of visible args (Visible) of a pattern}
   @<Declare \\{MPrefixFormat} object@>; @#

   @<Declare \\{MInfixFormat} object@>; @#
   
   @<Declare \\{MBracketFormat} object@>; @#

   @<Declare \\{MFormatsList} object@>;

@ The \emph{presentation} of the code is a bit disorganized from the
perspective of pedagogy, so I am going to re-organize for the sake of
discussing it.

@<Implementation for \texttt{\_formats.pas}@>=

@<Constructors for derived format classess@>@;

@<Compare formats@>@;

@<Implementation for \\{MFormatsList}@>@;

@<Read formats from an \XML/ input stream@>@;

@<Implement \\{MFormatObj}@>@;

@ \node{Format base class.} All format instances have a lexeme called
its \\{fSymbol}. Recall that \\{LexemeRec} (\section\xref{LexemRec})
is a normalized token using a single character to describe its kind,
and an integer to keep track of it (instead of relying on a raw string).

@<Declare \\{MFormat} object@>=
   MFormatPtr = ^MFormatObj; @/
   MFormatObj = object(MObject) @t\1@> @/
      fSymbol: LexemRec;
      constructor Init(aKind:Char; aSymNr:integer); @t\2@>
      procedure Out_Format( var fOutFile: XMLOutStreamObj; aFormNr: integer); @t\2\2\2@>
   end

@ The constructor expects the ``kind'' of the object and its symbol number.

@<Constructors for derived format classess@>=
constructor MFormatObj.Init(aKind:Char; aSymNr:integer);
begin
   fSymbol.Kind:=aKind;
   fSymbol.Nr:=aSymNr;
end;

@ \node{Prefix format object.}

@<Declare \\{MPrefixFormat} object@>=
   MPrefixFormatPtr =  ^MPrefixFormatObj; @/
   MPrefixFormatObj =  object(MFormatObj) @t\1@> @/
      fRightArgsNbr: byte;
      constructor Init(aKind:Char; aSymNr,aRArgsNbr:integer); @t\2\2\2@>
   end

@ Prefix formats track how many arguments are to the right of the prefix symbol.

@<Constructors for derived format classess@>=
constructor MPrefixFormatObj.Init(aKind:Char; aSymNr,aRArgsNbr:integer);
begin
   fSymbol.Kind:=aKind;
   fSymbol.Nr:=aSymNr;
   fRightArgsNbr:=aRArgsNbr;
end;

@ \node{Infix format object.}

\label{MInfixFormatObj}

@<Declare \\{MInfixFormat} object@>=
   MInfixFormatPtr = ^MInfixFormatObj; @/
   MInfixFormatObj = object(MPrefixFormatObj) @t\1@> @/
      fLeftArgsNbr: byte;
      constructor Init(aKind:Char; aSymNr,aLArgsNbr,aRArgsNbr:integer); @t\2\2\2@>
   end

@
And just as prefix symbols tracks the number of arguments to the
right, infix symbols tracks the number of arguments to both the
left and right.
   
@<Constructors for derived format classess@>=
constructor MInfixFormatObj.Init(aKind:Char; aSymNr,aLArgsNbr,aRArgsNbr:integer);
begin
   fSymbol.Kind:=aKind;
   fSymbol.Nr:=aSymNr;
   fLeftArgsNbr:=aLArgsNbr;
   fRightArgsNbr:=aRArgsNbr;
end;

@ \node{Bracket format object.}

@<Declare \\{MBracketFormat} object@>=
   MBracketFormatPtr = ^MBracketFormatObj; @/
   MBracketFormatObj = object(MInfixFormatObj) @t\1@> @/
      fRightSymbolNr: integer; @/
      fArgsNbr: byte; @/
      constructor Init(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer); @t\2\2\2@>
   end

@ @<Constructors for derived format classess@>=
constructor MBracketFormatObj.Init(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer);
begin
   fSymbol.Kind:='K';
   fSymbol.Nr:=aLSymNr;
   fRightSymbolNr:=aRSymNr;
   fArgsNbr:=aArgsNbr;
   fLeftArgsNbr:=aLArgsNbr;
   fRightArgsNbr:=aRArgsNbr;
end;

@ \node{Ordering format objects.}
We need a \\{Compare} ordering function on formats. This is a
lexicographic ordering on the (kind, number of right symbols, number
of arguments, number of left symbols), more or less.

@<Compare formats@>=
function CompareFormats(aItem1, aItem2: Pointer): Integer;
begin
   CompareFormats:=1;
   if MFormatPtr(aItem1)^.fSymbol.Kind < MFormatPtr(aItem2)^.fSymbol.Kind then
      CompareFormats := -1
   else if MFormatPtr(aItem1)^.fSymbol.Kind = MFormatPtr(aItem2)^.fSymbol.Kind then
      @<Compare symbols of the same kind@>;
end;

@ We then check the indexing number of the symbol. When they are the
same, we look at the next ``entry'' in the tuple.

@<Compare symbols of the same kind@>=
if MFormatPtr(aItem1)^.fSymbol.Nr < MFormatPtr(aItem2)^.fSymbol.Nr then
   CompareFormats := -1
else if MFormatPtr(aItem1)^.fSymbol.Nr = MFormatPtr(aItem2)^.fSymbol.Nr then
   @<Compare same kinded symbols with the same number@>

@ The next ``entry'' in the tuple depends on the kind of symbols we
are comparing. Selectors (\texttt{'U'}) are, at this point, identical
(so we return zero). Note that \texttt{'J'} is a historic artifact no
longer used (in fact, I cannot locate its meaning in the literature I
possess). 

Structure (\texttt{'G'}), right functor brackets (\texttt{'L'}), modes
(\texttt{'M'}), and attributes (\texttt{'V'}) can be compared as
prefix symbols.

Functors (\texttt{'O'}) and predicates (\texttt{'R'}) can be compared
as infix symbols.

Left functor brackets (\texttt{'K'}) can be compared first with
bracket-specific characteristics, then as infix symbols.

@<Compare same kinded symbols with the same number@>=
case MFormatPtr(aItem1)^.fSymbol.Kind of
   'J','U':
      CompareFormats := 0;
 @t\4@>  'G',@+'L','M','V':
      @<Compare prefix symbols@>;
   'O','R':
      @<Compare infix symbols@>;
   'K':
      @<Compare bracket symbols@>;
endcases

@ Comparing prefixing symbols, at this points, can only compare the
number of arguments to the right.

@<Compare prefix symbols@>=
      if MPrefixFormatPtr(aItem1)^.fRightArgsNbr < MPrefixFormatPtr(aItem2)^.fRightArgsNbr then
         CompareFormats := -1
      else if MPrefixFormatPtr(aItem1)^.fRightArgsNbr = MPrefixFormatPtr(aItem2)^.fRightArgsNbr then
         CompareFormats := 0

@ Comparing bracket symbols first tries to compare the number of
symbols to its right. If these are equal, then we try to compare the
number of arguments. If these are equal, then we compare them ``as
if'' they were infixing symbols.

@<Compare bracket symbols@>=
      if MBracketFormatPtr(aItem1)^.fRightSymbolNr < MBracketFormatPtr(aItem2)^.fRightSymbolNr then
         CompareFormats := -1
      else if MBracketFormatPtr(aItem1)^.fRightSymbolNr = MBracketFormatPtr(aItem2)^.fRightSymbolNr then
         if MBracketFormatPtr(aItem1)^.fArgsNbr < MBracketFormatPtr(aItem2)^.fArgsNbr then
            CompareFormats := -1
         else if MBracketFormatPtr(aItem1)^.fArgsNbr = MBracketFormatPtr(aItem2)^.fArgsNbr then
            @<Compare infix symbols@>

@ Comparing infixing symbols compares the number of arguments to the
left. If these are equal, then we try to compare the number of
arguments to the right. If these are equal, then we return 0.

@<Compare infix symbols@>=
      if MInfixFormatPtr(aItem1)^.fLeftArgsNbr < MInfixFormatPtr(aItem2)^.fLeftArgsNbr then
         CompareFormats := -1
      else if MInfixFormatPtr(aItem1)^.fLeftArgsNbr = MInfixFormatPtr(aItem2)^.fLeftArgsNbr then
         if MInfixFormatPtr(aItem1)^.fRightArgsNbr < MInfixFormatPtr(aItem2)^.fRightArgsNbr then
            CompareFormats := -1
         else if MInfixFormatPtr(aItem1)^.fRightArgsNbr = MInfixFormatPtr(aItem2)^.fRightArgsNbr then
            CompareFormats := 0

@* [S] List of formats.
We have a collection of format objects managed by a \\{MFormatsList}
object. There are two groups of public functions: ``Lookup''
functions (to find the format matching certain parameters), and
``Collect'' functions (to insert a new format).

@<Declare \\{MFormatsList} object@>=
   MFormatsListPtr = ^MFormatsList; @/
   MFormatsList = object(MSortedList) @t\1@>

      constructor Init(ALimit: Integer); @t\2@> @#

      constructor LoadFormats(fName:string); @t\2@>
      procedure StoreFormats(fName:string); @t\2@> @#

      function LookUp_PrefixFormat(aKind:char;
                                   aSymNr,aArgsNbr:integer):integer; @t\2@>
      function LookUp_FuncFormat(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2@>
      function LookUp_BracketFormat(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2@>
      function LookUp_PredFormat(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2@> @#

      function CollectFormat(aFormat: MFormatPtr): integer; @t\2@>
      function CollectPrefixForm(aKind:char;
                                 aSymNr,aArgsNbr:integer): integer; @t\2@>
      function CollectFuncForm(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2@>
      function CollectBracketForm(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2@>
      function CollectPredForm(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer; @t\2\2\2@>

   end

@ We prefix format objects specified by its kind, its symbol number,
and the number of arguments it expects.

When the format object is not found, then 0 will be returned. This is
a standard convention in these functions to indicate the thing is missing.

@<Implementation for \\{MFormatsList}@>=
const PrefixFormatChars = [ 'M', 'V', 'U', 'J', 'L', 'G']; @#
function MFormatsList.LookUp_PrefixFormat(aKind:char;
                                          aSymNr,aArgsNbr:integer):integer;
var lFormat:MPrefixFormatObj; i: integer;
begin
   MizAssert(3300, aKind in PrefixFormatChars); @/
   lFormat.Init(aKind, aSymNr, aArgsNbr);
   if Find(@@lFormat,i) then
      LookUp_PrefixFormat:=fIndex^[i]+1
   else LookUp_PrefixFormat:=0;
end;

@ Looking up an infix functor format
(\section\xref{MInfixFormatObj}). This returns the \emph{index} for
the entry.

The contract here is rather confusing. What \emph{should} occur is: if
there is a functor symbol with the given left and right number of
arguments, then return the index for the entry. Otherwise (when there
is no functor symbol) return $-1$.

What happens instead is these values are incremented, so if the
functor symbol with the given number of left and right arguments is
contained in position $k$, then $k+1$ will be returned. If there is no
such functor symbol, then $0$ will be returned.

\label{MFormatsList.LookUp_FuncFormat}

@p
function MFormatsList.LookUp_FuncFormat(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormat:MInfixFormatObj; i: integer;
begin
   lFormat.Init('O',aSymNr,aLArgsNbr,aRArgsNbr);
   if Find(@@lFormat,i) then
      LookUp_FuncFormat:=fIndex^[i]+1
   else LookUp_FuncFormat:=0;
end;

@ Looking up a bracket.

@p
function MFormatsList.LookUp_BracketFormat(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormat:MBracketFormatObj; i: integer;
begin
   lFormat.Init(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr);
   if Find(@@lFormat,i) then
      LookUp_BracketFormat:=fIndex^[i]+1
   else LookUp_BracketFormat:=0;
end;

@ Looking up a predicate.

@p
function MFormatsList.LookUp_PredFormat(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormat:MInfixFormatObj; i: integer;
begin
   lFormat.Init('R',aSymNr,aLArgsNbr,aRArgsNbr);
   if Find(@@lFormat,i) then
      LookUp_PredFormat:=fIndex^[i]+1
   else LookUp_PredFormat:=0;
end;

@ Insert a format, if it's missing.

@p
function MFormatsList.CollectFormat(aFormat: MFormatPtr): integer;
var lFormatNr,i:integer;
begin
   lFormatNr:=0;
   if not Find(aFormat,i) then
   begin lFormatNr:=Count+1;
   Insert(aFormat);
   end;
   CollectFormat:=lFormatNr;
end;

@ Inserting a bracket, if it is missing. Returns the format number for
the format, whether it is missing or not.

@p
function MFormatsList.CollectBracketForm(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormatNr:integer;
begin
   lFormatNr:=LookUp_BracketFormat(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr);
   if lFormatNr = 0 then
   begin
      lFormatNr:=Count+1;
      Insert(new(MBracketFormatPtr,Init(aLSymNr,aRSymNr,aArgsNbr,aLArgsNbr,aRArgsNbr)));
   end;
   CollectBracketForm:=lFormatNr;
end;

@ Inserting a functor format, if it is missing. This returns the
format number for the functor (whether it is missing or not).

@p
function MFormatsList.CollectFuncForm(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormatNr:integer;
begin
   lFormatNr:=LookUp_FuncFormat(aSymNr,aLArgsNbr,aRArgsNbr);
   if lFormatNr = 0 then
   begin
      lFormatNr:=Count+1;
      Insert(new(MInfixFormatPtr,Init('O',aSymNr,aLArgsNbr,aRArgsNbr)));
   end;
   CollectFuncForm:=lFormatNr;
end;

@ Insert a prefix format if it is missing. Then return the format
number for the prefix format, missing or not.

@p
function MFormatsList.CollectPrefixForm(aKind:char;
                                        aSymNr,aArgsNbr:integer): integer;
var lFormatNr:integer;
begin
   lFormatNr:=LookUp_PrefixFormat(aKind,aSymNr,aArgsNbr);
   if lFormatNr = 0 then
   begin
      lFormatNr:=Count+1;
      Insert(new(MPrefixFormatPtr,Init(aKind,aSymNr,aArgsNbr)));
   end;
   CollectPrefixForm:=lFormatNr;
end;

@ Insert a predicate format, if it is missing. Then return the format
number, whether the predicate format is missing or not.

@p
function MFormatsList.CollectPredForm(aSymNr,aLArgsNbr,aRArgsNbr:integer): integer;
var lFormatNr:integer;
begin
   lFormatNr:=LookUp_PredFormat(aSymNr,aLArgsNbr,aRArgsNbr);
   if lFormatNr = 0 then
   begin
      lFormatNr:=Count+1;
      Insert(new(MInfixFormatPtr,Init('R',aSymNr,aLArgsNbr,aRArgsNbr)));
   end;
   CollectPredForm:=lFormatNr;
end;

@ \node{Constructor.} Construct the empty list of formats.

@p
constructor MFormatsList.Init(ALimit: Integer);
begin
   InitSorted(ALimit,CompareFormats);
end;

@ \node{Constructor.} Parse an \XML/ file for formats, and populate a
format list object with the file's contents.

@p
constructor MFormatsList.LoadFormats(fName:string);
var
   lEnvFile: XMLInStreamPtr;
   lValue: integer; lLex: LexemRec;
begin
   InitSorted(100,CompareFormats);
   lEnvFile:=new(XMLInStreamPtr,OpenFile(fName));
   with lEnvFile^ do
   begin
      NextElementState;
      XMLASSERT( nElName = XMLElemName[elFormats]);
      NextElementState;
      while not (nState = eEnd) and (nElName = XMLElemName[elFormat]) do
         Insert( In_Format( lEnvFile));
      gPriority.Init(10);
      while not (nState = eEnd) do
      begin
         XMLASSERT(nElName = XMLElemName[elPriority]);
         lLex.Kind:=GetAttr(XMLAttrName[ atKind])[1];
         lLex.Nr:=GetIntAttr(XMLAttrName[ atSymbolNr]);
         MizAssert(3300, lLex.Kind in ['O','L','K']);
         lValue:= GetIntAttr(XMLAttrName[ atValue]);
         gPriority.Assign(ord(lLex.Kind), lLex.Nr, lValue);
         AcceptEndState;
         NextElementState;
      end;
   end;
   dispose(lEnvFile,Done);
end;

@ We can read exactly one format from an \XML/ input stream.

@<Read formats from an \XML/ input stream@>=
function In_Format(fInFile: XMLInStreamPtr): MFormatPtr;
var
   lLex: LexemRec;
   lArgsNbr,lLeftArgsNbr,lRightSymNr:integer;
begin
   with fInFile^ do
   begin
      lLex.Kind:=GetAttr(XMLAttrName[atKind])[1];
      lLex.Nr:=GetIntAttr(XMLAttrName[atSymbolNr]);
      lArgsNbr:= GetIntAttr(XMLAttrName[atArgNr]);
      case lLex.Kind of
         'O','R':
            begin
               lLeftArgsNbr:= GetIntAttr(XMLAttrName[atLeftArgNr]);
               In_Format:= new(MInfixFormatPtr, Init(lLex.Kind,lLex.Nr,lLeftArgsNbr,
                                                     lArgsNbr - lLeftArgsNbr));
            end;
         'J','U','V','G','L','M':
            In_Format:= new(MPrefixFormatPtr,Init(lLex.Kind,lLex.Nr,lArgsNbr));
         'K':
            begin
               lRightSymNr:= GetIntAttr( XMLAttrName[ atRightSymbolNr]);
               In_Format:= new(MBracketFormatPtr, Init(lLex.Nr, lRightSymNr,
                                                       lArgsNbr, 0, 0));
            end;
      othercases RunTimeError(2019);
      endcases; @/
      AcceptEndState;
      NextElementState;
   end;
end;

@ Conversely, we can print to an output stream an \XML/ representation
for a format object.

@<Implement \\{MFormatObj}@>=
procedure MFormatObj.Out_Format(var fOutFile: XMLOutStreamObj; aFormNr: integer);
begin
   with fOutFile do
   begin
      Out_XElStart(XMLElemName[elFormat]);
      Out_XAttr(XMLAttrName[atKind], fSymbol.Kind);
      if aFormNr > 0 then Out_XIntAttr(XMLAttrName[atNr], aFormNr);
      Out_XIntAttr(XMLAttrName[atSymbolNr], fSymbol.Nr);
      case fSymbol.Kind of
         'J','U','V','G','L','M':
            Out_XIntAttr(XMLAttrName[atArgNr], MPrefixFormatPtr(@@Self)^.fRightArgsNbr);
         'O','R':
            with MInfixFormatPtr(@@Self)^ do
         begin
            Out_XIntAttr(XMLAttrName[atArgNr], fLeftArgsNbr+fRightArgsNbr);
            Out_XIntAttr(XMLAttrName[atLeftArgNr], fLeftArgsNbr);
         end;
         'K':
            with MBracketFormatPtr(@@Self)^ do
         begin
            Out_XIntAttr(XMLAttrName[atArgNr], fArgsNbr);
            Out_XIntAttr(XMLAttrName[atRightSymbolNr], fRightSymbolNr);
         end;
      othercases RuntimeError(3300);
      endcases; @/
      Out_XElEnd0;
   end;
end;

@ Given a list of formats, we can store them to an \XML/ file using
the previous function.

@p
procedure MFormatsList.StoreFormats(fName:string);
var lEnvFile: XMLOutStreamObj;
z: integer;
begin
   lEnvFile.OpenFile(fName);
   with lEnvFile do
   begin
      Out_XElStart0(XMLElemName[elFormats]);
      for z:=0 to Count-1 do
         MFormatPtr(Items^[z])^.Out_Format(lEnvFile, z + 1);
      with gPriority do
         for z:=0 to fCount-1 do
         begin
            Out_XElStart(XMLElemName[elPriority]);
            Out_XAttr(XMLAttrName[atKind], chr(fList^[z].X1));
            Out_XIntAttr(XMLAttrName[atSymbolNr], fList^[z].X2);
            Out_XIntAttr(XMLAttrName[atValue], fList^[z].Y);
            Out_XElEnd0;
         end;
      Out_XElEnd(XMLElemName[elFormats]);
   end;
   lEnvFile.Done;
end;

@ We clean up the formats collection and the priority.
The \\{gPriority} is initialized and populated in other
functions. The \\{gFormatsColl} is used heavily in \texttt{parseraddition.pas}
and a few other places.

@p
procedure DisposeFormats;
begin
   gFormatsColl.Done;
   gPriority.Done;
end;


@* [F] Syntax.
This describes the syntax for the Mizar language, using expressions,
subexpressions, blocks, and ``items'' (statements).

We will need to recall \\{StackedObj} from \texttt{mobjects.pas}
(\section\xref{StackedObj}). 

@<syntax.pas@>=
@<GNU License@>

unit syntax;

interface @|@#

uses mobjects,errhan;

@<Interface for \texttt{syntax.pas}@>@;

implementation @|@#

uses mconsole
mdebug , info @+ end_mdebug; @/

@<Implementation for \texttt{syntax.pas}@> @t\2@> @; @#

end.

@ The maximum number of ``visible'' arguments to an expression is set
here, at 10.

\label{MaxVisArgNbr}

@<Public constants for \texttt{syntax.pas}@>=
const
   MaxVisArgNbr = 10;

@ The implementation for the abstract syntax of Mizar is rather
uninteresting, since most of the methods are abstract.

@<Implementation for \texttt{syntax.pas}@>=
@<Subexpression constructor@>@;

@<Subexpression destructor@>@;

@<Expression constructor@>@;

@<Subexpression procedures@>@;

@<Create a subexpression for an expression@>@;

@<Item object implementation@>@;

@<Block object implementation@>@;

@<Public procedures implementation for \texttt{syntax.pas}@>@; 

@ \node{Destructor wrappers.}
We have a few public-facing procedures to free the global
subexpression, expression, etc., variables describing the state of the
parser.

\label{KillSubexpression}

@<Public procedures implementation for \texttt{syntax.pas}@>=
procedure KillSubexpression;
begin
   if gSubexpPtr = nil then RunTimeError(2144)
   else dispose(gSubexpPtr, Done);
end;
@


@<Public procedures implementation for \texttt{syntax.pas}@>=
procedure KillExpression;
begin
   if gExpPtr = nil then RunTimeError(2143)
   else dispose(gExpPtr, Done);
end;

@ This method will not be used until we get to the parser, sadly. I am
not sure why there are calls to \\{DisplayLine} in \\{KillItem}
and \\{KillBlock}, though.

The \\{KillItem} is called in exactly two places: (1) \\{Semicolon}
in \texttt{parser.pas}, (2) \\{SchemeBlock}, also in the
parser. (And \\{KillBlock} is called only in the parser, as well.)

\label{KillItem:syntax.pas}

@<Public procedures implementation for \texttt{syntax.pas}@>=
procedure KillItem;
begin
   if gItemPtr = nil then RunTimeError(2142)
   else
   begin
      gItemPtr^.Pop;
      dispose(gItemPtr, Done); @+
   end;
   DisplayLine(CurPos.Line,ErrorNbr);
end;
@
\label{KillBlock}
@<Public procedures implementation for \texttt{syntax.pas}@>=
procedure KillBlock;
begin
   if gBlockPtr = nil then RunTimeError(2141)
   else
   begin
      gBlockPtr^.Pop;
      dispose(gBlockPtr, Done);
   end;
   DisplayLine(CurPos.Line,ErrorNbr);
end;



@

@<Interface for \texttt{syntax.pas}@>=
@<Public constants for \texttt{syntax.pas}@>

type @/
   @<BlockKinds (\texttt{syntax.pas})@>@; @#

   @<ItemKinds (\texttt{syntax.pas})@>@; @#
   
   @<ExpKinds (\texttt{syntax.pas})@>@; @#

   @<Block object interface@>; @#

   @<Class declaration for Item object@>; @#

   @<Subexpression object class@>; @#

   @<Expression class declaration@>; @#
      
   @<Public procedures for \texttt{syntax.pas}@>@; @#

   @<Public variables for \texttt{syntax.pas}@>@;

@ @<Public procedures for \texttt{syntax.pas}@>=
   procedure @? KillBlock; @t\2@>
   procedure @? KillItem; @t\2@>
   procedure @? KillExpression; @t\2@>
   procedure @? KillSubexpression; @t\2\2@>

@ These global public variables for syntax will be manipulated by the
parser.

\label{gSubexpPtr}

@<Public variables for \texttt{syntax.pas}@>=
   var
      gBlockPtr	 : BlockPtr = nil;
      gItemPtr	   : ItemPtr = nil;
      gExpPtr	   : ExpressionPtr = nil;
      gSubexpPtr	 : SubexpPtr = nil;

@* [S] Block Object.
The Mizar language is block-structured, so we have a Block represent a
sequence of statements contained within a block.

This is extended in \texttt{parseraddition.pas}.

\label{BlockObj:syntax.pas}

\medbreak
\figure
\centerline{\graphics{img/classdiagram-2}}
\caption{UML class diagram for Block object class.}
\endfigure
\medbreak\noindent%

@ There are about a dozen different kinds of blocks.

\label{type:BlockKind}

@<BlockKinds (\texttt{syntax.pas})@>=
  @! BlockKind =
      (@! blMain, @! blDiffuse, @! blHereby, @! blProof,@! blDefinition,@! blNotation,
       @! blRegistration,@! blCase,@! blSuppose,@! blPublicScheme ); @#

@ @<Block object interface@>=
  @! BlockPtr = ^BlockObj; @/
  @! ItemPtr = ^ItemObj; @#

   @! BlockObj =
      object(StackedObj) @t\1@> @/
        @! nBlockKind: BlockKind; @/
         constructor @? Init(fBlockKind:BlockKind); @t\2@>
         procedure @? Pop; virtual; @t\2@> {inheritance}
         destructor @? Done; virtual; @t\2@>
         procedure @? StartProperText; virtual; @t\2@>
         procedure @? ProcessLink; virtual; @t\2@>
         procedure @? ProcessRedefine; virtual; @t\2@>
         procedure @? ProcessBegin; virtual; @t\2@>
         procedure @? ProcessPragma; virtual; @t\2@>
         procedure @? StartAtSignProof; virtual; @t\2@>
         procedure @? FinishAtSignProof; virtual; @t\2@>
         procedure @? FinishDefinition; virtual; @t\2@>
         procedure @? CreateItem(fItemKind:ItemKind); virtual; @t\2@>
         procedure @? CreateBlock(fBlockKind:BlockKind); virtual; @t\2@>
         procedure @? StartSchemeDemonstration; virtual; @t\2@>
         procedure @? FinishSchemeDemonstration; virtual; @t\2\2\2@>
      end

@ The constructor for a Block will initialize its \\{Previous} pointer
to point at the global \\{gBlockPtr} instance.

\label{BlockObj.Init}

@<Block object implementation@>=
constructor @? BlockObj.Init(fBlockKind: BlockKind);
begin
   nBlockKind:=fBlockKind;
   Previous:=gBlockPtr;
end;

@ Note that popping a block object is left for subclasses to handle.

\label{BlockObj.Pop}

@<Block object implementation@>=
procedure @? BlockObj.Pop;
begin
end;

@ @<Block object implementation@>=
destructor @? BlockObj.Done;
begin
   gBlockPtr:=BlockPtr(Previous);
end;

@ \node{Abstract methods.}

\label{BlockObj.abstract-methods}

@<Block object implementation@>=
procedure @? BlockObj.StartProperText; begin end;

procedure @? BlockObj.ProcessRedefine; begin end;

procedure @? BlockObj.ProcessLink; begin end;

procedure @? BlockObj.ProcessBegin; begin end;

procedure @? BlockObj.ProcessPragma; begin end;

procedure @? BlockObj.StartAtSignProof; begin end;

procedure @? BlockObj.FinishAtSignProof; begin end;

procedure @? BlockObj.FinishDefinition; begin end;

@ @<Block object implementation@>=
procedure @? BlockObj.CreateItem(fItemKind:ItemKind);
begin
   gItemPtr:=new(ItemPtr, Init(fItemKind));
end;

@ @<Block object implementation@>=
procedure @? BlockObj.CreateBlock(fBlockKind:BlockKind);
begin
   gBlockPtr:=new(BlockPtr, Init(fBlockKind));
end;

@ More abstract methods.

@<Block object implementation@>=
procedure @? BlockObj.StartSchemeDemonstration; begin end;

procedure @? BlockObj.FinishSchemeDemonstration; begin end;

@* [S] Item objects.
The class declaration for an \\{Item} object is depressingly long,
with most of its virtual methods not used. The class diagram is worth
drawing out.

\medbreak
\figure
\centerline{\graphics{img/classdiagram-1}}
\caption{UML class diagram for Item object class.}
\endfigure
\medbreak\noindent%

@ Items are a tagged union, tagged by the ``kind'' of item.
\label{type:ItemKind}

@<ItemKinds (\texttt{syntax.pas})@>=
  @! ItemKind =
      (@! itIncorrItem, @!
        itDefinition, @! itSchemeBlock, @! itSchemeHead, @! itTheorem, @! itAxiom, @!
        itReservation, @!
        itCanceled, @! itSection, @!
        itRegularStatement, @! itChoice, @! itReconsider, @!
        itPrivFuncDefinition, @! itPrivPredDefinition, @! itConstantDefinition, @!
        itGeneralization, @! itLociDeclaration, @!itExistentialAssumption, @! itExemplification, @!
        itPerCases, @! itConclusion, @! itCaseBlock, @! itCaseHead, @! itSupposeHead, @! itAssumption, @!
        itCorrCond, @! itCorrectness, @! itProperty, @!
        itDefPred, @! itDefFunc, @! itDefMode, @! itDefAttr, @! itDefStruct, @!
        itPredSynonym, @! itPredAntonym, @! itFuncNotation, @! itModeNotation, @!
        itAttrSynonym, @! itAttrAntonym, @!
        itCluster, @! itIdentify, @! itReduction, @! itPropertyRegistration,
        @! itPragma
      );

@ @<Class declaration for Item object@>=
 @!  ItemObj =
      object(StackedObj) @t\1@> @/
        @! nItemKind: ItemKind; @/
         constructor @? Init(fItemKind:ItemKind); @t\2@>
         procedure @? Pop; virtual; @t\2@>
         destructor @? Done; virtual;@|@/ 
 @t\4\4@>        @<Method declarations for Item object@> @t\2\2\2@>@;
      end

@ It is particularly important to note, when constructing an \\{Item}
object, the previous item will \emph{automatically} be set to point to
the global \\{gItem} variable.

\label{ItemObj.Pop}

@<Item object implementation@>=
constructor @? ItemObj.Init(fItemKind:ItemKind);
begin
   nItemKind:=fItemKind;
   Previous:=gItemPtr;
end;

procedure @? ItemObj.Pop;
begin
   DisplayLine(CurPos.Line,ErrorNbr);
end;

destructor @? ItemObj.Done;
begin
   DisplayLine(CurPos.Line,ErrorNbr);
   gItemPtr:=ItemPtr(Previous);
end;

@ Creating an expression in an item is handled with this method.

@<Item object implementation@>=
procedure @? ItemObj.CreateExpression(fExpKind:ExpKind);
begin
   gExpPtr:=new(ExpressionPtr, Init(fExpKind));
end;

@ \node{Abstract methods.} The methods of the \\{Item} class can be
partitioned into two groups: those which will be implemented by a
subclass, and those which will remain ``empty'' (i.e., whose body is
just |begin end|).

@<Methods overriden by extended Item class@>=
         procedure StartSentence; virtual; @t\2@> @#
         
         procedure StartAttributes; virtual; @t\2@>
         procedure FinishAntecedent; virtual; @t\2@>
         procedure FinishConsequent; virtual; @t\2@>
         procedure FinishClusterTerm; virtual; @t\2@> @#

         procedure StartFuncIdentify; virtual; @t\2@>
         procedure ProcessFuncIdentify; virtual; @t\2@>
         procedure CompleteFuncIdentify; virtual; @t\2@>
         procedure ProcessLeftLocus; virtual; @t\2@>
         procedure ProcessRightLocus; virtual; @t\2@> @#

         procedure StartFuncReduction; virtual; @t\2@>
         procedure ProcessFuncReduction; virtual; @t\2@> @#

         procedure FinishPrivateConstant; virtual; @t\2@>
         procedure StartFixedVariables; virtual; @t\2@>
         procedure ProcessFixedVariable; virtual; @t\2@>
         procedure ProcessBeing; virtual; @t\2@>
         procedure StartFixedSegment; virtual; @t\2@>
         procedure FinishFixedSegment; virtual; @t\2@>
         procedure FinishFixedVariables; virtual; @t\2@>
         procedure StartAssumption; virtual; @t\2@>
         procedure StartCollectiveAssumption; virtual; @t\2@>
         procedure ProcessMeans; virtual; @t\2@>
         procedure FinishOtherwise; virtual; @t\2@>
         procedure StartDefiniens; virtual; @t\2@>
         procedure FinishDefiniens; virtual; @t\2@>
         procedure StartGuard; virtual; @t\2@>
         procedure FinishGuard; virtual; @t\2@>
         procedure ProcessEquals; virtual; @t\2@> @#

         procedure StartExpansion; virtual; @t\2@>
         procedure FinishSpecification; virtual; @t\2@>
         procedure StartConstructionType; virtual; @t\2@>
         procedure FinishConstructionType; virtual; @t\2@>
         procedure StartAttributePattern; virtual; @t\2@>
         procedure FinishAttributePattern; virtual; @t\2@>
         procedure FinishSethoodProperties; virtual; @t\2@>
         procedure StartModePattern; virtual; @t\2@>
         procedure FinishModePattern; virtual; @t\2@>
         procedure StartPredicatePattern; virtual; @t\2@>
         procedure ProcessPredicateSymbol; virtual; @t\2@>
         procedure FinishPredicatePattern; virtual; @t\2@>
         procedure StartFunctorPattern; virtual; @t\2@>
         procedure ProcessFunctorSymbol; virtual; @t\2@>
         procedure FinishFunctorPattern; virtual; @t\2@> @#
         
         procedure ProcessAttrAntonym; virtual; @t\2@>
         procedure ProcessAttrSynonym; virtual; @t\2@>
         procedure ProcessPredAntonym; virtual; @t\2@>
         procedure ProcessPredSynonym; virtual; @t\2@>
         procedure ProcessFuncSynonym; virtual; @t\2@>
         procedure ProcessModeSynonym; virtual; @t\2@> @#

         procedure StartVisible; virtual; @t\2@>
         procedure ProcessVisible; virtual; @t\2@>
         procedure FinishPrefix; virtual; @t\2@>
         procedure ProcessStructureSymbol; virtual; @t\2@>
         procedure StartFields; virtual; @t\2@>
         procedure FinishFields; virtual; @t\2@>
         procedure StartAggrPattSegment; virtual; @t\2@>
         procedure ProcessField; virtual; @t\2@>
         procedure FinishAggrPattSegment; virtual; @t\2@>
         procedure ProcessSchemeName; virtual; @t\2@>
         procedure StartSchemeSegment; virtual; @t\2@>
         procedure StartSchemeQualification; virtual; @t\2@>
         procedure FinishSchemeQualification; virtual; @t\2@>
         procedure ProcessSchemeVariable; virtual; @t\2@>
         procedure FinishSchemeSegment; virtual; @t\2@>
         procedure FinishSchemeThesis; virtual; @t\2@>
         procedure FinishSchemePremise; virtual; @t\2@> @#
         
         procedure StartReservationSegment; virtual; @t\2@>
         procedure ProcessReservedIdentifier; virtual; @t\2@>
         procedure FinishReservationSegment; virtual; @t\2@>
         procedure StartPrivateDefiniendum; virtual; @t\2@>
         procedure FinishLocusType; virtual; @t\2@> @#
         
         procedure CreateExpression(fExpKind:ExpKind); virtual; @t\2@> @#

         procedure StartPrivateConstant; virtual; @t\2@>
         procedure StartPrivateDefiniens; virtual; @t\2@>
         procedure FinishPrivateFuncDefinienition; virtual; @t\2@>
         procedure FinishPrivatePredDefinienition; virtual; @t\2@>
         procedure ProcessReconsideredVariable; virtual; @t\2@>
         procedure FinishReconsideredTerm; virtual; @t\2@>
         procedure FinishDefaultTerm; virtual; @t\2@>
         procedure FinishCondition; virtual; @t\2@>
         procedure FinishHypothesis; virtual; @t\2@>
         procedure ProcessExemplifyingVariable; virtual; @t\2@>
         procedure FinishExemplifyingVariable; virtual; @t\2@>
         procedure StartExemplifyingTerm; virtual; @t\2@>
         procedure FinishExemplifyingTerm; virtual; @t\2@>
         procedure ProcessCorrectness; virtual; @t\2@>
         procedure ProcessLabel; virtual; @t\2@>
         procedure StartRegularStatement; virtual; @t\2@>
         procedure ProcessDefiniensLabel; virtual; @t\2@>
         procedure FinishCompactStatement; virtual; @t\2@>
         procedure StartIterativeStep; virtual; @t\2@>
         procedure FinishIterativeStep; virtual; @t\2@> @#

         {{\it Justification}}

         procedure ProcessSchemeReference; virtual; @t\2@>
         procedure ProcessPrivateReference; virtual; @t\2@>
         procedure StartLibraryReferences; virtual; @t\2@>
         procedure StartSchemeLibraryReference; virtual; @t\2@>
         procedure ProcessDef; virtual; @t\2@>
         procedure ProcessTheoremNumber; virtual; @t\2@>
         procedure ProcessSchemeNumber; virtual; @t\2@>
         procedure StartJustification; virtual; @t\2@>
         procedure StartSimpleJustification; virtual; @t\2@>
         procedure FinishSimpleJustification; virtual; @t\2@> @#

@ @<Method declarations for Item object@>=
         @<Methods overriden by extended Item class@>
         procedure FinishClusterType; virtual; @t\2@>
         procedure FinishSentence; virtual; @t\2@>
         procedure FinishReconsidering; virtual; @t\2@>
         procedure StartNewType; virtual; @t\2@>
         procedure StartCondition; virtual; @t\2@>
         procedure FinishChoice; virtual; @t\2@>
         procedure FinishAssumption; virtual; @t\2@> @#

         procedure StartEquals; virtual; @t\2@>
         procedure StartOtherwise; virtual; @t\2@>
         procedure StartSpecification; virtual; @t\2@>
         procedure ProcessAttributePattern; virtual; @t\2@>
         procedure StartDefPredicate; virtual; @t\2@> @#

         procedure CompletePredAntonymByAttr; virtual; @t\2@>
         procedure CompletePredSynonymByAttr; virtual; @t\2@> @#

         procedure StartPredIdentify; virtual; @t\2@>
         procedure ProcessPredIdentify; virtual; @t\2@>
         procedure CompleteAttrIdentify; virtual; @t\2@>
         procedure StartAttrIdentify; virtual; @t\2@>
         procedure ProcessAttrIdentify; virtual; @t\2@>
         procedure CompletePredIdentify; virtual; @t\2@> @#

         procedure FinishFuncReduction; virtual; @t\2@> @#

         procedure StartSethoodProperties; virtual; @t\2@> @#
         
         procedure ProcessModePattern; virtual; @t\2@>
         procedure StartPrefix; virtual; @t\2@>
         procedure FinishVisible; virtual; @t\2@>
         procedure FinishSchemeHeading; virtual; @t\2@>
         procedure FinishSchemeDeclaration; virtual; @t\2@>
         procedure StartSchemePremise; virtual; @t\2@>
         procedure StartTheoremBody; virtual; @t\2@>
         procedure FinishTheoremBody; virtual; @t\2@>
         procedure FinishTheorem; virtual; @t\2@>
         procedure FinishReservation; virtual; @t\2@>
         procedure ProcessIterativeStep; virtual; @t\2@> @#
         
         {{\it Justification}}

         procedure StartSchemeReference; virtual; @t\2@>
         procedure StartReferences; virtual; @t\2@>
         procedure ProcessSch; virtual; @t\2@>
         procedure FinishTheLibraryReferences; virtual; @t\2@>
         procedure FinishSchLibraryReferences; virtual; @t\2@>
         procedure FinishReferences; virtual; @t\2@>
         procedure FinishSchemeReference; virtual; @t\2@>
         procedure FinishJustification; virtual; @t\2@>

@t\2\2\2@>

@ @<Item object implementation@>=
procedure @? ItemObj.StartAttributes; begin end;

procedure @? ItemObj.FinishAntecedent; begin end;

procedure @? ItemObj.FinishConsequent; begin end;

procedure @? ItemObj.FinishClusterTerm; begin end;

procedure @? ItemObj.FinishClusterType; begin end;

procedure @? ItemObj.StartSentence; begin end;

procedure @? ItemObj.FinishSentence; begin end;

procedure @? ItemObj.FinishPrivateConstant; begin end;

procedure @? ItemObj.StartPrivateConstant; begin end;

procedure @? ItemObj.ProcessReconsideredVariable; begin end;

procedure @? ItemObj.FinishReconsidering; begin end;

procedure @? ItemObj.FinishReconsideredTerm; begin end;

procedure @? ItemObj.FinishDefaultTerm; begin end;

procedure @? ItemObj.StartNewType; begin end;

procedure @? ItemObj.StartCondition; begin end;

procedure @? ItemObj.FinishCondition; begin end;

procedure @? ItemObj.FinishChoice; begin end;

procedure @? ItemObj.StartFixedVariables; begin end;

procedure @? ItemObj.StartFixedSegment; begin end;

procedure @? ItemObj.ProcessFixedVariable; begin end;

procedure @? ItemObj.ProcessBeing; begin end;

procedure @? ItemObj.FinishFixedSegment; begin end;

procedure @? ItemObj.FinishFixedVariables; begin end;

procedure @? ItemObj.StartAssumption; begin end;

procedure @? ItemObj.StartCollectiveAssumption; begin end;

procedure @? ItemObj.FinishHypothesis; begin end;

procedure @? ItemObj.FinishAssumption; begin end;

procedure @? ItemObj.ProcessExemplifyingVariable; begin end;

procedure @? ItemObj.FinishExemplifyingVariable; begin end;

procedure @? ItemObj.StartExemplifyingTerm; begin end;

procedure @? ItemObj.FinishExemplifyingTerm; begin end;

procedure @? ItemObj.ProcessMeans; begin end;

procedure @? ItemObj.FinishOtherwise; begin end;

procedure @? ItemObj.StartDefiniens; begin end;

procedure @? ItemObj.FinishDefiniens; begin end;

procedure @? ItemObj.StartGuard; begin end;

procedure @? ItemObj.FinishGuard; begin end;

procedure @? ItemObj.StartOtherwise; begin end;

procedure @? ItemObj.ProcessEquals; begin end;

procedure @? ItemObj.StartEquals; begin end;

procedure @? ItemObj.ProcessCorrectness; begin end;

procedure @? ItemObj.FinishSpecification; begin end;

procedure @? ItemObj.FinishConstructionType; begin end;

procedure @? ItemObj.StartSpecification; begin end;

procedure @? ItemObj.StartExpansion; begin end;

procedure @? ItemObj.StartConstructionType; begin end;

procedure @? ItemObj.StartPredicatePattern; begin end;

procedure @? ItemObj.ProcessPredicateSymbol; begin end;

procedure @? ItemObj.FinishPredicatePattern; begin end;

procedure @? ItemObj.StartFunctorPattern; begin end;

procedure @? ItemObj.ProcessFunctorSymbol; begin end;

procedure @? ItemObj.FinishFunctorPattern; begin end;

procedure @? ItemObj.ProcessAttrAntonym; begin end;

procedure @? ItemObj.ProcessAttrSynonym; begin end;

procedure @? ItemObj.ProcessPredAntonym; begin end;

procedure @? ItemObj.ProcessPredSynonym; begin end;

procedure @? ItemObj.ProcessFuncSynonym; begin end;

procedure @? ItemObj.CompletePredSynonymByAttr; begin end;

procedure @? ItemObj.CompletePredAntonymByAttr; begin end;

procedure @? ItemObj.ProcessModeSynonym; begin end;

procedure @? ItemObj.StartFuncIdentify;  begin end;

procedure @? ItemObj.ProcessFuncIdentify;  begin end;

procedure @? ItemObj.CompleteFuncIdentify;  begin end;

procedure @? ItemObj.StartPredIdentify;  begin end;

procedure @? ItemObj.ProcessPredIdentify;  begin end;

procedure @? ItemObj.CompletePredIdentify;  begin end;

procedure @? ItemObj.StartAttrIdentify;  begin end;

procedure @? ItemObj.ProcessAttrIdentify;  begin end;

procedure @? ItemObj.CompleteAttrIdentify;  begin end;

procedure @? ItemObj.ProcessLeftLocus;  begin end;

procedure @? ItemObj.ProcessRightLocus;  begin end;

procedure @? ItemObj.StartFuncReduction;  begin end;

procedure @? ItemObj.ProcessFuncReduction;  begin end;

procedure @? ItemObj.FinishFuncReduction;  begin end;

procedure @? ItemObj.StartSethoodProperties;  begin end;

procedure @? ItemObj.FinishSethoodProperties;  begin end;

procedure @? ItemObj.StartModePattern; begin end;

procedure @? ItemObj.ProcessModePattern; begin end;

procedure @? ItemObj.FinishModePattern; begin end;

procedure @? ItemObj.StartAttributePattern; begin end;

procedure @? ItemObj.ProcessAttributePattern; begin end;

procedure @? ItemObj.FinishAttributePattern; begin end;

procedure @? ItemObj.StartDefPredicate; begin end;

procedure @? ItemObj.StartVisible; begin end;

procedure @? ItemObj.ProcessVisible; begin end;

procedure @? ItemObj.FinishVisible; begin end;

procedure @? ItemObj.StartPrefix; begin end;

procedure @? ItemObj.FinishPrefix; begin end;

procedure @? ItemObj.ProcessStructureSymbol; begin end;

procedure @? ItemObj.StartFields; begin end;

procedure @? ItemObj.FinishFields; begin end;

procedure @? ItemObj.StartAggrPattSegment; begin end;

procedure @? ItemObj.ProcessField; begin end;

procedure @? ItemObj.FinishAggrPattSegment; begin end;

procedure @? ItemObj.ProcessSchemeName; begin end;

procedure @? ItemObj.StartSchemeSegment; begin end;

procedure @? ItemObj.ProcessSchemeVariable; begin end;

procedure @? ItemObj.StartSchemeQualification; begin end;

procedure @? ItemObj.FinishSchemeQualification; begin end;

procedure @? ItemObj.FinishSchemeSegment; begin end;

procedure @? ItemObj.FinishSchemeHeading; begin end;

procedure @? ItemObj.FinishSchemeDeclaration; begin end;

procedure @? ItemObj.FinishSchemeThesis; begin end;

procedure @? ItemObj.StartSchemePremise; begin end;

procedure @? ItemObj.FinishSchemePremise; begin end;

procedure @? ItemObj.StartTheoremBody; begin end;

procedure @? ItemObj.FinishTheoremBody; begin end;

procedure @? ItemObj.FinishTheorem; begin end;

procedure @? ItemObj.StartReservationSegment; begin end;

procedure @? ItemObj.ProcessReservedIdentifier; begin end;

procedure @? ItemObj.FinishReservationSegment; begin end;

procedure @? ItemObj.FinishReservation; begin end;

procedure @? ItemObj.StartPrivateDefiniendum; begin end;

procedure @? ItemObj.FinishLocusType; begin end;

procedure @? ItemObj.StartPrivateDefiniens; begin end;

procedure @? ItemObj.FinishPrivateFuncDefinienition; begin end;

procedure @? ItemObj.FinishPrivatePredDefinienition; begin end;

procedure @? ItemObj.ProcessLabel; begin end;

procedure @? ItemObj.StartRegularStatement; begin end;

procedure @? ItemObj.ProcessDefiniensLabel; begin end;

procedure @? ItemObj.ProcessSchemeReference; begin end;

procedure @? ItemObj.StartSchemeReference; begin end;

procedure @? ItemObj.StartReferences; begin end;

procedure @? ItemObj.ProcessPrivateReference; begin end;

procedure @? ItemObj.StartLibraryReferences; begin end;

procedure @? ItemObj.StartSchemeLibraryReference; begin end;

procedure @? ItemObj.ProcessDef; begin end;

procedure @? ItemObj.ProcessSch; begin end;

procedure @? ItemObj.ProcessTheoremNumber; begin end;

procedure @? ItemObj.ProcessSchemeNumber; begin end;

procedure @? ItemObj.FinishTheLibraryReferences; begin end;

procedure @? ItemObj.FinishSchLibraryReferences; begin end;

procedure @? ItemObj.FinishReferences; begin end;

procedure @? ItemObj.FinishSchemeReference; begin end;

procedure @? ItemObj.StartJustification;  begin end;

procedure @? ItemObj.FinishJustification;  begin end;

procedure @? ItemObj.StartSimpleJustification; begin end;

procedure @? ItemObj.FinishSimpleJustification; begin end;

procedure @? ItemObj.FinishCompactStatement;  begin end;

procedure @? ItemObj.StartIterativeStep; begin end;

procedure @? ItemObj.ProcessIterativeStep; begin end;

procedure @? ItemObj.FinishIterativeStep; begin end;

@* [S] Expressions.


@<ExpKinds (\texttt{syntax.pas})@>=
   ExpKind = (exNull, exType, exTerm, exFormula, exResType, exAdjectiveCluster );

@ @<Expression class declaration@>=
   ExpressionPtr = ^ExpressionObj; @/
   ExpressionObj =
      object(MObject) @t\1@> @/
         nExpKind: ExpKind;
         constructor Init(fExpKind:ExpKind); @t\2@>
         procedure CreateSubexpression; virtual; @t\2\2\2@>
      end

@ \node{Constructor.}
\label{ExpressionObj.Init}

@<Expression constructor@>=
constructor ExpressionObj.Init(fExpKind:ExpKind);
begin
   nExpKind:=fExpKind;
end;

@ Observe that creating a subexpression (1) allocates a
new \\{SubexpPtr} on the heap, and (2) mutates the \\{gSubexpPtr}
global variable.

\label{ExpressionObj.CreateSubexpression}

@<Create a subexpression for an expression@>=
procedure ExpressionObj.CreateSubexpression;
begin
   gSubexpPtr:=new(SubexpPtr, Init);
end;

@* [S] Subexpressions.

@<Subexpression object class@>=
   SubexpPtr = ^SubexpObj; @/
   SubexpObj =
      object(StackedObj) @t\1@>
         constructor Init; @t\2@>
         destructor Done; virtual;@|@/ @t\2@>
  @t\4\4@>       @<Empty method declarations for |SubexpObj|@>@t\2\2@>@;
      end

@ \node{Constructor.} Importantly, constructing a new \\{Subexp}
object will initialize its \\{Previous} field to point to the
global \\{gSubexpPtr} object. 

@<Subexpression constructor@>=
constructor SubexpObj.Init;
begin
   Previous:=gSubexpPtr;
end;

@ \node{Destructor.}

@<Subexpression destructor@>=
destructor SubexpObj.Done;
begin
   gSubexpPtr:=SubexpPtr(Previous);
end;

@
The remaining methods for subexpression objects are empty.

@<Methods implemented by subclasses of |SubexpObj|@>=
         procedure ProcessSimpleTerm; virtual; @t\2@>
         procedure StartFraenkelTerm; virtual; @t\2@>
         procedure StartPostqualification; virtual; @t\2@>
         procedure StartPostqualifyingSegment; virtual; @t\2@>
         procedure ProcessPostqualifiedVariable; virtual; @t\2@>
         procedure StartPostqualificationSpecyfication; virtual; @t\2@>
         procedure FinishPostqualifyingSegment; virtual; @t\2@>
         procedure FinishFraenkelTerm; virtual; @t\2@>
         procedure StartSimpleFraenkelTerm; virtual; @t\2@>
         procedure FinishSimpleFraenkelTerm; virtual; @t\2@>
         procedure ProcessThesis; virtual; @t\2@>
         procedure StartPrivateTerm; virtual; @t\2@>
         procedure FinishPrivateTerm; virtual; @t\2@>
         procedure StartBracketedTerm; virtual; @t\2@>
         procedure FinishBracketedTerm; virtual; @t\2@>
         procedure StartAggregateTerm; virtual; @t\2@>
         procedure FinishAggregateTerm; virtual; @t\2@>
         procedure StartSelectorTerm; virtual; @t\2@>
         procedure FinishSelectorTerm; virtual; @t\2@>
         procedure StartForgetfulTerm; virtual; @t\2@>
         procedure FinishForgetfulTerm; virtual; @t\2@>
         procedure StartChoiceTerm;  virtual; @t\2@>
         procedure FinishChoiceTerm;  virtual; @t\2@>
         procedure ProcessNumeralTerm; virtual; @t\2@>
         procedure ProcessItTerm; virtual; @t\2@>
         procedure ProcessLocusTerm; virtual; @t\2@>
         procedure ProcessQua; virtual; @t\2@>
         procedure FinishQualifiedTerm; virtual; @t\2@>
         procedure ProcessExactly; virtual; @t\2@>
         procedure StartLongTerm; virtual; @t\2@>
         procedure ProcessFunctorSymbol; virtual; @t\2@>
         procedure FinishArgList; virtual; @t\2@>
         procedure FinishLongTerm; virtual; @t\2@>
         procedure FinishArgument; virtual; @t\2@>
         procedure FinishTerm; virtual; @t\2@>
         procedure StartType; virtual; @t\2@>
         procedure ProcessModeSymbol; virtual; @t\2@>
         procedure FinishType; virtual; @t\2@>
         procedure CompleteType; virtual; @t\2@> {+}
         procedure ProcessAtomicFormula; virtual; @t\2@>
         procedure ProcessPredicateSymbol; virtual; @t\2@>
         procedure ProcessRightSideOfPredicateSymbol; virtual; @t\2@>
         procedure FinishPredicativeFormula; virtual; @t\2@>
         procedure FinishRightSideOfPredicativeFormula; virtual; @t\2@>
         procedure StartMultiPredicativeFormula; virtual; @t\2@>
         procedure FinishMultiPredicativeFormula; virtual; @t\2@>
         procedure StartPrivateFormula; virtual; @t\2@> {+}
         procedure FinishPrivateFormula; virtual; @t\2@>
         procedure ProcessContradiction; virtual; @t\2@> @#
         procedure ProcessNegative; virtual; @t\2@> @#

         { This is a temporary solution, the generation of ExpNodes is
         such that it is not possible to handle negation uniformly. }
         { Jest to tymczasowe rozwiazanie, generowanie ExpNode'ow jest takie,
           ze nie ma mozliwosci obsluzenia jednolicie negacji.
         }
         procedure ProcessNegation; virtual; @t\2@>
         procedure FinishQualifyingFormula; virtual; @t\2@>
         procedure FinishAttributiveFormula; virtual; @t\2@>
         procedure ProcessBinaryConnective; virtual; @t\2@> {+}
         procedure ProcessFlexDisjunction; virtual; @t\2@>
         procedure ProcessFlexConjunction; virtual; @t\2@>
         procedure StartRestriction; virtual; @t\2@>
         procedure FinishRestriction; virtual; @t\2@>
         procedure FinishBinaryFormula; virtual; @t\2@>
         procedure FinishFlexDisjunction; virtual; @t\2@>
         procedure FinishFlexConjunction; virtual; @t\2@>
         procedure StartExistential; virtual; @t\2@>
         procedure FinishExistential; virtual; @t\2@>
         procedure StartUniversal; virtual; @t\2@>
         procedure FinishUniversal; virtual; @t\2@> {+}
         procedure StartQualifiedSegment; virtual; @t\2@>
         procedure StartQualifyingType; virtual; @t\2@>
         procedure FinishQualifiedSegment; virtual; @t\2@>
         procedure ProcessVariable; virtual; @t\2@>
         procedure StartAttributes; virtual; @t\2@> @#
         procedure ProcessNon; virtual; @t\2@> {+}
         procedure ProcessAttribute; virtual; @t\2@> {+}
         procedure StartAttributeArguments; virtual; @t\2@> {+}
         procedure CompleteAttributeArguments; virtual; @t\2@> {+}
         procedure FinishAttributeArguments; virtual; @t\2@> {+}
         procedure CompleteAdjectiveCluster; virtual; @t\2@> {+}
         procedure CompleteClusterTerm; virtual; @t\2@> @#
         
         {{\it Errors Recovery}}

         procedure InsertIncorrTerm; virtual; @t\2@>
         procedure InsertIncorrType; virtual; @t\2@>
         procedure InsertIncorrBasic; virtual; @t\2@>
         procedure InsertIncorrFormula; virtual;

@ @<Empty method declarations for |SubexpObj|@>=
         @<Methods implemented by subclasses of |SubexpObj|@>@;@#
         procedure FinishSample; virtual; @t\2@>
         procedure ProcessThe; virtual; @t\2@>
         procedure StartArgument; virtual; @t\2@>
         procedure ProcessLeftParenthesis; virtual; @t\2@>
         procedure ProcessRightParenthesis; virtual; @t\2@>
         procedure StartAtomicFormula; virtual; @t\2@> @#
         
         procedure ProcessHolds; virtual; @t\2@>
         procedure FinishQuantified; virtual; @t\2@> @#
         
         procedure ProcessNot; virtual; @t\2@>
         procedure ProcessDoesNot; virtual; @t\2@> @#

         procedure StartAdjectiveCluster; virtual; @t\2@>
         procedure FinishAdjectiveCluster; virtual; @t\2@> @#

         procedure FinishAttributes; virtual; @t\2@>
         procedure CompleteAttributes; virtual; @t\2@>
         procedure CompleteClusterType; virtual; @t\2@>
         procedure FinishEquality; virtual; @t\2@>@#

@
\label{SubexpObj.abstract-methods}

@<Subexpression procedures@>=
procedure SubexpObj.StartAttributes; begin end;

procedure SubexpObj.StartAdjectiveCluster; begin end;

procedure SubexpObj.FinishAdjectiveCluster; begin end;

procedure SubexpObj.ProcessNon; begin end;

procedure SubexpObj.ProcessAttribute; begin end;

procedure SubexpObj.FinishAttributes; begin end;

procedure SubexpObj.CompleteAttributes; begin end;

procedure SubexpObj.StartAttributeArguments; begin end;

procedure SubexpObj.CompleteAttributeArguments; begin end;

procedure SubexpObj.FinishAttributeArguments; begin end;

procedure SubexpObj.CompleteAdjectiveCluster; begin end;

procedure SubexpObj.CompleteClusterTerm; begin end;

procedure SubexpObj.CompleteClusterType; begin end;

procedure SubexpObj.ProcessSimpleTerm; begin end;

procedure SubexpObj.ProcessQua; begin end;

procedure SubexpObj.FinishQualifiedTerm; begin end;

procedure SubexpObj.ProcessExactly; begin end;

procedure SubexpObj.StartArgument; begin end;

procedure SubexpObj.FinishArgument; begin end;

procedure SubexpObj.FinishTerm; begin end;

procedure SubexpObj.StartType; begin end;

procedure SubexpObj.ProcessModeSymbol; begin end;

procedure SubexpObj.FinishType; begin end;

procedure SubexpObj.CompleteType; begin end;

procedure SubexpObj.StartLongTerm; begin end;

procedure SubexpObj.FinishLongTerm; begin end;

procedure SubexpObj.FinishArgList; begin end;

procedure SubexpObj.ProcessFunctorSymbol; begin end;

procedure SubexpObj.StartFraenkelTerm; begin end;

procedure SubexpObj.FinishSample; begin end;

procedure SubexpObj.StartPostqualification; begin end;

procedure SubexpObj.StartPostqualificationSpecyfication; begin end;

procedure SubexpObj.StartPostqualifyingSegment; begin end;

procedure SubexpObj.ProcessPostqualifiedVariable; begin end;

procedure SubexpObj.FinishPostqualifyingSegment; begin end;

procedure SubexpObj.FinishFraenkelTerm; begin end;

procedure SubexpObj.StartSimpleFraenkelTerm; begin end;

procedure SubexpObj.FinishSimpleFraenkelTerm; begin end;

procedure SubexpObj.StartPrivateTerm; begin end;

procedure SubexpObj.FinishPrivateTerm; begin end;

procedure SubexpObj.StartBracketedTerm; begin end;

procedure SubexpObj.FinishBracketedTerm; begin end;

procedure SubexpObj.StartAggregateTerm; begin end;

procedure SubexpObj.FinishAggregateTerm; begin end;

procedure SubexpObj.ProcessThe; begin end;

procedure SubexpObj.StartSelectorTerm; begin end;

procedure SubexpObj.FinishSelectorTerm; begin end;

procedure SubexpObj.StartForgetfulTerm; begin end;

procedure SubexpObj.FinishForgetfulTerm; begin end;

procedure SubexpObj.StartChoiceTerm; begin end;

procedure SubexpObj.FinishChoiceTerm; begin end;

procedure SubexpObj.ProcessNumeralTerm; begin end;

procedure SubexpObj.ProcessItTerm; begin end;

procedure SubexpObj.ProcessLocusTerm; begin end;

procedure SubexpObj.ProcessThesis; begin end;

procedure SubexpObj.StartAtomicFormula; begin end;

procedure SubexpObj.ProcessAtomicFormula; begin end;

procedure SubexpObj.ProcessPredicateSymbol; begin end;

procedure SubexpObj.ProcessRightSideOfPredicateSymbol; begin end;

procedure SubexpObj.FinishPredicativeFormula; begin end;

procedure SubexpObj.FinishRightSideOfPredicativeFormula; begin end;

procedure SubexpObj.StartMultiPredicativeFormula; begin end;

procedure SubexpObj.FinishMultiPredicativeFormula; begin end;

procedure SubexpObj.FinishQualifyingFormula; begin end;

procedure SubexpObj.FinishAttributiveFormula; begin end;

procedure SubexpObj.StartPrivateFormula; begin end;

procedure SubexpObj.FinishPrivateFormula; begin end;

procedure SubexpObj.ProcessContradiction; begin end;

procedure SubexpObj.ProcessNot; begin end;

procedure SubexpObj.ProcessDoesNot; begin end;

procedure SubexpObj.ProcessNegative; begin end;

procedure SubexpObj.ProcessNegation; begin end;

procedure SubexpObj.StartRestriction; begin end;

procedure SubexpObj.FinishRestriction; begin end;

procedure SubexpObj.ProcessHolds; begin end;

procedure SubexpObj.ProcessBinaryConnective; begin end;

procedure SubexpObj.FinishBinaryFormula; begin end;

procedure SubexpObj.ProcessFlexDisjunction; begin end;

procedure SubexpObj.ProcessFlexConjunction; begin end;

procedure SubexpObj.FinishFlexDisjunction; begin end;

procedure SubexpObj.FinishFlexConjunction; begin end;

procedure SubexpObj.StartQualifiedSegment; begin end;

procedure SubexpObj.StartQualifyingType; begin end;

procedure SubexpObj.FinishQualifiedSegment; begin end;

procedure SubexpObj.FinishQuantified; begin end;

procedure SubexpObj.ProcessVariable; begin end;

procedure SubexpObj.StartExistential; begin end;

procedure SubexpObj.FinishExistential; begin end;

procedure SubexpObj.StartUniversal; begin end;

procedure SubexpObj.FinishUniversal; begin end;

procedure SubexpObj.ProcessLeftParenthesis; begin end;

procedure SubexpObj.ProcessRightParenthesis; begin end;

procedure SubexpObj.InsertIncorrType; begin end;

procedure SubexpObj.InsertIncorrTerm; begin end;

procedure SubexpObj.InsertIncorrBasic; begin end;

procedure SubexpObj.InsertIncorrFormula; begin end;

procedure SubexpObj.FinishEquality; begin end;


@* [F] MScanner.
We have the MScanner module transform an article (an input file) into
a stream of tokens.

@<scanner.pas@>=
@<GNU License@>

unit mscanner;

interface @|@#

uses errhan,mobjects,scanner; @|@#


  @<Public interface for MScanner@>@; @#

implementation @|@#

uses mizenv; @#

@<Implementation for MScanner@>; @t\2@> @#

end.

@ \node{Public types.} We have enumerated types for each construction
we'll encounter in Mizar.

\label{PropertyKind}

@<Public interface for MScanner@>=
type
   @<Token kinds for MScanner@>;

   CorrectnessKind  = (syCorrectness,
                       syCoherence, syCompatibility, syConsistency,
                       syExistence, syUniqueness, syReducibility); @#

   PropertyKind = (sErrProperty,
                   sySymmetry,syReflexivity,syIrreflexivity,
                   syAssociativity,syTransitivity,syCommutativity,
                   syConnectedness,syAsymmetry,syIdempotence,
                   syInvolutiveness,syProjectivity,sySethood,syAbstractness); @#

   LibraryReferenceKind = (syThe,syDef,sySch); @#

   DirectiveKind =
      (syVocabularies,syNotations,
       syDefinitions,syTheorems,sySchemes,syRegistrations,
       syConstructors,syRequirements,syEqualities,syExpansions); @#

   @<Token type for MScanner@>; @#
@ \node{Token type for MScanner.}

@<Token type for MScanner@>=
   Token =
      record @t\1@> Kind:TokenKind;
         Nr:integer;
         Spelling: string @t\2@>;
      end

@ \node{Constants for MScanner}

\label{MScanner:constants}

@<Public interface for MScanner@>=
const
   {Homonymic and special symbols in buildin vocabulery}
   {Homonymic Selector Symbol}
   StrictSym = 1;       {``strict''}
   {Homonymic Mode Symbol}
   SetSym = 1;          {`set'}
   {Homonymic Predicate Symbol}
   EqualitySym = 1;     {`='}
   {Homonymic Circumfix Symbols}
   SquareBracket = 1;   {`[' `]'}
   CurlyBracket = 2;    { ``\LB'' ``\RB'' }
   RoundedBracket = 3;  { ``('' ``)'' }
   
   scTooLongLineErrorNr = 200;  {Error number: Too long line}

   @<Token names for MScanner@>;

   CorrectnessName: array[CorrectnessKind] of string =
      ('correctness',
       'coherence',
       'compatibility',
       'consistency',
       'existence',
       'uniqueness',
       'reducibility'
      );

   PropertyName: array[PropertyKind] of string =
      ('',
       'symmetry',
       'reflexivity',
       'irreflexivity',
       'associativity',
       'transitivity',
       'commutativity',
       'connectedness',
       'asymmetry',
       'idempotence',
       'involutiveness',
       'projectivity',
       'sethood',
       'abstractness'
      );
   
   LibraryReferenceName: array[LibraryReferenceKind] of string =
      ( 'the','def','sch');
   
   DirectiveName: array[DirectiveKind] of string =
      ( 'vocabularies',
        'notations',
        'definitions',
        'theorems',
        'schemes',
        'registrations',
        'constructors',
        'requirements',
        'equalities',
        'expansions'
      );
   
   PlaceHolderName: array[1..10] of string =
      ( '$1', '$2', '$3', '$4', '$5', '$6', '$7', '$8', '$9', '$10' );
   
   Unexpected = sErrProperty;

@ \node{Public facing procedures and global variables.}
Of particular importance, the global variable \\{gScanner} is declared here.

@<Public interface for MScanner@>=   
var
   PrevWord,CurWord,AheadWord: Token; @/
   PrevPos,AheadPos: Position; @#
   
   procedure @? ReadToken; @t\2@> @#
   
   procedure @? LoadPrf(const aPrfFileName:string); @t\2@> @/
   procedure @? DisposePrf; @t\2@> @#
   
   procedure @? StartScaner; @t\2@> @#
   
   procedure @? InitSourceFile(const aFileName, aDctFileName:string); @t\2@> @/
   procedure @? CloseSourceFile; @t\2@> @/
   procedure @? InitScanning(const aFileName,aDctFileName:string); @t\2@> @/
   procedure @? FinishScanning; @t\2@> @/
   
var
  gScanner: MScannPtr = nil; {This is important}
  @? ModeMaxArgs,@? StructModeMaxArgs,@? PredMaxArgs: IntSequence;

@ \node{Token kinds.}
If I were cleverer, I would have some \WEB/ macros to make this
readable. 
\label{TokenKind}
@<Token kinds for MScanner@>=
   TokenKind = (
      syT0, @t\1@> {\begingroup\tt  \#0  }
      syT1, {  \#1  }
      syT2, {  \#2  }
      syT3, {  \#3  }
      syT4, {  \#4  }
      syT5, {  \#5  }
      syT6, {  \#6  }
      syT7, {  \#7  }
      syT8, {  \#8  }
      syT9, {  \#9  }
      syT10, {  \#10 }
      syT11, {  \#11 }
      syT12, {  \#12 }
      syT13, {  \#13 }
      syT14, {  \#14 }
      syT15, {  \#15 }
      syT16, {  \#16 }
      syT17, {  \#17 }
      syT18, {  \#18 }
      syT19, {  \#19 }
      syT20, {  \#20 }
      syT21, {  \#21 }
      syT22, {  \#22 }
      syT23, {  \#23 }
      syT24, {  \#24 }
      syT25, {  \#25 }
      syT26, {  \#26 }
      syT27, {  \#27 }
      syT28, {  \#28 }
      syT29, {  \#29 }
      syT30, {  \#30 }
      syT31, {  \#31 }
      Pragma, {  \#32 }
      EOT = 33, {! \#33 }
      sy_from, {" \#34 }
      sy_identify, {\# \#35 }
      sy_thesis, { \$ \#36}
      sy_contradiction, {\% \#37 }
      sy_Ampersand, {\AM\ \#38 }
      sy_by, {' \#39 }
      sy_LeftParanthesis, {( \#40 }
      sy_RightParanthesis, {) \#41 }
      sy_registration, {* \#42 }
      sy_definition, {+ \#43 }
      sy_Comma, {, \#44 }
      sy_notation, {- \#45 }
      sy_Ellipsis, {. \#46 }
      sy_proof, {/ \#47 }
      syT48, {0 \#48 }
      syT49, {1 \#49 }
      syT50, {2 \#50 }
      syT51, {3 \#51 }
      syT52, {4 \#52 }
      syT53, {5 \#53 }
      syT54, {6 \#54 }
      syT55, {7 \#55 }
      syT56, {8 \#56 }
      syT57, {9 \#57 }
      sy_Colon, {: \#58 }
      sy_Semicolon, {; \#59 }
      sy_now, {< \#60 }
      sy_Equal, {= \#61 }
      sy_end, {> \#62 }
      sy_Error, {? \#63 }
      syT64, {@@ \#64 }
      MMLIdentifier, {A \#65 }
      syT66, {B \#66 }
      syT67, {C \#67 }
      sy_LibraryDirective, {D \#68 } @+ {{\rm see DirectiveKind}}
      syT69, {E \#69 }
      syT70, {F \#70 }
      StructureSymbol, {G \#71 }
      syT72, {H \#72 }
      Identifier, {I \#73 }
      ForgetfulFunctor, {J \#74 }
      LeftCircumfixSymbol, {K \#75 }
      RightCircumfixSymbol, {L \#76 }
      ModeSymbol, {M \#77 }
      Numeral, {N \#78 }
      InfixOperatorSymbol, {O \#79 }
      syT80, {P \#80 }
      ReferenceSort, {Q \#81 }
      PredicateSymbol, {R \#82 }
      syT83, {S \#83 }
      syT84, {T \#84 }
      SelectorSymbol, {U \#85 }
      AttributeSymbol, {V \#86 }
      syT87, {W \#87 }
      sy_Property, {X \#88 } @+ {{\rm see PropertyKind}}
      sy_CorrectnessCondition, {Y \#89 } @+ {{\rm see CorrectnessKind }}
      sy_Dolar, {Z \#90 } @+ { \$1 \$2 \$3 \$4 \$5 \$6 \$7 \$8 \$9 \$10 }
      sy_LeftSquareBracket, {[ \#91 }
      syT92, {\ \#92 }
      sy_RightSquareBracket, {] \#93 }
      syT94, {\shiftSix\ \#94 }
      syT95, {\_ \#95 }
      syT96, {` \#96 }
      sy_according, {a \#97 }
      syT98, {b \#98 }
      sy_reduce, {c \#99 }
      syT100, {d \#100}
      sy_equals, {e \#101}
      syT102, {f \#102}
      syT103, {g \#103}
      sy_with, {h \#104}
      syT105, {i \#105}
      syT106, {j \#106}
      syT107, {k \#107}
      syT108, {l \#108}
      syT109, {m \#109}
      syT110, {n \#110}
      syT111, {o \#111}
      syT112, {p \#112}
      syT113, {q \#113}
      sy_wrt = 114, {r \#114}
      syT115, {s \#115}
      sy_to, {t \#116}
      syT117, {u \#117}
      syT118, {v \#118}
      sy_when, {w \#119}
      sy_axiom, {x \#120}
      syT121, {y \#121}
      syT122, {z \#122}
      sy_LeftCurlyBracket, {  \#123}
      syT124, {\pipe\ \#124}
      sy_RightCurlyBracket, {  \#125}
      syT126, {\TL\ \#126}
      syT127, {\#127}
      syT128, {\#128}
      syT129, {\#129}
      syT130, {\#130}
      syT131, {\#131}
      syT132, {\#132}
      syT133, {\#133}
      syT134, {\#134}
      sy_correctness = 135, {\#135}
      syT136, {\#136}
      syT137, {\#137}
      syT138, {\#138}
      syT139, {\#139}
      sy_if = 140, {\#140}
      syT141, {\#141}
      syT142, {\#142}
      syT143, {\#143}
      sy_is = 144, {\#144}
      sy_are, {\#145}
      syT146, {\#146}
      sy_otherwise, {\#147}
      syT148, {\#148}
      syT149, {\#149}
      syT150, {\#150}
      syT151, {\#151}
      syT152, {\#152}
      syT153, {\#153}
      syT154, {\#154}
      syT155, {\#155}
      sy_ex = 156, {\#156}
      sy_for, {\#157}
      syT158, {\#158}
      sy_define, {\#159}
      syT160, {\#160}
      sy_being, {\#161}
      sy_over, {\#162}
      syT163, {\#163}
      sy_canceled, {\#164}
      sy_do, {\#165}
      sy_does, {\#166}
      sy_or, {\#167}
      sy_where, {\#168}
      sy_non, {\#169}
      sy_not, {\#170}
      sy_cluster, {\#171}
      sy_attr, {\#172}
      syT173, {\#173}
      sy_StructLeftBracket, {\#174}
      sy_StructRightBracket, {\#175}
      sy_environ, {\#176}
      syT177, {\#177}
      sy_begin, {\#178}
      syT179, {\#179}
      syT180, {\#180}
      syT181, {\#181}
      syT182, {\#182}
      syT183, {\#183}
      syT184, {\#184}
      sy_hence, {\#185}
      syT186, {\#186}
      syT187, {\#187}
      sy_hereby, {\#188}
      syT189, {\#189}
      syT190, {\#190}
      syT191, {\#191}
      sy_then, {\#192}
      sy_DotEquals, {\#193}
      syT194, {\#194}
      syT195, {\#195}
      sy_synonym, {\#196}
      sy_antonym, {\#197}
      syT198, {\#198}
      syT199, {\#199}
      sy_let, {\#200}
      sy_take, {\#201}
      sy_assume, {\#202}
      sy_thus, {\#203}
      sy_given, {\#204}
      sy_suppose, {\#205}
      sy_consider, {\#206}
      syT207, {\#207}
      syT208, {\#208}
      syT209, {\#209}
      syT210, {\#210}
      sy_Arrow, {\#211}
      sy_as, {\#212}
      sy_qua, {\#213}
      sy_be, {\#214}
      sy_reserve, {\#215}
      syT216, {\#216}
      syT217, {\#217}
      syT218, {\#218}
      syT219, {\#219}
      syT220, {\#220}
      syT221, {\#221}
      syT222, {\#222}
      syT223, {\#223}
      sy_set, {\#224}
      sy_selector, {\#225}
      sy_cases, {\#226}
      sy_per, {\#227}
      sy_scheme, {\#228}
      sy_redefine, {\#229}
      sy_reconsider, {\#230}
      sy_case, {\#231}
      sy_prefix, {\#232}
      sy_the, {\#233}
      sy_it, {\#234}
      sy_all, {\#235}
      sy_theorem, {\#236}
      sy_struct, {\#237}
      sy_exactly, {\#238}
      sy_mode, {\#239}
      sy_iff, {\#240}
      sy_func, {\#241}
      sy_pred, {\#242}
      sy_implies, {\#243}
      sy_st, {\#244}
      sy_holds, {\#245}
      sy_provided, {\#246}
      sy_means, {\#247}
      sy_of, {\#248}
      sy_defpred, {\#249}
      sy_deffunc, {\#250}
      sy_such, {\#251}
      sy_that, {\#252}
      sy_aggregate, {\#253}
      sy_and {\#254\endgroup}
   );

@ We have string representation for each of the token kinds, which is
useful for debugging purposes.

@<Token names for MScanner@>=
   TokenName: array[TokenKind] of string =
      ('', {\begingroup\tt  \#0  } 
       '', {  \#1  } 
       '', {  \#2  } 
       '', {  \#3  } 
       '', {  \#4  } 
       '', {  \#5  } 
       '', {  \#6  } 
       '', {  \#7  } 
       '', {  \#8  } 
       '', {  \#9  } 
       '', {  \#10 } 
       '', {  \#11 } 
       '', {  \#12 } 
       '', {  \#13 } 
       '', {  \#14 } 
       '', {  \#15 } 
       '', {  \#16 } 
       '', {  \#17 } 
       '', {  \#18 } 
       '', {  \#19 } 
       '', {  \#20 } 
       '', {  \#21 } 
       '', {  \#22 } 
       '', {  \#23 } 
       '', {  \#24 } 
       '', {  \#25 } 
       '', {  \#26 } 
       '', {  \#27 } 
       '', {  \#28 } 
       '', {  \#29 } 
       '', {  \#30 } 
       '', {  \#31 } 
       '', {  \#32 } 
       '', {! \#33 } 
       'from', { {\tt "} \#34 }
       'identify', {\# \#35 } 
       'thesis', { \$ \#36 } 
       'contradiction', {\% \#37 } 
       '&', {\AM\ \#38 } 
       'by', {' \#39 } 
       '(',  {( \#40 } 
       ')', {) \#41 } 
       'registration', {* \#42 } 
       'definition', {+ \#43 } 
       ',', {, \#44 }
       'notation', {- \#45 } 
       '...', {. \#46 } 
       'proof', {/ \#47 } 
       '', {0 \#48 } 
       '', {1 \#49 } 
       '', {2 \#50 } 
       '', {3 \#51 } 
       '', {4 \#52 } 
       '', {5 \#53 } 
       '', {6 \#54 } 
       '', {7 \#55 } 
       '', {8 \#56 } 
       '', {9 \#57 } 
       ':', {: \#58 }
       ';', {; \#59 }
       'now',    {< \#60 }
       '=',   {= \#61 }
       'end', {> \#62 }
       '', {? \#63 } 
       '', {@@ \#64 } 
       '', {A \#65 } 
       '', {B \#66 } 
       '', {C \#67 } 
       'vocabularies', {D \#68 }
       '', {E \#69 } 
       '', {F \#70 } 
       '', {G \#71 } 
       '', {H \#72 } 
       '', {I \#73 } 
       '', {J \#74 } 
       '', {K \#75 } 
       '', {L \#76 } 
       '', {M \#77 } 
       '', {N \#78 } 
       '', {O \#79 } 
       '', {P \#80 } 
       'def', {Q \#81 } 
       '', {R \#82 } 
       '', {S \#83 } 
       '', {T \#84 } 
       '', {U \#85 } 
       '', {V \#86 } 
       '', {W \#87 } 
       'symmetry', {X \#88 } 
       'coherence', {Y \#89 } 
       '$1`', {Z \#90 }
       '[', {[ \#91 }
       '', {{\rm`}\SP{\rm'} \#92 } 
       ']', {] \#93 } 
       '', {\lower3pt\hbox{$\widehat{\ }$} \shiftSix\ \#94 }
       '', {\_ \#95 }
       '', {` \#96 }
       'according', {a \#97 }
       '', {b \#98 }
       'reduce', {c \#99 }
       '', {d \#100}
       'equals', {e \#101}
       '', {f \#102}
       '', {g \#103}
       'with', {h \#104}
       '', {i \#105}
       '', {j \#106}
       '', {k \#107}
       '', {l \#108}
       '', {m \#109}
       '', {n \#110}
       '', {o \#111}
       '', {p \#112}
       '', {q \#113}
       'wrt', {r \#114}
       '', {s \#115}
       'to', {t \#116}
       '', {u \#117}
       '', {v \#118}
       'when', {w \#119}
       'axiom', {x \#120}
       '', {y \#121}
       '', {z \#122}
       '{', {  \#123}
       '', {\pipe\ \#124}
       '}', { \#125}
       '', {\TL\ \#126}
       'T127', {\#127}
       '', {\#128}
       'T129', {\#129}
       '', {\#130}
       'T131', {\#131}
       '', {\#132}
       '', {\#133}
       '', {\#134}
       'correctness', {\#135}
       'T136', {\#136}
       '', {\#137}
       '', {\#138}
       '', {\#139}
       'if', {\#140}
       '', {\#141}
       '', {\#142}
       '', {\#143}
       'is', {\#144}
       'are', {\#145}
       '', {\#146}
       'otherwise', {\#147}
       '', {\#148}
       '', {\#149}
       '', {\#150}
       '', {\#151}
       'T152', {\#152}
       '', {\#153}
       '', {\#154}
       '', {\#155}
       'ex', {\#156}
       'for', {\#157}
       '', {\#158}
       'define', {\#159}
       '', {\#160}
       'being', {\#161}
       'over', {\#162}
       '', {\#163}
       'canceled', {\#164}
       'do', {\#165}
       'does', {\#166}
       'or', {\#167}
       'where', {\#168}
       'non', {\#169}
       'not', {\#170}
       'cluster', {\#171}
       'attr', {\#172}
       '', {\#173}
       '(\#', {\#174}
       '\#)', {\#175}
       'environ', {\#176}
       '', {\#177}
       'begin', {\#178}
       '', {\#179}
       '', {\#180}
       '', {\#181}
       '', {\#182}
       '', {\#183}
       '', {\#184}
       'hence', {\#185}
       '', {\#186}
       '', {\#187}
       'hereby', {\#188}
       '', {\#189}
       '', {\#190}
       '', {\#191}
       'then', {\#192}
       '.=', {\#193}
       '', {\#194}
       '', {\#195}
       'synonym', {\#196}
       'antonym', {\#197}
       '', {\#198}
       '', {\#199}
       'let', {\#200}
       'take', {\#201}
       'assume', {\#202}
       'thus', {\#203}
       'given', {\#204}
       'suppose', {\#205}
       'consider', {\#206}
       '', {\#207}
       '', {\#208}
       '', {\#209}
       '', {\#210}
       '->', {\#211}
       'as', {\#212}
       'qua', {\#213}
       'be', {\#214}
       'reserve', {\#215}
       '', {\#216}
       '', {\#217}
       '', {\#218}
       '', {\#219}
       '', {\#220}
       '', {\#221}
       '', {\#222}
       '', {\#223}
       'set', {\#224}
       'selector', {\#225}
       'cases', {\#226}
       'per', {\#227}
       'scheme', {\#228}
       'redefine', {\#229}
       'reconsider', {\#230}
       'case', {\#231}
       'prefix', {\#232}
       'the', {\#233}
       'it', {\#234}
       'all', {\#235}
       'theorem', {\#236}
       'struct', {\#237}
       'exactly', {\#238}
       'mode', {\#239}
       'iff', {\#240}
       'func', {\#241}
       'pred', {\#242}
       'implies', {\#243}
       'st', {\#244}
       'holds', {\#245}
       'provided', {\#246}
       'means', {\#247}
       'of', {\#248}
       'defpred', {\#249}
       'deffunc', {\#250}
       'such', {\#251}
       'that', {\#252}
       'aggregate', {\#253}
       'and' {\#254\endgroup}
      )

@ \node{Reading a token.}
This tokenizes a Mizar article, using the scanner's \\{GetToken}
method. We can trace this \\{GetToken} back to its
implementation (\section\xref{MTokeniser.GetToken}). This, in turn,
depends on the \\{SliceIt} method (\section\xref{MTokeniser.SliceIt}).

This method is used to determine the next token
in \texttt{parser.pas}'s \\{Parse} function.

This assumes that |StartScanner| (\section\xref{StartScanner}) has
been invoked already, which initializes the \\{CurWord} token and
other variables.

Also important to observe: the \\{Kind} of the token is populated here.

\label{ReadToken}

@^Tokenization@>

@<Implementation for MScanner@>=
procedure ReadToken;
begin
   PrevWord:=CurWord; PrevPos:=CurPos;
   CurWord:=AheadWord; CurPos:=AheadPos;
   {'\_' is not allowed in an identifiers in the text proper}
   if (CurWord.Kind = sy_Begin)
   then gScanner^.Allowed['_']:=0;
   if (CurWord.Kind = sy_Error) and
         (CurWord.Nr = scTooLongLineErrorNr)
   then ErrImm(CurWord.Nr);
   gScanner^.GetToken; @/
   AheadWord.Kind:=TokenKind(gScanner^.fLexem.Kind);
   AheadWord.Nr:=gScanner^.fLexem.Nr;
   AheadWord.Spelling:=gScanner^.fStr;
   AheadPos:=gScanner^.fPos;
end;

@ \node{Loading a proof file.}
The \texttt{.prf} file is a file containing numerals, and its usage
eludes me. The format consists of multiple lines:

{Line 1:} Three non-negative integers are on the first line ``$M$ $S$ $P$'' 

{Line 2:} Contains $M$ non-negative integers separated by a
single whitespace

{Line 3:} Contains $S$ non-negative integers separated by a
single whitespace

{Line 4:} Contains $P$ non-negative integers separated by a
single whitespace.

\medbreak\noindent%
This function loads the contents of the \texttt{.prf} file. This
initializes the global variables |ModeMaxArgs|,
|StructureModeMaxArgs|, |PredMaxArgs|, then populates them.

@:File, prf}{File, \texttt{.prf}@>
@:prf file}{\texttt{.prf} File@>
@^\texttt{.prf} File@>

@<Implementation for MScanner@>=
procedure LoadPrf(const aPrfFileName:string);
var lPrf: text;
lModeMaxArgsSize,lStructModeMaxArgsSize,lPredMaxArgsSize,i,lInt,r: integer;
begin
   assign(lPrf,aPrfFileName+'.prf'); reset(lPrf);
   Read(lPrf,lModeMaxArgsSize,lStructModeMaxArgsSize,lPredMaxArgsSize);
   ModeMaxArgs.Init(lModeMaxArgsSize+1);
   r:=ModeMaxArgs.Insert(0);
   StructModeMaxArgs.Init(lStructModeMaxArgsSize+1);
   r:=StructModeMaxArgs.Insert(0);
   PredMaxArgs.Init(lPredMaxArgsSize+1);
   r:=PredMaxArgs.Insert(0);
   for i:=1 to lModeMaxArgsSize do
   begin Read(lPrf,lInt);
   r:=ModeMaxArgs.Insert(lInt);
   end;
   for i:=1 to lStructModeMaxArgsSize do
   begin Read(lPrf,lInt);
   r:=StructModeMaxArgs.Insert(lInt);
   end;
   for i:=1 to lPredMaxArgsSize do
   begin Read(lPrf,lInt);
   r:=PredMaxArgs.Insert(lInt);
   end;
   close(lPrf);
end;

@ We cleanup after using the \texttt{.prf} file.

@<Implementation for MScanner@>=
procedure DisposePrf;
begin
   ModeMaxArgs.Done;
   PredMaxArgs.Done;
   StructModeMaxArgs.Done;
end;

@ We construct an MScann object to scan a file.

\label{StartScanner}

@<Implementation for MScanner@>=
procedure StartScaner;
begin
   CurPos.Line:=1; CurPos.Col:=0;
   AheadWord.Kind:=TokenKind(gScanner^.fLexem.Kind);
   AheadWord.Nr:=gScanner^.fLexem.Nr;
   AheadWord.Spelling:=gScanner^.fStr;
   AheadPos:=gScanner^.fPos;
end;

@ We initialize a scanner for a file.

@<Implementation for MScanner@>=
procedure InitSourceFile(const aFileName,aDctFileName:string);
begin
   new(@! gScanner,InitScanning(aFileName,aDctFileName));
   StartScaner;
end;

@ When we're done with a scanner, we call the destructor for the MScanner.

@<Implementation for MScanner@>=
procedure CloseSourceFile;
begin
   dispose(gScanner,Done);
end;

@ We can combine the previous functions together to initialize a
scanner for a file (an article) and its dictionary file.

@<Implementation for MScanner@>=
procedure InitScanning(const aFileName,aDctFileName:string);
begin
   gScanner:=new(MScannPtr, InitScanning(aFileName,aDctFileName));
   StartScaner;
   LoadPrf(aDctFileName);
end;

@ We cleanup after scanning, saving a dictionary \XML/ file to an
``\texttt{.idx}'' file. This uses the global variable |EnvFileName|
declared in \texttt{mizenv.pas} (\section\xref{mizenv-global-vars}).

@^\texttt{.idx} file@>
@:File, idx}{File, \texttt{.idx}@>
@:idx File}{\texttt{.idx} File@>

@<Implementation for MScanner@>=
procedure FinishScanning;
begin
   gScanner^.fIdents.SaveXDct(EnvFileName+'.idx');
   CloseSourceFile;
   DisposePrf;
end;
@* [F] Abstract Syntax.
A crucial step in any interpreter, compiler, or proof assistant is to
transform the concrete syntax into an abstract syntax tree. This
module provides all the classes for the abstract syntax tree \emph{of
expressions, types, and formulas} in Mizar. The abstract syntax tree
for ``statements'' will be found in the ``Weakly Strict Text Proper'' module.

This is a bit, well, ``Java-esque'', in the sense that each different
kind of node in the abstract syntax tree is represented by a different
class. If you don't know abstract syntax trees, I can heartily
recommend Bob Nystrom's \emph{Crafting Interpreters} (\href{https://craftinginterpreters.com/representing-code.html}{Ch.\ 5: Representing Code})
for an overview.

I'll be quoting from the grammar for Mizar as we go along, since the
class hierarchy names their classes after the nonterminal symbols in
the grammar. (It's what anyone would do.) You can find a local copy of
the grammar on most \UNIX/ machines with Mizar installed located
at \texttt{/usr/local/doc/Mizar/syntax.txt}, which you can study at
your leisure.

@ \node{Warning:} There is a lot of boiler plate code in the
constructors and destructors. I am going to pass over them without
much comment, because they are monotonous and uninteresting. The more
interesting part will be discussed with the class declarations for
each kind of node. I will simply entitle the paragraphs
``Constructor'' to indicate I am recognizing their existence and
moving on.

@<abstract\_syntax.pas@>=
@<GNU License@>@;

unit abstract_syntax;

interface

uses errhan,mobjects,syntax; @#

@<Interface for abstract syntax@>@; @#

implementation @|@#
@<Implementation of abstract syntax@>@t\2@>@; @#
end.

@ The implementation requires discussing a few ``special cases''
(variables, qualified segments, adjectives) before getting to the
usual syntactic classes (terms, types, formulas).


@<Implementation of abstract syntax@>=
@<Variable AST constructor@>@;
@<Qualified segment AST constructor@>@;
@<Adjective expression AST constructor@>@;
@<Adjective AST constructor@>@;
@<Negated adjective AST constructor@>@;
@<Implementing term AST@>@;
@<Implementing type AST@>@;
@<Implementing formula AST@>@;
@<Within expression AST implementation@>@;

@ The interface consists mostly of classes, as well as a few
enumerated types. The gambit resembles what we would do if we were
programming in \CEE/: define an \texttt{enum TermSort}, then
introduce a \texttt{struct TermAstNode \LB enum TermSort sort;\RB}
to act as an abstract base class for terms (and do likewise for
formulas, types, etc.). This allows us to use ``struct inheritance''
in \CEE/, as Bob Nystrom's \emph{Crafting Interpreters}
(\href{https://www.craftinginterpreters.com/strings.html}{Ch.\ 19})
calls it.

@<Interface for abstract syntax@>=
type

   @<Abstract base class for types@>;

   @<Abstract base class for terms@>;

   @<Abstract base class for formulas@>; @#

   @<Adjective expression (abstract syntax tree)@>;

   @<Negated adjective expression (abstract syntax tree)@>;
   
   @<Adjective (abstract syntax tree)@>; @#

   { Auxiliary structures }

   @<Variable (abstract syntax tree)@>;
   
   @<Qualified segment (abstract syntax tree)@>; @#

   @<Classes for terms (abstract syntax tree)@>@;

   @<Classes for type (abstract syntax tree)@>@;

   @<Classes for formula (abstract syntax tree)@>@; @#

   {----------------------------------------------------------------}

   @<Class for Within expression@>;


@ \node{Variable.} A variable in the abstract syntax tree is basically
a de Bruijn index, in the sense that it is represented by an integer
in the metalanguage (\PASCAL/).

Logicians may feel uncomfortable at variables being outside the term
syntax tree. But what logicians think of as ``variables'' in
first-order logic, Mizar calls them ``Simple Terms''
(\section\xref{ast:SimpleTerm}). 

@<Variable (abstract syntax tree)@>=
   VariablePtr = ^VariableObj; @/
   VariableObj = object(MObject) @t\1@> @/
      nIdent: integer; { identifier number }
      nVarPos: Position; @/
      constructor Init(const aPos:Position;@+ aIdentNr:integer); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Variable AST constructor@>=
constructor VariableObj.Init(const aPos:Position;@+ aIdentNr:integer);
begin
   nIdent:=aIdentNr;
   nVarPos:=aPos;
end;

@ \node{Qualified segment.} A qualified segment refers to situations
in, e.g.,``\texttt{consider} $\langle\hbox{\textit{qualified-segment\/}}\rangle^{+}$
\texttt{such that} \dots''. This also happens in quantifiers where the
Working Mathematician writes $\forall\vec{x}\ldotp P[\vec{x}]$, for
example (that quantifier prefix ``$\forall\vec{x}\,$'' uses the
qualifying segment $\vec{x}\,$).

The Mizar grammar for qualified segments looks like:

{\advance\leftskip by2pc\obeylines\tt
Qualified-Variables = Implicitly-Qualified-Variables
\quad\pipe\ Explicitly-Qualified-Variables
\quad\pipe\ Explicitly-Qualified-Variables "," Implicitly-Qualified-Variables .

Implicitly-Qualified-Variables = Variables .

Explicitly-Qualified-Variables = Qualified-Segment \LB "," Qualified-Segment \RB .

Qualified-Segment = Variables Qualification .

Variables = Variable-Identifier \LB "," Variable-Identifier \RB .

Qualification = ( "being" \pipe\ "be" ) Type-Expression .
\par}

\noindent We will implement \texttt{Qualified-Variables} as an array
of pointers to \\{QualifiedSegment} objects, each one being either
implicit or explicit.

@ \node{Abstract base class for qualified segments.}
We have \emph{implicitly} qualified segments and \emph{explicitly}
qualified segments, which are ``both'' qualified
segments. Object-oriented yoga teaches us to describe this situation
using a ``qualified segment'' abstract base class, and then extend it
with two subclasses.

@<Qualified segment (abstract syntax tree)@>=
   SegmentKind = (ikImplQualifiedSegm, ikExplQualifiedSegm); @#
   
   QualifiedSegmentPtr = ^QualifiedSegmentObj; @/
   QualifiedSegmentObj = object(MObject) @t\1@> @/
      nSegmPos: Position; @/
      nSegmentSort: SegmentKind; @/
      constructor Init(const aPos:Position;@+ aSort:SegmentKind); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Qualified segment AST constructor@>=
constructor QualifiedSegmentObj.Init(const aPos:Position;@+ aSort:SegmentKind);
begin
   nSegmPos:=aPos;
   nSegmentSort:=aSort;
end;

@ \node{Implicitly qualified segments.} When we use ``reserved
variables'' in the qualifying segment, we can suppress the type
ascription (i.e., the ``\texttt{being} $\langle\textit{Type}\rangle$'').
This makes the typing \emph{implicit}. Hence the
name \emph{implicitly} qualified segments (the types are implicitly given).

@<Qualified segment (abstract syntax tree)@>=
   ImplicitlyQualifiedSegmentPtr = ^ImplicitlyQualifiedSegmentObj; @/
   ImplicitlyQualifiedSegmentObj = object(QualifiedSegmentObj) @t\1@> @/
      nIdentifier: VariablePtr; @/
      constructor Init(const aPos:Position;@+ aIdentifier:VariablePtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}
The constructors and destructors for implicitly qualified segments
are straightforward.

@<Qualified segment AST constructor@>=
constructor ImplicitlyQualifiedSegmentObj.Init(const aPos:Position;@+ aIdentifier:VariablePtr);
begin
   inherited Init(aPos,ikImplQualifiedSegm);
   nIdentifier:=aIdentifier;
end; @#

destructor ImplicitlyQualifiedSegmentObj.Done;
begin
   dispose(nIdentifier,Done);
end;

@ \node{Explicitly qualified segment.} The other possibility in Mizar
is that we will have ``explicitly typed variables'' in the qualifying
segment. The idea is that, in Mizar, we can permit the following
situation:

\smallbreak
{\narrower\tt consider x,y,z being set such that \dots\par}
\smallbreak\noindent%
This means the three variables $x$, $y$, $z$ are explicitly qualified
variables with the type ``\texttt{set}''. We represent this using one 
\\{ExplicitlyQualifiedSegment} object, a vector for the identifiers
($x$, $y$, $z$) and a pointer to their type (\texttt{set}).

@<Qualified segment (abstract syntax tree)@>=
   ExplicitlyQualifiedSegmentPtr = ^ExplicitlyQualifiedSegmentObj; @/
   ExplicitlyQualifiedSegmentObj = object(QualifiedSegmentObj) @t\1@> @/
      nIdentifiers: PList; { of identifier numbers }
      nType: TypePtr; @/
      constructor Init(const aPos:Position;@+ aIdentifiers:PList;@+ aType:TypePtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ The constructors and destructors for explicitly qualified segments
are straightforward.

@<Qualified segment AST constructor@>=
constructor ExplicitlyQualifiedSegmentObj.Init(const aPos:Position;
@t\hskip17.3333pc @>  aIdentifiers:PList;
                         @t\hskip17.3333pc @>  aType:TypePtr);
begin
   inherited Init(aPos,ikExplQualifiedSegm);
   nIdentifiers:=aIdentifiers;
   nType:=aType;
end; @#

destructor ExplicitlyQualifiedSegmentObj.Done;
begin
   dispose(nIdentifiers,Done);
   dispose(nType,Done);
end;

@ \node{Attributes.}
Attributes can have arguments \emph{preceding} it.
The relevant part of the Mizar grammar, I think, is:

{\advance\leftskip by2pc\obeylines\tt
Adjective-Cluster = \LB\ Adjective \RB\ .

Adjective = [ "non" ] [ Adjective-Arguments ] Attribute-Symbol .

\par}

@<Adjective expression (abstract syntax tree)@>=
   AdjectiveSort = (wsNegatedAdjective,wsAdjective); @#

   AdjectiveExpressionPtr = ^AdjectiveExpressionObj; @/
   AdjectiveExpressionObj = object(MObject) @t\1@> @/
      nAdjectivePos: Position; @/
      nAdjectiveSort: AdjectiveSort; @/
      constructor Init(const aPos:Position;@+ aSort: AdjectiveSort); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ @<Adjective expression AST constructor@>=
constructor AdjectiveExpressionObj.Init(const aPos:Position;@+ aSort: AdjectiveSort);
begin
   nAdjectivePos:=aPos;
   nAdjectiveSort:=aSort;
end;

destructor AdjectiveExpressionObj.Done;
begin
end;

@ \node{Negated adjective.} We represent an adjective using the EBNF
grammar (c.f., the WSM article-related function \\{InWSMizFileObj.Read\_Adjective:AdjectiveExpressionPtr}):

\smallbreak
{\advance\leftskip by2pc\obeylines\tt
Negated-Adjective ::= "non" Adjective-Expr;
Positive-Adjective ::= [Adjective-Arguments] Attribute-Symbol;
Adjective-Expr ::= Negated-Adjective \pipe\ Positive-Adjective;
\par}
\smallbreak\noindent%
Hence we only really need a pointer to the ``adjective being negated''.

@<Negated adjective expression (abstract syntax tree)@>=
   NegatedAdjectivePtr = ^NegatedAdjectiveObj; @/
   NegatedAdjectiveObj = object(AdjectiveExpressionObj) @t\1@> @/
      nArg: AdjectiveExpressionPtr; { of TermPtr, visible arguments }
      constructor Init(const aPos:Position;@+ aArg:AdjectiveExpressionPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Negated adjective AST constructor@>=
constructor NegatedAdjectiveObj.Init(const aPos:Position;@+ aArg:AdjectiveExpressionPtr);
begin
   inherited Init(aPos,wsNegatedAdjective);
   nArg:=aArg;
end;

destructor NegatedAdjectiveObj.Done;
begin
   dispose(nArg,Done);
end;

@ \node{Adjective objects.} \Ithink{This is the preferred node for later
intermediate representations for attributes, since \\{nNegated} is a
field in the class.}

@<Adjective (abstract syntax tree)@>=
   AdjectivePtr = ^AdjectiveObj; @/
   AdjectiveObj = object(AdjectiveExpressionObj) @t\1@> @|@/
      nAdjectiveSymbol: integer; @/
      nNegated: boolean; @/
      nArgs: PList; { of TermPtr, visible arguments }
      constructor Init(const aPos:Position;@+ aAdjectiveNr: integer@+;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Adjective AST constructor@>=
constructor AdjectiveObj.Init(const aPos:Position;@+ aAdjectiveNr:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,wsAdjective);
   nAdjectiveSymbol:=aAdjectiveNr;
   nArgs:=aArgs;
end;

destructor AdjectiveObj.Done;
begin
   dispose(nArgs,Done);
end;

@* [S] Terms (abstract syntax tree).
We have an abstract base class for terms, along with the ``sorts''
(syntactic subclasses) allowed. This allows, e.g., formulas, to refer
to terms without knowing the sort of term involved. The UML class
diagram for term:
\medbreak
\figure
\centerline{\graphics{img/classdiagram-0}}
%\centerline{\includegraphics{img/classdiagram-0.pdf}}
% \epsfbox{img/termclassUML.eps} % for non-PDF output
\caption{UML class diagram for abstract syntax tree for terms.}
\endfigure
\medbreak\noindent%
The arrows indicate inheritance, pointing from the subclass to the
parent superclass. The abstract base class \\{TermExpression} is
italicized, but it is so difficult to distinguish we have colored it
yellow.

N{\sc OTE}: the class UML diagram may be missing a few descendents
of \\{TermExpression}, but it contains the important subclasses which
I could fit into it.

\label{uml-class-diagram-for-term-ast}

@<Abstract base class for terms@>=
   TermSort = (wsErrorTerm,
               wsPlaceholderTerm,
               wsNumeralTerm,
               wsSimpleTerm,
               wsPrivateFunctorTerm,
               wsInfixTerm,
               wsCircumfixTerm,
               wsAggregateTerm,
               wsForgetfulFunctorTerm,
               wsInternalForgetfulFunctorTerm,
               wsSelectorTerm,
               wsInternalSelectorTerm,
               wsQualificationTerm,
               wsGlobalChoiceTerm,
               wsSimpleFraenkelTerm,
               wsFraenkelTerm,
               wsItTerm,
               wsExactlyTerm
              );

   TermPtr = ^TermExpressionObj; @/
   TermExpressionObj = object(MObject) @/
      nTermSort: TermSort; @/
      nTermPos: Position; @/
   end

@
The grammar for term expressions in Mizar as stated in \texttt{syntax.txt}:

{\advance\leftskip by2pc\obeylines\tt
Term-Expression = "(" Term-Expression ")" 
\quad\pipe\ [ Arguments ] Functor-Symbol [ Arguments ] 
\quad\pipe\ Left-Functor-Bracket Term-Expression-List Right-Functor-Bracket 
\quad\pipe\ Functor-Identifier "(" [ Term-Expression-List ] ")" 
\quad\pipe\ Structure-Symbol "(\#" Term-Expression-List "\#)" 
\quad\pipe\ "the" Structure-Symbol "of" Term-Expression 
\quad\pipe\ Variable-Identifier 
\quad\pipe\ "\LB" Term-Expression \LB\ Postqualification \RB\ ":" Sentence "\RB"
\quad\pipe\ "the" "set" "of" "all" Term-Expression \LB\ Postqualification \RB
\quad\pipe\ Numeral 
\quad\pipe\ Term-Expression "qua" Type-Expression 
\quad\pipe\ "the" Selector-Symbol "of" Term-Expression 
\quad\pipe\ "the" Selector-Symbol 
\quad\pipe\ "the" Type-Expression 
\quad\pipe\ Private-Definition-Parameter 
\quad\pipe\ "it" .
\par}
\smallbreak\noindent%
But I think it might be clearer if we view it using the equivalent
grammar:


{\advance\leftskip by2pc\obeylines\tt
Term-Expression = "(" Term-Expression ")" 
\quad\pipe\ [ Arguments ] Functor-Symbol [ Arguments ] 
\quad\pipe\ Left-Functor-Bracket Term-Expression-List Right-Functor-Bracket 
\quad\pipe\ Functor-Identifier "(" [ Term-Expression-List ] ")" 
\quad\pipe\ Aggregate-Term
\quad\pipe\ Forgetful-Functor-Term 
\quad\pipe\ Variable-Identifier 
\quad\pipe\ Fraenkel-Term
\quad\pipe\ Numeral 
\quad\pipe\ Qualified-Term 
\quad\pipe\ Selector-Functor 
\quad\pipe\ Internal-Selector-Functor 
\quad\pipe\ Choice-Term 
\quad\pipe\ Private-Definition-Parameter 
\quad\pipe\ "it" .
Aggregate-Term = Structure-Symbol "(\#" Term-Expression-List "\#)" .
Choice-Term = "the" Type-Expression.
Forgetful-Functor-Term = "the" Structure-Symbol "of" Term-Expression.
Fraenkel-Term = "\LB" Term-Expression \LB Postqualification\RB\ ":" Sentence "\RB"
\quad\pipe\ "the" "set" "of" "all" Term-Expression \LB\ Postqualification \RB.
Internal-Selector-Functor = "the" Selector-Symbol.
Selector-Functor = "the" Selector-Symbol "of" Term-Expression.
Qualified-Term = Term-Expression "qua" Type-Expression.
\par}

@ Class structure for this syntax tree.

@<Classes for terms (abstract syntax tree)@>=
   { Terms }
   @<Simple term (abstract syntax tree)@>; 

   @<Placeholder term (abstract syntax tree)@>; 

   @<Numeral term (abstract syntax tree)@>; 

   @<Infix term (abstract syntax tree)@>; 

   @<Terms with arguments (abstract syntax tree)@>; 

   @<Circumfix term (abstract syntax tree)@>; 

   @<Private functor term (abstract syntax tree)@>; 

   @<One-argument term (abstract syntax tree)@>; 

   @<Selector term (abstract syntax tree)@>; 

   @<Internal selector term (abstract syntax tree)@>; 

   @<Aggregate term (abstract syntax tree)@>; 

   @<Forgetful functor (abstract syntax tree)@>; 

   @<Internal forgetful functors (abstract syntax tree)@>; 

   @<Fraenkel terms (abstract syntax tree)@>; 

   @<Exactly term (abstract syntax tree)@>; 

   @<Qualified term (abstract syntax tree)@>; 

   @<Choice term (abstract syntax tree)@>; 

   @<``It'' term (abstract syntax tree)@>; 

   @<Incorrect term (abstract syntax tree)@>; 

@ \node{Simple terms.} Mizar describes variables \emph{as terms} as
a \\{SimpleTerm}.

\label{ast:SimpleTerm}

@<Simple term (abstract syntax tree)@>=
   SimpleTermPtr = ^SimpleTermObj; @/
   SimpleTermObj = object(TermExpressionObj) @t\1@> @/
      nIdent: integer; { identifier number }
      constructor Init(const aPos:Position; @+ aIdentNr:integer); @t\2\2\2@>
   end

@ \node{Constructors.}

@<Implementing term AST@>=
constructor SimpleTermObj.Init(const aPos:Position;@+ aIdentNr:integer);
begin
   nTermPos:=aPos;
   nTermSort:=wsSimpleTerm;
   nIdent:=aIdentNr;
end;

@ \node{Placeholder terms.} These are the parameters ``\texttt{\$1}'',
``\texttt{\$2}'', etc., which appear in a private functor
``\texttt{deffunc Foo(object) = \dots}''.

@<Placeholder term (abstract syntax tree)@>=
   PlaceholderTermPtr = ^PlaceholderTermObj; {placeholder}
   PlaceholderTermObj = object(TermExpressionObj) @t\1@> @/
      nLocusNr: integer; { \$1, ... }
      constructor Init(const aPos:Position;@+ aLocusNr:integer); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor PlaceholderTermObj.Init(const aPos:Position;@+ aLocusNr:integer);
begin
   nTermPos:=aPos;
   nTermSort:=wsPlaceholderTerm;
   nLocusNr:=aLocusNr;
end;

@ \node{Numeral terms.} Mizar can handle 32-bit integers. If we wanted
to extend this to, say, arbitrary precision arithmetic, then we would
want to modify this class (and a few other places).

@<Numeral term (abstract syntax tree)@>=
   NumeralTermPtr = ^NumeralTermObj; @/
   NumeralTermObj = object(TermExpressionObj) @t\1@> @/
      nValue: integer; @/
      constructor Init(const aPos:Position;@+ aValue:integer); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor NumeralTermObj.Init(const aPos:Position;@+ aValue:integer);
begin
   nTermPos:=aPos;
   nTermSort:=wsNumeralTerm;
   nValue:=aValue;
end;

@ \node{Infix terms.} When we have infix binary operators, they are terms
with arguments on both sides of it. For example $x + 2$ will have
``+'' be an infix term with arguments $(x, 2)$.

We \emph{could} permit multiple arguments on the left-hand side (and
on the right-hand side), but they are comma-separated in Mizar. This
could happen in finite group theory, for example,
``\texttt{p -signalizer\_over H,G}'' has two arguments on the right
but only one argument on the left.

@<Infix term (abstract syntax tree)@>=
   InfixTermPtr = ^InfixTermObj; @/
   InfixTermObj = object(TermExpressionObj) @t\1@> @/
      nFunctorSymbol: integer; @/
      nLeftArgs,nRightArgs: PList; @/
      constructor Init(const aPos:Position;@+ aFunctorNr:integer; @+ aLeftArgs,aRightArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor InfixTermObj.Init(const aPos:Position;
@t\hskip11.3333pc@> aFunctorNr:integer;
@t\hskip11.3333pc@> aLeftArgs,aRightArgs:PList);
begin
   nTermPos:=aPos;
   nTermSort:=wsInfixTerm;
   nFunctorSymbol:=aFunctorNr;
   nLeftArgs:=aLeftArgs;
   nRightArgs:=aRightArgs;
end; @#

destructor InfixTermObj.Done;
begin
   dispose(nLeftArgs,Done);
   dispose(nRightArgs,Done);
end;

@ \node{Terms with arguments.} This class seems to be used only
internally to the \texttt{abstract\_syntax.pas} module. Recalling the
UML class diagram (\section\xref{uml-class-diagram-for-term-ast}), we
remember there are three sublcasses to this: private functor terms
(which appear in Mizar when we use ``\texttt{deffunc F(...) = \dots}''),
circumfix (``bracketed'') terms, and aggregate terms (when we
construct an instance of a structure).

@<Terms with arguments (abstract syntax tree)@>=
   TermWithArgumentsPtr = ^TermWithArgumentsObj; @/
   TermWithArgumentsObj = object(TermExpressionObj) @t\1@> @/
      nArgs: PList; @/
      constructor Init(const aPos:Position;@+ aKind:TermSort;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor TermWithArgumentsObj.Init(const aPos:Position;@+ aKind:TermSort;@+ aArgs:PList);
begin
   nTermPos:=aPos;
   nTermSort:=aKind;
   nArgs:=aArgs;
end; @#

destructor TermWithArgumentsObj.Done;
begin
   dispose(nArgs,Done);
end;


@ \node{Circumfix terms.} We can introduce different types of brackets
in Mizar. For example, for groups, we have the commutator of group
elements \texttt{[.x,y.]}. These ``bracketed terms'' are referred to
as circumfix terms.

@^Bracket@>
@^Term, Bracket@>

@<Circumfix term (abstract syntax tree)@>=
   CircumfixTermPtr = ^CircumfixTermObj; @/
   CircumfixTermObj = object(TermWithArgumentsObj) @t\1@> @/
      nLeftBracketSymbol,nRightBracketSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aLeftBracketNr,aRightBracketNr:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor CircumfixTermObj.Init(const aPos:Position;
  @t\hskip13.3333pc@>                  aLeftBracketNr,aRightBracketNr:integer;
  @t\hskip13.3333pc@>                  aArgs:PList);
begin
   inherited Init(aPos,wsCircumfixTerm,aArgs);
   nLeftBracketSymbol:=aLeftBracketNr;
   nRightBracketSymbol:=aRightBracketNr;
end; @#

destructor CircumfixTermObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{Private functor terms.} We introduce private functor terms in
Mizar when we have ``{\tt defpred F(\dots) = \dots}''.

@<Private functor term (abstract syntax tree)@>=
   PrivateFunctorTermPtr = ^PrivateFunctorTermObj; @/
   PrivateFunctorTermObj = object(TermWithArgumentsObj) @t\1@> @/
      nFunctorIdent: integer; @/
      constructor Init(const aPos:Position;@+ aFunctorIdNr:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor PrivateFunctorTermObj.Init(const aPos:Position;@+ aFunctorIdNr:integer;@+
                                       aArgs:PList);
begin
   inherited Init(aPos,wsPrivateFunctorTerm,aArgs);
   nFunctorIdent:=aFunctorIdNr;
end; @#

destructor PrivateFunctorTermObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{One-argument terms.} Recalling the UML class diagram for terms
(\section\xref{uml-class-diagram-for-term-ast}), we remember the class for
\\{OneArgument} terms are either selector terms (``\texttt{the}
$\langle\textit{field\/}\rangle$ \texttt{of} $\langle\textit{aggregate\/}\rangle\,$'') or forgetful functors
(``\texttt{the}
$\langle\textit{structure\/}\rangle$ \texttt{of} $\langle\textit{aggregate\/}\rangle\,$'').

@<One-argument term (abstract syntax tree)@>=
   OneArgumentTermPtr = ^OneArgumentTermObj; @/
   OneArgumentTermObj = object(TermExpressionObj) @t\1@> @/
      nArg: TermPtr; @/
      constructor Init(const aPos:Position;@+ aKind:TermSort;@+ aArg:TermPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor OneArgumentTermObj.Init(const aPos:Position;@+ aKind:TermSort;@+ aArg:TermPtr);
begin
   nTermPos:=aPos;
   nTermSort:=aKind;
   nArg:=aArg;
end; @#

destructor OneArgumentTermObj.Done;
begin
   dispose(nArg,Done);
end;

@ \node{Selector terms.} When we have an aggregate term (i.e., an
instance of a structure), we want to refer to fields of the
structure. This is done with selector terms. \Ithink{The selector
number refers to the position in the underlying tuple of the structure instance.}

@<Selector term (abstract syntax tree)@>=
   SelectorTermPtr = ^SelectorTermObj; @/
   SelectorTermObj = object(OneArgumentTermObj) @t\1@> @/
      nSelectorSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aSelectorNr:integer;@+ aArg:TermPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor SelectorTermObj.Init(const aPos:Position;@+ aSelectorNr:integer;@+ aArg:TermPtr);
begin
   inherited Init(Apos,wsSelectorTerm,aArg);
   nSelectorSymbol:=aSelectorNr;
end; @#

destructor SelectorTermObj.Done;
begin
   dispose(nArg,Done);
end;

@ \node{Internal selector terms.} An ``internal selector'' term refers
to the case where we have in Mizar ``\texttt{the} $\langle\textit{selector\/}\rangle\,$''
treated as a term.

@<Internal selector term (abstract syntax tree)@>=
   InternalSelectorTermPtr = ^InternalSelectorTermObj; @/
   InternalSelectorTermObj = object(TermExpressionObj) @t\1@> @/
      nSelectorSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aSelectorNr:integer); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor InternalSelectorTermObj.Init(const aPos:Position;@+ aSelectorNr:integer);
begin
   nTermPos:=aPos;
   nTermSort:=wsInternalSelectorTerm;
   nSelectorSymbol:=aSelectorNr;
end;

@ \node{Aggregate terms.} When we construct a new instance of a
structure, well, that's a term. Such terms are called ``aggregate
terms'' in Mizar.

@<Aggregate term (abstract syntax tree)@>=
   AggregateTermPtr = ^AggregateTermObj; @/
   AggregateTermObj = object(TermWithArgumentsObj) @t\1@> @/
      nStructSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aStructSymbol:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor AggregateTermObj.Init(const aPos:Position;@+ aStructSymbol:integer;@+
                                  aArgs:PList);
begin
   inherited Init(aPos,wsAggregateTerm,aArgs);
   nStructSymbol:=aStructSymbol;
end; @#

destructor AggregateTermObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{Forgetful functors.} When we have structure inheritance in
Mizar, say structure $B$ extends structure $A$, and we have $b$ being
an instance of $B$, then we can obtain ``the $A$-object underlying $b$''
by writing ``\texttt{the A of b}''. This is an example of what Mizar
calls a ``forgetful functor'' (which is quite the pun).

@<Forgetful functor (abstract syntax tree)@>=
   ForgetfulFunctorTermPtr = ^ForgetfulFunctorTermObj; @/
   ForgetfulFunctorTermObj = object(OneArgumentTermObj) @t\1@> @/
      nStructSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aStructSymbol:integer;@+ aArg:TermPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor ForgetfulFunctorTermObj.Init(const aPos:Position;@+ aStructSymbol:integer;
   @t\hskip15.75pc @>                                      aArg:TermPtr);
begin
   inherited Init(aPos,wsForgetfulFunctorTerm,aArg);
   nStructSymbol:=aStructSymbol;
end; @#

destructor ForgetfulFunctorTermObj.Done;
begin
   dispose(nArg,Done);
end;

@ \node{Internal forgetful functors.} When we omit the ``structure instance''
$b$ in a forgetful functor term --- e.g., when we have ``\texttt{the A}''
--- then we have an ``internal forgetful functor'' (named analogous to
internal selectors).

@<Internal forgetful functors (abstract syntax tree)@>=
   InternalForgetfulFunctorTermPtr = ^InternalForgetfulFunctorTermObj; @/
   InternalForgetfulFunctorTermObj = object(TermExpressionObj) @t\1@> @/
      nStructSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aStructSymbol:integer); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor InternalForgetfulFunctorTermObj.Init(const aPos:Position;@+ aStructSymbol:integer);
begin
   nTermPos:=aPos;
   nTermSort:= wsInternalForgetfulFunctorTerm;
   nStructSymbol:=aStructSymbol;
end;

@ \node{Simple Fraenkel terms.} Fraenkel terms are set-builder
notation in Mizar. But ``simple'' Fraenkel terms occurs when we have
``\texttt{the set of all $\langle\textit{term expr\/}\rangle\,$}''.

@<Fraenkel terms (abstract syntax tree)@>=
   SimpleFraenkelTermPtr = ^SimpleFraenkelTermObj; @/
   SimpleFraenkelTermObj = object(TermExpressionObj) @t\1@> @/
      nPostqualification: PList; { of segments }
      nSample: TermPtr; @/
      constructor Init(const aPos:Position;@+ aPostqual:PList;@+ aSample:TermPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementing term AST@>=
constructor SimpleFraenkelTermObj.Init(const aPos:Position;@+ aPostqual:PList;@+ aSample:TermPtr);
begin
   nTermPos:=aPos;
   nTermSort:=wsSimpleFraenkelTerm;
   nPostqualification:=aPostqual;
   nSample:=aSample;
end; @#

destructor SimpleFraenkelTermObj.Done;
begin
   dispose(nSample,Done);
end;

@ \node{Fraenkel terms.} Fraenkel terms are sets given by set-builder
notation, usually they look like
$$\{f(\vec{t})\hbox{\texttt{\ where\ }} \vec{t}\hbox{\texttt{\ being\ }}\vec{T} \texttt{\ :\ } P[\vec{t}]\}$$
This is technically a higher-order object (look, it takes a functor
$f$ and a predicate $P$).

@^Fraenkel term@>
@^Term, Fraenkel@>

@<Fraenkel terms (abstract syntax tree)@>=
   FraenkelTermPtr = ^FraenkelTermObj; @/
   FraenkelTermObj = object(SimpleFraenkelTermObj) @t\1@> @/
      nFormula: FormulaPtr; @/
      constructor Init(const aPos:Position;@+ aPostqual:PList;@+ aSample:TermPtr;@+ aFormula:FormulaPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor FraenkelTermObj.Init(const aPos:Position;
  @t\hskip12.75pc@>                 aPostqual:PList;
  @t\hskip12.75pc@>                 aSample:TermPtr;
  @t\hskip12.75pc@>                 aFormula:FormulaPtr);
begin
   nTermPos:=aPos;
   nTermSort:=wsFraenkelTerm;
   nPostqualification:=aPostqual;
   nSample:=aSample;
   nFormula:=aFormula;
end; @#

destructor FraenkelTermObj.Done;
begin
   dispose(nSample,Done);
   dispose(nPostqualification,Done);
   dispose(nFormula,Done);
end;

@ \node{Qualified terms.} We may wish to explicitly type cast a term
(e.g., ``\texttt{term qua newType}''),
which is what Mizar calls a ``qualified term''.

@<Qualified term (abstract syntax tree)@>=
   QualifiedTermPtr = ^QualifiedTermObj; @/
   QualifiedTermObj = object(ExactlyTermObj) @t\1@> @/
      nQualification: TypePtr; @/
      constructor Init(const aPos:Position;@+ aSubject:TermPtr;@+ aType:TypePtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor QualifiedTermObj.Init(const aPos:Position;@+ aSubject:TermPtr;@+ aType:TypePtr);
begin
   nTermPos:=aPos;
   nTermSort:=wsQualificationTerm;
   nSubject:=aSubject;
   nQualification:=aType;
end; @#

destructor QualifiedTermObj.Done;
begin
   dispose(nSubject,Done);
   dispose(nQualification,Done);
end;

@ \node{Exactly terms.} This is the base class for qualified terms. It
does not appear to be used anywhere outside the abstract syntax module.

@<Exactly term (abstract syntax tree)@>=
   ExactlyTermPtr = ^ExactlyTermObj; @/
   ExactlyTermObj = object(TermExpressionObj) @t\1@> @/
      nSubject: TermPtr; @/
      constructor Init(const aPos:Position;@+ aSubject:TermPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor ExactlyTermObj.Init(const aPos:Position;@+ aSubject:TermPtr);
begin
   nTermPos:=aPos;
   nTermSort:=wsExactlyTerm;
   nSubject:=aSubject;
end; @#

destructor ExactlyTermObj.Done;
begin
   dispose(nSubject,Done);
end;

@ \node{Choice terms.} This refers to ``\texttt{the} $\langle\textit{type}\rangle$''
terms. It is a ``global choice term'' of sorts, except it ``operates''
on soft types instead of arbitrary predicates.

@^Choice, Axiom of@>
@^Choice operator@>
@:the}{\texttt{the} (Choice operator)@>

@<Choice term (abstract syntax tree)@>=
   ChoiceTermPtr = ^ChoiceTermObj; @/
   ChoiceTermObj = object(TermExpressionObj) @t\1@> @/
      nChoiceType: TypePtr; @/
      constructor Init(const aPos:Position;@+ aType:TypePtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor ChoiceTermObj.Init(const aPos:Position;@+ aType:TypePtr);
begin
   nTermPos:=aPos;
   nTermSort:=wsGlobalChoiceTerm;
   nChoiceType:=aType;
end; @#

destructor ChoiceTermObj.Done;
begin
   dispose(nChoiceType,Done);
end;

@ \node{It terms.} When we define a new mode [type] or functors
[terms], Mizar introduces an anaphoric keyword ``\texttt{it}'' referring to 
an example of the mode (resp., to the term being defined). Here I
borrow the scary phrase ``anaphoric'' from Lisp macros, so blame Paul
Graham for this pretentiousness.

@^Graham, Paul@>
@:it}{\texttt{it}, reserved word@>
@^Anaphora@>

@<``It'' term (abstract syntax tree)@>=
   ItTermPtr = ^ItTermObj; @/
   ItTermObj = object(TermExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor ItTermObj.Init(const aPos:Position);
begin
   nTermPos:=aPos;
   nTermSort:=wsItTerm;
end;

@ \node{Incorrect terms.} Generically, when we run into an error of
some kind, we represent the term with an \\{Incorrect} term
instance. This will allow Mizar to continue working when the user
goofed.

@<Incorrect term (abstract syntax tree)@>=
   IncorrectTermPtr = ^IncorrectTermObj; @/
   IncorrectTermObj = object(TermExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing term AST@>=
constructor IncorrectTermObj.Init(const aPos:Position);
begin
   nTermPos:=aPos;
   nTermSort:=wsErrorTerm;
end;

@* [S] Types (abstract syntax tree).
The grammar for Mizar types looks like:

{\advance\leftskip by2pc\obeylines\tt
Type-Expression = "(" Radix-Type ")" 
\quad\pipe\ Adjective-Cluster Type-Expression 
\quad\pipe\ Radix-Type .

Structure-Type-Expression =
\quad\phantom{\pipe} "(" Structure-Symbol ["over" Term-Expression-List] ")" 
\quad\pipe\ Adjective-Cluster Structure-Symbol [ "over" Term-Expression-List ].

Radix-Type = Mode-Symbol [ "of" Term-Expression-List ] 
\quad\pipe\ Structure-Symbol [ "over" Term-Expression-List ] .

Type-Expression-List = Type-Expression \LB\ "," Type-Expression \RB\ .
\par}
\medbreak\noindent%
So there are several main sources of modes [types]: structures,
primitive types (like ``\texttt{set}'' and ``\texttt{object}''), and
affixing adjectives to types.

For readers who are unfamiliar with types in Mizar, they are ``soft types''.
What does this mean? Well, we refer the reader to
Free Wiedijk's ``Mizar's Soft Type System'' (in K.\ Schneider and J.\
Brandt, eds., \emph{Theorem Proving in Higher Order Logics. TPHOLs 2007},
Springer, \doi{10.1007/978-3-540-74591-4_28}).
Essentially, a type ascription in Mizar of the form ``\texttt{for x
being Foo st P[x] holds Q[x]}'', this is equivalent to \texttt{Foo}
being a unary predicate and the formula in first-order logic is
``$\forall x\ldotp\texttt{Foo}[x]\land Q[x]\implies P[x]$''.

@^Wiedijk, Freek@>
@^Type, Soft@>
@^Soft type@>

@
We have an abstract base class for types.

@<Abstract base class for types@>=
   TypeSort = (wsErrorType,
               wsStandardType,
               wsStructureType,
               wsClusteredType,
               wsReservedDscrType
              );

   { Initial structures }

   TypePtr = ^TypeExpressionObj; @/
   TypeExpressionObj = object(MObject) @/
      nTypeSort: TypeSort; @/
      nTypePos: Position; @/
   end

@ \node{Radix type.} A ``radix type'' refers to any type of the form
``\texttt{$\langle\textit{RadixType\/}\rangle$ of $T_{1}$, \dots, $T_{n}$}''.
This usually appears when defining a new expandable mode, where we
have:

{\narrower
``\texttt{mode $\langle\textit{Expandable\ Mode\/}\rangle$ is 
$\langle\textit{Adjective\/}_{1}\rangle$ \dots
$\langle\textit{Adjective\/}_{n}\rangle$ 
$\langle\textit{Radix\ Type\/}\rangle\,$}''\par}

\noindent%
This appears to be used only in definitions.

@<Classes for type (abstract syntax tree)@>=
   { Types }

   RadixTypePtr = ^RadixTypeObj; @/
   RadixTypeObj = object(TypeExpressionObj) @t\1@> @/
      nArgs: PList; { of }
      constructor Init(const aPos:Position;@+ aKind: TypeSort;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementing type AST@>=
constructor RadixTypeObj.Init(const aPos:Position;@+ aKind:TypeSort;@+ aArgs:PList);
begin
   nTypePos:=aPos;
   nTypeSort:=aKind;
   nArgs:=aArgs;
end;

destructor RadixTypeObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{Standard type.} When we want to refer to an expandable mode in
a Mizar formula, then it is represented by a ``standard type''. This
contrasts it with ``clustered types'' (i.e., a type stacked with
adjectives) and ``structure types''.

@^Type, Standard@>

@<Classes for type (abstract syntax tree)@>=
   StandardTypePtr = ^StandardTypeObj; @/
   StandardTypeObj = object(RadixTypeObj) @t\1@> @/
      nModeSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aModeSymbol:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementing type AST@>=
constructor StandardTypeObj.Init(const aPos:Position;@+ aModeSymbol:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,wsStandardType,aArgs);
   nModeSymbol:=aModeSymbol;
end; @#

destructor StandardTypeObj.Done;
begin
   inherited Done;
end;

@ \node{Structure type.} When we define a new structure, we are really
introducing a new type. \Ithink{The \\{aArgs} tracks its parent
structures and parameter types.} The structure type extends the
RadixType class because RadixType instances can be ``stacked with adjectives''.

@<Classes for type (abstract syntax tree)@>=
   StructTypePtr = ^StructTypeObj; @/
   StructTypeObj = object(RadixTypeObj) @t\1@> @/
      nStructSymbol: integer; @/
      constructor Init(const aPos:Position;@+ aStructSymbol:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementing type AST@>=
constructor StructTypeObj.Init(const aPos:Position;@+ aStructSymbol:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,wsStructureType,aArgs);
   nStructSymbol:=aStructSymbol;
end; @#

destructor StructTypeObj.Done;
begin
   inherited Done;
end;

@ \node{Clustered type.} The clustered type describes the situation
where we accumulate \\{aCluster} of adjectives atop \\{aType}.

@<Classes for type (abstract syntax tree)@>=
   ClusteredTypePtr = ^ClusteredTypeObj; @/
   ClusteredTypeObj = object(TypeExpressionObj) @t\1@> @/
      nAdjectiveCluster: PList; @/
      nType: TypePtr; @/
      constructor Init(const aPos:Position;@+ aCluster:PList;@+ aType:TypePtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementing type AST@>=
constructor ClusteredTypeObj.Init(const aPos:Position;@+ aCluster:PList;@+ aType:TypePtr);
begin
   nTypePos:=aPos;
   nTypeSort:=wsClusteredType;
   nAdjectiveCluster:=aCluster;
   nType:=aType;
end; @#

destructor ClusteredTypeObj.Done;
begin
   dispose(nAdjectiveCluster,Done);
   dispose(nType,Done);
end;

@ \node{Incorrect type.} We want Mizar to be resilient against typing
errors, so we have an \\{IncorrectType} node for the syntax tree. The
alternative would be to crash upon error.

@<Classes for type (abstract syntax tree)@>=
   IncorrectTypePtr = ^IncorrectTypeObj; @/
   IncorrectTypeObj = object(TypeExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing type AST@>=
constructor IncorrectTypeObj.Init(const aPos:Position);
begin
   nTypePos:=aPos;
   nTypeSort:=wsErrorType;
end;

@* [S] Formulas (abstract syntax tree).
We have an abstract base class for formulas.

@<Abstract base class for formulas@>=
   FormulaSort = (wsErrorFormula,
                  wsThesis,
                  wsContradiction,
                  wsRightSideOfPredicativeFormula,
                  wsPredicativeFormula,
                  wsMultiPredicativeFormula,
                  wsPrivatePredicateFormula,
                  wsAttributiveFormula,
                  wsQualifyingFormula,
                  wsUniversalFormula,
                  wsExistentialFormula,
                  wsNegatedFormula,
                  wsConjunctiveFormula,
                  wsDisjunctiveFormula,
                  wsConditionalFormula,
                  wsBiconditionalFormula,
                  wsFlexaryConjunctiveFormula,
                  wsFlexaryDisjunctiveFormula
                 );

   FormulaPtr = ^FormulaExpressionObj; @/
   FormulaExpressionObj = object(MObject) @/
      nFormulaSort: FormulaSort; @/
      nFormulaPos: Position; @/
   end

@
The syntax for Mizar formulas looks like:

%{\advance\leftskip by2pc\obeylines\ninett
{\obeylines\tt
Formula-Expression = "(" Formula-Expression ")" 
\quad\pipe\  Atomic-Formula-Expression 
\quad\pipe\  Quantified-Formula-Expression 
\quad\pipe\  Formula-Expression "\AM" Formula-Expression 
\quad\pipe\  Formula-Expression "\AM" "..." "\AM" Formula-Expression 
\quad\pipe\  Formula-Expression "or" Formula-Expression 
\quad\pipe\  Formula-Expression "or" "..." "or" Formula-Expression 
\quad\pipe\  Formula-Expression "implies" Formula-Expression 
\quad\pipe\  Formula-Expression "iff" Formula-Expression 
\quad\pipe\  "not" Formula-Expression 
\quad\pipe\  "contradiction" 
\quad\pipe\  "thesis" .

Atomic-Formula-Expression =
{\advance\leftskip1.5pc
[Term-Expression-List] [("does" \pipe\ "do") "not"] Predicate-Symbol \rlap{[Term-Expression-List] }
\LB[("does" \pipe\  "do") "not"] Predicate-Symbol Term-Expression-List\RB\par}
\quad\pipe\  Predicate-Identifier "[" [ Term-Expression-List ] "]" 
\quad\pipe\  Term-Expression "is" Adjective \LB\ Adjective \RB 
\quad\pipe\  Term-Expression "is" Type-Expression .

Quantified-Formula-Expression =
\quad\qquad"for" Qualified-Variables
\quad\qquad[ "st" Formula-Expression ]
\quad\qquad( "holds" Formula-Expression \pipe\  Quantified-Formula-Expression ) 
\quad\pipe\  "ex" Qualified-Variables "st" Formula-Expression .
\par}

@ \node{Right-side of predicative formula.}

@<Classes for formula (abstract syntax tree)@>=
   { Formulas }

   RightSideOfPredicativeFormulaPtr = ^RightSideOfPredicativeFormulaObj; @/
   RightSideOfPredicativeFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nPredNr: integer; @/
      nRightArgs: PList; @/
      constructor Init(const aPos:Position;@+ aPredNr:integer;@+ aRightArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor RightSideOfPredicativeFormulaObj.Init(const aPos:Position;
@t\hskip19pc@> aPredNr:integer;
@t\hskip19pc@> aRightArgs:PList);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsRightSideOfPredicativeFormula;
   nPredNr:=aPredNr;
   nRightArgs:=aRightArgs;
end; @#

destructor RightSideOfPredicativeFormulaObj.Done;
begin
   dispose(nRightArgs,Done);
end;

@ \node{Predicative formula.}
A ``predicative'' formula refers to a formula involving predicates. A
predicate will have a list of terms $\vec{t}$ it expects as arguments, as well
as two numbers $\ell$, $r$ such that $t_{1},\dots,t_{\ell}$ are the
arguments to its left, and $t_{\ell+1}$, \dots, $t_{\ell+r}$ are on
the right. When $\ell=0$, all arguments are on the right; and when
$r=0$, all arguments are on the left.

@<Classes for formula (abstract syntax tree)@>=
   PredicativeFormulaPtr = ^PredicativeFormulaObj; @/
   PredicativeFormulaObj = object(RightSideOfPredicativeFormulaObj) @t\1@> @/
      nLeftArgs: PList; @/
      constructor Init(const aPos:Position;@+ aPredNr:integer;@+ aLeftArgs,aRightArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor PredicativeFormulaObj.Init(const aPos:Position;
@t\hskip14.6667pc@> aPredNr:integer;
@t\hskip14.6667pc@> aLeftArgs,aRightArgs:PList);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsPredicativeFormula;
   nPredNr:=aPredNr;
   nLeftArgs:=aLeftArgs;
   nRightArgs:=aRightArgs;
end; @#

destructor PredicativeFormulaObj.Done;
begin
   dispose(nLeftArgs,Done);
   dispose(nRightArgs,Done);
end;

@ \node{Multi-predicative formula.}
The Working Mathematician writes things like ``$1\leq i\leq\magnitude{T}$''
and Mizar wants to support this. Multi-predicative formulas are of
this form ``\texttt{1 <= i <= len T}''. This occurs
in \texttt{VECTSP13}, for example.

@<Classes for formula (abstract syntax tree)@>=
   MultiPredicativeFormulaPtr = ^MultiPredicativeFormulaObj; @/
   MultiPredicativeFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nScraps: PList; @/
      constructor Init(const aPos:Position;@+ aScraps:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor MultiPredicativeFormulaObj.Init(const aPos:Position;@+ aScraps:PList);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsMultiPredicativeFormula;
   nScraps:=aScraps;
end; @#

destructor MultiPredicativeFormulaObj.Done;
begin
   dispose(nScraps,Done);
end;


@ \node{Attributive formula.} As part of Mizar's soft type system,
we can use attributes (adjectives) to form a formula like
``\texttt{$\langle\textit{term\/}\rangle$ is $\langle\textit{adjective\/}\rangle$}''.
We can stack multiple adjectives in an attributive formula.

@<Classes for formula (abstract syntax tree)@>=
   AttributiveFormulaPtr = ^AttributiveFormulaObj; @/
   AttributiveFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nSubject: TermPtr; @/
      nAdjectives: PList; @/
      constructor Init(const aPos:Position;@+ aSubject:TermPtr;@+ aAdjectives:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor AttributiveFormulaObj.Init
   (const aPos:Position;@+ aSubject:TermPtr; @+ aAdjectives:PList);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsAttributiveFormula;
   nSubject:=aSubject;
   nAdjectives:=aAdjectives;
end; @#

destructor AttributiveFormulaObj.Done;
begin
   dispose(nSubject,Done);
   dispose(nAdjectives,Done);
end;

@ \node{Private predicative formula.}
When we have ``\texttt{defpred P[\dots] means \dots}'' in Mizar, we
refer to ``\texttt{P}'' as a private predicate. It is represented in
the abstract syntax tree as a private predicative formula object.

@<Classes for formula (abstract syntax tree)@>=
   PrivatePredicativeFormulaPtr = ^PrivatePredicativeFormulaObj; @/
   PrivatePredicativeFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nPredIdNr: integer; @/
      nArgs: PList; @/
      constructor Init(const aPos:Position;@+ aPredIdNr:integer;@+ aArgs:PList); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor PrivatePredicativeFormulaObj.Init(const aPos:Position;
@t\hskip17.3333pc@> aPredIdNr:integer;
       @t\hskip17.3333pc@>                                       aArgs:PList);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsPrivatePredicateFormula;
   nPredIdNr:=aPredIdNr;
   nArgs:=aArgs;
end; @#

destructor PrivatePredicativeFormulaObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{Qualifying formula.}
Using Mizar's soft type system, we may have formulas of the form
``\texttt{$\langle\textit{term\/}\rangle$ is $\langle\textit{type\/}\rangle$}''.
These are referred to as ``qualifying formulas'', at least when
discussing the abstract syntax tree.

@<Classes for formula (abstract syntax tree)@>=
   QualifyingFormulaPtr = ^QualifyingFormulaObj; @/
   QualifyingFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nSubject: TermPtr; @/
      nType: TypePtr; @/
      constructor Init(const aPos:Position;@+ aSubject:TermPtr;@+ aType:TypePtr);y @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor QualifyingFormulaObj.Init(const aPos:Position;@+ aSubject:TermPtr;@+ aType:TypePtr);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsQualifyingFormula;
   nSubject:=aSubject;
   nType:=aType;
end; @#

destructor QualifyingFormulaObj.Done;
begin
   dispose(nSubject,Done);
   dispose(nType,Done);
end;

@ \node{Negative formula.} Now we can proceed with the familiar
formulas in first-order logic. Negative formulas are of the form
$\neg\varphi$ for some formula $\varphi$.

@<Classes for formula (abstract syntax tree)@>=
   NegativeFormulaPtr = ^NegativeFormulaObj; @/
   NegativeFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nArg: FormulaPtr; @/
      constructor Init(const aPos:Position;@+ aArg:FormulaPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor NegativeFormulaObj.Init(const aPos:Position;@+ aArg:FormulaPtr);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsNegatedFormula;
   nArg:=aArg;
end; @#

destructor NegativeFormulaObj.Done;
begin
   dispose(nArg,Done);
end;

@ \node{Binary arguments formula.} We have a class describing formulas
involving binary logical connectives. We will extend it to describe
conjunctive formulas, disjunctive formulas, conditionals,
biconditionals, etc.

@<Classes for formula (abstract syntax tree)@>=
   BinaryFormulaPtr = ^BinaryArgumentsFormula; @/
   BinaryArgumentsFormula = object(FormulaExpressionObj) @t\1@> @/
      nLeftArg,nRightArg: FormulaPtr;
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor BinaryArgumentsFormula.Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr);
begin
   nFormulaPos:=aPos;
   nLeftArg:=aLeftArg;
   nRightArg:=aRightArg;
end; @#

destructor BinaryArgumentsFormula.Done;
begin
   dispose(nLeftArg,Done);
   dispose(nRightArg,Done);
end;

@ \node{Conjunctive formula.} A conjunctive formula looks like
$\varphi\land\psi$ where $\varphi$ and $\psi$ are logical formulas.

@<Classes for formula (abstract syntax tree)@>=
   ConjunctiveFormulaPtr = ^ConjunctiveFormulaObj; @/
   ConjunctiveFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor ConjunctiveFormulaObj.Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsConjunctiveFormula;
end;

@ \node{Disjunctive formula.} Disjunctive formulas look like $\varphi\lor\psi$
where $\varphi$ and $\psi$ are formulas.

@<Classes for formula (abstract syntax tree)@>=
   DisjunctiveFormulaPtr = ^DisjunctiveFormulaObj; @/
   DisjunctiveFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor DisjunctiveFormulaObj.Init(const aPos:Position; aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsDisjunctiveFormula;
end;

@ \node{Conditional formula.} Conditional formulas look like
$\varphi\implies\psi$ where $\varphi$ and $\psi$ are formulas.

@<Classes for formula (abstract syntax tree)@>=
   ConditionalFormulaPtr = ^ConditionalFormulaObj; @/
   ConditionalFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor ConditionalFormulaObj.Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsConditionalFormula;
end;

@ \node{Biconditional formula.} Biconditional formulas look like
$\varphi\iff\psi$ where $\varphi$ and $\psi$ are formulas.

@<Classes for formula (abstract syntax tree)@>=
   BiconditionalFormulaPtr = ^BiconditionalFormulaObj; @/
   BiconditionalFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor BiconditionalFormulaObj.Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsBiconditionalFormula;
end;

@ \node{Flexary Conjunctive formula.} Flexary conjunctive formulas are
unique to Mizar, though the Working Mathematician would recognize them
as ``just a bunch of conjunctions''. These look like
$\varphi[1]\land\cdots\land\varphi[n]$ where $\varphi[i]$ is a formula
parametrized by a natural number $i$.

@<Classes for formula (abstract syntax tree)@>=
   FlexaryConjunctiveFormulaPtr = ^FlexaryConjunctiveFormulaObj; @/
   FlexaryConjunctiveFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor FlexaryConjunctiveFormulaObj.Init(const aPos:Position;
 @t\hskip17.6667pc@> aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsFlexaryConjunctiveFormula;
end;

@ \node{Flexary Disjunctive formula.} Flexary disjunctive formulas are
unique to Mizar, though the Working Mathematician would recognize them
as ``just a bunch of disjunctions''. These look like
$\varphi[1]\lor\cdots\lor\varphi[n]$ where $\varphi[i]$ is a formula
parametrized by a natural number $i$.

@<Classes for formula (abstract syntax tree)@>=
   FlexaryDisjunctiveFormulaPtr = ^FlexaryDisjunctiveFormulaObj; @/
   FlexaryDisjunctiveFormulaObj = object(BinaryArgumentsFormula) @t\1@> @/
      constructor Init(const aPos:Position;@+ aLeftArg,aRightArg:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor FlexaryDisjunctiveFormulaObj.Init(const aPos:Position;
@t\hskip17.6667pc@> aLeftArg,aRightArg:FormulaPtr);
begin
   inherited Init(aPos,aLeftArg,aRightArg);
   nFormulaSort:=wsFlexaryDisjunctiveFormula;
end;

@ \node{Quantified formula.}
First-order logic is distinguished by the use of terms and quantifying
formulas over terms. We have a base class for quantified
formulas. Using the Mizar soft type system, quantified variables are
``qualified segments''.

@<Classes for formula (abstract syntax tree)@>=
   QuantifiedFormulaPtr = ^QuantifiedFormulaObj; @/
   QuantifiedFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      nSegment: QualifiedSegmentPtr; @/
      nScope: FormulaPtr; @/
      constructor Init(const aPos:Position;@+ aSegment:QualifiedSegmentPtr;@+ aScope:FormulaPtr); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor QuantifiedFormulaObj.Init(const aPos:Position;
@t\hskip14.5pc@>  aSegment:QualifiedSegmentPtr;
 @t\hskip14.5pc@>                                     aScope:FormulaPtr);
begin
   nFormulaPos:=aPos;
   nSegment:=aSegment;
   nScope:=aScope;
end; @#

destructor QuantifiedFormulaObj.Done;
begin
   dispose(nSegment,Done);
   dispose(nScope,Done);
end;

@ \node{Universal formula.}
When we want to describe a formula of the form ``$\forall x:T\ldotp\varphi[x]$''
where $T$ is a soft type and $\varphi[x]$ is a formula parametrized by $x$.

@<Classes for formula (abstract syntax tree)@>=
   UniversalFormulaPtr = ^UniversalFormulaObj; @/
   UniversalFormulaObj = object(QuantifiedFormulaObj) @t\1@> @/
      constructor Init(const aPos:Position;@+ aSegment:QualifiedSegmentPtr;@+ aScope:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor UniversalFormulaObj.Init(const aPos:Position;
@t\hskip14.25pc@> aSegment:QualifiedSegmentPtr;
   @t\hskip14.25pc@>                                  aScope:FormulaPtr);
begin
   inherited Init(aPos,aSegment,aScope);
   nFormulaSort:=wsUniversalFormula;
end;

@ \node{Existential formula.}
The other quantified formula are existentially quantified formulas,
which resemble ``$\exists x:T\ldotp\varphi[x]$'' where $T$ is a soft
type and $\varphi[x]$ is a formula parametrized by $x$.

@<Classes for formula (abstract syntax tree)@>=
   ExistentialFormulaPtr = ^ExistentialFormulaObj; @/
   ExistentialFormulaObj = object(QuantifiedFormulaObj) @t\1@> @/
      constructor Init(const aPos:Position;@+ aSegment:QualifiedSegmentPtr;@+ aScope:FormulaPtr); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor ExistentialFormulaObj.Init(const aPos:Position;
@t\hskip14.6667pc@> aSegment:QualifiedSegmentPtr;
@t\hskip14.6667pc@>                                      aScope:FormulaPtr);
begin
   inherited Init(aPos,aSegment,aScope);
   nFormulaSort:=wsExistentialFormula;
end;

@ \node{Contradiction formula.}
The canonical contradiction $\bot$ in Mizar is represented by the
reserved keyword ``\texttt{contradiction}''.

@^Contradiction@>

@<Classes for formula (abstract syntax tree)@>=
   ContradictionFormulaPtr = ^ContradictionFormulaObj; @/
   ContradictionFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor ContradictionFormulaObj.Init(const aPos:Position);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsContradiction;
end;

@ \node{Thesis formula.}
When we are in the middle of a proof, the goal or obligation left to
be proven is called the ``\texttt{thesis}''.

@:Thesis}{\texttt{thesis}@>

@<Classes for formula (abstract syntax tree)@>=
   ThesisFormulaPtr = ^ThesisFormulaObj; @/
   ThesisFormulaObj = object(FormulaExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor ThesisFormulaObj.Init(const aPos:Position);
begin
   nFormulaPos:=aPos;
   nFormulaSort:=wsThesis;
end;

@ \node{Incorrect formula.}
We also have a node in abstract syntax trees for ``incorrect''
formulas.

@<Classes for formula (abstract syntax tree)@>=
   IncorrectFormulaPtr = ^IncorrectFormula; @/
   IncorrectFormula = object(FormulaExpressionObj) @t\1@> @/
      constructor Init(const aPos:Position); @t\2\2\2@>
   end

@ \node{Constructor.}

@<Implementing formula AST@>=
constructor IncorrectFormula.Init(const aPos:Position);
begin
   nFormulaPos:=aPos;
   nformulaSort:=wsErrorFormula;
end;


@* [S] Within expressions (deferred).
The ``first identification'' process needs to track ``within
expressions''. You should probably come back to this section when
you've arrived at the ``first identification'' unit.

@<Class for Within expression@>=
   biStackedPtr = ^biStackedObj; @/
   biStackedObj =
      object(MObject)
      end; @#
      
   WithinExprPtr =  ^WithinExprObj; @/
   WithinExprObj =
      object(MObject) @t\1@> @/
         nExpKind: ExpKind; @/
         nStackArr: array of  biStackedPtr; @/
         nStackCnt: integer; @#

         constructor Init(aExpKind:ExpKind); @t\2@>
         destructor Done; virtual; @t\2@>
         function CreateExpressionsVariableLevel: biStackedPtr; virtual@t\2@>; {??} 

         procedure Process_Adjective(aAttr:AdjectiveExpressionPtr ); virtual; @t\2@>
         procedure Process_AdjectiveList(aCluster: PList ); virtual; @t\2@>
         procedure Process_Variable(var aVar: VariablePtr); virtual; @t\2@>
         procedure Process_ImplicitlyQualifiedVariable(var aSegm: ImplicitlyQualifiedSegmentPtr); virtual; @t\2@>
         procedure Process_VariablesSegment(aSegm: QualifiedSegmentPtr); virtual; @t\2@>
         procedure Process_StartVariableSegment; virtual; @t\2@>
         procedure Process_FinishVariableSegment; virtual; @t\2@>

         procedure Process_Type (aTyp: TypePtr ); virtual; @t\2@>
         procedure Process_BinaryFormula (aFrm:BinaryFormulaPtr ); virtual; @t\2@>
         procedure Process_StartQuantifiedFormula(aFrm:QuantifiedFormulaPtr); virtual; @t\2@>
         procedure Process_QuantifiedFormula(aFrm:QuantifiedFormulaPtr); virtual; @t\2@>
         procedure Process_FinishQuantifiedFormula(aFrm:QuantifiedFormulaPtr); virtual; @t\2@>
         procedure Process_Formula (aFrm:FormulaPtr ); virtual; @t\2@>
         procedure Process_TermList (aTrmList:PList ); virtual; @t\2@>
         procedure Process_SimpleTerm (var aTrm: SimpleTermPtr ); virtual; @t\2@>
         procedure Process_StartFraenkelTerm(aTrm:SimpleFraenkelTermPtr); virtual; @t\2@>
         procedure Process_FinishFraenkelTerm(var aTrm:SimpleFraenkelTermPtr); virtual; @t\2@>
         procedure Process_FraenkelTermsScope (var aFrm:FormulaPtr ); virtual; @t\2@>
         procedure Process_SimpleFraenkelTerm(var aTrm:SimpleFraenkelTermPtr); virtual; @t\2@>
         procedure Process_Term (var aTrm: TermPtr ); virtual; @t\2\2\2@>
      end;

@ @<Within expression AST implementation@>=
constructor WithinExprObj.Init(aExpKind:ExpKind);
begin
   setlength(nStackArr,50);
   nStackCnt:=0;
   nExpKind:=aExpKind;
end;

@ @<Within expression AST implementation@>=
destructor WithinExprObj.Done;
begin
   inherited Done;
end;

@ @<Within expression AST implementation@>=
function WithinExprObj.CreateExpressionsVariableLevel: biStackedPtr;
begin
   result:=new(biStackedPtr, Init);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_Adjective(aAttr:AdjectiveExpressionPtr);
begin
   case aAttr^.nAdjectiveSort of
      wsAdjective:
         begin
            Process_TermList(AdjectivePtr(aAttr)^.nArgs );
            {nAdjectiveSymbol;}
         end;
      wsNegatedAdjective:
         Process_Adjective(NegatedAdjectivePtr(aAttr)^.nArg );
   endcases;
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_AdjectiveList(aCluster: PList);
var i: integer;
begin
   with aCluster^ do
      for i:=0 to Count-1 do
         Process_Adjective(Items^[i]);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_Variable(var aVar: VariablePtr);
begin
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_ImplicitlyQualifiedVariable(var aSegm: ImplicitlyQualifiedSegmentPtr);
begin
   Process_Variable(aSegm^.nIdentifier);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_VariablesSegment(aSegm: QualifiedSegmentPtr);
var i: integer;
begin
   Process_StartVariableSegment;
   case aSegm^.nSegmentSort of
      ikImplQualifiedSegm:
         Process_ImplicitlyQualifiedVariable(ImplicitlyQualifiedSegmentPtr(aSegm));
      ikExplQualifiedSegm:
         with ExplicitlyQualifiedSegmentPtr(aSegm)^ do
      begin
         for i:=0 to nIdentifiers.Count-1 do
            Process_Variable(VariablePtr(nIdentifiers.Items^[i]));
         Process_Type(nType);
      end;
   endcases;
   Process_FinishVariableSegment;
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_StartVariableSegment;
begin
end; @#

procedure WithinExprObj.Process_FinishVariableSegment;
begin
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_TermList (aTrmList:PList );
var i: integer;
begin
   for i:=0 to aTrmList^.Count-1 do
      Process_Term(TermPtr(aTrmList^.Items^[i]));
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_Type (aTyp: TypePtr);
begin
   with aTyp^ do
   begin
      case aTyp^.nTypeSort of
         wsStandardType:
            with StandardTypePtr(aTyp)^ do
         begin
            {nModeSymbol}
            Process_TermList(nArgs);
         end;
         wsStructureType:
            with StructTypePtr(aTyp)^ do
         begin
            {nStructSymbol}
            Process_TermList(nArgs);
         end;
         wsClusteredType:
            with ClusteredTypePtr(aTyp)^ do
         begin
            Process_AdjectiveList(nAdjectiveCluster);
            Process_Type(nType);
         end;
         wsErrorType: ;
      endcases;
   end;
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_BinaryFormula (aFrm:BinaryFormulaPtr );
begin
   Process_Formula(aFrm^.nLeftArg);
   Process_Formula(aFrm^.nRightArg);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_StartQuantifiedFormula(aFrm:QuantifiedFormulaPtr);
begin
end; @#

procedure WithinExprObj.Process_FinishQuantifiedFormula(aFrm:QuantifiedFormulaPtr);
begin
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_QuantifiedFormula (aFrm: QuantifiedFormulaPtr );
begin
   Process_VariablesSegment(aFrm^.nSegment);
   Process_Formula(aFrm^.nScope);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_Formula (aFrm: FormulaPtr );
var i: integer;
begin
   case aFrm^.nFormulaSort of
      wsNegatedFormula:
         Process_Formula(NegativeFormulaPtr(aFrm)^.nArg);
      wsConjunctiveFormula,wsDisjunctiveFormula,
      wsConditionalFormula,wsBiconditionalFormula,
      wsFlexaryConjunctiveFormula,wsFlexaryDisjunctiveFormula:
         Process_BinaryFormula(BinaryFormulaPtr(aFrm));
      wsRightSideOfPredicativeFormula:
         with RightSideOfPredicativeFormulaPtr(aFrm)^ do
      begin
         {nPredNr}
         Process_TermList(nRightArgs);
      end;
      wsPredicativeFormula:
         with PredicativeFormulaPtr(aFrm)^ do
      begin
         Process_TermList(nLeftArgs);
         {nPredNr}
         Process_TermList(nRightArgs);
      end;
      wsMultiPredicativeFormula:
         with MultiPredicativeFormulaPtr(aFrm)^ do
      begin
         for i := 0 to nScraps.Count - 1 do
            Process_Formula(nScraps.Items^[i]);
      end;
      wsPrivatePredicateFormula:
         with PrivatePredicativeFormulaPtr(aFrm)^ do
      begin
         {nPredIdNr}
         Process_TermList(nArgs);
      end;
      wsAttributiveFormula:
         with AttributiveFormulaPtr(aFrm)^ do
      begin
         Process_Term(nSubject);
         Process_AdjectiveList(nAdjectives);
      end;
      wsQualifyingFormula:
         with QualifyingFormulaPtr(aFrm)^ do
      begin
         Process_Term(nSubject);
         Process_Type(nType);
      end;
      wsExistentialFormula, wsUniversalFormula:
         with QuantifiedFormulaPtr(aFrm)^ do
      begin
         inc(nStackCnt);
         if nStackCnt > length(nStackArr) then
            setlength(nStackArr,2*length(nStackArr));
         nStackArr[nStackCnt]:=CreateExpressionsVariableLevel;
         Process_StartQuantifiedFormula(QuantifiedFormulaPtr(aFrm));
         Process_QuantifiedFormula(QuantifiedFormulaPtr(aFrm));
         Process_FinishQuantifiedFormula(QuantifiedFormulaPtr(aFrm));
         dispose(nStackArr[nStackCnt],Done);
         dec(nStackCnt);
      end;
      wsContradiction: ;
      wsThesis: ;
      wsErrorFormula: ;
   endcases;
end;

@ There are a few empty ``abstract virtual'' methods.

@<Within expression AST implementation@>=
procedure WithinExprObj.Process_SimpleTerm (var aTrm: SimpleTermPtr );
begin
end; @#

procedure WithinExprObj.Process_StartFraenkelTerm(aTrm:SimpleFraenkelTermPtr);
begin
end; @#

procedure WithinExprObj.Process_FinishFraenkelTerm(var aTrm:SimpleFraenkelTermPtr);
begin
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_FraenkelTermsScope(var aFrm:FormulaPtr );
begin
   Process_Formula(aFrm);
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_SimpleFraenkelTerm(var aTrm:SimpleFraenkelTermPtr);
var i: integer;
begin
   with aTrm^ do
   begin
      for i := 0 to nPostqualification^.Count - 1 do
         Process_VariablesSegment(QualifiedSegmentPtr(nPostqualification^.Items^[i]));
      Process_Term(nSample);
   end;
end;

@ @<Within expression AST implementation@>=
procedure WithinExprObj.Process_Term(var aTrm: TermPtr);
begin
   case aTrm^.nTermSort of
      wsPlaceholderTerm: ;
      {|PlaceholderTermPtr(aTrm)^.nLocusNr|}
      wsSimpleTerm:
         Process_SimpleTerm (SimpleTermPtr(aTrm));
      wsNumeralTerm: ;
      {|NumeralTermPtr(aTrm)^.nValue|}
      wsInfixTerm:
         with InfixTermPtr(aTrm)^ do
      begin
         Process_TermList(nLeftArgs);
         {nFunctorSymbol}
         Process_TermList(nRightArgs);
      end;
      wsCircumfixTerm:
         with CircumfixTermPtr(aTrm)^ do
      begin
         {nLeftBracketSymbol}
         Process_TermList(nArgs);
         {nRightBracketSymbol}
      end;
      wsPrivateFunctorTerm:
         with PrivateFunctorTermPtr(aTrm)^ do
      begin
         {nFunctorIdent}
         Process_TermList(nArgs);
      end;
      wsAggregateTerm:
         with AggregateTermPtr(aTrm)^ do
      begin
         { nStructSymbol}
         Process_TermList(nArgs);
      end;
      wsSelectorTerm:
         with SelectorTermPtr(aTrm)^ do
      begin
         {nSelectorSymbol}
         Process_Term(nArg);
      end;
      wsInternalSelectorTerm: ;
      {|InternalSelectorTermPtr(aTrm)^.nSelectorSymbol|}
      wsForgetfulFunctorTerm:
         with ForgetfulFunctorTermPtr(aTrm)^ do
      begin
         {nStructSymbol}
         Process_Term(nArg);
      end;
      wsInternalForgetfulFunctorTerm: ;
      {|InternalForgetfulFunctorTermPtr(aTrm)^.nStructSymbol|}
      wsSimpleFraenkelTerm,wsFraenkelTerm:
         with FraenkelTermPtr(aTrm)^ do
      begin
         inc(nStackCnt);
         if nStackCnt > length(nStackArr) then
            setlength(nStackArr,2*length(nStackArr));
         nStackArr[nStackCnt]:=CreateExpressionsVariableLevel;
         Process_StartFraenkelTerm(SimpleFraenkelTermPtr(aTrm));
         Process_SimpleFraenkelTerm(SimpleFraenkelTermPtr(aTrm));
         if aTrm^.nTermSort = wsFraenkelTerm then
            Process_FraenkelTermsScope(FraenkelTermPtr(aTrm)^.nFormula);
         Process_FinishFraenkelTerm(SimpleFraenkelTermPtr(aTrm));
         dispose(nStackArr[nStackCnt],Done);
         dec(nStackCnt);
      end;
      wsQualificationTerm:
         with QualifiedTermPtr(aTrm)^ do
      begin
         Process_Term(nSubject);
         Process_Type(nQualification);
      end;
      wsExactlyTerm:
         Process_Term(ExactlyTermPtr(aTrm)^.nSubject);
      wsGlobalChoiceTerm:
         Process_Type(ChoiceTermPtr(aTrm)^.nChoiceType);
      wsItTerm: ;
      wsErrorTerm: ;
   endcases;
end;



@* [F] Weakly strict Mizar article.
The parser ``eats in'' a mizar article, then produces
a \texttt{.wsx} (weakly strict Mizar) \XML/ file containing the
abstract syntax tree, and also a \texttt{.frt} article containing the
formats for the article.

This strategy should be familiar to anyone who has looked into
compilers and interpreters: transform the abstract syntax tree into an
intermediate representation, then transform the intermediate
representations in various passes.

This module will transform the parse tree to an abstract syntax tree
in \XML/ format.

@^\texttt{.wsx} file@>
@:wsx file}{\texttt{.wsx} file@>
@:File, wsx}{File, \texttt{.wsx}@>
@^Weakly strict Mizar@>
@^\texttt{.frt} file@>
@:frt file}{\texttt{.frt} file@>
@:File, frt}{File, \texttt{.frt}@>

@<wsmarticle.pas@>=

@<GNU License@>@;
unit wsmarticle;

interface @|@#

uses mobjects, errhan, mscanner, syntax, abstract_syntax, xml_dict,
xml_inout; @#

@<Publicly declared types in \texttt{wsmarticle.pas}@> @;

const @|@/
@<Publicly declared constants in \texttt{wsmarticle.pas}@> @;

@<Publicly declared functions in \texttt{wsmarticle.pas}@> @; @t\2@>

@<Global variables publicly declared in \texttt{wsmarticle.pas}@> @t\1@>@; @#

implementation @|@#

uses mizenv, mconsole, librenv, scanner, xml_parser
mdebug ,info @+ end_mdebug;

@<Implementation for \texttt{wsmarticle.pas}@>@t\2@>@; @#

end.

@ \node{Exercise.} We will create a class hierarchy for the abstract
syntax trees for Mizar. A lot of this is boiler-plate. The reader is
invited to write a couple of programs which will:
\enumerate
\item read in an EBNF-like grammar and emit the class hierarchy for
its abstract syntax tree.
\item read in an EBNF-like grammar, and emit the class hierarchy for
generating the \XML/ for it.
\endenumerate

\medbreak\noindent%
After all, if you look at the sheer number of sections in this file,
it's staggeringly huge. But a lot of it is boiler-plate.

@^Exercises@>

@ @<Publicly declared types in \texttt{wsmarticle.pas}@>=

@ @<Publicly declared functions in \texttt{wsmarticle.pas}@>=

@ @<Implementation for \texttt{wsmarticle.pas}@>=

@* [S] Weakly strict text proper.
Mizar provides a grammar for its syntax in the file
\centerline{\texttt{/usr/local/doc/mizar/syntax.txt}}
It uses a variant of EBNF:
\item{$\bullet$} Terminal symbols are written \texttt{"in quotes"}
\item{$\bullet$} Production rules are separated by vertical lines ``$\pipe$''
\item{$\bullet$} Optional symbols are placed in \texttt{[brackets]}
\item{$\bullet$} Repeated items zero or more times are placed
in \texttt{\LB braces\RB}.
\item{$\bullet$} Rules end in a period ``.''

\noindent%
We will freely quote from \texttt{syntax.txt}, rearranging the rules
as needed to discuss the relevant parts of Mizar's grammar. We will
write the \texttt{syntax.txt} passages in typewriter font.

We should recall the syntax for text items:
\medbreak
{\advance\leftskip by3pc\obeylines\tt
Text-Proper = Section \LB\ Section \RB\ .\smallbreak

Section = "begin" \LB\ Text-Item \RB\ .\smallbreak

Text-Item = Reservation
\quad\pipe\ Definitional-Item 
\quad\pipe\ Registration-Item 
\quad\pipe\ Notation-Item 
\quad\pipe\ Theorem 
\quad\pipe\ Scheme-Item 
\quad\pipe\ Auxiliary-Item .\smallbreak

Definitional-Item = Definitional-Block ";" .\smallbreak

Registration-Item = Registration-Block ";" .\smallbreak

Theorem = "theorem" Compact-Statement .\smallbreak

Compact-Statement = Proposition Justification ";" .\smallbreak

Justification = Simple-Justification \pipe\ Proof .\smallbreak

Auxiliary-Item = Statement \pipe\ Private-Definition .
\par}
\medbreak\noindent%
These are the different syntactic classes for ``top-level statements''
in the text (not the environment header) of a Mizar article. The
interested reader can investigate the \texttt{syntax.txt} file more
fully to get all the block statements in Mizar. We have already made
these different kinds of blocks syntactic values of \\{BlockKind}
earlier (\section\xref{type:BlockKind}). Now we want to be able to
translate them into English. We will just skip
ahead and make these different syntactic classes into values of an
enumerated type.

@^EBNF@>
@^Grammar, for Mizar@>
@:Syntax.txt}{\texttt{syntax.txt}@>

@<Publicly declared constants in \texttt{wsmarticle.pas}@>=
   BlockName: array[BlockKind] of string = @|@/
      ('Text-Proper', {blMain}
       'Now-Reasoning', {blDiffuse}
       'Hereby-Reasoning', {blHereby}
       'Proof', {blProof}
       'Definitional-Block', {blDefinition}
       'Notation-Block', {blNotation}
       'Registration-Block', {blRegistration}
       'Case', {blCase}
       'Suppose', {blSuppose}
       'Scheme-Block' {blPublicScheme} 
      );

@ \node{Class hierarchy for blocks.}
We can now translate the grammar for blocks into a class hierarchy.
The ``text proper'' extends an abstract ``block'' statement. We will
provide factory methods ``\\{wsTextProper.NewBlock}'' and ``\\{NewItem}'' for
adding a new block (and item) contained within the caller ``block''.
We will be tracking the ``kind'' of block (\section\xref{type:BlockKind}),
and the text proper will need to track which article it belongs to.

All the various kinds of blocks are handled with this one class:
proofs, definitions, notations, registrations, cases, suppose blocks,
schemes, hereby statements, and so on. However, some of these blocks
have extra content which needs their own nodes in the abstract syntax
tree, especially Definitions
(\section\section\xref{esm:ast:definitions} \emph{et seq.}) and
Registrations (\section\section\xref{esm:ast:registrations} \emph{et seq}.).

\medbreak
\figure
\centerline{\graphics{img/classdiagram-3}}
%\centerline{\includegraphics{img/classdiagram-0.pdf}}
% \epsfbox{img/termclassUML.eps} % for non-PDF output
\caption{UML class diagram for \\{wsBlock} and related classes.}
\endfigure
\medbreak\noindent%
It is important to stress: \textbf{wsBlock instances represent all statements
which are block statements and all other statements are wsItem instances.}
Looking back at the different kinds of blocks, you see that they are
``block openers'' and will expect to have a matching ``\texttt{end}''
statement closing it.

\label{wsTextProper:ast}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   wsBlockPtr = ^wsBlock; @/
   wsBlock = object(MObject) @t\1@> @/
      nBlockKind: BlockKind; @/
      nItems: PList; {list of \\{wsItem} objects}
      nBlockPos,nBlockEndPos: Position; @/
      constructor Init(aBlokKind:BlockKind@+;@+ const aPos:Position); @t\2@>
      destructor Done; virtual; @t\2\2\2@> 
   end; @#

   @<Weakly strict Item class@>; @#

   wsTextProperPtr = ^wsTextProper; @/
   wsTextProper = object(wsBlock) @t\1@> @/
      nArticleID, nArticleExt: string; @/
      constructor Init(const aArticleID,aArticleExt:string@+;@+ const aPos:Position); @t\2@> 
      destructor Done; virtual; @t\2@>

      function NewBlock(aBlockKind:BlockKind@+;@+ const aPos:Position): wsBlockPtr; @t\2@>
      function NewItem(aItemKind:ItemKind@+;@+ const aPos:Position): wsItemPtr; @t\2\2\2@> 
   end;

@ \node{Constructor.}
We initialize using the inherited \\{wsBlock} constructor
(\section\xref{wsBlock.Init}). The ``text proper'' refers to a block
which is as top-level as possible, so we construct it as a block whose
kind is \texttt{blMain} located at \\{aPos}.

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor wsTextProper.Init(const aArticleID, aArticleExt: string;@+ const aPos:Position);
begin
   inherited Init(blMain,aPos);
   nArticleID:=aArticleID;
   nArticleExt:=aArticleExt;
end; @#

destructor wsTextProper.Done;
begin
   inherited Done;
end;

@ \node{Adding statements into a block.} we will add a block to a
``text proper'', which will then construct a block which tracks the
caller as its containing block. This requires giving the kind of the
newly minted block (\section\xref{type:BlockKind}).

Similarly, when constructing an item which is contained in the block,
we need to pass along the item kind (\section\xref{type:ItemKind}).

@<Implementation for \texttt{wsmarticle.pas}@>=
function wsTextProper.NewBlock(aBlockKind: BlockKind@+;@+ const aPos:Position): wsBlockPtr;
begin
   result:=new(WSBlockPtr,Init(aBlockKind,CurPos));
end; @#

function wsTextProper.NewItem(aItemKind:ItemKind@+;@+ const aPos:Position): wsItemPtr;
begin
   result:=new(wsItemPtr,Init(aItemKind,CurPos));
end;

@ \node{Block Constructor.} Curiously, the \\{MObject} constructor
(\section\xref{MObject.Init}) is not invoked when constructing
a \\{wsBlock}. We will also need the position (\section\xref{type:Position})
of the block in the article. The collection of items in the block is
initialized to be empty.

\label{wsBlock.Init}

@p
constructor wsBlock.Init(aBlokKind: BlockKind@+;@+ const aPos:Position);
begin
   nBlockKind:=aBlokKind;
   nBlockPos:=aPos;
   nBlockEndPos:=aPos;
   nItems:=New(PList,Init(0));
end; @#

destructor wsBlock.Done;
begin
   dispose(nItems,Done);
   inherited Done;
end;

@ \node{Text items.}
An item requires its ``kind'' (\section\xref{type:ItemKind}) for its
syntactic class.

\label{TextItem:ast}

@<Weakly strict Item class@>=
   wsItemPtr = ^wsItem; @/
   wsItem = object(MObject) @t\1@> @/
      nItemKind: ItemKind; @/
      nItemPos,nItemEndPos: Position; @/
      nContent: PObject; @/
      nBlock: wsBlockPtr; @/
      constructor Init(aItemKind:ItemKind@+;@+ const aPos:Position); @t\2@>
      destructor Done; virtual; @t\2\2\2@> 
   end;

@ \node{Constructor}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor wsItem.Init(aItemKind: ItemKind@+;@+ const aPos:Position);
begin
   nItemKind:=aItemKind;
   nItemPos:=aPos;
   nItemEndPos:=aPos;
   nContent:=nil;
   nBlock:=nil;
end;

destructor wsItem.Done;
begin
   if nBlock <> nil then dispose(nBlock,Done);
   inherited Done;
end;

@ \node{Pragmas.}
Mizar supports pragmas (analogous to conditional compilation).

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PragmaPtr = ^PragmaObj; @/
   PragmaObj = object(MObject) @t\1@> @/
      nPragmaStr: string; @/
      constructor Init(aStr: string); @t\2\2\2@>
   end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PragmaObj.Init(aStr: string);
begin
   nPragmaStr:=aStr;
end;

@ \node{Labels and propositions.} A proposition is just a sentence
with a label. We will need to represent both of these in our abstract
syntax tree.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   LabelPtr = ^LabelObj; @/
   LabelObj = object(MObject)  @t\1@> @/
      nLabelIdNr: integer; @/
      nLabelPos: Position; @/
      constructor Init(aLabelId:integer@+;@+ const aPos:Position); @t\2\2\2@>
   end; @#

   PropositionPtr = ^PropositionObj; @/
   PropositionObj = object(mObject)  @t\1@> @/
      nLab: LabelPtr; @/
      nSntPos: Position; @/
      nSentence: FormulaPtr; @/
      constructor Init(aLab:LabelPtr; aSentence:FormulaPtr@+;@+ const aSntPos:Position); @t\2@>
      destructor Done; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor LabelObj.Init(aLabelId: integer@+;@+ const aPos:Position);
begin
   nLabelIdNr:=aLabelId;
   nLabelPos:=aPos;
end; @#

constructor PropositionObj.Init(alab:LabelPtr; aSentence: FormulaPtr@+;@+ const aSntPos:Position);
begin
   nLab:=aLab;
   nSntPos:=aSntPos;
   nSentence:=aSentence;
end;

destructor PropositionObj.Done;
begin
   dispose(nLab,Done);
   dispose(nSentence,Done);
end;

@ \node{References.} References are either local (i.e., from the file
being processed) or library (i.e., from the Mizar math library). The
grammar for library references is rather generous. The basic rules are
that we have theorem references,
$$\<article>\hbox{ \texttt{":"} }\<number>$$
and definition references,
$$\<article>\hbox{ \texttt{":def "} }\<number>$$
and scheme references,
$$\<article>\hbox{ \texttt{":sch "} }\<number>$$
What makes it tricky is we also allow multiple references from the
same article to just add a comma followed by the theorem number
$$\<article>\hbox{ \texttt{":"} }\<number>\ \LB\hbox{ \texttt{","}}\<number>\ \RB$$
or a comma followed by definition numbers
$$\<article>\hbox{ \texttt{":def "} }\<number>\ \LB\hbox{ \texttt{"," "def "} }\<number>\ \RB$$
So far, so good, right? Now we can go even further, mixing theorem
references and definitions references from the same article.

We recall the grammar for references:
$$\vbox{\halign{$#$\hfil\cr
\<Reference> ::= \<Local-Reference> \mid \<Library-Reference> .\cr
\<Scheme-Reference> ::= \<Local-Scheme-Reference> \mid
\<Library-Scheme-Reference> .\cr
\<Local-Reference> ::= \<Label-Identifier> .\cr
\<Local-Scheme-Reference> ::= \<Scheme-Identifier> .\cr
\<Library-Reference> ::= \<Article-Name>
\hbox{ \texttt{":"} } ( \<Theorem-Number> \mid \hbox{ \texttt{"def"} } \<Definition-Number> )\cr
\quad \LB\ \hbox{ \texttt{","} } ( \<Theorem-Number> \mid \hbox{ \texttt{"def"} }\<Definition-Number> ) \RB\ .\cr
\<Library-Scheme-Reference> ::= \<Article-Name> \hbox{ \texttt{":" "sch"} } \<Scheme-Number> .\cr
}}$$

@ \node{Class structure.} We have an abstract ``reference'' class,
which is either a local reference (to a label within the article) or a
library reference (to some result in the MML).

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ReferenceKind = (LocalReference,
                    TheoremReference,
                    DefinitionReference
                   );

   @<Inference kinds (\texttt{wsmarticle.pas})@>;
   ReferencePtr = ^ReferenceObj; @/
   ReferenceObj =
      object(MObject) @/
         nRefSort: ReferenceKind; @/
         nRefPos: Position @t\2@>; @/
      end;

@ \node{Local references.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   LocalReferencePtr = ^LocalReferenceObj; @/
   LocalReferenceObj =
      object(ReferenceObj) @t\1@> @/
         nLabId: integer; @/
         constructor Init(aLabId:integer@+;@+ const aPos:Position); @t\2\2\2@>
      end; @#


@ \node{Constructor.} The reference constructors simply populate the
appropriate fields in the reference, and the position in the article's
text.

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor LocalReferenceObj.Init(aLabId:integer; const aPos:Position);
begin
   nRefSort:=LocalReference;
   nLabId:= aLabId;
   nRefPos:=aPos
end;

@ \node{Library references.} This is the abstract class representing
either theorem or definition references from an article.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   LibraryReferencePtr = ^LibraryReferenceObj; @/
   LibraryReferenceObj =
      object(ReferenceObj) @/
         nArticleNr: integer @t\2@> ;@/
      end;@t\1@>@;

@ \node{Theorem and definition references.} I am of a divided mind
here. On the one hand, we can see that a \\{LibraryReference} is a tagged union
already, and we do not need separate subclasses for theorem references
and definition references. On the other hand, separate subclasses
makes things easier when emitting \XML/ for the abstract syntax tree
for a Mizar article. Since it is more clear with separate subclasses,
and it is better to be clear than clever, I think this design is wiser
than the alternatives.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   TheoremReferencePtr = ^TheoremReferenceObj; @/
   TheoremReferenceObj =
      object(LibraryReferenceObj) @t\1@> @/
         nTheoNr:integer; @/
         constructor Init(aArticleNr,aTheoNr:integer@+;@+ const aPos:Position); @t\2\2\2@>
      end; @#

   DefinitionReferencePtr = ^DefinitionReferenceObj; @/
   DefinitionReferenceObj =
      object(LibraryReferenceObj) @t\1@> @/
         nDefNr:integer; @/
         constructor Init(aArticleNr,aDefNr:integer@+;@+ const aPos:Position); @t\2\2\2@>
      end;

@ \node{Constructor.} The reference constructors simply populate the
appropriate fields in the reference, and the position in the article's
text.

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor TheoremReferenceObj.Init(aArticleNr,aTheoNr:integer; const aPos:Position);
begin
   nRefSort:=TheoremReference;
   nArticleNr:=aArticleNr;
   nTheoNr:=aTheoNr;
   nRefPos:=aPos
end; @#

constructor DefinitionReferenceObj.Init(aArticleNr,aDefNr:integer; const aPos:Position);
begin
   nRefSort:=DefinitionReference;
   nArticleNr:=aArticleNr;
   nDefNr:=aDefNr;
   nRefPos:=aPos
end;

@ \node{Justifications.}
The grammar for justifications looks like:

\medbreak
{\obeylines\parindent=0pt\tt
Justification = Simple-Justification
\quad\pipe\ Proof .\smallbreak

Simple-Justification = Straightforward-Justification
\quad\pipe\ Scheme-Justification .\smallbreak

Proof = "proof" Reasoning "end" .\smallbreak

Straightforward-Justification = [ "by" References ] .\smallbreak

Scheme-Justification = "from" Scheme-Reference [ "(" References ")" ] .
\par}
\medbreak\noindent%
Proof blocks are already represented as a \\{Block} object. We just
need to represent the other kinds of justifications as nodes in the
abstract syntax tree.

@ The different kinds of inference, since a \\{Justification} is a
tagged union of sorts.

@<Inference kinds (\texttt{wsmarticle.pas})@>=
   InferenceKind = (infError,
                    infStraightforwardJustification,
                    infSchemeJustification,
                    infProof,
                    infSkippedProof)

@ \node{Class structure for justifications.}
The class hierarchy for justifications reflects the grammar we just
discussed.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   JustificationPtr = ^JustificationObj; @/
   JustificationObj =
      object(MObject) @t\1@> @/
         nInfSort: InferenceKind; @/
         nInfPos: Position; @/
         constructor Init(aInferSort:InferenceKind@+;@+ const aPos: Position); @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor JustificationObj.Init(aInferSort:InferenceKind@+;@+ const aPos: Position);
begin
   nInfSort:=aInferSort;
   nInfPos:=aPos;
end; @#

@ \node{Simple justifications.}
These are either ``\texttt{by}'' a list of references, or
``\texttt{from}'' a scheme.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SimpleJustificationPtr = ^SimpleJustificationObj; @/
   SimpleJustificationObj =
      object(JustificationObj) @t\1@> @/
         nReferences: PList; @/
         constructor Init(aInferSort:InferenceKind@+;@+ const aPos: Position); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SimpleJustificationObj.Init(aInferSort:InferenceKind@+;@+ const aPos: Position);
begin
   inherited Init(aInferSort,aPos);
   nReferences:=new(Plist,Init(0));
end; @#

destructor SimpleJustificationObj.Done;
begin
   dispose(nReferences,Done);
   inherited Done;
end;

@ \node{Straightforward justification.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   StraightforwardJustificationPtr = ^StraightforwardJustificationObj; @/
   StraightforwardJustificationObj =
      object(SimpleJustificationObj) @t\1@>@/
         nLinked: boolean; @/
         nLinkPos: Position; @/
         constructor Init(const aPos:Position;@+ aLinked:boolean;@+ const aLinkPos:Position); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor StraightforwardJustificationObj.Init(const aPos:Position@t\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1@>;
 aLinked:boolean;
 const aLinkPos:Position)@t\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2@>;
begin
   inherited Init(infStraightforwardJustification,aPos);
   nLinked:=aLinked;
   nLinkPos:=aLinkPos;
end; @#

destructor StraightforwardJustificationObj.Done;
begin
   inherited Done;
end;

@ \node{Scheme justification.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SchemeJustificationPtr = ^SchemeJustificationObj; @/
   SchemeJustificationObj =
      object(SimpleJustificationObj) @t\1@> @/
         nSchFileNr: integer; {0 for schemes from current article and positive for library references}
         nSchemeIdNr: integer; {a number of a scheme for library reference |nSchFileNr > 0| or
                                 a number of an identifier name for scheme name from current article}
         nSchemeInfPos: Position; @/
         constructor Init(const aPos:Position;@+ aArticleNr,aNr:integer); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SchemeJustificationObj.Init(const aPos:Position;@+ aArticleNr,aNr:integer);
begin
   inherited Init(infSchemeJustification,aPos);
   nSchFileNr:=aArticleNr;
   nSchemeIdNr:=aNr;
   nSchemeInfPos:=aPos;
end; @#

destructor SchemeJustificationObj.Done;
begin
   inherited Done;
end;

@* [S] Schemes.
The grammar for schemes looks like:
\medbreak
{\obeylines\parindent=0pt\tt%\ninett\baselineskip=11pt
Scheme-Item = Scheme-Block ";" .\smallbreak

Scheme-Block = "scheme" Scheme-Identifier "\LB" Scheme-Parameters "\RB" ":"
\quad Scheme-Conclusion ["provided" Scheme-Premise \LB "and" Scheme-Premise\RB]
\quad  ("proof" \pipe\ ";") Reasoning "end" .\smallbreak

Scheme-Identifier = Identifier .\smallbreak

Scheme-Parameters = Scheme-Segment { "," Scheme-Segment } .\smallbreak

Scheme-Conclusion = Sentence .\smallbreak

Scheme-Premise = Proposition .\smallbreak

Scheme-Segment = Predicate-Segment \pipe\ Functor-Segment .\smallbreak

Predicate-Segment =
\quad Predicate-Identifier \LB "," Predicate-Identifier\RB\ \rlap{"[" [Type-Expression-List] "]" .}\smallbreak

Predicate-Identifier = Identifier .\smallbreak

Functor-Segment =
\quad Functor-Identifier \LB "," Functor-Identifier\RB\ "(" \rlap{[Type-Expression-List] ")" Specification .}\smallbreak

Functor-Identifier = Identifier .
\par}
\medbreak\noindent%
We begin with the abstract syntax for scheme parameters.

@ \node{Class hierarchy for schemes.}
We need ``predicate segments'' and ``functor segments'' for the
second-order variable parameters to the scheme.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SchemeSegmentKind = (PredicateSegment,FunctorSegment); @#

   SchemeSegmentPtr = ^SchemeSegmentObj; @/
   SchemeSegmentObj =
      object(MObject) @t\1@> @/
         nSegmPos: Position; @/
         nSegmSort: SchemeSegmentKind; @/
         nVars: PList; @/
         nTypeExpList: PList; @/
         constructor Init(const aPos:Position;@+ aSegmSort:SchemeSegmentKind;
                          aVars,aTypeExpList: PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SchemeSegmentObj.Init(const aPos:Position@t\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1@>;
aSegmSort:SchemeSegmentKind;
                             aVars,aTypeExpList: PList@t\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2@>);
begin
   nSegmPos:=aPos;
   nSegmSort:=aSegmSort;
   nVars:=aVars;
   nTypeExpList:=aTypeExpList;
end; @#

destructor SchemeSegmentObj.Done;
begin
   dispose(nVars,Done);
   dispose(nTypeExpList,Done);
end; @# 

@ \node{Segment variables for schemes.}
We need ``predicate segments'' and ``functor segments'' for the
second-order variable parameters to the scheme.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PredicateSegmentPtr = SchemeSegmentPtr; @/
   FunctorSegmentPtr = ^FunctorSegmentObj; @/
   FunctorSegmentObj =
      object(SchemeSegmentObj) @t\1@> @/
         nSpecification: TypePtr; @/
         constructor Init(const aPos:Position;@+
                          aVars,aTypeExpList: PList;@+ aSpecification: TypePtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FunctorSegmentObj.Init(const aPos:Position@t\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1@>;
                                   aVars,aTypeExpList: PList; aSpecification: TypePtr@t\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2@>);
begin
   inherited Init(aPos,FunctorSegment,aVars,aTypeExpList);
   nSpecification:=aSpecification;
end; @#

destructor FunctorSegmentObj.Done;
begin
   dispose(nSpecification,Done);
   inherited Done;
end; @#

@ \node{Scheme.} A \\{Scheme} object is the parent class
of \\{MSScheme} objects in \texttt{first\_identification.pas}.
But it does not appear to be used anywhere else. This has no place in
the abstract syntax tree, for example.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SchemePtr = ^SchemeObj; @/
   SchemeObj =
      object(MObject) @t\1@> @/
         nSchemeIdNr: integer; @/
         nSchemePos: Position; @/
         nSchemeParams: PList; @/
         nSchemeConclusion: FormulaPtr; @/
         nSchemePremises: PList; @/
         constructor Init(aIdNr:integer@+;@+ const aPos:Position;@+ aParams:PList;@+
                          aPrems:PList; aConcl:FormulaPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SchemeObj.Init(aIdNr:integer@t\1\1\1\1\1\1\1\1\1\1\1\1@>;
const aPos:Position@t\1@>; aParams:PList;
                           aPrems:PList; aConcl:FormulaPtr@t\2\2\2\2\2\2\2\2\2\2\2\2\2@>);
begin
   nSchemeIdNr:=aIdNr;
   nSchemePos:=aPos;
   nSchemeParams:=aParams;
   nSchemeConclusion:=aConcl;
   nSchemePremises:=aPrems;
end; @#

destructor SchemeObj.Done;
begin
   dispose(nSchemeParams,Done);
   dispose(nSchemeConclusion,Done);
   dispose(nSchemePremises,Done);
end;

@ \node{Reservations.}
We can ``reserve'' an identifier and its type, so we do not need to
quantify over it for each theorem. The grammar for it:
\medbreak
{\obeylines\parindent=0pt\tt
Reservation = "reserve" Reservation-Segment \rlap{$\LB$ "," Reservation-Segment $\RB$ ";" .}\smallbreak

Reservation-Segment = Reserved-Identifiers "for" Type-Expression .\smallbreak

Reserved-Identifiers = Identifier $\LB$ "," Identifier $\RB$ .
\par}

\medbreak\noindent%
The data needed for a \texttt{reserved} node in the abstract syntax tree amounts to a list of identifiers and a type.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ReservationSegmentPtr = ^ReservationSegmentObj; @/
   ReservationSegmentObj =
      object(MObject) @t\1@> @/
         nIdentifiers: PList; @/
         nResType: TypePtr; @/
         constructor Init(aIdentifiers:PList; aType:TypePtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ReservationSegmentObj.Init(aIdentifiers:PList; aType:TypePtr);
begin
   nIdentifiers:=aIdentifiers;
   nResType:=aType;
end; @#

destructor ReservationSegmentObj.Done;
begin
   dispose(nIdentifiers,Done);
   dispose(nResType,Done);
end;

@* [S] Private definitions.
The grammar for ``private definitions'' (which introduces block-local
or article-local terms and predicates) looks like:
\medbreak
{\obeylines\parindent=0pt\tt%\tentt
Private-Definition = Constant-Definition
\quad\pipe\ Private-Functor-Definition
\quad\pipe\ Private-Predicate-Definition .\smallbreak

Constant-Definition = "set" Equating-List ";" .\smallbreak

Equating-List = Equating \LB "," Equating \RB .\smallbreak

Equating = Variable-Identifier "=" Term-Expression .\smallbreak

Private-Functor-Definition = "deffunc" Private-Functor-Pattern "=" \rlap{Term-Expression ";" .}\smallbreak

Private-Predicate-Definition = "defpred" Private-Predicate-Pattern \rlap{"means" Sentence ";" .}\smallbreak

Private-Functor-Pattern = Functor-Identifier "(" [ Type-Expression-List ] ")" .\smallbreak

Private-Predicate-Pattern = Predicate-Identifier \rlap{"[" [ Type-Expression-List ] "]" .}
\par}
\medbreak\noindent%
So we really only need to describe private predicates, private
functors, and ``constant definitions'' (which introduce an abbreviation).

@ \node{Private functors.}

\label{PrivateFunctorDefinitionObj}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PrivateFunctorDefinitionPtr = ^PrivateFunctorDefinitionObj; @/
   PrivateFunctorDefinitionObj =
      object(MObject) @t\1@> @/
         nFuncId: VariablePtr; @/ 
         nTypeExpList: PList; @/
         nTermExpr: TermPtr; @/
         constructor Init(aFuncId:VariablePtr; aTypeExpList:Plist; aTerm:TermPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PrivateFunctorDefinitionObj.Init(aFuncId:VariablePtr; aTypeExpList:Plist; aTerm:TermPtr);
begin
   nFuncId:=aFuncId;
   nTypeExpList:=aTypeExpList;
   nTermExpr:=aTerm;
end; @#

destructor PrivateFunctorDefinitionObj.Done;
begin
   dispose(nFuncId,Done);
   dispose(nTypeExpList,Done);
   dispose(nTermExpr,Done);
end;

@ \node{Private predicates.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PrivatePredicateDefinitionPtr = ^PrivatePredicateDefinitionObj; @/
   PrivatePredicateDefinitionObj =
      object(MObject) @t\1@> @/
         nPredId: VariablePtr; @/
         nTypeExpList: PList; @/
         nSentence: FormulaPtr; @/
         constructor Init(aPredId:VariablePtr; aTypeExpList:Plist; aSnt:FormulaPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PrivatePredicateDefinitionObj.Init(aPredId:VariablePtr; aTypeExpList:Plist; aSnt:FormulaPtr);
begin
   nPredId:=aPredId;
   nTypeExpList:=aTypeExpList;
   nSentence:=aSnt;
end; @#

destructor PrivatePredicateDefinitionObj.Done;
begin
   dispose(nPredId,Done);
   dispose(nTypeExpList,Done);
   dispose(nSentence,Done);
end;

@ \node{Constant definitions.} These are little more than
abbreviations for terms, and their implementations reflects this: they
are pointers with delusions of grandeur.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ConstantDefinitionPtr = ^ConstantDefinitionObj; @/
   ConstantDefinitionObj =
      object(MObject) @t\1@> @/
         nVarId: VariablePtr; @/
         nTermExpr: TermPtr; @/
         constructor Init(aVarId:VariablePtr; aTerm:TermPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ConstantDefinitionObj.Init(aVarId:VariablePtr; aTerm:TermPtr);
begin
   nVarId:=aVarId;
   nTermExpr:=aTerm;
end; @#

destructor ConstantDefinitionObj.Done;
begin
   dispose(nVarId,Done);
   dispose(nTermExpr,Done);
end;

@* [S] Changing types.
Each term has a soft type associated with it, but we can
``\texttt{reconsider}'' or change its type. Mizar requires a proof
that the term really has the new type. The grammar for this statement:

\medbreak
{\obeylines\parindent=0pt\tt
Type-Changing-Statement =
\quad"reconsider" Type-Change-List "as" Type-Expression\rlap{ Simple-Justification ";" .}\smallbreak

Type-Change-List =
\quad(Equating \pipe\ Variable-Identifier) \rlap{\LB "," (Equating \pipe\ Variable-Identifier)\RB\ .}
\par}

\medbreak\noindent%
This requires a bit of work since we really have \emph{two} types of
reconsiderations within a single reconsider statement:
\enumerate
\item ``\texttt{reconsider} \<identifier> \texttt{as} \<type>''
\item ``\texttt{reconsider} \<identifier> = \<term> \texttt{as} \<type>''
\endenumerate
\medbreak
The trick is to represent a \texttt{Type-Change-List} as a list
of \texttt{Type-Change}s. Then a \texttt{Type-Change-Statement} is
just a \texttt{Type-Change-List} and a type.

@^Reconsider (statement)@>
@:Reconsider}{\texttt{reconsider}@>

@ \node{Class hierarchy.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   TypeChangeSort =  (Equating,VariableIdentifier); @#

   TypeChangePtr = ^TypeChangeObj; @/
   TypeChangeObj =
      object(MObject) @t\1@> @/
         nTypeChangeKind: TypeChangeSort; @/
         nVar: VariablePtr; @/
         nTermExpr: TermPtr; @/
         constructor Init(aKind:TypeChangeSort; aVar:VariablePtr; aTerm:TermPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

   @<Example classes (\texttt{wsmarticle.pas})@>@; @#
   
   TypeChangingStatementPtr = ^TypeChangingStatementObj; @/
   TypeChangingStatementObj =
      object(MObject) @t\1@> @/
         nTypeChangeList: PList; @/
         nTypeExpr: TypePtr; @/
         nJustification: SimpleJustificationPtr; @/
         constructor Init(aTypeChangeList: PList; aTypeExpr: TypePtr;
                          aJustification:SimpleJustificationPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor TypeChangeObj.Init(aKind:TypeChangeSort; aVar:VariablePtr; aTerm:TermPtr);
begin
   nTypeChangeKind:=aKind;
   nVar:=aVar;
   nTermExpr:=aTerm;
end; @#

destructor TypeChangeObj.Done;
begin
   dispose(nVar,Done);
   if nTermExpr <> nil then
      dispose(nTermExpr,Done);
end; @#

@t\4@> @<Constructors for example statements (\texttt{wsmarticle.pas})@>@; @#

constructor TypeChangingStatementObj.Init(aTypeChangeList: PList; aTypeExpr: TypePtr;
                                          aJustification:SimpleJustificationPtr);
begin
   nTypeChangeList:=aTypeChangeList;
   nTypeExpr:=aTypeExpr;
   nJustification:=aJustification;
end;

destructor TypeChangingStatementObj.Done;
begin
   dispose(nTypeChangeList,Done);
   dispose(nTypeExpr,Done);
   dispose(nJustification,Done);
end;

@* [S] Proof steps. Most of the proof steps are handled in generic
text-item objects. But there are a few which are outside that tagged union.
In particular: existential elimination (\texttt{consider}
\<variables> \texttt{such that} \<formula>),
existential introduction (\texttt{take} \<terms>),
and concluding statements (\texttt{thus} \<formula>).

@ \node{Examples, existential introduction.} The proof step
``\texttt{take} $x$'' transforms goals of the form $\exists x\ldotp P[x]$
into a new goal $P[x]$.
The grammar for examples looks like:

\medbreak
{\obeylines\parindent=0pt\tt
Exemplification = "take" Example \LB "," Example\RB\ ";" .\smallbreak

Example = Term-Expression \pipe\ Variable-Identifier "=" Term-Expression .
\par}

@<Example classes (\texttt{wsmarticle.pas})@>=
   ExamplePtr = ^ExampleObj; @/
   ExampleObj =
      object(MObject) @t\1@> @/
         nVarId: VariablePtr; @/
         nTermExpr: TermPtr; @/
         constructor Init(aVarId:VariablePtr; aTerm:TermPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Constructors for example statements (\texttt{wsmarticle.pas})@>=
constructor ExampleObj.Init(aVarId:VariablePtr; aTerm:TermPtr);
begin
   nVarId:=aVarId;
   nTermExpr:=aTerm;
end;

destructor ExampleObj.Done;
begin
   if nVarId <> nil then dispose(nVarId,Done);
   if nTermExpr <> nil then dispose(nTermExpr,Done);
end;

@ \node{Existential elimination.} We continue plugging along with the
statements, and existential elimination (or ``choice'') statements are
the next one.

\medbreak
{\obeylines\parindent=0pt\tt
Linkable-Statement = Compact-Statement
\quad\pipe\ Choice-Statement
\quad\pipe\ Type-Changing-Statement
\quad\pipe\ Iterative-Equality .\smallbreak

Choice-Statement = "consider" Qualified-Variables "such" \rlap{Conditions Simple-Justification ";" .}
\par}

@ @<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ChoiceStatementPtr = ^ChoiceStatementObj; @/
   ChoiceStatementObj =
      object(MObject) @t\1@> @/
         nQualVars: PList; @/
         nConditions: PList; @/
         nJustification: SimpleJustificationPtr; @/
         constructor Init(aQualVars,aConds:PList; aJustification:SimpleJustificationPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ChoiceStatementObj.Init(aQualVars,aConds:PList; aJustification:SimpleJustificationPtr);
begin
   nQualVars:=aQualVars;
   nConditions:=aConds;
   nJustification:=aJustification;
end;

destructor ChoiceStatementObj.Done;
begin
   dispose(nQualVars,Done);
   dispose(nConditions,Done);
   dispose(nJustification,Done);
end;

@ \node{Conclusion statements.}
We recall the grammar for conclusion statements:
\medbreak
{\obeylines\parindent=0pt\tt
Conclusion = ( "thus" \pipe\ "hence" ) ( Compact-Statement \pipe\ Iterative-Equality )
\quad\pipe\ Diffuse-Conclusion .\smallbreak

Diffuse-Conclusion = "thus" Diffuse-Statement \pipe\ "hereby" Reasoning "end"\rlap{ ";" .}\smallbreak

Iterative-Equality =
[ Label-Identifier ":" ] Term-Expression \rlap{"=" Term-Expression Simple-Justification}
\hskip17.5pc \rlap{".=" Term-Expression Simple-Justification}
\hskip16.6pc \rlap{\LB\ ".=" Term-Expression Simple-Justification \RB\ ";" .}

\par}
\medbreak\noindent%
N{\sc OTE}: the whitespace in the \texttt{Iterative-Equality} rule is
unimportant, but that is how Mizar users often structure them (to
align the equals sign).

@ \node{Abstract base class.}
\label{RegularStatementKind}
@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   RegularStatementKind = (stDiffuseStatement,stCompactStatement,stIterativeEquality); @#

   RegularStatementPtr = ^RegularStatementObj; @/
   RegularStatementObj =
      object(MObject) @t\1@> @/
         nStatementSort: RegularStatementKind; @/
         nLab: LabelPtr; @/
         constructor Init(aStatementSort:RegularStatementKind); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor RegularStatementObj.Init(aStatementSort: RegularStatementKind);
begin
   nStatementSort:=aStatementSort;
end;

destructor RegularStatementObj.Done;
begin
   inherited Done;
end;

@ \node{Thus statement.} The conclusion of a proof (idiomatically
``\texttt{thus thesis}'') is always a ``\texttt{thus}'', which Mizar
calls a ``diffuse statement''.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   DiffuseStatementPtr = ^DiffuseStatementObj; @/
   DiffuseStatementObj =
      object(RegularStatementObj) @t\1@> @/
         constructor Init(aLab: LabelPtr; aStatementSort:RegularStatementKind); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor DiffuseStatementObj.Init(aLab: LabelPtr; aStatementSort: RegularStatementKind);
begin
   inherited Init(stDiffuseStatement);
   nLab:=aLab;
   nStatementSort:=aStatementSort;
end;

destructor DiffuseStatementObj.Done;
begin
   dispose(nLab,Done);
end;

@ \node{Compact statements.}
We recall the syntax for a compact statement is:
\medbreak
{\obeylines\parindent=0pt\tt
Compact-Statement = Proposition Justification ";" .
\par}
\medbreak

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CompactStatementPtr =  ^CompactStatementObj; @/
   CompactStatementObj =
      object(RegularStatementObj) @t\1@> @/
         nProp: PropositionPtr; @/
         nJustification: JustificationPtr; @/
         constructor Init(aProp:PropositionPtr; aJustification:JustificationPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CompactStatementObj.Init(aProp:PropositionPtr; aJustification:JustificationPtr);
begin
   inherited Init(stCompactStatement);
   nProp:=aProp;
   nJustification:=aJustification;
end;

destructor CompactStatementObj.Done;
begin
   if nJustification <> nil then dispose(nJustification,Done);
   inherited Done;
end;

@ \node{Iterative equality.} Chain of equations, where we keep
transforming the right-hand side until we arrive at the desired outcome.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   IterativeStepPtr = ^IterativeStepObj; @/
   IterativeStepObj =
      object(MObject) @t\1@> @/
         nIterPos: Position; @/
         nTerm: TermPtr; @/
         nJustification: SimpleJustificationPtr; @/
         constructor Init(const aPos:Position;@+ aTerm: TermPtr;@+ aJustification:JustificationPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ @<Publicly declared types in \texttt{wsmarticle.pas}@>=
   IterativeEqualityPtr = ^IterativeEqualityObj; @/
   IterativeEqualityObj =
      object(CompactStatementObj) @t\1@> @/
         nIterSteps: PList; @/
         constructor Init(aProp:PropositionPtr; aJustification:JustificationPtr; aIters: PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor IterativeStepObj.Init(const aPos:Position;@+ aTerm: TermPtr;@+ aJustification:JustificationPtr);
begin
   nIterPos:=aPos;
   nTerm:=aTerm;
   nJustification:=SimpleJustificationPtr(aJustification);
end;

destructor IterativeStepObj.Done;
begin
   dispose(nTerm,Done);
   dispose(nJustification,Done);
end;
@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor IterativeEqualityObj.Init(aProp:PropositionPtr;aJustification:JustificationPtr; aIters: PList);
begin
   inherited Init(aProp,aJustification);
   nStatementSort:=stIterativeEquality;
   nIterSteps:=aIters;
end;

destructor IterativeEqualityObj.Done;
begin
   dispose(nIterSteps,Done);
   inherited Done;
end;

@ \node{Remaining proof steps?}
So where are the other proof steps like \texttt{let}
or \texttt{assume}? Well, these are handled as ``generic text items''
and use the \\{TextItem} class (\section\xref{TextItem:ast}).

@* [S] Structures.
Just an aside first on ``what is a structure in Mathematics?''
Logic textbooks assume an \emph{intuitive} (i.e., not formal)
``finitary metatheory'' following Hilbert and his famous Programme in
the foundations of Mathematics. We will build a ``skyscraper'' atop
this foundation of finitary metatheory. The first thing we do is describe a
logic, the first floor in our sky scraper. This ``Logic \#1'' is the
metalogic we use to construct an axiomatic set theory, ``Set Theory \#2''.
We use ``Set Theory \#2'' to construct another floor, a ``Logic \#3'',
which then builds another floor ``Set Theory \#4'', and so on. We can
potentially iterate building as many floors as we want, but 4 is
sufficient for our purposes.

We \textbf{assert} that ``Set Theory \#2'' \emph{is} the Platonic
``mathematical reality''. Then ``Logic \#3'' is the (ambient) logic we use to do
Mathematics; it is purely ``syntactic'', a language for expressing
proofs and definitions. Mizar's proof steps, formulas, and definitions
corresponds to ``Logic \#3''. With it, we describe an axiomatic ``Set
Theory \#4'', which is Tarski--Grothendieck set theory for
Mizar. Sketching this situation out diagrammatically:

\medbreak
\figure
\centerline{\vbox{\offinterlineskip
\halign{&\quad\vrule#&\quad\hfil#\hfil\quad&\vrule#&\quad#\hfil\quad\cr
& \multispan1\hrulefill && \omit\cr
height2pt&\omit&&\omit\cr
& Set Theory \#4 & & (Where we work) [syntactic]\cr
height2pt&\omit&&\omit\cr
& \multispan1\hrulefill && \omit\cr
height2pt&\omit&&\omit\cr
&      Logic \#3 & & ``Object logic'' (Where we write proofs) [syntactic]\cr
height2pt&\omit&&\omit\cr
& \multispan1\hrulefill && \omit\cr
height2pt&\omit&&\omit\cr
& Set Theory \#2 & & ``Mathematical Reality'' [semantic]\cr
height2pt&\omit&&\omit\cr
& \multispan1\hrulefill && \omit\cr
height2pt&\omit&&\omit\cr
&      Logic \#1 & & ``Metalogic''\cr
height2pt&\omit&&\omit\cr}\hrule
\vbox{\vskip 3pt\hbox{\quad Finitary Metatheory}}
}}
%% \rightline{\vbox{\vskip-3pc\hbox{\eightrm{\eightbf Fig.~\the\fig.}
%% Mathematical Platonism as a skyscaper.}}}
\caption{Mathematical Platonism as a skyscaper.}\label{fig:platonic-skyscraper}
\endfigure

\medbreak
Now, ``mathematical objects'' live in ``Set Theory \#2''. Model theory
studies structures (objects in ``Set Theory \#2'') of theories
(described in ``Logic \#3''). Since we ``believe'' that set theory
``describes reality'', that means we just need to describe
[``syntactic''] theories using ``Set Theory \#4'' and their ``real
world occurrences'' in ``Set Theory \#2''. (Well, this is a gloss,
model theory sets up two additional floors in the skyscraper, and
studies ``models'' of theories described using Logic~\#5 and Set Theory~\#6
in Set Theory~\#4 --- and we pretend it describes the relationship
between Set Theory~\#2 and the ``syntactic floors'' of the
Mathematical skyscraper.)

How do we \emph{syntactically} describe these ``structures''? Well,
we \emph{know} they are not ``first-class citizens'' in Mizar, in the
sense that they are not ``just'' a tuple. How do we know this? Gilbert
Lee and Piotr Rudnicki's ``Alternative Aggregates in Mizar''
(in \emph{MKM 2007}, Springer, pp.327--341; \doi{10.1007/978-3-540-73086-6_26})
discuss how to implement first-class structures in Mizar. This means
that \emph{technically} structures live in Logic~\#3. Field symbols
are terms in Logic~\#3.

@^Structure, first-class@>
@^Rudnicki, Piotr@>
@^Lee, Gilbert@>
@^Hilbert's programme@>
@^Finitary metatheory@>
@^Metamathematics@>
@^Skyscraper@>

@ Why do we need this convoluted skyscraper? Without it, how do we
describe a ``true'' formula? We can only speak of a \emph{provable}
formula. Bourbaki's \emph{Theory of Sets} (I \section2.2) confuses
``provable'' with ``true'' formulas (they speak of a formula being
``false in a theory ${\cal T}$'' as being
synonymous with the formula contradicting the axioms for a theory,
and true in a theory as being synonymous for being a logical
consequence from the axioms for a theory). This only matters for
Mathematical Platonists. Formalists (like the author) would find this
discussion muddled and nearly metaphysical, generating more heat than light.

@^Bourbaki, Nicolas@>

@ \node{Aside: finitary metatheory, programming languages,
implementing proof assistants.}\hfill\break
How does that diagram in
Figure~\ref{fig:platonic-skyscraper} of the last section compare to
the \emph{actual implementation} of Mizar? Well, a proof assistant
replaces the ``finitary metatheory'' with an actual programming
language. Then, since only Mathematical Platonists care about the
``Metalogic'' and ``Mathematical reality'', we jump ahead to implement
Logic \#3 --- this is what happens in Mizar and other proof
assistants: we implement a ``purely formal'' (purely syntactic) logic
using a programming language. Curiously, this reflects Bourbaki's
approach to the foundations of Mathematics.

We should note that programming languages are strictly stronger than
finitary metatheory, since programming languages are \emph{Turing complete}.
This means they support general recursion, whereas finitary metatheory
supports only primitive recursive functions. For an example of a
``programming language'' which is equally as strong as a finitary
metatheory, see Albert R.\ Meyer and Dennis M.\ Ritchie,
``The complexity of loop programs''
(\emph{ACM '67 Proc.},
1967,
\doi{10.1145/800196.806014}).

Is Turing completeness ``too much'' for a finitary metatheory? The
short answer is: yes. Even restricting a Turing complete programming
language is ``too much'' to be finitary.
G\"{o}del's System~T was developed to preserve the ``constructive character''
while jettisoning the ``finitary character'' of Hilbert's finitary
metatheory, and System~T is not even Turing complete. See
Kurt G\"{o}del's \emph{Collected Works} (vol.\ II, Oxford University Press, \doi{10.1093/oso/9780195147216.001.0001},
1989; viz., pp.\ 245--247) for his discussion of System~T.
The interested reader should consult 
David A.\ Turner's ``Elementary strong functional programming'' (in
\emph{Int.\ Symp.\ on Funct.\ Program.\ Lang.\ in Educ.}, eds P.H.\
Hartel and R.\ Plasmeijer, Springer, pages 1--13, \doi{10.1007/3-540-60675-0_35})
for how to obtain System~T by restricting any statically typed
functional programming language.

@^Bourbaki, Nicolas@>
@:Godel, Kurt}{G\"{o}del, Kurt@>
@^Turner, David A.@>
@^Total functional programming@>
@^System T@>
@^Ritchie, Dennis M.@>
@^Meyer, Albert R.@>
@^Primitive Recursive Function@>
@^Turing complete@>
@^Finitary metatheory@>
@^LOOP programming language@>

@ \node{Grammar for structures.} We can recall the syntax for
structures and fields:

\medbreak
{\obeylines\parindent=0pt\tt
Structure-Definition =
\quad"struct" [ "(" Ancestors ")" ] Structure-Symbol [ "over" Loci ] \rlap{"(\#" Fields "\#)" ";" .}\smallbreak

Ancestors = Structure-Type-Expression \LB\ "," Structure-Type-Expression \RB\ .\smallbreak

Structure-Symbol = Symbol .\smallbreak

Loci = Locus \LB\ "," Locus \RB\ .\smallbreak

Fields = Field-Segment \LB\ "," Field-Segment \RB\ .\smallbreak

Locus = Variable-Identifier .\smallbreak

Variable-Identifier = Identifier .\smallbreak

Field-Segment = Selector-Symbol \LB\ "," Selector-Symbol \RB\ Specification .\smallbreak

Selector-Symbol = Symbol .
\par}

@ \node{Field symbol.} A ``field symbol'' refers to the identifier
used for a field in a structure, but not its type.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   FieldSymbolPtr = ^FieldSymbolObj; @/
   FieldSymbolObj =
      object(MObject) @t\1@> @/
         nFieldPos: Position; @/
         nFieldSymbol: integer; @/
         constructor Init(const aPos:Position;@+ aFieldSymbNr:integer); @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FieldSymbolObj.Init(const aPos:Position;@+ aFieldSymbNr:integer);
begin
   nFieldPos:=aPos;
   nFieldSymbol:=aFieldSymbNr;
end;

@ \node{Field segment.} A field segment refers to a list of 1 or more
field symbols, and the associated type it has.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   FieldSegmentPtr = ^FieldSegmentObj; @/
   FieldSegmentObj =
      object(MObject) @t\1@> @/
         nFieldSegmPos: Position; @/
         nFields: PList; @/
         nSpecification: TypePtr; @/
         constructor Init(const aPos:Position;@+ aFields:PList;@+ aSpec:TypePtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FieldSegmentObj.Init(const aPos:Position;@+ aFields:PList;@+ aSpec:TypePtr);
begin
   nFieldSegmPos:=aPos;
   nFields:=aFields;
   nSpecification:=aSpec;
end;

destructor FieldSegmentObj.Done;
begin
   dispose(nFields,Done);
   dispose(nSpecification,Done);
end;

@ \node{Locus.} A ``locus'' refers to a term or type parametrizing a
definition.

\label{Locus:ast}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   LocusPtr = ^LocusObj; @/
   LocusObj =
      object(MObject) @t\1@> @/
         nVarId: integer; @/
         nVarIdPos: Position; @/
         constructor Init(const aPos:Position;@+ aIdentNr:integer); @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor LocusObj.Init(const aPos:Position;@+ aIdentNr:integer);
begin
   nVarId:=aIdentNr;
   nVarIdPos:=aPos;
end;

@ \node{Structure definition.} Finally, structures are finite maps
from selectors to terms, with structure inheritance thrown into the
mix. They may be defined ``\texttt{over}'' a finite list of types
(e.g., a module structure is ``\texttt{over}'' a ring). Note that we
need to first introduce ``patterns'' before describing the structure
definition, since ``patterns'' are needed in definitions.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=   
   @<Pattern objects (\texttt{wsmarticle.pas})@>@; @#
   
   StructureDefinitionPtr = ^StructureDefinitionObj; @/
   StructureDefinitionObj =
      object(MObject) @t\1@> @/
         nStrPos: Position; @/
         nAncestors: PList; @/
         nDefStructPattern: ModePatternPtr; @/
         nSgmFields: PList; @/
         constructor Init(const aPos:Position;@+ aAncestors:PList;@+ aStructSymb:integer;
                          aOverArgs:PList;@+ aFields:PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor StructureDefinitionObj.Init(const aPos:Position;@+ aAncestors:PList;
                                       @t\hskip14.6667pc @> aStructSymb:integer;@+ aOverArgs:PList;@+ aFields:PList);
begin
   nStrPos:=aPos;
   nAncestors:=aAncestors;
   nDefStructPattern:=new(ModePatternPtr,Init(aPos,aStructSymb,aOverArgs));
   nDefStructPattern^.nPatternSort:=itDefStruct;
   nSgmFields:=aFields;
end;

destructor StructureDefinitionObj.Done;
begin
   dispose(nAncestors,Done);
   dispose(nDefStructPattern,Done);
   dispose(nSgmFields,Done);
end;

@* [S] Patterns.
A ``\emph{Pattern\/}'' in Mizar is a format with the type information
for all the arguments around a term. The notion of a
``\emph{Pattern\/}'' also refers to the definiendum of a definition.
The syntax of patterns
\medbreak
{\obeylines\parindent=0pt\tt
Mode-Pattern = Mode-Symbol [ "of" Loci ] . \smallbreak

Attribute-Pattern = Locus "is" [ Attribute-Loci ] Attribute-Symbol .\smallbreak

Attribute-Loci = Loci \pipe\ "(" Loci ")" .\smallbreak

Predicate-Pattern = [ Loci ] Predicate-Symbol [ Loci ] .\smallbreak

Functor-Pattern = [ Functor-Loci ] Functor-Symbol [ Functor-Loci ]
\quad\pipe\ Left-Functor-Bracket Loci Right-Functor-Bracket .\smallbreak

Functor-Loci = Locus \pipe\ "(" Loci ")" .
\par}


@ \node{Base class for patterns.}

@<Pattern objects (\texttt{wsmarticle.pas})@>=
   PatternPtr = ^PatternObj; @/
   PatternObj =
      object(mObject) @t\1@> @/
         nPatternPos: Position; @/
         nPatternSort: ItemKind; @/
         constructor Init(const aPos:Position;@+ aSort:ItemKind); @t\2\2\2@>
      end; @#

@ @<Implementation for \texttt{wsmarticle.pas}@>=
constructor PatternObj.Init(const aPos:Position;@+ aSort:ItemKind);
begin
   nPatternPos:=aPos;
   nPatternSort:=aSort;
end;

@ \node{Mode patterns.} The syntax for ``mode patterns'' looks like:

\medbreak
{\obeylines\parindent=0pt\tt
Mode-Pattern = Mode-Symbol [ "of" Loci ] .
\par}

@<Pattern objects (\texttt{wsmarticle.pas})@>=
   ModePatternPtr = ^ModePatternObj; @/
   ModePatternObj =
      object(PatternObj) @t\1@> @/
         nModeSymbol: Integer; @/
         nArgs: PList; @/
         constructor Init(const aPos:Position;@+ aSymb:integer;@+ aArgs:PList); @t\2@>
         destructor Done; virtual;  @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ModePatternObj.Init(const aPos:Position;@+ aSymb:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,itDefMode);
   nModeSymbol:=aSymb;
   nArgs:=aArgs;
end; @#

destructor ModePatternObj.Done;
begin
   dispose(nArgs,Done);
end;

@ \node{Attribute patterns.} Attributes can have loci prefixing the
attribute symbol, but \emph{not} suffixing the attribute symbol.

\medbreak
{\obeylines\parindent=0pt\tt
Attribute-Pattern = Locus "is" [ Attribute-Loci ] Attribute-Symbol .\smallbreak

Attribute-Loci = Loci \pipe\ "(" Loci ")" .

\par}

@<Pattern objects (\texttt{wsmarticle.pas})@>=
   AttributePatternPtr = ^AttributePatternObj; @/
   AttributePatternObj =
      object(PatternObj) @t\1@> @/
         nAttrSymbol: Integer; @/
         nArg: LocusPtr; @/
         nArgs: PList; @/
         constructor Init(const aPos:Position;@+ aArg:LocusPtr;@+ aSymb:integer;@+ aArgs:PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor AttributePatternObj.Init(const aPos:Position;@+ aArg:LocusPtr;@+ aSymb:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,itDefAttr);
   nAttrSymbol:=aSymb;
   nArg:=aArg;
   nArgs:=aArgs;
end;

destructor AttributePatternObj.Done;
begin
   dispose(nArg,Done);
   dispose(nArgs,Done);
end;

@ \node{Predicate patterns.} Predicates can have loci on either side
of the predicate symbol, without requiring parentheses (unlike functors).

\medbreak
{\obeylines\parindent=0pt\tt
Predicate-Pattern = [ Loci ] Predicate-Symbol [ Loci ] .
\par}

@<Pattern objects (\texttt{wsmarticle.pas})@>=
   PredicatePatternPtr = ^PredicatePatternObj; @/
   PredicatePatternObj =
      object(PatternObj) @t\1@> @/
         nPredSymbol: Integer; @/
         nLeftArgs,nRightArgs: PList; @/
         constructor Init(const aPos:Position;@+ aLArgs:PList;@+ aSymb:integer;@+ aRArgs:PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PredicatePatternObj.Init(const aPos:Position;
@t\qquad @> aLArgs:PList;@+ aSymb:integer;@+ aRArgs:PList);
begin
   inherited Init(aPos,itDefPred);
   nPredSymbol:=aSymb;
   nLeftArgs:=aLArgs;
   nRightArgs:=aRArgs;
end;

destructor PredicatePatternObj.Done;
begin
   dispose(nLeftArgs,Done);
   dispose(nRightArgs,Done);
end;

@ \node{Functor pattern.} Functors can have loci on either side. If
more than one locus is used on one side, then it must be placed in
parentheses and comma-separated. The syntax:

\medbreak
{\obeylines\parindent=0pt\tt
Functor-Pattern = [ Functor-Loci ] Functor-Symbol [ Functor-Loci ]
\quad\pipe\ Left-Functor-Bracket Loci Right-Functor-Bracket .\smallbreak

Functor-Loci = Locus \pipe\ "(" Loci ")" .
\par}

@<Pattern objects (\texttt{wsmarticle.pas})@>=
   FunctorSort = (InfixFunctor,CircumfixFunctor); @#

   FunctorPatternPtr = ^FunctorPatternObj; @/
   FunctorPatternObj =
      object(PatternObj) @t\1@> @/
         nFunctKind: FunctorSort; @/
         constructor Init(const aPos:Position;@+ aKind: FunctorSort); @t\2\2\2@>
      end; @#

   CircumfixFunctorPatternPtr = ^CircumfixFunctorPatternObj; @/
   CircumfixFunctorPatternObj =
      object(FunctorPatternObj) @t\1@> @/
         nLeftBracketSymb,nRightBracketSymb: integer; @/
         nArgs: PList; @/
         constructor Init(const aPos:Position;@+ aLBSymb,aRBSymb:integer;@+ aArgs:PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

   InfixFunctorPatternPtr = ^InfixFunctorPatternObj; @/
   InfixFunctorPatternObj =
      object(FunctorPatternObj) @t\1@> @/
         nOperSymb: integer; @/
         nLeftArgs,nRightArgs: PList; @/
         constructor Init(const aPos:Position;@+ aLArgs:PList;@+ aSymb:integer;@+ aRArgs:PList); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FunctorPatternObj.Init(const aPos:Position;@+ aKind:FunctorSort);
begin
   inherited Init(aPos,itDefFunc);
   nFunctKind:=aKind;
end;

constructor CircumfixFunctorPatternObj.Init(const aPos:Position;@+ aLBSymb,aRBSymb:integer;@+ aArgs:PList);
begin
   inherited Init(aPos,CircumfixFunctor);
   nLeftBracketSymb:=aLBSymb;
   nRightBracketSymb:=aRBSymb;
   nArgs:=aArgs;
end;

destructor CircumfixFunctorPatternObj.Done;
begin
   dispose(nArgs,Done);
end;

constructor InfixFunctorPatternObj.Init(const aPos:Position;@+ aLArgs:PList;@+ aSymb:integer;@+ aRArgs:PList);
begin
   inherited Init(aPos,InfixFunctor);
   nOperSymb:=aSymb;
   nLeftArgs:=aLArgs;
   nRightArgs:=aRArgs;
end;

destructor InfixFunctorPatternObj.Done;
begin
   dispose(nLeftArgs,Done);
   dispose(nRightArgs,Done);
end;

@* [S] Definitions.
In Mizar, we can redefine an existing
definition (either changing the type of a term or ``the right hand
side'' of a definition) \emph{or} we can introduce a new
definition. There are 5 different things we can introduce: structures,
modes [types], functors [terms], predicates, and attributes. Rather
than bombard the reader with a long chunk of grammar, let us divide it
up into easy-to-digest pieces. The basic block structure of a
definition is the same for all these situations, its grammar looks like:

\label{esm:ast:definitions}

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Definitional-Item = Definitional-Block ";" .\smallbreak

Definitional-Block = "definition" \LB\ Definition-Item \pipe\ Definition \pipe\ Redefinition \RB\ "end" .\smallbreak

Definition-Item = Loci-Declaration \pipe\ Permissive-Assumption \pipe\ Auxiliary-Item .\smallbreak

Loci-Declaration = "let" Qualified-Variables [ "such" Conditions ] ";" .\smallbreak

Permissive-Assumption = Assumption .\smallbreak

Definition = Structure-Definition
\quad\pipe\ Mode-Definition
\quad\pipe\ Functor-Definition
\quad\pipe\ Predicate-Definition
\quad\pipe\ Attribute-Definition .\par}

@ \node{Redefinitions.} Redefinitions allow us to alter the type or
meaning of a definition. This isn't willy-nilly, the user still needs
to prove the redefined version is logically equivalent to the initial
definition. 

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Redefinition =
\quad"redefine" \rlap{( Mode-Definition \pipe\ Functor-Definition \pipe\ Predicate-Definition \pipe\ Attribute-Definition ) .}
\par}

@ \node{Structure definitions.} Structures intuitively correspond to
new ``gadgets'' (sets equipped with extra structure), which is often
presented in Mathematics as ``just another tuple''. Mizar allows
structures to inherit other structures, so a topological group extends
a topological space structure \emph{and} a magma structure (since a
group in Mizar is a magma with some extra properties).

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Structure-Definition =
\quad"struct" [ "(" Ancestors ")" ] Structure-Symbol \rlap{[ "over" Loci ] "(\#" Fields "\#)" ";" .}\smallbreak

Ancestors = Structure-Type-Expression \LB\ "," Structure-Type-Expression \RB\ .\smallbreak

Structure-Symbol = Symbol .\smallbreak

Loci = Locus \LB\ "," Locus \RB\ .\smallbreak

Fields = Field-Segment \LB\ "," Field-Segment \RB\ .\smallbreak

Locus = Variable-Identifier .\smallbreak

Variable-Identifier = Identifier .\smallbreak

Field-Segment = Selector-Symbol \LB\ "," Selector-Symbol \RB\ Specification .\smallbreak

Selector-Symbol = Symbol .\smallbreak

Specification = "->" Type-Expression .\par}




@ \node{Definiens.} Recall the grammar
for \texttt{Definiens}
looks like:
\medbreak
{\obeylines\parindent=0pt\tt
Definiens = Simple-Definiens \pipe\ Conditional-Definiens .\smallbreak

Simple-Definiens = [ ":" Label-Identifier ":" ] ( Sentence \pipe\ Term-Expression ) .\smallbreak

Label-Identifier = Identifier .\smallbreak

Conditional-Definiens = [ ":" Label-Identifier ":" ] Partial-Definiens-List
\quad[ "otherwise" ( Sentence \pipe\ Term-Expression ) ] .\smallbreak

Partial-Definiens-List = Partial-Definiens \LB\ "," Partial-Definiens \RB\ .\smallbreak

Partial-Definiens = ( Sentence \pipe\ Term-Expression ) "if" Sentence .\smallbreak
\par}
\medbreak\noindent%
We begin with a base class for definiens. This is extended
by \\{SimpleDefiniens} and \\{ConditionalDefiniens} classes.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   HowToDefine = (dfEmpty,dfMeans,dfEquals); @/
   DefiniensSort = (SimpleDefiniens,ConditionalDefiniens); @#

   DefiniensPtr = ^DefiniensObj; @/
   DefiniensObj =
      object(MObject) @t\1@> @/
         nDefSort: DefiniensSort; @/
         nDefPos: Position; @/
         nDefLabel: LabelPtr; @/
         constructor Init(const aPos: Position;@+ aLab:LabelPtr;@+ aKind:DefiniensSort); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor DefiniensObj.Init(const aPos: Position;@+ aLab:LabelPtr;@+ aKind:DefiniensSort);
begin
   nDefSort:=aKind;
   nDefPos:=aPos;
   nDefLabel:=aLab;
end;

destructor DefiniensObj.Done;
begin
   if nDefLabel <> nil then
      dispose(nDefLabel,Done);
end;

@ \node{Definiens expression.} These nodes in the abstract syntax tree
describe ``the right hand side'' of a definition. A simple definiens
is just a pointer to one definiens expression object, for example.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   DefExpressionPtr = ^DefExpressionObj; @/
   DefExpressionObj =
      object(MObject) @t\1@> @/
         nExprKind: ExpKind; @/
         nExpr: PObject; @/
         constructor Init(aKind:ExpKind; aExpr:PObject); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor DefExpressionObj.Init(aKind:ExpKind; aExpr:Pobject);
begin
   nExprKind:=aKind;
   nExpr:=aExpr;
end;

destructor DefExpressionObj.Done;
begin
   dispose(nExpr,Done);
end;

@ \node{Simple definiens.}
This is the ``default'' definiens, i.e., the definiens which are not
``by cases''.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SimpleDefiniensPtr = ^SimpleDefiniensObj; @/
   SimpleDefiniensObj =
      object(DefiniensObj) @t\1@> @/
         nExpression: DefExpressionPtr; @/
         constructor Init(const aPos: Position;@+ aLab:LabelPtr;@+ aDef:DefExpressionPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SimpleDefiniensObj.Init(const aPos:Position;@+ aLab:LabelPtr;@+ aDef:DefExpressionPtr);
begin
   inherited Init(aPos,aLab,SimpleDefiniens);
   nExpression:=aDef;
end;

destructor SimpleDefiniensObj.Done;
begin
   dispose(nExpression,Done);
   inherited Done;
end;

@ \node{Definition for particular case.}
We have ``\<sentence or term> \texttt{if} \<guard condition>'' represented by a couple
of pointers: one to the ``sentence or term'' definiens, and the second
to the ``guard'' condition.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PartDefPtr = ^PartDefObj; @/
   PartDefObj =
      object(MObject) @t\1@> @/
         nPartDefiniens: DefExpressionPtr; @/
         nGuard: FormulaPtr; @/
         constructor Init(aPartDef:DefExpressionPtr; aGuard:FormulaPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PartDefObj.Init(aPartDef:DefExpressionPtr; aGuard:FormulaPtr);
begin
   nGuard:=aGuard;
   nPartDefiniens:=aPartDef;
end;

destructor PartDefObj.Done;
begin
   dispose(nPartDefiniens,Done);
   dispose(nGuard,Done);
end;

@ \node{Conditional definiens.} A conditional definiens consists of a
finite list of pointers to \\{PartDef} objects, and a pointer to the
default ``\texttt{otherwise}'' definien.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ConditionalDefiniensPtr = ^ConditionalDefiniensObj; @/
   ConditionalDefiniensObj =
      object(DefiniensObj) @t\1@> @/
         nConditionalDefiniensList: PList; @/
         nOtherwise: DefExpressionPtr; @/
         constructor Init(const aPos:Position;@+ aLab:LabelPtr;@+ aPartialDefs:PList; aOtherwise:DefExpressionPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ConditionalDefiniensObj.Init(const aPos:Position;
@t\qquad @> aLab:LabelPtr;@+ aPartialDefs:PList;@+ aOtherwise:DefExpressionPtr);
begin
   inherited Init(aPos,aLab,ConditionalDefiniens);
   nConditionalDefiniensList:=aPartialDefs;
   nOtherwise:=aOtherwise;
end;

destructor ConditionalDefiniensObj.Done;
begin
   if nOtherwise <> nil then dispose(nOtherwise,Done);
   dispose(nConditionalDefiniensList,Done);
   inherited Done;
end;

@ \node{Mode definitions.} Mizar was heavily inspired by \ALGOL/, and
even borrows \ALGOL/'s terminology for types (``modes''). These are
``soft types'', which are predicates in the ambient logic.

However, we need to establish the well-definedness of types (i.e.,
they are inhabited by at least one term), or else we end up in ``free
logic''. For example, if \texttt{EmptyType} is a hypothetical empty
type, then \texttt{for x being EmptyType holds P[x]} is always true,
and \texttt{ex x being EmptyType st P[x]} is always false. The clever
Mizar user can abuse this, and end up compromising the soundness of
classical logic. To avert catastrophe, we require proving there exists
at least one term of the newly defined type.

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Mode-Definition = "mode" Mode-Pattern
\quad( [ Specification ] [ "means" Definiens ] ";" Correctness-Conditions \pipe\ "is" Type-Expression ";" )
\quad\LB\ Mode-Property \RB\ .\smallbreak

Mode-Pattern = Mode-Symbol [ "of" Loci ] .\smallbreak

Mode-Symbol = Symbol \pipe\ "set" .\smallbreak

Mode-Synonym = "synonym" Mode-Pattern "for" Mode-Pattern ";" .\smallbreak

Mode-Property = "sethood" Justification ";" .\par}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ModeDefinitionSort = (defExpandableMode,defStandardMode); @#

   ModeDefinitionPtr = ^ModeDefinitionObj; @/
   ModeDefinitionObj =
      object(MObject) @t\1@> @/
         nDefKind: ModeDefinitionSort; @/
         nDefModePos: Position; @/
         nDefModePattern: ModePatternPtr; @/
         nRedefinition: boolean; @/
         constructor Init(const aPos: Position;@+ aDefKind:ModeDefinitionSort;@+ aRedef: boolean;
                          aPattern: ModePatternPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ModeDefinitionObj.Init(const aPos:@+ Position;@+ aDefKind:ModeDefinitionSort;
@t\hskip13.3333pc@>                          aRedef: boolean;@+ aPattern: ModePatternPtr);
begin
   nDefKind:=aDefKind;
   nDefModePos:=aPos;
   nRedefinition:=aRedef;
   nDefModePattern:=aPattern;
end;

destructor ModeDefinitionObj.Done;
begin
   dispose(nDefModePattern,Done);
end;

@ \node{Expandable mode definitions.} These are simple
``abbreviations'' of modes which are of the form ``\texttt{mode}
\<type name> \texttt{is} $\langle\textit{adjective\/}_{1}\rangle$
$\cdots$ $\langle\textit{adjective\/}_{n}\rangle$ \<type>'',
i.e., just a stack of adjectives atop a type.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ExpandableModeDefinitionPtr =  ^ExpandableModeDefinitionObj; @/
   ExpandableModeDefinitionObj =
      object(ModeDefinitionObj) @t\1@> @/
         nExpansion: TypePtr; @/
         constructor Init(const aPos:Position;@+ aPattern:ModePatternPtr;@+ aExp:TypePtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ExpandableModeDefinitionObj.Init(const aPos: Position;
 @t\qquad @> aPattern: ModePatternPtr;@+ aExp:TypePtr);
begin
   inherited Init(aPos,defExpandableMode,false,aPattern);
   nExpansion:=aExp;
end;

destructor ExpandableModeDefinitionObj.Done;
begin
   dispose(nExpansion,Done);
   inherited Done;
end;

@ \node{Standard mode definitions.}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   StandardModeDefinitionPtr =  ^StandardModeDefinitionObj; @/
   StandardModeDefinitionObj =
      object(ModeDefinitionObj) @t\1@> @/
         nSpecification: TypePtr; @/
         nDefiniens: DefiniensPtr; @/
         constructor Init(const aPos:Position;@+ aRedef:boolean;@+ aPattern:ModePatternPtr;
                          aSpec:TypePtr;@+ aDef:DefiniensPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor StandardModeDefinitionObj.Init(const aPos: Position; @t\qquad @>  aRedef: boolean;@+
                                          aPattern: ModePatternPtr;@+ aSpec:TypePtr;@+
                                           aDef:DefiniensPtr);
begin
   inherited Init(aPos,defStandardMode,aRedef,aPattern);
   nSpecification:=aSpec;
   nDefiniens:=aDef;
end;

destructor StandardModeDefinitionObj.Done;
begin
   dispose(nSpecification,Done);
   dispose(nDefiniens,Done);
   inherited Done;
end;

@ \node{Attribute definitions.} Attributes, like predicates, do not
need to worry about correctness conditions. It's only when we want to
use them like adjectives on a type that we need to worry, but that's
a \texttt{registration} block concern.

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Attribute-Definition = "attr" Attribute-Pattern "means" Definiens \rlap{";"\ Correctness-Conditions .}\smallbreak

Attribute-Pattern = Locus "is" [ Attribute-Loci ] Attribute-Symbol .

\par}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   AttributeDefinitionPtr = ^AttributeDefinitionObj; @/
   AttributeDefinitionObj =
      object(MObject) @t\1@> @/
         nDefAttrPos: Position; @/
         nDefAttrPattern: AttributePatternPtr; @/
         nRedefinition: boolean; @/
         nDefiniens: DefiniensPtr; @/
         constructor Init(const aPos:Position;@+ aRedef:boolean;@+ aPattern:AttributePatternPtr;
                          aDef:DefiniensPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor AttributeDefinitionObj.Init(const aPos: Position;
@t\qquad @> aRedef: boolean;@+
                                        aPattern:AttributePatternPtr;@+ aDef:DefiniensPtr);
begin
   nDefAttrPos:=aPos;
   nRedefinition:=aRedef;
   nDefAttrPattern:=aPattern;
   nDefiniens:=aDef;
end; @#

destructor AttributeDefinitionObj.Done;
begin
   dispose(nDefAttrPattern,Done);
   dispose(nDefiniens,Done);
end;

@ \node{Predicate definitions.} Predicates are among the less
demanding of the definitions: they are always well-defined, so we do
not need to worry about correctness conditions.

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Predicate-Definition = "pred" Predicate-Pattern [ "means" Definiens ] ";" Correctness-Conditions \LB\ Predicate-Property \RB\ .\smallbreak

Predicate-Pattern = [ Loci ] Predicate-Symbol [ Loci ] .\smallbreak

Predicate-Property = ("symmetry" \pipe\ "asymmetry" \pipe\ "connectedness" \pipe\ "reflexivity" \pipe\ "irreflexivity")
\quad Justification ";" .\smallbreak

Predicate-Synonym = "synonym" Predicate-Pattern "for" Predicate-Pattern ";" .\smallbreak

Predicate-Antonym = "antonym" Predicate-Pattern "for" Predicate-Pattern ";" .\smallbreak

Predicate-Symbol = Symbol \pipe\ "=" .\par}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PredicateDefinitionPtr = ^PredicateDefinitionObj; @/
   PredicateDefinitionObj =
      object(MObject) @t\1@> @/
         nDefPredPos: Position; @/
         nDefPredPattern: PredicatePatternPtr; @/
         nRedefinition: boolean; @/
         nDefiniens: DefiniensPtr; @/
         constructor Init(const aPos:Position;@+ aRedef:boolean;@+ aPattern:PredicatePatternPtr;
                          aDef:DefiniensPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PredicateDefinitionObj.Init(const aPos: Position;
@t\qquad @> aRedef: boolean;@+ aPattern:PredicatePatternPtr;@+ aDef:DefiniensPtr);
begin
   nDefPredPos:=aPos;
   nRedefinition:=aRedef;
   nDefPredPattern:=aPattern;
   nDefiniens:=aDef;
end; @#

destructor PredicateDefinitionObj.Done;
begin
   dispose(nDefPredPattern,Done);
   dispose(nDefiniens,Done);
end;

@ \node{Functor definitions.} We can also define new terms. Well, they
introduce ``term constructors'' (constructors for terms). Mizar calls
these guys ``functors''.

Functor definitions need to establish the well-definedness of the new
term constructor. What this means depends on whether we define the new
term using ``means'' or ``equals'', i.e.,
\enumerate
\item ``\<new term> \texttt{means} \<formula>''
  requires proving the existence and uniqueness of the new term;
\item ``\<new term> \texttt{equals} \<term expression>''
  requires proving the new term has the given type.
\endenumerate
Why do we need to prove well-definedness? Well, classical logic
requires proving there exists a model for a theory, so our hands are
tied. If we removed this restriction, then we'd end up with something
called ``free logic'', which is\dots weird.

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt
Functor-Definition = "func" Functor-Pattern [ Specification ]
\quad[ ( "means" \pipe\ "equals" ) Definiens ] ";"
\quad Correctness-Conditions \LB\ Functor-Property \RB\ .\smallbreak

Functor-Pattern = [ Functor-Loci ] Functor-Symbol [ Functor-Loci ]
\quad\pipe\ Left-Functor-Bracket Loci Right-Functor-Bracket .\smallbreak

Functor-Property = ( "commutativity" \pipe\ "idempotence" \pipe\ "involutiveness" \pipe\ "projectivity" )
\quad Justification ";" .\smallbreak

Functor-Synonym = "synonym" Functor-Pattern "for" Functor-Pattern ";" .\smallbreak

Functor-Loci = Locus \pipe\ "(" Loci ")" .\smallbreak

Functor-Symbol = Symbol .\smallbreak

Left-Functor-Bracket = Symbol \pipe\ "\LB" \pipe\ "[" .\smallbreak

Right-Functor-Bracket = Symbol \pipe\ "\RB" \pipe\ "]" .\par}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   FunctorDefinitionPtr = ^FunctorDefinitionObj; @/
   FunctorDefinitionObj =
      object(MObject) @t\1@> @/
         nDefFuncPos: Position; @/
         nDefFuncPattern: FunctorPatternPtr; @/
         nRedefinition: boolean; @/
         nSpecification: TypePtr; @/
         nDefiningWay: HowToDefine; @/
         nDefiniens: DefiniensPtr; @/
         constructor Init(const aPos:Position;@+ aRedef:boolean;@+ aPattern:FunctorPatternPtr;
                          aSpec:TypePtr;@+ aDefWay:HowToDefine;@+ aDef:DefiniensPtr); @t\2@>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FunctorDefinitionObj.Init(const aPos: Position; @+
aRedef: boolean;
 @t\qquad @>                                     aPattern:FunctorPatternPtr;@+ aSpec: TypePtr;@+
                                      aDefWay:HowToDefine;@+ aDef:DefiniensPtr);
begin
   nDefFuncPos:=aPos;
   nRedefinition:=aRedef;
   nDefFuncPattern:=aPattern;
   nSpecification:=aSpec;
   nDefiningWay:=aDefWay;
   nDefiniens:=aDef;
end;

destructor FunctorDefinitionObj.Done;
begin
   dispose(nDefFuncPattern,Done);
   dispose(nDefiniens,Done);
end;

@ \node{Notation block.} We can recall the syntax for notation blocks.

\medbreak
{\obeylines\parindent=0pt\tt
Notation-Block = "notation" \LB\ Loci-Declaration \pipe\ Notation-Declaration \RB\ "end" .\smallbreak

Notation-Declaration = Mode-Synonym
\quad\pipe\ Functor-Synonym
\quad\pipe\ Attribute-Synonym \pipe\ Attribute-Antonym
\quad\pipe\ Predicate-Synonym \pipe\ Predicate-Antonym .\smallbreak

Mode-Synonym = "synonym" Mode-Pattern "for" Mode-Pattern ";" .\smallbreak

Functor-Synonym = "synonym" Functor-Pattern "for" Functor-Pattern ";" .\smallbreak

Predicate-Synonym = "synonym" Predicate-Pattern "for" Predicate-Pattern ";" .\smallbreak

Predicate-Antonym = "antonym" Predicate-Pattern "for" Predicate-Pattern ";" .\smallbreak

Attribute-Synonym = "synonym" Attribute-Pattern "for" Attribute-Pattern ";" .\smallbreak

Attribute-Antonym = "antonym" Attribute-Pattern "for" Attribute-Pattern ";" .
\par}
\medbreak\noindent%
The reader will observe all these notation items relate a new pattern
which is either a synonym or antonym for an old pattern. That is to
say, we only need two patterns to store as data in a notation item
node in the abstract syntax tree.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   NotationDeclarationPtr = ^NotationDeclarationObj; @/
   NotationDeclarationObj =
      object(mObject) @t\1@> @/
         nNotationPos: Position; @/
         nNotationSort: ItemKind; @/
         nOriginPattern,nNewPattern: PatternPtr; @/
         constructor Init(const aPos:Position;@+ aNSort:ItemKind;@+ aNewPatt,aOrigPatt:PatternPtr);@t\2 @>
         destructor Done; virtual; @t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor NotationDeclarationObj.Init(const aPos:Position;@+ aNSort:ItemKind;
@t\qquad @> aNewPatt,aOrigPatt:PatternPtr);
begin
   nNotationPos:=aPos;
   nNotationSort:=aNSort;
   nOriginPattern:=aOrigPatt;
   nNewPattern:=aNewPatt;
end;

destructor NotationDeclarationObj.Done;
begin
   dispose(nOriginPattern,Done);
   dispose(nNewPattern,Done);
end;

@ \node{Assumptions in a definition block.} The syntax for assumptions
in a definition block looks like:

\medbreak
{\obeylines\parindent=0pt\tt
Assumption = Single-Assumption \pipe\ Collective-Assumption \pipe\ Existential-Assumption .\smallbreak

Single-Assumption = "assume" Proposition ";" .\smallbreak

Collective-Assumption = "assume" Conditions ";" .\smallbreak

Existential-Assumption = "given" Qualified-Variables [ "such" Conditions ] \rlap{";"\ .}\smallbreak

Conditions = "that" Proposition \LB\ "and" Proposition \RB\ .\smallbreak

Proposition = [ Label-Identifier ":" ] Sentence .\smallbreak

Sentence = Formula-Expression .
\par}

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   AssumptionKind = (SingleAssumption,CollectiveAssumption,ExistentialAssumption); @#

   AssumptionPtr = ^AssumptionObj; @/
   AssumptionObj =
      object(MObject) @t\1@> @/
         nAssumptionPos: Position; @/
         nAssumptionSort: AssumptionKind; @/
         constructor Init(const aPos:Position;@+ aSort:AssumptionKind);@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor AssumptionObj.Init(const aPos:Position;@+ aSort:AssumptionKind);
begin
   nAssumptionPos:=aPos;
   nAssumptionSort:=aSort;
end;

@ \node{Single assumption.} When a definition has a single assumption,
i.e., a single (usually labeled) formula.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SingleAssumptionPtr = ^SingleAssumptionObj; @/
   SingleAssumptionObj =
      object(AssumptionObj) @t\1@> @/
         nProp: PropositionPtr; @/
         constructor Init(const aPos:Position;@+ aProp:PropositionPtr); @t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SingleAssumptionObj.Init(const aPos:Position;@+ aProp:PropositionPtr);
begin
   inherited Init(aPos,SingleAssumption);
   nProp:=aProp;
end;

destructor SingleAssumptionObj.Done;
begin
   dispose(nProp,Done);
end;

@ \node{Collective assumption.} This describes the case when the
assumption is ``\texttt{assume} $C_{1}$ \texttt{and}
\dots \texttt{and} $C_{n}$''.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CollectiveAssumptionPtr = ^CollectiveAssumptionObj; @/
   CollectiveAssumptionObj =
      object(AssumptionObj) @t\1@> @/
         nConditions: PList; @/
         constructor Init(const aPos:Position;@+ aProps:PList); @t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CollectiveAssumptionObj.Init(const aPos:Position;@+ aProps:PList);
begin
   inherited Init(aPos,CollectiveAssumption);
   nConditions:=aProps;
end;

destructor CollectiveAssumptionObj.Done;
begin
   dispose(nConditions,Done);
end;

@ \node{Existential assumption.}
I must confess I am surprised to see an existential assumption node
being a subclass of a collective assumption node.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ExistentialAssumptionPtr = ^ExistentialAssumptionObj; @/
   ExistentialAssumptionObj =
      object(CollectiveAssumptionObj) @t\1@> @/
         nQVars: PList; @/
         constructor Init(const aPos:Position;@+ aQVars,aProps:PList); @t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ExistentialAssumptionObj.Init(const aPos:Position;@+ aQVars,aProps:PList);
begin
   AssumptionObj.Init(aPos,CollectiveAssumption);
   nConditions:=aProps;
   nQVars:=aQVars;
end;

destructor ExistentialAssumptionObj.Done;
begin
   dispose(nQVars,Done);
   inherited Done;
end;

@ \node{Correctness conditions.} % section 132, pg 39
The syntax for correctness conditions:

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt%\tt

Correctness-Conditions = \LB Correctness-Condition\RB\ \rlap{[\ "correctness"\ Justification ";" ] .}\smallbreak

Correctness-Condition =
\quad( "existence" \pipe\ "uniqueness" \pipe\ "coherence" \pipe\ "compatibility" \pipe\ "consistency" \pipe\ "reducibility" ) 
\quad Justification ";" .
\par}
\medbreak\noindent%
We begin with an abstract base class for correctness conditions.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CorrectnessPtr =^CorrectnessObj; @/
   CorrectnessObj =
      object(MObject) @t\1@> @/
         nCorrCondPos: Position; @/
         nJustification: JustificationPtr; @/
         constructor Init(const aPos:Position;@+ aJustification:JustificationPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CorrectnessObj.Init(const aPos:Position;@+ aJustification:JustificationPtr);
begin
   nCorrCondPos:=aPos;
   nJustification:=aJustification;
end;

destructor CorrectnessObj.Done;
begin
   dispose(nJustification,Done);
end;

@ \node{Correctness condition.} For the correctness condition
associated with a definition or registration, we have
this \\{CorrectnessCondition} object. When we need multiple
correctness conditions, we extend it with a subclass.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CorrectnessConditionPtr =^CorrectnessConditionObj; @/
   CorrectnessConditionObj =
      object(CorrectnessObj) @t\1@> @/
         nCorrCondSort: CorrectnessKind; @/
         constructor Init(const aPos:Position;@+ aSort:CorrectnessKind;@+
                          aJustification:JustificationPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CorrectnessConditionObj.Init(const aPos:Position;
 @t\qquad @> aSort:CorrectnessKind; @+
                          aJustification:JustificationPtr);
begin
   inherited Init(aPos,aJustification);
   nCorrCondSort:=aSort;
end;

destructor CorrectnessConditionObj.Done;
begin
   inherited Done;
end;

@ \node{Multiple correctness conditions.}
For, e.g., functors which require proving both ``existence'' and
``uniqueness'', we have a \\{CorrectnessConditions} class. This
extends the [singular] \\{CorrectnessCondition} class.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CorrectnessConditionsSet = set of CorrectnessKind; @#

   CorrectnessConditionsPtr =^CorrectnessConditionsObj; @/
   CorrectnessConditionsObj =
      object(CorrectnessObj) @t\1@> @/
         nConditions: CorrectnessConditionsSet; @/
         constructor Init(const aPos:Position;@+ const aConds: CorrectnessConditionsSet;
                          aJustification:JustificationPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CorrectnessConditionsObj.Init(const aPos:Position;
 const aConds: CorrectnessConditionsSet;
   @t\qquad @>                            aJustification:JustificationPtr);
begin
   inherited Init(aPos,aJustification);
   nConditions:=aConds;
end;

destructor CorrectnessConditionsObj.Done;
begin
   inherited Done;
end;

@ \node{Definition properties.} The grammar for properties in a
definition looks like:
\medbreak
{\obeylines\parindent=0pt\tt
Mode-Property = "sethood" Justification ";" .\smallbreak

Functor-Property = ("commutativity" \pipe\ "idempotence" \pipe\ "involutiveness" \pipe\ "projectivity")
\quad Justification ";" .\smallbreak

Predicate-Property = ("symmetry" \pipe\ "asymmetry" \pipe\ "connectedness" \pipe\ "reflexivity" \rlap{\pipe\ "irreflexivity")}
\quad Justification ";" .
\par}
\medbreak\noindent%
We see these are all, more or less, ``the same'': we have a ``kind''
of property and a justification. We recall
(\section\xref{PropertyKind}) that we have already introduced the
``kind'' of properties. So the class describing a definition property
node in the abstract syntax tree is:

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PropertyPtr =^PropertyObj; @/
   PropertyObj =
      object(MObject) @t\1@> @/
         nPropertyPos: Position; @/
         nPropertySort: PropertyKind; @/
         nJustification: JustificationPtr; @/
         constructor Init(const aPos:Position;@+ aSort:PropertyKind;@+ aJustification:JustificationPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=

constructor PropertyObj.Init(const aPos:Position;@+ aSort:PropertyKind;
 @t\qquad @>                 aJustification:JustificationPtr);
begin
   nPropertyPos:=aPos;
   nPropertySort:=aSort;
   nJustification:=aJustification;
end;

destructor PropertyObj.Done;
begin
   inherited Done;
end;

@* [S] Registrations.
There are three ``main'' types of registrations, which are ``cluster
registrations'' (because they all involve the ``\texttt{cluster}'' keyword):
\enumerate
\item Existential registrations are of the form ``\texttt{cluster}
\<attributes> \texttt{for} \<type>''
and establishes that a given attribute can act as an adjective for the
type.
\item Conditional registrations are of the form
``\texttt{cluster}
$\langle\textit{attribute}_{1}\rangle$ \texttt{->} $\langle\textit{attribute}_{2}\rangle$ \texttt{for} \<type>''
which tells Mizar that when $\langle\textit{attribute}_{1}\rangle$ is
established for a term, then Mizar can automatically add
$\langle\textit{attribute}_{2}\rangle$ for the term
\item Functorial registrations are of the form
``\texttt{cluster}
\<term> \texttt{->} \<attribute> [\texttt{for} \<type>]''
which will automatically add an attribute to a term.
\endenumerate
\medbreak\noindent%
We also have three lesser registrations which are still important:
\enumerate
\item Sethood registrations, establishes a type can be used as a set
in a Fraenkel term.
\item Reduction registration, which allows Mizar's term rewriting
module to use this rule when reasoning about things.
\item Identification registration, which allows Mizar to identify
terms of different types.
\endenumerate

\label{esm:ast:registrations}

\medbreak
{\obeylines\parindent=0pt\ninett\baselineskip=11pt
Cluster-Registration = Existential-Registration
\quad\pipe\ Conditional-Registration
\quad\pipe\ Functorial-Registration .\smallbreak

Existential-Registration = "cluster" Adjective-Cluster "for" \rlap{Type-Expression ";" }
\quad Correctness-Conditions . \smallbreak

Adjective-Cluster = \LB\ Adjective \RB\ .\smallbreak

Adjective = [ "non" ] [ Adjective-Arguments ] Attribute-Symbol .\smallbreak

Conditional-Registration = "cluster" Adjective-Cluster "->" \rlap{Adjective-Cluster "for" Type-Expression ";"}
\quad Correctness-Conditions .\smallbreak

Functorial-Registration = "cluster" Term-Expression "->" \rlap{Adjective-Cluster [ "for" Type-Expression ] ";"}
\quad Correctness-Conditions .\smallbreak

Identify-Registration = "identify" Functor-Pattern "with" Functor-Pattern
\qquad [ "when" Locus "=" Locus \LB\ "," Locus "=" Locus \RB\ ] ";"
\quad Correctness-Conditions .\smallbreak

Property-Registration = "sethood" "of" Type-Expression Justification ";" .\smallbreak

Reduction-Registration = "reduce" Term-Expression "to" Term-Expression ";"
\quad Correctness-Conditions .
\par}

@ \node{Cluster registration.} We have a base class for the three
types of cluster registrations.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ClusterRegistrationKind = (ExistentialRegistration,ConditionalRegistration,
                              FunctorialRegistration); @#

   ClusterPtr = ^ClusterObj; @/
   ClusterObj =
      object(MObject) @t\1@> @/
         nClusterPos: Position; @/
         nClusterKind: ClusterRegistrationKind; @/
         nConsequent: PList; @/
         nClusterType: TypePtr; @/
         constructor Init(const aPos: Position;@+ aKind:ClusterRegistrationKind;@+ aCons:PList; aTyp:TypePtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ClusterObj.Init(const aPos: Position;
@t\qquad @> aKind:ClusterRegistrationKind;@+ aCons:PList;@+ aTyp:TypePtr);
begin
   nClusterPos:=aPos;
   nClusterKind:=aKind;
   nConsequent:=aCons;
   nClusterType:=aTyp;
end;

destructor ClusterObj.Done;
begin
   dispose(nConsequent,Done);
end;

@ \node{Existential cluster.} We register the fact there always exists
a term of a given type satisfying an attribute (e.g., ``empty'' for
``set'' means there always exists an empty set;
registering the existential cluster ``non empty'' for ``set'' means
there always exists a nonempty set).
This means the attribute may henceforth be used as an adjective on the type.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   EClusterPtr = ^EClusterObj; @/
   EClusterObj =
      object(ClusterObj) @t\1@> @/
         constructor Init(const aPos: Position;@+ aCons:PList;@+ aTyp:TypePtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}
There are no additional fields to an existential cluster object, so it
literally passes the parameters onto the superclass's constructor.

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor EClusterObj.Init(const aPos: Position;@+ aCons:PList;@+ aTyp:TypePtr);
begin
   ClusterObj.Init(aPos,ExistentialRegistration,aCons,aTyp);
end;

destructor EClusterObj.Done;
begin
   if nClusterType <> nil then dispose(nClusterType,Done);
   inherited Done;
end;

@ \node{Conditional cluster.} For example ``empty sets'' are always
``finite sets''. This requires tracking the antecedent (``empty''),
and the superclass tracks the consequents (``finite'').

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   CClusterPtr = ^CClusterObj; @/
   CClusterObj =
      object(ClusterObj) @t\1@> @/
         nAntecedent: PList; @/
         constructor Init(const aPos: Position;@+ aAntec,aCons:PList;@+ aTyp:TypePtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor CClusterObj.Init(const aPos:Position;@+ aAntec,aCons:PList;@+ aTyp:TypePtr);
begin
   ClusterObj.Init(aPos,ConditionalRegistration,aCons,aTyp);
   nAntecedent:=aAntec;
end;

destructor CClusterObj.Done;
begin
   dispose(nAntecedent,Done);
   inherited Done;
end;

@ \node{Functorial cluster.} The generic form a functorial
registrations associated to a term some cluster of adjectives. We need
to track the term, but the superclass can manage the cluster of
adjectives. 

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   FClusterPtr = ^FClusterObj; @/
   FClusterObj =
      object(ClusterObj) @t\1@> @/
         nClusterTerm: TermPtr; @/
         constructor Init(const aPos: Position;@+ aTrm:TermPtr;@+ aCons:PList;@+ aTyp:TypePtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor FClusterObj.Init(const aPos: Position;
@t\qquad @> aTrm:TermPtr;@+ aCons:PList;@+ aTyp:TypePtr);
begin
   ClusterObj.Init(aPos,FunctorialRegistration,aCons,aTyp);
   nClusterTerm:=aTrm;
end;

destructor FClusterObj.Done;
begin
   if nClusterTerm <> nil then Dispose(nClusterTerm,Done);
   if nClusterType <> nil then dispose(nClusterType,Done);
   inherited Done;
end;


@ \node{Loci equality.} This is used in identification registrations.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   LociEqualityPtr = ^LociEqualityObj; @/
   LociEqualityObj =
      object(mObject) @t\1@> @/
         nEqPos: Position; @/
         nLeftLocus,nRightLocus: LocusPtr; @/
         constructor Init(const aPos:Position;@+ aLeftLocus,aRightLocus:LocusPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor LociEqualityObj.Init(const aPos:Position;@+ aLeftLocus,aRightLocus:LocusPtr);
begin
   nEqPos:=aPos;
   nLeftLocus:=aLeftLocus;
   nRightLocus:=aRightLocus;
end;

destructor LociEqualityObj.Done;
begin
   Dispose(nLeftLocus,Done);
   dispose(nRightLocus,Done);
end;

@ \node{Identification registration.}
Term identification was first introduced in
Artur Korni\l{}owicz's ``How to define terms in Mizar effectively''
(in A.\ Grabowski and A.\ Naumowicz (eds.),
\emph{Computer Reconstruction of the Body of Mathematics},
issue of \emph{Studies in Logic, Grammar and
Rhetoric} \textbf{18} no.31 (2009), pp. 67--77). See also \section2.7
of Adam Grabowski,
Artur Korni\l{}owicz, and
Adam Naumowicz's ``Mizar in a Nutshell'' (\doi{10.6092/issn.1972-5787/1980})
for user-oriented details.
@^Grabowski, Adam@>
@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>
@^Naumowicz, Adam@>

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   IdentifyRegistrationPtr = ^IdentifyRegistrationObj; @/
   IdentifyRegistrationObj =
      object(mObject) @t\1@> @/
         nIdentifyPos: Position; @/
         nOriginPattern,nNewPattern: PatternPtr; @/
         nEqLociList:PList; @/
         constructor Init(const aPos:Position;@+ aNewPatt,aOrigPatt:PatternPtr;@+ aEqList:PList);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor IdentifyRegistrationObj.Init(const aPos:Position;
@t\qquad @> aNewPatt,aOrigPatt:PatternPtr;@+ aEqList:PList);
begin
   nIdentifyPos:=aPos;
   nOriginPattern:=aOrigPatt;
   nNewPattern:=aNewPatt;
   nEqLociList:=aEqList;
end;

destructor IdentifyRegistrationObj.Done;
begin
   dispose(nOriginPattern,Done);
   dispose(nNewPattern,Done);
   if nEqLociList <> nil then
      dispose(nEqLociList,Done);
end;


@ \node{Property registration.} These were introduced in Mizar to
facilitated registering ``\texttt{sethood}'' for types. Thus far, only the
``\texttt{sethood}'' property is handled in this registration.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   PropertyRegistrationPtr = ^PropertyRegistrationObj; @/
   PropertyRegistrationObj =
      object(mObject) @t\1@> @/
         nPropertyPos: Position; @/
         nPropertySort: PropertyKind; @/
         constructor Init(const aPos:Position;@+ aKind:PropertyKind);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor PropertyRegistrationObj.Init(const aPos:Position;@+ aKind:PropertyKind);
begin
   nPropertyPos:=aPos;
   nPropertySort:=aKind;
end;

destructor PropertyRegistrationObj.Done;
begin
end;


@ \node{Sethood registration.}
Artur Korni\l{}owicz's ``Sethood Property in Mizar''
(in \emph{Joint Proc.\ FMM and LML Workshops}, 2019,
\href{https://ceur-ws.org/Vol-2634/FMM3.pdf}{{\tt ceur-ws.org/Vol-2634/FMM3.pdf}})
introduces this ``sethood'' property. It's the first (and, so far, only)
property registration in Mizar.

@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   SethoodRegistrationPtr = ^SethoodRegistrationObj; @/
   SethoodRegistrationObj =
      object(PropertyRegistrationObj) @t\1@> @/
         nSethoodType: TypePtr; @/
         nJustification: JustificationPtr; @/
         constructor Init(const aPos:Position;@+ aKind:PropertyKind;@+ aType:TypePtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end; @#

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor SethoodRegistrationObj.Init(const aPos:Position;
@t\qquad @> aKind:PropertyKind;@+ aType:TypePtr);
begin
   inherited Init(aPos,aKind);
   nSethoodType:=aType;
   nJustification:=nil;
end;

destructor SethoodRegistrationObj.Done;
begin
   dispose(nSethoodType,Done);
   dispose(nJustification,Done);
   inherited Done;
end;


@ \node{Reduce registration.}
These were introduced, I think, in Artur Korni\l{}owicz's ``On rewriting rules in Mizar''
(\emph{J.\ Autom.\ Reason.} \textbf{50} no.2 (2013) 203--210,
\doi{10.1007/s10817-012-9261-6}). These extend the checker with new
term rewriting rules.

@^Term rewriting@>
@:Kornilowicz, Artur}{Korni\l{}owicz, Artur@>

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   ReduceRegistrationPtr = ^ReduceRegistrationObj; @/
   ReduceRegistrationObj =
      object(MObject) @t\1@> @/
         nReducePos: Position; @/
         nOriginTerm,nNewTerm:TermPtr; @/
         constructor Init(const aPos:Position;@+ aOrigTerm,aNewTerm:TermPtr);@t\2 @>
         destructor Done; virtual;@t\2\2\2@>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor ReduceRegistrationObj.Init(const aPos:Position;@+ aOrigTerm,aNewTerm:TermPtr);
begin
   nReducePos:=aPos;
   nOriginTerm:=aOrigTerm;
   nNewTerm:=aNewTerm;
end;

destructor ReduceRegistrationObj.Done;
begin
   dispose(nOriginTerm,Done);
   dispose(nNewTerm,Done);
end;

@* [S] Helper functions.
Capitlization checks if the first character $c$ is lowercase. If so,
then set the leading character to be |c := c - (ord('a') - ord('A'))|.
But it leaves the rest of the string untouched.

@<Implementation for \texttt{wsmarticle.pas}@>=
function CapitalizeName(aName: string): string;
begin
   result:=aName;
   if aName[1] in ['a'..'z'] then
      dec(Result[1], ord('a') - ord('A'))
end;

@ Uncapitalizing works in the opposite direction, setting the first
letter $c$ of a string to be |c := c + (ord('a') - ord('A'))|.
Observe capitalizing and uncapitalizing are ``nearly inverses'' of
each other: |CapitalizeName(UncapitalizeName(CapitalizeName(s)))=CapitalizeName(s)|,
and similarly we find\hfill\break
|UncapitalizeName(CapitalizeName(UncapitalizeName(s)))=UncapitalizeName(s)|. 

@<Implementation for \texttt{wsmarticle.pas}@>=
function UncapitalizeName(aName: string): string;
begin
   result:=aName;
   if aName[1] in ['A'..'Z'] then
      inc(Result[1], ord('a') - ord('A'))
end;

@ We will be populating global variables tracking names of
identifiers, modes, and other syntactic classes.

@<Global variables publicly declared in \texttt{wsmarticle.pas}@>=
var
   IdentifierName,AttributeName,StructureName,ModeName,PredicateName,FunctorName,SelectorName,LeftBracketName,RightBracketName,MMLIdentifierName: array of string;

@ We will want to initialize these global variables based on previous
passes of the scanner.

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure InitScannerNames;
var i,lCnt,lNr: integer;
lDct: text;
lInFile: XMLInStreamPtr;
lKind,lDummy:AnsiChar; lString: string;
begin
   @<Populate global variables with \XML/ entities@>;
   @<Reset reserved keywords@>; @/
   {Identifiers}
   @<Initialize identifier names from \texttt{.idx} file@>;
end;

@ We need to initialize the length for each of these arrays. Even a
crude approximation works, like the total number of lines in
the \texttt{.dct} file. Then we transform each line of the \\{lDct}
(dictionary file) into appropriate entries of the relevant array.

@:dct file}{\texttt{.dct} file@>
@:File, dct}{File, \texttt{.dct}@>

@<Populate global variables with \XML/ entities@>=
   assign(lDct,MizFileName+'.dct');
   reset(lDct);
   lCnt:=0;
   while not seekEof(lDct) do
   begin
      readln(lDct);
      inc(lCnt);
   end;
   setlength(AttributeName,lCnt);
   setlength(StructureName,lCnt);
   setlength(ModeName,lCnt);
   setlength(PredicateName,lCnt);
   setlength(FunctorName,lCnt);
   setlength(SelectorName,lCnt);
   setlength(LeftBracketName,lCnt);
   setlength(RightBracketName,lCnt);
   setlength(MMLIdentifierName,lCnt);
   reset(lDct);
   while not seekEof(lDct) do
   begin
      readln(lDct,lKind,lNr,lDummy,lString);
      @<Store \XML/ version of vocabulary word@>;
   end;
   close(lDct)

@ We have read in from the ``\texttt{.dct}'' file one line. The first
148 lines of a ``\texttt{.dct}'' file consists of the reserved
keywords for Mizar. A random example of the last few lines of such a file look like:

\medbreak
{\obeylines\parindent=0pt\advance\leftskip3pc\tt
A36 VECTSP\_4
A37 ORDINAL1
A38 CARD\_FIL
A39 RANKNULL
A40 VECTSP\_1
A41 VECTSP\_6
A42 VECTSP13
A43 ALGSTR\_0
A44 HALLMAR1
A45 MATROID0\par}

\medbreak\noindent%
So we read the first leading letter of a line into \\{lKind}, then the
number into \\{lNr}, the space is stuffed into \\{lDummy}, and the
remainder of the line is placed in \\{lString}.

@:dct file}{\texttt{.dct} file@>
@:File, dct}{File, \texttt{.dct}@>

@<Store \XML/ version of vocabulary word@>=
      case lKind of
         'A': MMLIdentifierName[lNr]:=QuoteStrForXML(lString);
         'G': StructureName[lNr]:=QuoteStrForXML(lString);
         'M': ModeName[lNr]:=QuoteStrForXML(lString);
         'K': LeftBracketName[lNr]:=QuoteStrForXML(lString);
         'L': RightBracketName[lNr]:=QuoteStrForXML(lString);
         'O': FunctorName[lNr]:=QuoteStrForXML(lString);
         'R': PredicateName[lNr]:=QuoteStrForXML(lString);
         'U': SelectorName[lNr]:=QuoteStrForXML(lString);
         'V': AttributeName[lNr]:=QuoteStrForXML(lString);
      endcases

@ \node{Preserve reserved keywords.}
We want to prevent the user from ``overwriting'' or ``shadowing''
the builtin primitive reserved words. This should probably be
documented in the user-manual somewhere. The reserved words are:
``\texttt{strict}'',  ``\texttt{set}'',``\texttt{=}'', and the
brackets \texttt{[\hskip1pt]}, braces \texttt{\LB\hskip1pt\RB}, and
parentheses \texttt{(\hskip1pt)}. Curiously, ``\texttt{object}'' is
not considered a `primitive' worth preserving.

@<Reset reserved keywords@>=
   AttributeName[StrictSym]:='strict';
   ModeName[SetSym]:='set';
   PredicateName[EqualitySym]:='=';
   LeftBracketName[SquareBracket]:='[';
   LeftBracketName[CurlyBracket]:='{';
   LeftBracketName[RoundedBracket]:='(';
   RightBracketName[SquareBracket]:=']';
   RightBracketName[CurlyBracket]:='}';
   RightBracketName[RoundedBracket]:=')'

@ The \texttt{.idx} file provides numbers for the local labels and
article names referenced in an article.

@:idx File}{\texttt{.idx} File@>
@:File, idx}{File, \texttt{.idx}@>

@<Initialize identifier names from \texttt{.idx} file@>=
   assign(lDct,MizFileName+'.idx');
   reset(lDct);
   lCnt:=0;
   while not seekEof(lDct) do
   begin
      readln(lDct);
      inc(lCnt);
   end;
   close(lDct); @#
   setlength(IdentifierName,lCnt);
   IdentifierName[0]:='';
   lInFile:=new(XMLInStreamPtr,OpenFile(MizFileName+'.idx'));
   lInFile^.NextElementState;
   lInFile^.NextElementState;
   while (lInFile.nState = eStart) and (lInFile.nElName = XMLElemName[elSymbol]) do
   begin
      lNr:=lInFile^.GetIntAttr('nr');
      lString:=lInFile^.GetAttr('name');
      IdentifierName[lNr]:=lString;
      lInFile^.NextElementState;
      lInFile^.NextElementState;
   end;
   dispose(lInFile,Done)

@ We will want to obtain the name for an article ID number, provided
it is a legal number (i.e., less than the dictionary for article ID numbers).
This function looks up its entry in the \\{IdentifierName} array.

@<Implementation for \texttt{wsmarticle.pas}@>=
function IdentRepr(aIdNr:integer):string;
begin
   mizassert(2000,aIdNr <= length(IdentifierName));
   if aIdNr > 0 then
      IdentRepr := IdentifierName[aIdNr]
   else IdentRepr := '';
end;

@* [S] Writing WSM XML files.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   OutWSMizFilePtr = ^OutWSMizFileObj; @/
   OutWSMizFileObj =
      object(XMLOutStreamObj) @t\1 @> @/
         nDisplayInformationOnScreen: boolean; @/
         nMizarAppearance: boolean; @/
         constructor OpenFile(const aFileName:string );@t\2@>
         constructor OpenFileWithXSL(const aFileName:string );@t\2@>
         destructor Done; virtual;@t\2@>

         procedure Out_TextProper(aWSTextProper:WSTextProperPtr); virtual;@t\2@>
         procedure Out_Block(aWSBlock:WSBlockPtr); virtual;@t\2@>
         procedure Out_Item(aWSItem:WSItemPtr); virtual;@t\2@>

         procedure Out_ItemContentsAttr(aWSItem:WSItemPtr); virtual;@t\2@>
         procedure Out_ItemContents(aWSItem:WSItemPtr); virtual;@t\2@>

         procedure Out_Variable( aVar: VariablePtr); virtual;@t\2@>
         procedure Out_ReservedVariable( aVar: VariablePtr); virtual;@t\2@>@#

         procedure Out_TermList ( aTrmList:PList ); virtual;@t\2@>
         procedure Out_Adjective(aAttr:AdjectiveExpressionPtr ); virtual;@t\2@>
         procedure Out_AdjectiveList( aCluster: PList ); virtual;@t\2@>
         procedure Out_Type ( aTyp: TypePtr ); virtual;@t\2@>
         procedure Out_ImplicitlyQualifiedVariable( aSegm: ImplicitlyQualifiedSegmentPtr); virtual;@t\2@>
         procedure Out_VariableSegment( aSegm: QualifiedSegmentPtr); virtual;@t\2@>
         procedure Out_PrivatePredicativeFormula ( aFrm: PrivatePredicativeFormulaPtr ); virtual;@t\2@>
         procedure Out_Formula ( aFrm:FormulaPtr ); virtual;@t\2@>
         procedure Out_Term ( aTrm: TermPtr ); virtual;@t\2@>
         procedure Out_SimpleTerm ( aTrm: SimpleTermPtr ); virtual;@t\2@>
         procedure Out_PrivateFunctorTerm ( aTrm: PrivateFunctorTermPtr ); virtual;@t\2@>
         procedure Out_InternalSelectorTerm ( aTrm: InternalSelectorTermPtr ); virtual;@t\2@>

         procedure Out_TypeList ( aTypeList: PList ); virtual;@t\2@>

         procedure Out_Locus( aLocus: LocusPtr); virtual;@t\2@>
         procedure Out_Loci( aLoci: PList); virtual;@t\2@>
         procedure Out_Pattern(aPattern: PatternPtr); virtual;@t\2@>@#

         procedure Out_Label(aLab:LabelPtr); virtual;@t\2@>
         procedure Out_Definiens(aDef:DefiniensPtr); virtual;@t\2@>@#

         procedure Out_ReservationSegment(aRes:ReservationSegmentPtr); virtual;@t\2@>
         procedure Out_SchemeNameInSchemeHead(aSch: SchemePtr); virtual;@t\2@>
         procedure Out_CompactStatement(aCStm:CompactStatementPtr; aBlock:wsBlockPtr); virtual;@t\2@>
         procedure Out_RegularStatement(aRStm:RegularStatementPtr; aBlock:wsBlockPtr); virtual;@t\2@>
         procedure Out_Proposition(aProp:PropositionPtr); virtual;@t\2@>
         procedure Out_LocalReference(aRef: LocalReferencePtr); virtual;@t\2@>
         procedure Out_References(aRefs: PList); virtual;@t\2@>
         procedure Out_Link(aInf: JustificationPtr); virtual;@t\2@>
         procedure Out_SchemeJustification(aInf: SchemeJustificationPtr); virtual;@t\2@>
         procedure Out_Justification(aInf: JustificationPtr; aBlock:wsBlockPtr); virtual;@t\2\2\2@>
      end;

@ \node{Constructor.} The constructor 
\\{OutWSMizFileObj.OpenFileWithXSL} is not used anywhere, nor is the
associated ``\texttt{wsmiz.xml}'' file present anywhere.

Importantly, the \\{nMizarAppearance} field controls whether the \XML/
generated includes the raw lexeme string as an attribute in the \XML/
elements or not.

The constructor \\{OpenFileWithXSL} is never used. The \XML/
stylesheet \texttt{wsmiz.xml} does not seem to be present in the Mizar
distribution. 

\label{OutWSMizFileObj.OpenFileWithXSL}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor OutWSMizFileObj.OpenFile(const aFileName:string);
begin
   inherited OpenFile( aFileName);
   nMizarAppearance:=false;
   nDisplayInformationOnScreen:=false;
end;

constructor OutWSMizFileObj.OpenFileWithXSL(const aFileName:string);
begin
   inherited OpenFile( aFileName);
   OutString('<?xml-stylesheet type="text/xml" href="file://'+MizFiles+'wsmiz.xml"?>'+#10);
   nMizarAppearance:=false;
end;

destructor OutWSMizFileObj.Done;
begin
   inherited Done;
end;

@ We can write the \XML/ for a \\{wsTextProper} object
(\section\xref{wsTextProper:ast}). This writes out the start tag, the
children, and the end-tag for the ``text proper'' and its
contents. The RNG compact schema for this looks like:

\medbreak
{\schema
TextProper = element Text-Proper \LB
\idnr{\quad},
\pos{\quad},
\quad  Item*
\RB\par}
@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_TextProper(aWSTextProper:WSTextProperPtr);
var i: integer;
begin
   with aWSTextProper^ do
   begin {Write the start-tag}
      Out_XElStart(BlockName[blMain]);
      Out_XAttr( XMLAttrName[atArticleId], nArticleId);
      Out_XAttr( XMLAttrName[atArticleExt], nArticleExt);
      Out_PosAsAttrs(nBlockPos);
      Out_XAttrEnd; 
      for i := 0 to nItems^.Count - 1 do
         Out_Item(nItems.Items^[i]); {...then write the children}
      Out_XElEnd( BlockName[blMain]);
   end;
end;

@ Writing a block out as \XML/ works similarly: write the start-tag,
then its children elements, then the end-tag.

\medbreak
{\schema
Block = element Block \LB
\quad attribute kind \LB\ "Text-Proper" \pipe\ "Now-Reasoning"
\qquad\pipe\ "Hereby-Reasoning" \pipe\ "Definitional-Block"
\qquad\pipe\ "Notation-Block" \pipe\ "Registration-Block" \pipe\ "Case"
\qquad\pipe\ "Suppose" \pipe\ "Scheme-Block" \RB,
\idnr{\quad},
\pos{\quad},
\quad  Item*
\RB\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Block(aWSBlock:WSBlockPtr);
var i: integer;
begin
   with aWSBlock^ do
   begin {write the start-tag}
      Out_XElStart( XMLElemName[elBlock]);
      Out_XAttr( XMLAttrName[atKind], BlockName[nBlockKind]);
      CurPos:=nBlockPos;
      Out_PosAsAttrs(nBlockPos);
      Out_XIntAttr( XMLAttrName[atPosLine], nBlockEndPos.Line);
      Out_XIntAttr( XMLAttrName[atPosCol], nBlockEndPos.Col);
      Out_XAttrEnd;
      for i := 0 to nItems^.Count - 1 do
      begin
         Out_Item(nItems^.Items^[i]); @+
      end; {Then write the children}
      Out_XElEnd( XMLElemName[elBlock]);
   end;
end;

@ Writing a term list to  \XML/ amounts to just writing the terms
as \XML/ elements. They will be contained in a parent element, so
there will be no ambiguity in their role.

\medbreak
{\schema
Term-List = ( Term* )
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_TermList ( aTrmList:PList );
var i: integer;
begin
   for i:=0 to aTrmList^.Count-1 do
      Out_Term(aTrmList^.Items^[i]);
end;

@ The \XML/ for an adjective boils down to two cases:

Case 1 (negated attribute). Write a \texttt{<NegatedAdjective>} tag
around the \XML/ produced from case 2 for the positive version of the attribute.

Case 2 (positive attribute). Write the adjective, and its children are
the [term] arguments to the adjective (if any --- if there are none,
then an empty-element will be produced).

\medbreak
{\schema
PositiveAdjective = element Adjective \LB
\quad attribute nr \LB\ xsd:integer \RB,
\quad attribute name \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad}
\quad Term*
\RB
Adjective = PositiveAdjective \pipe\ element NegatedAdjective \LB
\pos{\quad},
\quad PositiveAdjective
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Adjective(aAttr:AdjectiveExpressionPtr);
begin
   case aAttr^.nAdjectiveSort of
      wsAdjective:
         begin
            Out_XElStart( XMLElemName[elAdjective]);
            with AdjectivePtr(aAttr)^ do
            begin
               Out_XIntAttr( XMLAttrName[atNr],nAdjectiveSymbol );
               if nMizarAppearance then
                  Out_XAttr( XMLAttrName[atSpelling], AttributeName[nAdjectiveSymbol]);
               Out_PosAsAttrs(nAdjectivePos);
               if nArgs^.Count = 0 then
                  Out_XElEnd0
               else
               begin
                  Out_XAttrEnd;
                  Out_TermList( nArgs );
                  Out_XElEnd( XMLElemName[elAdjective]);
               end;
            end;
         end;
      wsNegatedAdjective:
         begin
            Out_XElStart( XMLElemName[elNegatedAdjective]);
            with NegatedAdjectivePtr(aAttr)^ do
            begin
               Out_PosAsAttrs(nAdjectivePos);
               Out_XAttrEnd;
               Out_Adjective( nArg );
            end;
            Out_XElEnd( XMLElemName[elNegatedAdjective]);
         end;
   endcases;
end;

@ Writing an adjective list to \XML/ amounts to stuffing all the
adjectives into an element. If there are no adjectives, it is the
empty-element.

\medbreak
{\schema
Adjective-Cluster = element Adjective-Cluster \LB
\quad attribute count \LB\ xsd:integer \RB,
\quad Adjective*
\RB\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_AdjectiveList(aCluster: PList);
var i: integer;
begin
   Out_XElStart( XMLElemName[elAdjectiveCluster]);
   if aCluster^.Count = 0 then begin Out_XElEnd0; exit; end;
   Out_XAttrEnd;
   with aCluster^ do
      for i:=0 to Count-1 do
         Out_Adjective( Items^[i]);
   Out_XElEnd( XMLElemName[elAdjectiveCluster]);
end;

@* [s] Emitting XML for types.
Writing the \XML/ for a Mizar type.

\medbreak
{\schema
StandardType = element Standard-Type \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Term*
\RB
StructureType = element Structure-Type \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Term*
\RB
ClusteredType = element Clustered-Type \LB
\pos{\quad},
\quad Adjective-Cluster,
\quad Type,
\RB
Type = StandardType \pipe\ StructureType \pipe\ ClusteredType
\par}

@d print_arguments(#) == if  nArgs^.Count = 0 then Out_XElEnd0
            else begin
               Out_XAttrEnd;
               Out_TermList( nArgs );
               Out_XElEnd( TypeName[#] );
            end

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Type ( aTyp: TypePtr);
begin
   with aTyp^ do
      case aTyp^.nTypeSort of
         wsStandardType:
            with StandardTypePtr(aTyp)^ do
         begin
            Out_XElStart( TypeName[wsStandardType] );
            Out_XIntAttr( XMLAttrName[atNr], nModeSymbol );
            if nMizarAppearance then
               Out_XAttr( XMLAttrName[atSpelling], ModeName[nModeSymbol]);
            Out_PosAsAttrs(nTypePos);
            print_arguments(wsStandardType);
         end;
         wsStructureType:
            with StructTypePtr(aTyp)^ do
         begin
            Out_XElStart( TypeName[wsStructureType] );
            Out_XIntAttr( XMLAttrName[atNr], nStructSymbol );
            if nMizarAppearance then
               Out_XAttr( XMLAttrName[atSpelling], StructureName[nStructSymbol]);
            Out_PosAsAttrs(nTypePos);
            print_arguments(wsStructureType);
         end;
         wsClusteredType:
            with ClusteredTypePtr(aTyp)^ do
         begin
            Out_XElStart( TypeName[wsClusteredType] );
            Out_PosAsAttrs(nTypePos);
            Out_XAttrEnd;
            Out_AdjectiveList(nAdjectiveCluster);
            Out_Type(nType);
            Out_XElEnd( TypeName[wsClusteredType] );
         end;
         wsErrorType:
            begin
               Out_XElWithPos(TypeName[wsErrorType],nTypePos);
            end;
      endcases;
end;

@ Printing a variable as an \XML/ element.

\medbreak
{\schema
Variable = element Variable \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad}
\RB\par}

\label{OutWSMizFileObj.Out_Variable}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Variable( aVar: VariablePtr);
begin
   with aVar ^ do
   begin
      Out_XElStart( XMLElemName[elVariable]);
      Out_XIntAttr( XMLAttrName[atIdNr], nIdent);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nIdent));
      Out_PosAsAttrs(nVarPos);
      Out_XElEnd0
   end;
end;

@ Variables introduced using ``\texttt{reserve}'' are just printed out
like any other variable.

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_ReservedVariable( aVar: VariablePtr);
begin
   Out_Variable(aVar);
end;

@ Implicitly qualified variables (i.e., variables which
are \texttt{reserved} with a type, then used in, e.g., a quantified
formula) are just variables appearing as children of an ``implicitly
qualified'' \XML/ element.

{\tt\obeylines
VariableSegment \pipe= element Implicitly-Qualified-Segment \LB
\pos{\quad},
\quad Variable
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_ImplicitlyQualifiedVariable( aSegm: ImplicitlyQualifiedSegmentPtr);
begin
   Out_XElStart( SegmentKindName[ikImplQualifiedSegm]);
   Out_PosAsAttrs(aSegm^.nSegmPos);
   Out_XAttrEnd;
   Out_Variable( aSegm^.nIdentifier);
   Out_XElEnd( SegmentKindName[ikImplQualifiedSegm]);
end;

@ Qualified variable segments are either implicitly qualified (hence
we use the previous function) or explicitly qualified (which look like
``\<variable list> \texttt{being} \<type>'').

Explicitly qualified segments are an \XML/ element with two children (a
``variables'' \XML/ element, and a ``type'' \XML/ element). 

\medbreak
{\schema
VariableSegment \pipe= element Explicitly-Qualified-Segment \LB
\pos{\quad},
\quad element Variables \LB\ Variable* \RB,
\quad Type
\RB
\par}

\label{OutWSMizFileObj.Out_VariableSegment}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_VariableSegment( aSegm: QualifiedSegmentPtr);
var i: integer;
begin
   case aSegm^.nSegmentSort of
      ikImplQualifiedSegm:
         Out_ImplicitlyQualifiedVariable(ImplicitlyQualifiedSegmentPtr(aSegm));
      ikExplQualifiedSegm:
         with ExplicitlyQualifiedSegmentPtr(aSegm)^ do
      begin
         Out_XElStart(SegmentKindName[ikExplQualifiedSegm]);
         Out_PosAsAttrs(nSegmPos);
         Out_XAttrEnd;
         Out_XElStart0( XMLElemName[elVariables]);
         for i:=0 to nIdentifiers^.Count-1 do
            Out_Variable( nIdentifiers^.Items^[i]);
         Out_XElEnd( XMLElemName[elVariables]);
         Out_Type(nType);
         Out_XElEnd( SegmentKindName[ikExplQualifiedSegm]);
      end;
   endcases;
end;

@ Private predicates have the \XML/ schema

{\tt\obeylines
Private-Predicate-Formula = element Private-Predicate-Formula \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad},
\quad  Term-List?
\RB\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_PrivatePredicativeFormula ( aFrm: PrivatePredicativeFormulaPtr );
begin
   with PrivatePredicativeFormulaPtr(aFrm)^ do
   begin
      Out_XElStart(FormulaName[wsPrivatePredicateFormula]);
      Out_XIntAttr( XMLAttrName[atIdNr], nPredIdNr);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nPredIdNr));
      Out_PosAsAttrs(nFormulaPos);
      if nArgs^.Count = 0 then Out_XElEnd0
      else begin
         Out_XAttrEnd;
         Out_TermList( nArgs);
         Out_XElEnd( FormulaName[wsPrivatePredicateFormula]);
      end;
   end;
end;

@* [s] Emitting XML for formulas.
The \XML/ schema for formulas looks something like:

\medbreak
{\schema
Formula = NegatedFormula
\pipe\ ConjunctiveFormula
\pipe\ DisjunctiveFormula
\pipe\ ConditionalFormula
\pipe\ BiconditionalFormula
\pipe\ FlexaryConjunctiveFormula
\pipe\ FlexaryDisjunctiveFormula
\pipe\ Predicative-Formula
\pipe\ RightSideOf-Predicative-Formula
\pipe\ Multi-Predicative-Formula
\pipe\ Attributive-Formula
\pipe\ Qualifying-Formula
\pipe\ Universal-Quantifier-Formula
\pipe\ Existential-Quantifier-Formula
\pipe\ element Contradiction \LB
\pos{\qquad}\ \RB
\pipe\ element Thesis \LB
\pos{\qquad}\ \RB
\pipe\ element Formula-Error \LB
\pos{\qquad}\ \RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Formula ( aFrm: FormulaPtr );
var i: integer;
begin
   case aFrm^.nFormulaSort of
      wsNegatedFormula:
         @<Emit \XML/ for negated formula (WSM)@>;
      wsConjunctiveFormula:
         @<Emit \XML/ for conjunction (WSM)@>;
      wsDisjunctiveFormula:
         @<Emit \XML/ for disjunction (WSM)@>;
      wsConditionalFormula:
         @<Emit \XML/ for conditional formula (WSM)@>;
      wsBiconditionalFormula:
         @<Emit \XML/ for biconditional formula (WSM)@>;
      wsFlexaryConjunctiveFormula:
         @<Emit \XML/ for flexary-conjunction (WSM)@>;
      wsFlexaryDisjunctiveFormula:
         @<Emit \XML/ for flexary-disjunction (WSM)@>;
      wsPredicativeFormula:
         @<Emit \XML/ for predicative formula (WSM)@>;
      wsRightSideOfPredicativeFormula:
         @<Emit \XML/ for right-side of predicative formula (WSM)@>;
      wsMultiPredicativeFormula:
         @<Emit \XML/ for multi-predicative formula (WSM)@>;
      wsPrivatePredicateFormula:
         Out_PrivatePredicativeFormula(PrivatePredicativeFormulaPtr(aFrm));
      wsAttributiveFormula:
         @<Emit \XML/ for attributive formula (WSM)@>;
      wsQualifyingFormula:
         @<Emit \XML/ for qualifying formula (WSM)@>;
      wsUniversalFormula:
         @<Emit \XML/ for universal formula (WSM)@>;
      wsExistentialFormula:
         @<Emit \XML/ for existential formula (WSM)@>;
      wsContradiction:
         begin
            Out_XElWithPos(FormulaName[wsContradiction],aFrm^.nFormulaPos);
         end;
      wsThesis:
         begin
            Out_XElWithPos(FormulaName[wsThesis],aFrm^.nFormulaPos);
         end;
      wsErrorFormula:
         begin
            Out_XElWithPos(FormulaName[wsErrorFormula],aFrm^.nFormulaPos);
         end;
   endcases;
end;

@


\medbreak
{\schema
NegatedFormula = element Negated-Formula \LB
\pos{\quad},
\quad Formula
\RB\par}

@<Emit \XML/ for negated formula (WSM)@>=
         begin
            Out_XElStart(FormulaName[wsNegatedFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula( NegativeFormulaPtr(aFrm)^.nArg);
            Out_XElEnd( FormulaName[wsNegatedFormula]);
         end

@

\medbreak
{\schema
ConjunctiveFormula = element Conjunctive-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for conjunction (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsConjunctiveFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsConjunctiveFormula]);
         end

@

\medbreak
{\schema
DisjunctiveFormula = element Disjunctive-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for disjunction (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsDisjunctiveFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsDisjunctiveFormula]);
         end

@

\medbreak
{\schema
ConditionalFormula = element Conditional-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for conditional formula (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsConditionalFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsConditionalFormula]);
         end

@
\medbreak
{\schema
BiconditionalFormula = element Biconditional-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for biconditional formula (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsBiconditionalFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsBiconditionalFormula]);
         end
@

\medbreak
{\schema
FlexaryConjunctiveFormula = element FlexaryConjunctive-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for flexary-conjunction (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsFlexaryConjunctiveFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsFlexaryConjunctiveFormula]);
         end

@

\medbreak
{\schema
FlexaryDisjunctiveFormula = element FlexaryDisjunctive-Formula \LB
\pos{\quad},
\quad Formula,
\quad Formula
\RB
\par}

@<Emit \XML/ for flexary-disjunction (WSM)@>=
         begin
            Out_XElStart( FormulaName[wsFlexaryDisjunctiveFormula]);
            Out_PosAsAttrs(aFrm^.nFormulaPos);
            Out_XAttrEnd;
            Out_Formula(BinaryFormulaPtr(aFrm)^.nLeftArg);
            Out_Formula(BinaryFormulaPtr(aFrm)^.nRightArg);
            Out_XElEnd( FormulaName[wsFlexaryDisjunctiveFormula]);
         end

@


\medbreak
{\schema
Predicative-Formula = element Predicative-Formula \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element Arguments \LB\ Term-List? \RB,
\quad element Arguments \LB\ Term-List? \RB
\RB
\par}

@<Emit \XML/ for predicative formula (WSM)@>=
         with PredicativeFormulaPtr(aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsPredicativeFormula]);
         Out_XIntAttr( XMLAttrName[atNr], nPredNr);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], PredicateName[nPredNr]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         if nLeftArgs^.Count = 0 then
            Out_XEl1(XMLElemName[elArguments])
         else
         begin
            Out_XElStart0(XMLElemName[elArguments]);
            Out_TermList( nLeftArgs);
            Out_XElEnd( XMLElemName[elArguments]);
         end;
         if nRightArgs^.Count = 0 then
            Out_XEl1(XMLElemName[elArguments])
         else
         begin
            Out_XElStart0(XMLElemName[elArguments]);
            Out_TermList( nRightArgs);
            Out_XElEnd( XMLElemName[elArguments]);
         end;
         Out_XElEnd( FormulaName[wsPredicativeFormula]);
      end

@

\medbreak
{\schema
RightSideOf-Predicative-Formula = element RightSideOf-Predicative-Formula \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element Arguments \LB\ Term-List? \RB
\RB
\par}

@<Emit \XML/ for right-side of predicative formula (WSM)@>=
         with RightSideOfPredicativeFormulaPtr(aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsRightSideOfPredicativeFormula]);
         Out_XIntAttr( XMLAttrName[atNr], nPredNr);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], PredicateName[nPredNr]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         if nRightArgs^.Count = 0 then
            Out_XEl1(XMLElemName[elArguments])
         else
         begin
            Out_XElStart0(XMLElemName[elArguments]);
            Out_TermList( nRightArgs);
            Out_XElEnd( XMLElemName[elArguments]);
         end;
         Out_XElEnd( FormulaName[wsRightSideOfPredicativeFormula])
      end
@

\medbreak
{\schema
Multi-Predicative-Formula = element Multi-Predicative-Formula \LB
\pos{\quad},
\quad Formula*
\RB

\par}

@<Emit \XML/ for multi-predicative formula (WSM)@>=
         with MultiPredicativeFormulaPtr(aFrm)^ do
      begin
         Out_XElStart( FormulaName[wsMultiPredicativeFormula]);
         Out_PosAsAttrs(aFrm^.nFormulaPos);
         Out_XAttrEnd;
         for i:=0 to nScraps.Count - 1 do
            Out_Formula(nScraps^.Items^[i]);
         Out_XElEnd( FormulaName[wsMultiPredicativeFormula])
      end

@

\medbreak
{\schema
Attributive-Formula = element Attributive-Formula \LB
\pos{\quad},
\quad Term,
\quad Adjective-Cluster.element
\RB\par}

@<Emit \XML/ for attributive formula (WSM)@>=
         with AttributiveFormulaPtr(aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsAttributiveFormula]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         Out_Term(nSubject);
         Out_AdjectiveList(nAdjectives);
         Out_XElEnd( FormulaName[wsAttributiveFormula]);
      end

@

\medbreak
{\schema
Qualifying-Formula = element Qualifying-Formula \LB
\pos{\quad},
\quad Term,
\quad Type,
\quad Formula
\RB\par}

@<Emit \XML/ for qualifying formula (WSM)@>=
         with QualifyingFormulaPtr(aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsQualifyingFormula]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         Out_Term(nSubject);
         Out_Type(nType);
         Out_XElEnd( FormulaName[wsQualifyingFormula]);
      end

@

\medbreak
{\schema
Universal-Quantifier-Formula = element Universal-Quantifier-Formula \LB
\pos{\quad},
\quad Variable-Segment,
\quad Formula
\RB\par}

@<Emit \XML/ for universal formula (WSM)@>=
         with QuantifiedFormulaPtr( aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsUniversalFormula]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         Out_VariableSegment(QuantifiedFormulaPtr(aFrm)^.nSegment);
         Out_Formula(QuantifiedFormulaPtr(aFrm)^.nScope);
         Out_XElEnd( FormulaName[wsUniversalFormula]);
      end

@

\medbreak
{\schema
Existential-Quantifier-Formula = element Existential-Quantifier-Formula \LB
\pos{\quad},
\quad Variable-Segment,
\quad Formula
\RB\par}

@<Emit \XML/ for existential formula (WSM)@>=
         with QuantifiedFormulaPtr( aFrm)^ do
      begin
         Out_XElStart(FormulaName[wsExistentialFormula]);
         Out_PosAsAttrs(nFormulaPos);
         Out_XAttrEnd;
         Out_VariableSegment(QuantifiedFormulaPtr(aFrm)^.nSegment);
         Out_Formula(QuantifiedFormulaPtr(aFrm)^.nScope);
         Out_XElEnd( FormulaName[wsExistentialFormula]);
      end

@* [s] Emitting XML for Terms.
We begin with simple terms.

\medbreak
{\schema
Term \pipe= element Simple-Term \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad}
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_SimpleTerm ( aTrm: SimpleTermPtr );
begin
   Out_XElStart( TermName[wsSimpleTerm]);
   Out_XIntAttr( XMLAttrName[atIdNr], aTrm^.nIdent);
   if nMizarAppearance then
      Out_XAttr( XMLAttrName[atSpelling], IdentRepr(aTrm^.nIdent));
   Out_PosAsAttrs(aTrm^.nTermPos);
   Out_XElEnd0;
end;

@ \node{Terms: Private functors.}

\medbreak
{\schema
Term \pipe= element Private-Functor-Term \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad},
\quad element Arguments \LB\ Term-List \RB?
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_PrivateFunctorTerm ( aTrm: PrivateFunctorTermPtr );
begin
   with PrivateFunctorTermPtr(aTrm)^ do
   begin
      Out_XElStart(TermName[wsPrivateFunctorTerm]);
      Out_XIntAttr( XMLAttrName[atIdNr], nFunctorIdent);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nFunctorIdent));
      Out_PosAsAttrs(nTermPos);
      if nArgs^.Count = 0 then Out_XElEnd0
      else begin
         Out_XAttrEnd;
         Out_TermList( nArgs);
         Out_XElEnd( TermName[wsPrivateFunctorTerm]);
      end;
   end;
end;

@ \node{Terms: internal selectors.}

\medbreak
{\schema
Term \pipe= element Internal-Selector-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad}
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_InternalSelectorTerm ( aTrm: InternalSelectorTermPtr );
begin
   with aTrm^ do
   begin
      Out_XElStart(TermName[wsInternalSelectorTerm]);
      Out_XIntAttr( XMLAttrName[atNr], nSelectorSymbol);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], SelectorName[nSelectorSymbol]);
      Out_PosAsAttrs(nTermPos);
      Out_XElEnd0;
   end;
end;

@ \node{Terms: numerals, anaphoric ``it'', error.}

\medbreak
{\schema
Term \pipe= element Numeral \LB
\qquad attribute number \LB\ xsd:int \RB,
\pos{\qquad}
\quad \RB
\par}

\medbreak
{\schema
Term \pipe= element It-Term \LB
\pos{\qquad}
\quad \RB
Term \pipe= element Error-Term \LB\ \RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Term ( aTrm: TermPtr );
var i: integer;
begin
   case aTrm^.nTermSort of
      wsPlaceholderTerm:
         @<Emit \XML/ for placeholder (WSM)@>;
      wsSimpleTerm:
         Out_SimpleTerm(SimpleTermPtr(aTrm));
      wsNumeralTerm:
         begin;
            Out_XElStart(TermName[wsNumeralTerm]);
            Out_XIntAttr(XMLAttrName[atNumber], NumeralTermPtr(aTrm)^.nValue);
            Out_PosAsAttrs(aTrm^.nTermPos);
            Out_XElEnd0;
         end;
      wsInfixTerm:
         @<Emit \XML/ for infix term (WSM)@>;
      wsCircumfixTerm:
         @<Emit \XML/ for circumfix term (WSM)@>;
      wsPrivateFunctorTerm:
         Out_PrivateFunctorTerm(PrivateFunctorTermPtr(aTrm));
      wsAggregateTerm:
         @<Emit \XML/ for aggregate term (WSM)@>;
      wsSelectorTerm:
         @<Emit \XML/ for selector term (WSM)@>;
      wsInternalSelectorTerm:
         Out_InternalSelectorTerm(InternalSelectorTermPtr(aTrm));
      wsForgetfulFunctorTerm:
         @<Emit \XML/ for forgetful functor (WSM)@>;
      wsInternalForgetfulFunctorTerm:
         @<Emit \XML/ for internal forgetful functor (WSM)@>;
      wsFraenkelTerm:
         @<Emit \XML/ for Fraenkel term (WSM)@>;
      wsSimpleFraenkelTerm:
         @<Emit \XML/ for simple Fraenkel term (WSM)@>;
      wsQualificationTerm:
         @<Emit \XML/ for qualification term (WSM)@>;
      wsExactlyTerm:
         @<Emit \XML/ for exactly qualification term (WSM)@>;
      wsGlobalChoiceTerm:
         @<Emit \XML/ for global choice term (WSM)@>;
      wsItTerm:
         Out_XElWithPos(TermName[wsItTerm],aTrm^.nTermPos);
      wsErrorTerm:
         Out_XEl1( TermName[wsErrorTerm]);
   endcases;
end;

@ \node{Terms: placeholders.}

\medbreak
{\schema
Term \pipe= element Placeholder-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad}
\RB\par}

@<Emit \XML/ for placeholder (WSM)@>=
         begin
            Out_XElStart( TermName[wsPlaceholderTerm]);
            Out_XIntAttr( XMLAttrName[atNr], PlaceholderTermPtr(aTrm)^.nLocusNr);
            if nMizarAppearance then
               Out_XAttr( XMLAttrName[atSpelling], QuoteStrForXML(PlaceHolderName[PlaceholderTermPtr(aTrm)^.nLocusNr]));
            Out_PosAsAttrs(aTrm^.nTermPos);
            Out_XElEnd0;
         end

@ \node{Terms: infixed.}

\medbreak
{\schema
Term \pipe= element Infix-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element Arguments \LB\ Term-List? \RB,
\quad element Arguments \LB\ Term-List? \RB
\RB\par}

@<Emit \XML/ for infix term (WSM)@>=
         with InfixTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsInfixTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nFunctorSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], FunctorName[nFunctorSymbol]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         if nLeftArgs^.Count = 0 then
            Out_XEl1(XMLElemName[elArguments])
         else
         begin
            Out_XElStart0(XMLElemName[elArguments]);
            Out_TermList( nLeftArgs);
            Out_XElEnd( XMLElemName[elArguments]);
         end;
         if nRightArgs^.Count = 0 then
            Out_XEl1(XMLElemName[elArguments])
         else
         begin
            Out_XElStart0(XMLElemName[elArguments]);
            Out_TermList( nRightArgs);
            Out_XElEnd(XMLElemName[elArguments]);
         end;
         Out_XElEnd(TermName[wsInfixTerm]);
      end

@ \node{Terms: brackets.}

\medbreak
{\schema
Term \pipe= element Circumfix-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element Right-Circumflex-Symbol \LB
\qquad attribute nr \LB\ text \RB,
\spelling{\qquad}?,
\pos{\qquad}
\quad \RB,
\quad element Arguments \LB\ Term-List? \RB
\RB\par}

@<Emit \XML/ for circumfix term (WSM)@>=
         with CircumfixTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsCircumfixTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nLeftBracketSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], LeftBracketName[nLeftBracketSymbol]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         Out_XElStart(XMLElemName[elRightCircumflexSymbol]);
         Out_XIntAttr( XMLAttrName[atNr], nRightBracketSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], RightBracketName[nRightBracketSymbol]);
         Out_PosAsAttrs(nTermPos);
         Out_XElEnd0;
         Out_TermList( nArgs);
         Out_XElEnd( TermName[wsCircumfixTerm]);
      end

@ \node{Terms: structure instances.}

\medbreak
{\schema
Term \pipe= element Aggregate-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element Arguments \LB\ Term-List \RB?
\RB\par}

@<Emit \XML/ for aggregate term (WSM)@>=
         with AggregateTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsAggregateTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nStructSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], StructureName[nStructSymbol]);
         Out_PosAsAttrs(nTermPos);
         if nArgs^.Count = 0 then Out_XElEnd0
         else begin
            Out_XAttrEnd;
            Out_TermList( nArgs);
            Out_XElEnd( TermName[wsAggregateTerm]);
         end;
      end

@ \node{Terms: selectors.}

\medbreak
{\schema
Term \pipe= element Selector-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Term
\RB\par}

@<Emit \XML/ for selector term (WSM)@>=
         with SelectorTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsSelectorTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nSelectorSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], SelectorName[nSelectorSymbol]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         Out_Term( nArg);
         Out_XElEnd( TermName[wsSelectorTerm]);
      end

@ \node{Terms: forgetful functors.}

\medbreak
{\schema
Term \pipe= element Forgetful-Functor-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Term
\RB\par}

@<Emit \XML/ for forgetful functor (WSM)@>=
         with ForgetfulFunctorTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsForgetfulFunctorTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nStructSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], StructureName[nStructSymbol]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         Out_Term( nArg);
         Out_XElEnd( TermName[wsForgetfulFunctorTerm]);
      end

@ \node{Terms: internal forgetful functors.}

\medbreak
{\schema
Term \pipe= element Internal-Forgetful-Functor-Term \LB
\quad attribute nr \LB\ text \RB,
\spelling{\quad}?,
\pos{\quad},
\RB\par}

@<Emit \XML/ for internal forgetful functor (WSM)@>=
         with InternalForgetfulFunctorTermPtr(aTrm)^ do
      begin
         Out_XElStart(TermName[wsInternalForgetfulFunctorTerm]);
         Out_XIntAttr( XMLAttrName[atNr], nStructSymbol);
         Out_PosAsAttrs(nTermPos);
         Out_XElEnd0;
      end

@ \node{Terms: Fraenkel operators.}

\medbreak
{\schema
Term \pipe= element Fraenkel-Term \LB
\pos{\quad},
\quad Variable-Segment*,
\quad Term,
\quad Formula
\RB\par}

@^Fraenkel term@>

@<Emit \XML/ for Fraenkel term (WSM)@>=
         with FraenkelTermPtr(aTrm)^ do
      begin
         Out_XElStart( TermName[wsFraenkelTerm]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         for i := 0 to nPostqualification^.Count - 1 do
            Out_VariableSegment(nPostqualification^.Items^[i]);
         Out_Term(nSample);
         Out_Formula(nFormula);
         Out_XElEnd( TermName[wsFraenkelTerm]);
      end

@ \node{Terms: Simple Fraenkel expressions.}

\medbreak
{\schema
Term \pipe= element Simple-Fraenkel-Term \LB
\pos{\quad},
\quad Variable-Segment*,
\quad Term
\RB\par}

@<Emit \XML/ for simple Fraenkel term (WSM)@>=
         with SimpleFraenkelTermPtr(aTrm)^ do
      begin
         Out_XElStart( TermName[wsSimpleFraenkelTerm]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         for i := 0 to nPostqualification^.Count - 1 do
            Out_VariableSegment(nPostqualification^.Items^[i]);
         Out_Term(nSample);
         Out_XElEnd( TermName[wsSimpleFraenkelTerm]);
      end

@ \node{Terms: qualification.}

\medbreak
{\schema
Term \pipe= element Qualification-Term \LB
\pos{\quad},
\quad Term,
\quad Type
\RB\par}

@<Emit \XML/ for qualification term (WSM)@>=
         with QualifiedTermPtr(aTrm)^ do
      begin
         Out_XElStart( TermName[wsQualificationTerm]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         Out_Term(nSubject);
         Out_Type(nQualification);
         Out_XElEnd( TermName[wsQualificationTerm]);
      end

@ \node{Terms: exactly qualified.}

\medbreak
{\schema
Term \pipe= element Exactly-Qualification-Term \LB
\pos{\quad},
\quad Term
\RB\par}

@<Emit \XML/ for exactly qualification term (WSM)@>=
         with ExactlyTermPtr(aTrm)^ do
      begin
         Out_XElStart( TermName[wsQualificationTerm]);
         Out_PosAsAttrs(nTermPos);
         Out_XAttrEnd;
         Out_Term(nSubject);
         Out_XElEnd( TermName[wsQualificationTerm]);
      end

@ \node{Terms: global choice expressions.}

\medbreak
{\schema
Term \pipe= element Global-Choice-Term \LB
\pos{\quad},
\quad Type
\RB\par}

@^Choice operator@>

@<Emit \XML/ for global choice term (WSM)@>=
         begin
            Out_XElStart(TermName[wsGlobalChoiceTerm]);
            Out_PosAsAttrs(aTrm^.nTermPos);
            Out_XAttrEnd;
            Out_Type(ChoiceTermPtr(aTrm)^.nChoiceType);
            Out_XElEnd(TermName[wsGlobalChoiceTerm]);
         end

@* [s] Emitting XML for text items.
Type-lists are needed for text items.

\medbreak
{\schema
Type-List = element Type-List \LB
\quad Type*
\RB
\par}
@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_TypeList ( aTypeList: PList );
var i: integer;
begin
   Out_XElStart0(XMLElemName[elTypeList]);
   for i:=0 to aTypeList^.Count-1 do
      Out_Type(aTypeList^.Items^[i]);
   Out_XElEnd( XMLElemName[elTypeList]);
end;

@ \node{Locus.}

\medbreak
{\schema
Locus = element Locus \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad}
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Locus( aLocus: LocusPtr);
begin
   with aLocus ^ do
   begin
      Out_XElStart( XMLElemName[elLocus]);
      Out_XIntAttr( XMLAttrName[atIdNr], nVarId);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nVarId));
      Out_PosAsAttrs(nVarIdPos);
      Out_XElEnd0
   end;
end;

@

\medbreak
{\schema
Loci = element Loci \LB\ Locus* \RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Loci( aLoci: PList);
var i: integer;
begin
   if (aLoci = nil) or (aLoci^.Count = 0) then
      Out_XEl1(XMLElemName[elLoci])
   else
   begin
      Out_XElStart0(XMLElemName[elLoci]);
      for i:=0 to aLoci^.Count-1 do
         Out_Locus(aLoci^.Items^[i]);
      Out_XElEnd( XMLElemName[elLoci]);
   end;
end;

@ \node{Patterns.}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Pattern(aPattern: PatternPtr);
begin
   case aPattern^.nPatternSort of
      itDefPred:
         @<Emit \XML/ for predicate pattern (WSM)@>;
      itDefFunc:
         begin
            case FunctorPatternPtr(aPattern)^.nFunctKind of
               InfixFunctor:
                  @<Emit \XML/ for infix functor pattern (WSM)@>;
               CircumfixFunctor:
                  @<Emit \XML/ for bracket functor pattern (WSM)@>;
            endcases;
         end;
      itDefMode:
         @<Emit \XML/ for mode pattern (WSM)@>;
      end;
      itDefAttr:
         @<Emit \XML/ for attribute pattern (WSM)@>;
   endcases;
end;

@

\medbreak
{\schema
Predicate-Pattern = element Predicate-Pattern \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Loci,
\quad Loci
\RB
\par}

@<Emit \XML/ for predicate pattern (WSM)@>=
         with PredicatePatternPtr(aPattern)^ do
      begin
         Out_XElStart(DefPatternName[itDefPred]);
         Out_XIntAttr( XMLAttrName[atNr], nPredSymbol );
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], PredicateName[nPredSymbol]);
         Out_PosAsAttrs(nPatternPos);
         Out_XAttrEnd;
         Out_Loci(nLeftArgs);
         Out_Loci(nRightArgs);
         Out_XElEnd( DefPatternName[itDefPred]);
      end

@
\medbreak
{\schema
Operation-Functor-Pattern = element Operation-Functor-Pattern \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Loci,
\quad Loci
\RB
\par}

@<Emit \XML/ for infix functor pattern (WSM)@>=
                  with InfixFunctorPatternPtr(aPattern)^ do
               begin
                  Out_XElStart(FunctorPatternName[InfixFunctor]);
                  Out_XIntAttr( XMLAttrName[atNr], nOperSymb);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], FunctorName[nOperSymb]);
                  Out_PosAsAttrs(nPatternPos);
                  Out_XAttrEnd;
                  Out_Loci(nLeftArgs);
                  Out_Loci(nRightArgs);
                  Out_XElEnd( FunctorPatternName[InfixFunctor]);
               end

@

\medbreak
{\schema
Bracket-Functor-Pattern = element Bracket-Functor-Pattern \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad element RightCircumflexSymbol \LB
\qquad attribute nr \LB\ xsd:integer \RB,
\spelling{\qquad }?
\quad \RB,
\quad Loci
\RB
\par}

@<Emit \XML/ for bracket functor pattern (WSM)@>=
                  with CircumfixFunctorPatternPtr(aPattern)^ do
               begin
                  Out_XElStart(FunctorPatternName[CircumfixFunctor]);
                  Out_XIntAttr( XMLAttrName[atNr], nLeftBracketSymb);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], LeftBracketName[nLeftBracketSymb]);
                  Out_PosAsAttrs(nPatternPos);
                  Out_XAttrEnd;
                  Out_XElStart(XMLElemName[elRightCircumflexSymbol]);
                  Out_XIntAttr( XMLAttrName[atNr], nRightBracketSymb);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], RightBracketName[nRightBracketSymb]);
                  Out_XAttrEnd;
                  Out_XElEnd(XMLElemName[elRightCircumflexSymbol]);
                  Out_Loci(nArgs);
                  Out_XElEnd( FunctorPatternName[CircumfixFunctor]);
               end

@

\medbreak
{\schema
Mode-Pattern = element Mode-Pattern \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Loci
\RB
\par}

@<Emit \XML/ for mode pattern (WSM)@>=
         with ModePatternPtr(aPattern)^ do
      begin
         Out_XElStart(DefPatternName[itDefMode]);
         Out_XIntAttr( XMLAttrName[atNr], nModeSymbol);
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], ModeName[nModeSymbol]);
         Out_PosAsAttrs(nPatternPos);
         Out_XAttrEnd;
         Out_Loci(nArgs);
         Out_XElEnd(DefPatternName[itDefMode])

@
I am confused why there is both a locus and loci elements in an
attribute pattern.

\medbreak
{\schema
Attribute-Pattern = element Attribute-Pattern \LB
\quad attribute nr \LB\ xsd:integer \RB,
\spelling{\quad}?,
\pos{\quad},
\quad Locus,
\quad Loci
\RB
\par}

@<Emit \XML/ for attribute pattern (WSM)@>=
         with AttributePatternPtr(aPattern)^ do
      begin
         Out_XElStart(DefPatternName[itDefAttr]);
         Out_XIntAttr( XMLAttrName[atNr], nAttrSymbol );
         if nMizarAppearance then
            Out_XAttr( XMLAttrName[atSpelling], AttributeName[nAttrSymbol]);
         Out_PosAsAttrs(nPatternPos);
         Out_XAttrEnd;
         Out_Locus(nArg);
         Out_Loci(nArgs);
         Out_XElEnd( DefPatternName[itDefAttr]);
      end

@

\medbreak
{\schema
Label = element Label \LB
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad},
\quad Locus,
\quad Loci
\RB
\par}
@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Label(aLab:LabelPtr);
begin
   if (aLab <> nil) { |and (aLab.nLabelIdNr > 0)| } then
   begin
      Out_XElStart( XMLElemName[elLabel]);
      Out_XIntAttr( XMLAttrName[atIdNr], aLab^.nLabelIdNr);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(aLab^.nLabelIdNr));
      Out_PosAsAttrs(aLab^.nLabelPos);
      Out_XElEnd0
   end;
end;

@ \node{Emitting XML for definiens.}

\medbreak
{\schema
Definiens = element Definiens \LB
\quad attribute kind \LB\ "Simple-Definiens" \RB,
\quad attribute shape \LB\ text \RB?,
\quad Label,
\quad (Term \pipe\ Formula)
\RB\ \pipe\ element Definiens \LB
\quad attribute kind \LB\ "Conditional-Definiens" \RB,
\quad attribute shape \LB\ text \RB?,
\quad Label,
\quad element Partial-Definiens \LB\ (Term \pipe\ Formula)* \RB,
\quad (Term \pipe\ Formula)?
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Definiens(aDef:DefiniensPtr);
var i: integer;
lExprKind: ExpKind;
begin
   if aDef <> nil then
      with DefiniensPtr(aDef)^ do
   begin
      Out_XElStart( XMLElemName[elDefiniens]);
      Out_PosAsAttrs(nDefPos);
      case nDefSort of
         SimpleDefiniens:
            with SimpleDefiniensPtr(aDef)^,nExpression^ do
         begin
            Out_XAttr( XMLAttrName[atKind],DefiniensKindName[SimpleDefiniens]);
            Out_XAttr( XMLAttrName[atShape],ExpName[nExprKind]);
            Out_XAttrEnd;
            Out_Label(nDefLabel);
            case nExprKind of
               exTerm: Out_Term(TermPtr(nExpr));
               exFormula: Out_Formula(FormulaPtr(nExpr));
            endcases;
         end;
         
         ConditionalDefiniens:
            with ConditionalDefiniensPtr(aDef)^ do
         begin
            Out_XAttr( XMLAttrName[atKind],DefiniensKindName[ConditionalDefiniens]);
            lExprKind:=exFormula;
            if nOtherwise <> nil then
               lExprKind:=nOtherwise^.nExprKind
            else if nConditionalDefiniensList^.Count > 0 then
               lExprKind:=PartDefPtr(nConditionalDefiniensList^.Items^[0])^.nPartDefiniens^.nExprKind;
            Out_XAttr( XMLAttrName[atShape],ExpName[lExprKind]);
            Out_XAttrEnd;
            Out_Label(nDefLabel);
            for i:=0 to nConditionalDefiniensList^.Count-1 do
               with PartDefPtr(nConditionalDefiniensList^.Items^[I])^ do
            begin
               Out_XElStart0(XMLElemName[elPartialDefiniens]);
               with nPartDefiniens^ do
                  case nExprKind of
                     exTerm: Out_Term(TermPtr(nExpr));
                     exFormula: Out_Formula(FormulaPtr(nExpr));
                  endcases;
               Out_Formula(nGuard);
               Out_XElEnd(XMLElemName[elPartialDefiniens]);
            end;
            if nOtherwise <> nil then
               with nOtherwise^ do
                  case nExprKind of
                     exTerm: Out_Term(TermPtr(nExpr));
                     exFormula: Out_Formula(FormulaPtr(nExpr));
                  endcases;
         end;
      endcases;
      Out_XElEnd( XMLElemName[elDefiniens]);
   end;
end;

@

\medbreak
{\schema
Proposition = element Proposition \LB
\quad Label,
\quad Formula
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Proposition(aProp:PropositionPtr);
begin
   Out_XElStart(XMLElemName[elProposition]);
   Out_XAttrEnd;
   Out_Label(aProp^.nLab);
   Out_Formula(aProp^.nSentence);
   Out_XElEnd( XMLElemName[elProposition]);
end;

@

\medbreak
{\schema
Local-Reference = element Local-Reference \LB
\pos{\quad},
\idnr{\quad},
\spelling{\quad}?
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_LocalReference(aRef: LocalReferencePtr);
begin
   with LocalReferencePtr(aRef)^ do
   begin
      Out_XElStart(ReferenceKindName[LocalReference]);
      Out_PosAsAttrs(nRefPos);
      Out_XIntAttr( XMLAttrName[atIdNr], nLabId);
      if nMizarAppearance then
         Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nLabId));
      Out_XElEnd0;
   end;
end;
@

\medbreak
{\schema
References = (Local-Reference
\quad\pipe\ element Theorem-Reference \LB
\pos{\qquad},
\qquad attribute at \LB\ xsd:integer \RB,
\spelling{\qquad}?,
\qquad attribute nr \LB\ xsd:integer \RB
\RB\ \pipe\ element Definition-Reference \LB
\pos{\qquad},
\qquad attribute at \LB\ xsd:integer \RB,
\spelling{\qquad}?,
\qquad attribute nr \LB\ xsd:integer \RB
\RB)*
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_References(aRefs: PList);
var i: integer;
begin
   for i:= 0 to aRefs^.Count-1 do
      with ReferencePtr(aRefs^.Items^[i])^ do
         case nRefSort of
            LocalReference:
               Out_LocalReference(aRefs^.Items^[i]);
            TheoremReference:
               begin
                  Out_XElStart(ReferenceKindName[TheoremReference]);
                  Out_PosAsAttrs(nRefPos);
                  Out_XIntAttr( XMLAttrName[atNr], TheoremReferencePtr(aRefs^.Items^[i])^.nArticleNr);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], MMLIdentifierName[TheoremReferencePtr(aRefs^.Items^[i])^.nArticleNr]);
                  Out_XIntAttr( XMLAttrName[atNumber], TheoremReferencePtr(aRefs^.Items^[i])^.nTheoNr);
                  Out_XElEnd0;
               end;
            DefinitionReference:
               begin
                  Out_XElStart(ReferenceKindName[DefinitionReference]);
                  Out_PosAsAttrs(nRefPos);
                  Out_XIntAttr( XMLAttrName[atNr], DefinitionReferencePtr(aRefs^.Items^[i])^.nArticleNr);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], MMLIdentifierName[TheoremReferencePtr(aRefs^.Items^[i])^.nArticleNr]);
                  Out_XIntAttr( XMLAttrName[atNumber], DefinitionReferencePtr(aRefs^.Items^[i])^.nDefNr);
                  Out_XElEnd0;
               end;
         endcases;
end;

@

\medbreak
{\schema
Link = element Link \LB
\pos{\quad}
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Link(aInf: JustificationPtr);
begin
   with StraightforwardJustificationPtr(aInf)^ do
      if nLinked then
      begin
         Out_XElStart(XMLElemName[elLink]);
         Out_PosAsAttrs(nLinkPos);
         Out_XElEnd0;
      end;
end;
@

\medbreak
{\schema
Scheme-Justification = element Scheme-Justification \LB
\quad attribute nr \LB\ xsd:integer \RB,
\idnr{\quad},
\spelling{\quad}?,
\pos{\quad},
\quad attribute poscol \LB\ xsd:integer \RB,
\quad attribute posline \LB\ xsd:integer \RB,
\quad References
\RB\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_SchemeJustification(aInf: SchemeJustificationPtr);
begin
   with aInf^ do
   begin
      Out_XElStart(InferenceName[infSchemeJustification]);
      Out_XIntAttr( XMLAttrName[atNr],nSchFileNr);
      Out_XIntAttr( XMLAttrName[atIdNr],nSchemeIdNr);
      if nMizarAppearance then
         if nSchFileNr > 0 then
            Out_XAttr( XMLAttrName[atSpelling], MMLIdentifierName[nSchFileNr])
         else if nSchemeIdNr > 0 then
            Out_XAttr( XMLAttrName[atSpelling], IdentRepr(nSchemeIdNr));
      Out_PosAsAttrs(nInfPos);
      Out_XIntAttr( XMLAttrName[atPosLine], nSchemeInfPos.Line);
      Out_XIntAttr( XMLAttrName[atPosCol], nSchemeInfPos.Col);
      Out_XAttrEnd;
      Out_References(nReferences);
      Out_XElEnd(InferenceName[infSchemeJustification]);
   end;
end;

@

\medbreak
{\schema
Justification =
(\ element Straightforward-Justification \LB
\pos{\qquad},
\qquad(Link, References)?
\quad\RB
\pipe\ Scheme-Justification
\pipe\ element Inference-Error \LB
\pos\qquad
\quad\RB
\pipe\ element Skipped-Proof \LB
\pos\qquad
\quad\RB
\pipe\ Block \# {\rm proof block}
)\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Justification(aInf: JustificationPtr; aBlock:wsBlockPtr);
begin
   case aInf^.nInfSort of
      infStraightforwardJustification:
         with StraightforwardJustificationPtr(aInf)^ do
      begin
         Out_XElStart(InferenceName[infStraightforwardJustification]);
         Out_PosAsAttrs(nInfPos);
         if not nLinked and (nReferences^.Count=0) then
            Out_XElEnd0
         else
         begin
            Out_XAttrEnd;
            Out_Link(aInf);
            Out_References(nReferences);
            Out_XElEnd(InferenceName[infStraightforwardJustification]);
         end;
      end;
      infSchemeJustification:
         Out_SchemeJustification(SchemeJustificationPtr(aInf));
      infError:
         Out_XElWithPos(InferenceName[infError],aInf^.nInfPos);
      infSkippedProof:
         Out_XElWithPos(InferenceName[infSkippedProof],aInf^.nInfPos);
      infProof:
         Out_Block(aBlock);
   endcases;
end;
@

\medbreak
{\schema
Compact-Statement = (Proposition, Justification)
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_CompactStatement(aCStm:CompactStatementPtr; aBlock:wsBlockPtr);
begin
   with aCStm^ do
   begin
      Out_Proposition(nProp);
      Out_Justification(nJustification,aBlock);
   end;
end;

@

\medbreak
{\schema
Regular-Statement =
( (Label, Block)
\pipe\ Compact-Statement
\pipe\ (Compact-Statement,
\quad\ element Iterative-Step \LB
\pos{\qquad\ },
\qquad\ Term,
\qquad\ Justification
\quad\ \RB)*
)\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_RegularStatement(aRStm:RegularStatementPtr; aBlock:wsBlockPtr);
var i: integer;
begin
   case aRStm^.nStatementSort of
      stDiffuseStatement:
         begin
            Out_Label(DiffuseStatementPtr(aRStm)^.nLab);
            Out_Block(aBlock);
         end;
      stCompactStatement:
         Out_CompactStatement(CompactStatementPtr(aRStm),aBlock);
      stIterativeEquality:
         begin
            Out_CompactStatement(CompactStatementPtr(aRStm),nil);
            with IterativeEqualityPtr(aRStm)^ do
               for i := 0 to nIterSteps^.Count - 1 do
                  with IterativeStepPtr(nIterSteps^.Items^[i])^ do
               begin
                  Out_XElStart(XMLElemName[elIterativeStep]);
                  Out_PosAsAttrs(nIterPos);
                  Out_XAttrEnd;
                  Out_Term(nTerm);
                  Out_Justification(nJustification,nil);
                  Out_XElEnd(XMLElemName[elIterativeStep]);
               end;
         end;
   endcases;
end;

@

\medbreak
{\schema
Variables = element Variables \LB
\quad Variable*
\RB
\par}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_ReservationSegment(aRes:ReservationSegmentPtr);
var i: integer;
begin
   with aRes^ do
   begin
      Out_XElStart0( XMLElemName[elVariables]);
      for i:=0 to nIdentifiers^.Count-1 do
         Out_ReservedVariable( nIdentifiers^.Items^[i]);
      Out_XElEnd( XMLElemName[elVariables]);
      Out_Type(nResType);
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_SchemeNameInSchemeHead(aSch: SchemePtr);
begin
   Out_XIntAttr( XMLAttrName[atIdNr], aSch^.nSchemeIdNr);
   if nMizarAppearance then
      Out_XAttr( XMLAttrName[atSpelling], IdentRepr(aSch^.nSchemeIdNr));
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_ItemContentsAttr(aWSItem:WSItemPtr);
begin
   with aWSItem^ do
   begin
      CurPos:=nItemPos;
      if nDisplayInformationOnScreen then
         DisplayLine(CurPos.Line,ErrorNbr);
      case nItemKind of
         itDefinition, itSchemeBlock, itSchemeHead, itTheorem, itAxiom,
         itReservation:;
         itSection:;
         itConclusion,
         itRegularStatement:
            case RegularStatementPtr(nContent)^.nStatementSort of
               stDiffuseStatement:
                  Out_XAttr( XMLAttrName[atShape], RegularStatementName[stDiffuseStatement]);
               stCompactStatement:
                  Out_XAttr( XMLAttrName[atShape], RegularStatementName[stCompactStatement]);
               stIterativeEquality:
                  Out_XAttr( XMLAttrName[atShape], RegularStatementName[stIterativeEquality]);
            endcases;
         itChoice, itReconsider,
         itPrivFuncDefinition, itPrivPredDefinition, itConstantDefinition,
         itGeneralization, itLociDeclaration,itExistentialAssumption, itExemplification,
         itPerCases, itCaseBlock:;
         itCaseHead, itSupposeHead,
         itAssumption:;
         itCorrCond:
            Out_XAttr( XMLAttrName[atCondition],
                       CorrectnessName[CorrectnessConditionPtr(nContent)^.nCorrCondSort]);
         itCorrectness:
            Out_XAttr( XMLAttrName[atCondition],CorrectnessName[syCorrectness]);
         itProperty:
            Out_XAttr( XMLAttrName[atProperty],PropertyName[PropertyPtr(nContent)^.nPropertySort]);
         itDefFunc:
            Out_XAttr( XMLAttrName[atShape],DefiningWayName[FunctorDefinitionPtr(nContent)^.nDefiningWay]);
         itDefPred, itDefMode, itDefAttr,
         itDefStruct,
         itPredSynonym, itPredAntonym, itFuncNotation, itModeNotation,
         itAttrSynonym, itAttrAntonym,
         itCluster,
         itIdentify, itReduction:;
         itPropertyRegistration:
            Out_XAttr( XMLAttrName[atProperty],PropertyName[PropertyPtr(nContent)^.nPropertySort]);
         itPragma:
            Out_XAttr( XMLAttrName[atSpelling],QuoteStrForXML(PragmaPtr(nContent)^.nPragmaStr));
      endcases;
   end;
end;

@ \node{Emitting XML for item contents.} This is used to expedite
emitting the \XML/ for a text-item (\section\xref{OutWSMizFileObj.Out_Item}).

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_ItemContents(aWSItem:WSItemPtr);
var i,j: integer;
s: CorrectnessKind;
begin
   with aWSItem^ do
   begin
      case nItemKind of
         itDefinition:
            Out_Block(nBlock);
         itSchemeBlock:
            Out_Block(nBlock);
         itSchemeHead:
            @<Emit \XML/ for schema (WSM)@>;
         itTheorem:
            Out_CompactStatement(CompactStatementPtr(nContent),nBlock);
         itAxiom:
            begin

            end;
         itReservation:
            Out_ReservationSegment(ReservationSegmentPtr(nContent));
         itSection:;
         itConclusion,
         itRegularStatement:
            Out_RegularStatement(RegularStatementPtr(nContent),nBlock);
         itChoice:
            @<Emit \XML/ for \texttt{consider} contents (WSM)@>;
         itReconsider:
            @<Emit \XML/ for \texttt{reconsider} contents (WSM)@>; @#
@t\4@>         @<Emit \XML/ for definition-related items (WSM)@>; @#
         itPredSynonym, itPredAntonym, itFuncNotation, itModeNotation,
         itAttrSynonym, itAttrAntonym:
            with NotationDeclarationPtr(nContent)^ do
         begin
            Out_Pattern(nOriginPattern);
            Out_Pattern(nNewPattern);
         end;
@t\4@>         @<Emit \XML/ for registration-related items (WSM)@>; @#
         itPragma: ;
         itIncorrItem:;
      end;
   endcases;
end;

@

\medbreak
{\schema
Item-contents \pipe= Scheme-contents
Scheme-contents = element Scheme \LB
\idnr{\quad},
\spelling{\quad}?,
\quad element Schematic-Variables \LB
\qquad\llap{(}element Predicate-Segment \LB
\pos{\qquad\quad},
\qquad\quad element Variables \LB\ Variable* \RB,
\qquad\quad Type
\qquad\RB\ \pipe\ element Functor-Segment \LB
\pos{\qquad\quad},
\qquad\quad element Variables \LB\ Variable* \RB,
\qquad\quad Type-List,
\qquad\quad element Type-Specification \LB\ Type \RB
\qquad\RB)*
\quad \RB,
\quad Formula,
\quad element Provisional-Formulas \LB\ Proposition* \RB?
\RB
\par}

@<Emit \XML/ for schema (WSM)@>=
            with SchemePtr(nContent)^ do
         begin
            Out_XElStart( XMLElemName[elScheme]);
            Out_SchemeNameInSchemeHead(SchemePtr(nContent));
            Out_XElEnd0;
            Out_XElStart0(XMLElemName[elSchematicVariables]);
            for j:=0 to nSchemeParams^.Count-1 do
               case SchemeSegmentPtr(nSchemeParams.Items^[j])^.nSegmSort of
                  PredicateSegment:
                     with PredicateSegmentPtr(nSchemeParams.Items^[j])^ do
                  begin
                     Out_XElStart( SchemeSegmentName[PredicateSegment]);
                     Out_PosAsAttrs(nSegmPos);
                     Out_XAttrEnd;
                     Out_XElStart0( XMLElemName[elVariables]);
                     for i:=0 to nVars^.Count-1 do
                        Out_Variable( nVars.Items^[i]);
                     Out_XElEnd( XMLElemName[elVariables]);
                     Out_TypeList(nTypeExpList);
                     Out_XElEnd( SchemeSegmentName[PredicateSegment]);
                  end;
                  FunctorSegment:
                     with FunctorSegmentPtr(nSchemeParams.Items^[j])^ do
                  begin
                     Out_XElStart( SchemeSegmentName[FunctorSegment]);
                     Out_PosAsAttrs(nSegmPos);
                     Out_XAttrEnd;
                     Out_XElStart0( XMLElemName[elVariables]);
                     for i:=0 to nVars^.Count-1 do
                        Out_Variable( nVars.Items^[i]);
                     Out_XElEnd( XMLElemName[elVariables]);
                     Out_TypeList(nTypeExpList);
                     Out_XElStart0( XMLElemName[elTypeSpecification]);
                     Out_Type(nSpecification);
                     Out_XElEnd( XMLElemName[elTypeSpecification]);
                     Out_XElEnd( SchemeSegmentName[FunctorSegment]);
                  end;
               endcases;
            Out_XElEnd( XMLElemName[elSchematicVariables]);
            Out_Formula(nSchemeConclusion);
            if (nSchemePremises <> nil) and (nSchemePremises^.Count > 0) then
            begin
               Out_XElStart0( XMLElemName[elProvisionalFormulas]);
               for i:=0 to nSchemePremises^.Count-1 do
                  Out_Proposition(nSchemePremises^.Items^[i]);
               Out_XElEnd( XMLElemName[elProvisionalFormulas]);
            end;
         end

@

\medbreak
{\schema
Item-contents \pipe= Consider-Statement-contents
Consider-Statement-contents =
\quad\llap{(\ }Variable-Segment*,
\quad element Conditions \LB\ Proposition \RB,
\quad Justification
)\par}

@<Emit \XML/ for \texttt{consider} contents (WSM)@>=
            with ChoiceStatementPtr(nContent)^ do
         begin
            for i:= 0 to  nQualVars^.Count-1 do
               Out_VariableSegment( nQualVars^.Items^[i]);
            Out_XElStart0( XMLElemName[elConditions]);
            for i:=0 to nConditions^.Count-1 do
               Out_Proposition(nConditions^.Items^[i]);
            Out_XElEnd( XMLElemName[elConditions]);
            Out_Justification(nJustification,nil);
         end

@
\medbreak
{\schema
Item-contents \pipe= Type-Changing-Statement-contents
Type-Changing-Statement-contents =
((element Equality \LB
\qquad Variable,
\qquad Term
\quad\RB\ \pipe\ Variable),
\ Type)
\par}

@<Emit \XML/ for \texttt{reconsider} contents (WSM)@>=
            with TypeChangingStatementPtr(nContent)^ do
         begin
            for i:=0 to nTypeChangeList^.Count-1 do
               case TypeChangePtr(nTypeChangeList.Items^[i])^.nTypeChangeKind of
                  Equating:
                     begin
                        Out_XElStart0( XMLElemName[elEquality]);
                        Out_Variable(TypeChangePtr(nTypeChangeList.Items^[i])^.nVar);
                        Out_Term(TypeChangePtr(nTypeChangeList.Items^[i])^.nTermExpr);
                        Out_XElEnd( XMLElemName[elEquality]);
                     end;
                  VariableIdentifier:
                     begin
                        Out_Variable(TypeChangePtr(nTypeChangeList.Items^[i])^.nVar);
                     end;
               endcases;
            Out_Type(nTypeExpr);
            Out_Justification(nJustification,nil);
         end

@
We will need to recall \\{Out\_Variable} (\section\xref{OutWSMizFileObj.Out_Variable})
fr \\{PrivateFunctorDefinitionObj} (\section\xref{PrivateFunctorDefinitionObj}).

\medbreak
{\schema
Item-contents \pipe=
\quad (Variable, Type-List, Term) \# {\rm private functors and predicates}
\pipe\ (Variable, Term) \hphantom{st, Terms } \# {\rm constants}
\pipe\ Variable-Segment \hphantom{st, Terms } \# {\rm loci}
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itPrivFuncDefinition:
            with PrivateFunctorDefinitionPtr(nContent)^ do
         begin
            Out_Variable(nFuncId);
            Out_TypeList(nTypeExpList);
            Out_Term(nTermExpr);
         end;
         itPrivPredDefinition:
            with PrivatePredicateDefinitionPtr(nContent)^ do
         begin
            Out_Variable(nPredId);
            Out_TypeList(nTypeExpList);
            Out_Formula(nSentence);
         end;
         itConstantDefinition:
            with ConstantDefinitionPtr(nContent)^ do
         begin
            Out_Variable(nVarId);
            Out_Term(nTermExpr);
         end;
         itLociDeclaration,
         itGeneralization:
            Out_VariableSegment( QualifiedSegmentPtr(nContent));
         itCaseHead,itSupposeHead,
         itAssumption:
            @<Emit \XML/ for assumptions item (WSM)@>;
@

\medbreak
{\schema
Item-contents \pipe=
( Variable-Segment*,
\quad element Conditions \LB\ Proposition* \RB\ )
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itExistentialAssumption:
            with ExistentialAssumptionPtr(nContent)^ do
         begin
            for i:= 0 to  nQVars^.Count-1 do
               Out_VariableSegment( nQVars^.Items^[i]);
            Out_XElStart0( XMLElemName[elConditions]);
            for i:=0 to nConditions^.Count-1 do
               Out_Proposition(nConditions^.Items^[i]);
            Out_XElEnd( XMLElemName[elConditions]);
         end;
@

\medbreak
{\schema
Item-contents \pipe= (\ Variable?, Term? ) \# {\rm Exemplification}
\qquad\qquad\qquad\qquad\pipe\ Justification\quad\qquad\ \# \rlap{\rm per cases,\ correctness-condition}
\qquad\qquad\qquad\qquad\pipe\ Block\qquad\qquad\qquad\quad\ \# \rlap{\rm case\ block}
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itExemplification:
            with ExamplePtr(nContent)^ do
         begin
            if nVarId <> nil then
               Out_Variable(nVarId);
            if nTermExpr <> nil then
               Out_Term(nTermExpr);
         end;
         itPerCases:
            Out_Justification(JustificationPtr(nContent),nil);
         itCaseBlock:
            Out_Block(nBlock);
         itCorrCond:
            Out_Justification(CorrectnessConditionPtr(nContent)^.nJustification,nBlock);
@

\medbreak
{\schema
Item-contents \pipe=
\quad element CorrectnessConditions \LB\ \# {\rm sic!}
\qquad element Correctness \LB\ attribute condition \LB\ text \RB\ \RB*,
\qquad\quad Justification \RB
\pipe Justification \# {\rm Property}
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itCorrectness:
            begin
               Out_XElStart0( XMLElemName[elCorrectnessConditions]);
               for s in CorrectnessConditionsPtr(nContent)^.nConditions do
               begin
                  Out_XElStart(ItemName[itCorrectness]);
                  Out_XAttr( XMLAttrName[atCondition],CorrectnessName[s]);
                  Out_XElEnd0;
               end;
               Out_XElEnd( XMLElemName[elCorrectnessConditions]);
               Out_Justification(CorrectnessPtr(nContent)^.nJustification,nBlock);
            end;
         itProperty:
            Out_Justification(PropertyPtr(nContent)^.nJustification,nBlock);
@

\medbreak
{\schema
Item-contents \pipe=
(\ element Redefine \LB\ \RB?,
\quad Pattern,
\quad element Standard-Mode \LB\ Type \RB,
\quad \pipe\ element Expandable-Mode \LB
\qquad\quad element Type-Specification \LB\ Type \RB?,
\qquad\quad Definiens
\qquad \RB)
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itDefMode:
            with ModeDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
               Out_XEl1(XMLElemName[elRedefine]);
            Out_Pattern(nDefModePattern);
            case nDefKind of
               defExpandableMode:
                  begin
                     Out_XElStart0( ModeDefinitionSortName[defExpandableMode]);
                     Out_Type(ExpandableModeDefinitionPtr(nContent)^.nExpansion);
                     Out_XElEnd( ModeDefinitionSortName[defExpandableMode]);
                  end;
               defStandardMode:
                  with StandardModeDefinitionPtr(nContent)^ do
               begin
                  Out_XElStart0( ModeDefinitionSortName[defStandardMode]);
                  if nSpecification <> nil then
                  begin
                     Out_XElStart0( XMLElemName[elTypeSpecification]);
                     Out_Type(nSpecification);
                     Out_XElEnd( XMLElemName[elTypeSpecification]);
                  end;
                  Out_Definiens(nDefiniens);
                  Out_XElEnd( ModeDefinitionSortName[defStandardMode]);
               end;
            endcases;
         end;
@

\medbreak
{\schema
Item-contents \pipe=
(element Redefine \LB\ \RB?,
\ Pattern,
\ Definiens)
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itDefAttr:
            with AttributeDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
               Out_XEl1(XMLElemName[elRedefine]);
            Out_Pattern(nDefAttrPattern);
            Out_Definiens(nDefiniens);
         end;
         itDefPred:
            with PredicateDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
               Out_XEl1(XMLElemName[elRedefine]);
            Out_Pattern(nDefPredPattern);
            Out_Definiens(nDefiniens);
         end;
@

\medbreak
{\schema
Item-contents \pipe=
(element Redefine \LB\ \RB?,
 Pattern,
 element Type-Specification \LB\ Type \RB?,
 Definiens)
\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itDefFunc:
            with FunctorDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
               Out_XEl1(XMLElemName[elRedefine]);
            Out_Pattern(nDefFuncPattern);
            if nSpecification <> nil then
            begin
               Out_XElStart0( XMLElemName[elTypeSpecification]);
               Out_Type(nSpecification);
               Out_XElEnd( XMLElemName[elTypeSpecification]);
            end;
            Out_Definiens(nDefiniens);
         end;
@

\medbreak
{\schema
Item-contents \pipe=
(element Ancestors \LB\ Type* \RB,
\quad\ attribute nr \LB\ xsd:integer \RB,
\spelling{\quad\ }?,
\pos{\quad\ },
\quad\ Loci,
\quad\ (element Field-Segment \LB
\pos{\quad\qquad},
\qquad\quad(element Selector \LB
\qquad\qquad attribute nr \LB\ xsd:integer \RB,
\spelling{\qquad\qquad}?,
\pos{\qquad\qquad}
\quad\qquad \RB)*,
\qquad\quad Type
\quad\ )*
\ \RB,

\par}

@<Emit \XML/ for definition-related items (WSM)@>=
         itDefStruct:
            with StructureDefinitionPtr(nContent)^ do
         begin
            Out_XElStart0( XMLElemName[elAncestors]);
            for i := 0 to nAncestors^.Count - 1 do
               Out_Type(nAncestors^.Items^[i]);
            Out_XElEnd( XMLElemName[elAncestors]);
            Out_XElStart(DefPatternName[itDefStruct]);
            Out_XIntAttr( XMLAttrName[atNr],nDefStructPattern^.nModeSymbol);
            if nMizarAppearance then
               Out_XAttr( XMLAttrName[atSpelling], StructureName[nDefStructPattern^.nModeSymbol]);
            Out_PosAsAttrs(nStrPos);
            Out_XAttrEnd;
            Out_Loci(nDefStructPattern^.nArgs);
            for i := 0 to nSgmFields^.Count - 1 do
               with FieldSegmentPtr(nSgmFields^.Items^[i])^ do
            begin
               Out_XElStart(XMLElemName[elFieldSegment]);
               Out_PosAsAttrs(nFieldSegmPos);
               Out_XAttrEnd;
               for j := 0 to nFields^.Count - 1 do
                  with FieldSymbolPtr(nFields^.Items^[j])^ do
               begin
                  Out_XElStart( XMLElemName[elSelector]);
                  Out_XIntAttr( XMLAttrName[atNr], nFieldSymbol);
                  if nMizarAppearance then
                     Out_XAttr( XMLAttrName[atSpelling], SelectorName[nFieldSymbol]);
                  Out_PosAsAttrs(nFieldPos);
                  Out_XElEnd0
               end;
               Out_Type(nSpecification);
               Out_XElEnd(XMLElemName[elFieldSegment]);
            end;
            Out_XElEnd( DefPatternName[itDefStruct]);
         end

@

\medbreak
{\schema
Item-contents \pipe= (element Single-Assumption \LB
\pos{\quad},
\quad Proposition
\RB\ \pipe\ element Collective-Assumption \LB
\pos{\quad},
\quad element Conditions \LB\ Proposition* \RB
\RB)\par}

@<Emit \XML/ for assumptions item (WSM)@>=
            case AssumptionPtr(nContent)^.nAssumptionSort of
               SingleAssumption:
                  begin
                     Out_XElStart( AssumptionKindName[SingleAssumption]);
                     Out_PosAsAttrs(AssumptionPtr(nContent)^.nAssumptionPos);
                     Out_XAttrEnd;
                     Out_Proposition(SingleAssumptionPtr(nContent)^.nProp);
                     Out_XElEnd( AssumptionKindName[SingleAssumption]);
                  end;
               CollectiveAssumption:
                  begin
                     Out_XElStart( AssumptionKindName[CollectiveAssumption]);
                     Out_PosAsAttrs(AssumptionPtr(nContent)^.nAssumptionPos);
                     Out_XAttrEnd;
                     Out_XElStart0( XMLElemName[elConditions]);
                     with CollectiveAssumptionPtr(nContent)^ do
                        for i:=0 to nConditions^.Count-1 do
                           Out_Proposition(nConditions^.Items^[i]);
                     Out_XElEnd( XMLElemName[elConditions]);
                     Out_XElEnd( AssumptionKindName[CollectiveAssumption]);
                  end;
            endcases

@ We have cluster registrations and non-cluster registrations.

\medbreak
{\schema
Existential-Registration-content = element Existential-Registration \LB
\pos{\quad},
\quad Adjective-Cluster,
\quad Type
\RB
Conditional-Registration-content = element Conditional-Registration \LB
\pos{\quad},
\quad Adjective-Cluster, Adjective-Cluster,
\quad Type
\RB
Functorial-Registration-content = element Functorial-Registration \LB
\pos{\quad},
\quad Term,
\quad Adjective-Cluster,
\quad Type?
\RB
\par}

@<Emit \XML/ for registration-related items (WSM)@>=
         itCluster:
            case ClusterPtr(nContent)^.nClusterKind of
               ExistentialRegistration :
                  with EClusterPtr(nContent)^ do
               begin
                  Out_XElStart( ClusterRegistrationName[ExistentialRegistration]);
                  Out_PosAsAttrs(nClusterPos);
                  Out_XAttrEnd;
                  Out_AdjectiveList(nConsequent);
                  Out_Type(nClusterType);
                  Out_XElEnd(ClusterRegistrationName[ExistentialRegistration]);
               end;
               ConditionalRegistration :
                  with CClusterPtr(nContent)^ do
               begin
                  Out_XElStart( ClusterRegistrationName[ConditionalRegistration]);
                  Out_PosAsAttrs(nClusterPos);
                  Out_XAttrEnd;
                  Out_AdjectiveList(nAntecedent);
                  Out_AdjectiveList(nConsequent);
                  Out_Type(nClusterType);
                  Out_XElEnd(ClusterRegistrationName[ConditionalRegistration]);
               end;
               FunctorialRegistration:
                  with FClusterPtr(nContent)^ do
               begin
                  Out_XElStart( ClusterRegistrationName[FunctorialRegistration]);
                  Out_PosAsAttrs(nClusterPos);
                  Out_XAttrEnd;
                  Out_Term(nClusterTerm);
                  Out_AdjectiveList(nConsequent);
                  if nClusterType <> nil then
                     Out_Type(nClusterType);
                  Out_XElEnd(ClusterRegistrationName[FunctorialRegistration]);
               end;
            endcases;
@

\medbreak
{\schema
Identify-Registration-content =
(Pattern, Pattern,
\quad  element LociEquality \LB
\pos{\qquad\quad},
\quad\qquad Locus, Locus
\quad\quad\RB*
\quad\RB)
Sethood-Registration-content = (Type, Justification)
Reduction-Registration-content = (Term, Term)
\par}

@<Emit \XML/ for registration-related items (WSM)@>=
         itIdentify:
            with IdentifyRegistrationPtr(nContent)^ do
         begin
            Out_Pattern(nOriginPattern);
            Out_Pattern(nNewPattern);
            if nEqLociList <> nil then
            begin
               for i := 0 to nEqLociList^.Count - 1 do
                  with LociEqualityPtr(nEqLociList^.Items^[i])^ do
               begin
                  Out_XElStart(XMLElemName[elLociEquality]);
                  Out_PosAsAttrs(nEqPos);
                  Out_XAttrEnd;
                  Out_Locus(nLeftLocus);
                  Out_Locus(nRightLocus);
                  Out_XElEnd(XMLElemName[elLociEquality]);
               end;
            end;
         end;
         itPropertyRegistration:
            case PropertyRegistrationPtr(nContent)^.nPropertySort of
               sySethood:
                  with SethoodRegistrationPtr(nContent)^ do
               begin
                  Out_Type(nSethoodType);
                  Out_Justification(nJustification,nBlock);
               end;
            endcases;
         itReduction:
            with ReduceRegistrationPtr(nContent)^ do
         begin
            Out_Term(nOriginTerm);
            Out_Term(nNewTerm);
         end

@ \node{Emitting an item.}

\medbreak
{\schema
Item = element Item \LB
\quad attribute kind \LB\ text \RB,
\quad Item-contents-attribute?,
\pos{\quad},
\quad attribute posline \LB\ xsd:integer \RB,
\quad attribute poscol \LB\ xsd:integer \RB,
\quad (Block \pipe\ Item-contents)?
\RB
\par}

\label{OutWSMizFileObj.Out_Item}

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure OutWSMizFileObj.Out_Item(aWSItem:WSItemPtr);
var i,j: integer;
begin
   with aWSItem^ do
   begin
      CurPos:=nItemPos;
      Out_XElStart(XMLElemName[elItem]);
      Out_XAttr( XMLAttrName[atKind], ItemName[nItemKind]);
      if nContent <> nil then
         Out_ItemContentsAttr(aWsItem);
      Out_PosAsAttrs(nItemPos);
      Out_XIntAttr( XMLAttrName[atPosLine], nItemEndPos.Line);
      Out_XIntAttr( XMLAttrName[atPosCol], nItemEndPos.Col);
      Out_XAttrEnd;
      if nContent = nil then
      begin
         if nBlock <> nil then
            Out_Block(nBlock);
      end
      else Out_ItemContents(aWsItem);
      Out_XElEnd( XMLElemName[elItem]);
   end;
end;

@ \node{Writing out to an XML file.}

@p
procedure Write_WSMizArticle(aWSTextProper:wsTextProperPtr; aFileName:string);
var lWSMizOutput: OutWSMizFilePtr;
begin
   InitScannerNames;
   lWSMizOutput:=new(OutWSMizFilePtr,OpenFile(aFileName));
   lWSMizOutput^.nMizarAppearance:=true;
   lWSMizOutput^.Out_TextProper(aWSTextProper);
   dispose(lWSMizOutput,Done);
end;

@* [S] Reading WSM files (deferred).
Reading a WSM file amounts to reading an \XML/ file, which means that
the \\{XMLInStream} class (\section\xref{XMLInStreamObj}) is a natural
parent class. Recall, the state of the \\{XMLInStream} contains the
current start tag and a dictionary for the attributes and their
values.

The code is a ``mirror image'' to writing \XML/ files, and the \XML/
schema guides the implementation.

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
   InWSMizFilePtr = ^InWSMizFileObj; @/
   InWSMizFileObj =
      object(XMLInStreamObj) @t\1 @> @/
         nDisplayInformationOnScreen: boolean; @/

         constructor OpenFile(const aFileName:string ); @t\2 @>
         destructor Done; virtual; @t\2 @>

         function GetAttrValue(const aAttrName:string): string; @t\2 @>
         function GetAttrPos: Position; @t\2 @>

         function Read_TextProper: wsTextProperPtr; virtual; @t\2 @>
         function Read_Block: wsBlockPtr; virtual; @t\2 @>
         function Read_Item: wsItemPtr; virtual; @t\2 @>

         procedure Read_ItemContentsAttr(aItem: wsItemPtr; var aShape: string); virtual; @t\2 @>
         procedure Read_ItemContents(aItem: wsItemPtr@+;@+ const aShape: string); virtual; @t\2 @>

         function Read_TermList:PList; virtual; @t\2 @>
         function Read_Adjective:AdjectiveExpressionPtr; virtual; @t\2 @>
         function Read_AdjectiveList: PList; virtual; @t\2 @>
         function Read_Type: TypePtr; virtual; @t\2 @>
         function Read_Variable: VariablePtr; virtual; @t\2 @>
         function Read_ImplicitlyQualifiedSegment: ImplicitlyQualifiedSegmentPtr; virtual; @t\2 @>
         function Read_VariableSegment: QualifiedSegmentPtr; virtual; @t\2 @>
         function Read_PrivatePredicativeFormula:PrivatePredicativeFormulaPtr; virtual; @t\2 @>
         function Read_Formula:FormulaPtr; virtual; @t\2 @>
         function Read_SimpleTerm: SimpleTermPtr; virtual; @t\2 @>
         function Read_PrivateFunctorTerm: PrivateFunctorTermPtr; virtual; @t\2 @>
         function Read_InternalSelectorTerm: InternalSelectorTermPtr; virtual; @t\2 @>
         function Read_Term: TermPtr; virtual; @t\2 @>

         function Read_TypeList: PList; virtual; @t\2 @>

         function Read_Locus: LocusPtr; virtual; @t\2 @>
         function Read_Loci: PList; virtual; @t\2 @>

         function Read_ModePattern: ModePatternPtr; virtual; @t\2 @>
         function Read_AttributePattern: AttributePatternPtr; virtual; @t\2 @>
         function Read_FunctorPattern: FunctorPatternPtr; virtual; @t\2 @>
         function Read_PredicatePattern: PredicatePatternPtr; virtual; @t\2 @>
         function Read_Pattern: PatternPtr; virtual; @t\2 @>

         function Read_Definiens: DefiniensPtr; virtual; @t\2 @>

         function Read_ReservationSegment: ReservationSegmentPtr; virtual; @t\2 @>
         function Read_SchemeNameInSchemeHead: SchemePtr; virtual; @t\2 @>
         function Read_Label: LabelPtr; virtual; @t\2 @>
         function Read_Proposition: PropositionPtr; virtual; @t\2 @>
         function Read_CompactStatement: CompactStatementPtr; virtual; @t\2 @>
         function Read_LocalReference: LocalReferencePtr; virtual; @t\2 @>
         function Read_References: PList; virtual; @t\2 @>
         function Read_StraightforwardJustification: StraightforwardJustificationPtr; virtual; @t\2 @>
         function Read_SchemeJustification: SchemeJustificationPtr; virtual; @t\2 @>
         function Read_Justification: JustificationPtr; virtual; @t\2 @>
         function Read_RegularStatement(const aShape: string): RegularStatementPtr; virtual; @t\2\2\2 @>
      end;

@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor InWSMizFileObj.OpenFile(const aFileName:string );
begin
   inherited OpenFile(aFileName);
   nDisplayInformationOnScreen:=false;
end;

destructor InWSMizFileObj.Done;
begin
   inherited Done;
end;

@ Getting the value for an attribute. Returns |nil| if there is no
attribute with the given name. (Recall (\section\xref{XMLAttrPtr}),
an \\{XMLAttr} is just a wrapper around a string \\{nValue}.)

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.GetAttrValue(const aAttrName:string): string;
var lObj: PObject;
begin
   result:='';
   lObj:=nAttrVals.ObjectOf(aAttrName);
   if lObj <> nil then
      result:=XMLAttrPtr(lObj)^.nValue;
end;

@ We can query for the \emph{position} of the \XML/ attribute.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.GetAttrPos: Position;
var lLine,lCol: XMLAttrPtr;
lCode: integer;
begin
   result.Line:=1;
   result.Col:=1;
   lLine:=XMLAttrPtr(nAttrVals.ObjectOf(XMLAttrName[atLine]));
   lCol:=XMLAttrPtr(nAttrVals.ObjectOf(XMLAttrName[atCol]));
   if (lLine <> nil) and (lCol <> nil) then
   begin
      Val(lLine^.nValue, result.Line,lCode);
      Val(lCol^.nValue, result.Col,lCode);
   end;
end;

@ The state of the  WSM parser may be described with a handful of
lookup tables.

@<Implementation for \texttt{wsmarticle.pas}@>=
var
   ElemLookupTable,AttrLookupTable,BlockLookUpTable,ItemLookUpTable,
   FormulaKindLookupTable,TermKindLookupTable,
   PatternKindLookupTable,
   CorrectnessKindLookupTable,PropertyKindLookupTable: MSortedStrList; @#

procedure InitWSLookupTables;
var e: XMLElemKind;
a: XMLAttrKind;
b: BlockKind;
i: ItemKind;
f: FormulaSort;
t: TermSort;
p: PropertyKind;
c: CorrectnessKind;
begin
   ElemLookupTable.Init( Ord( High( XMLElemKind)) + 1);
   AttrLookupTable.Init( Ord( High( XMLAttrKind)) + 1);
   BlockLookupTable.Init( Ord( High( BlockKind)) + 1);
   ItemLookupTable.Init( Ord( High( ItemKind)) + 1);
   FormulaKindLookupTable.Init( Ord( High( FormulaSort)) + 1);
   TermKindLookupTable.Init( Ord( High( TermSort)) + 1);
   PatternKindLookupTable.Init( Ord(itDefStruct)- Ord(itDefPred) + 1);
   CorrectnessKindLookupTable.Init(ord( High(CorrectnessKind)) + 1);
   PropertyKindLookupTable.Init( ord( High(PropertyKind)) + 1);

   for e:= Low( XMLElemKind) to High( XMLElemKind) do
      ElemLookupTable.Insert( new( MStrPtr, Init( XMLElemName[ e] )));
   for a:= Low( XMLAttrKind) to High( XMLAttrKind) do
      AttrLookupTable.Insert( new( MStrPtr, Init( XMLAttrName[ a] )));
   for b:= Low( BlockKind) to High( BlockKind) do
      BlockLookupTable.Insert( new( MStrPtr, Init( BlockName[ b] )));
   for i:= Low( ItemKind) to High( ItemKind) do
      ItemLookupTable.Insert( new( MStrPtr, Init( ItemName[ i] )));
   for f:= Low( FormulaSort) to High( FormulaSort) do
      FormulaKindLookupTable.Insert( new( MStrPtr, Init( FormulaName[ f] )));
   for t:= Low( TermSort) to High( TermSort) do
      TermKindLookupTable.Insert( new( MStrPtr, Init( TermName[ t] )));
   for i:= itDefPred to itDefStruct do
      PatternKindLookupTable.Insert( new( MStrPtr, Init( DefPatternName[ i] )));
   for p:= Low( PropertyKind) to High( PropertyKind) do
      PropertyKindLookupTable.Insert( new( MStrPtr, Init( PropertyName[ p] )));
   for c:= Low( CorrectnessKind) to High( CorrectnessKind) do
      CorrectnessKindLookupTable.Insert( new( MStrPtr, Init( CorrectnessName[ c] )));
end;

@ We also need to free the memory consumed by the lookup tables.

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure DisposeWSLookupTables;
begin
   ElemLookupTable.Done;
   AttrLookupTable.Done;
   BlockLookupTable.Done;
   ItemLookupTable.Done;
   FormulaKindLookupTable.Done;
   TermKindLookupTable.Done;
   CorrectnessKindLookupTable.Done;
   PropertyKindLookupTable.Done;
end;

@ We can recall, from the \XML/ dictionary module
(\section\xref{XMLDictionary}), the different kinds of \XML/ elements
as specified by an enumerated constant. This converts the
``\texttt{nr}'' attribute to the human readable equivalents.

@<Implementation for \texttt{wsmarticle.pas}@>=
function Str2XMLElemKind( aStr: string): XMLElemKind;
var lNr:integer;
begin
   lNr:= ElemLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2XMLElemKind:= XMLElemKind( lNr)
   else Str2XMLElemKind:= elUnknown;
end;

@ Like the previous function, this converts the ``\texttt{nr}''
attribute for a WSM Mizar attribute \XML/ element into a human
readable form.

@<Implementation for \texttt{wsmarticle.pas}@>=
function Str2XMLAttrKind( aStr: string): XMLAttrKind;
var lNr:integer;
begin
   lNr:= AttrLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2XMLAttrKind:= XMLAttrKind( lNr)
   else Str2XMLAttrKind:= atUnknown;
end;

@ The ``kinds'' of different syntactic classes were introduced earlier
in \texttt{wsmarticle.pas}, now we want to translate them into human
readable form.

@<Implementation for \texttt{wsmarticle.pas}@>=
function Str2BlockKind( aStr: string): BlockKind;
var lNr:integer;
begin
   lNr:= BlockLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2BlockKind:= BlockKind( lNr)
   else Str2BlockKind:= blMain;
end; @#

function Str2ItemKind( aStr: string): ItemKind;
var lNr:integer;
begin
   lNr:= ItemLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2ItemKind:= ItemKind( lNr)
   else Str2ItemKind:=itIncorrItem;
end; @#

function Str2PatterenKind( aStr: string): ItemKind;
var lNr:integer;
begin
   lNr:= PatternKindLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2PatterenKind:= ItemKind(Ord(ItDefPred)+lNr)
   else Str2PatterenKind:=itIncorrItem;
end; @#

function Str2FormulaKind( aStr: string): FormulaSort;
var lNr:integer;
begin
   lNr:= FormulaKindLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2FormulaKind:= FormulaSort( lNr)
   else Str2FormulaKind:=wsErrorFormula;
end; @#
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function Str2TermKind( aStr: string): TermSort;
var lNr:integer;
begin
   lNr:= TermKindLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2TermKind:= TermSort( lNr)
   else Str2TermKind:=wsErrorTerm;
end; @#

function Str2PropertyKind( aStr: string): PropertyKind;
var lNr:integer;
begin
   lNr:= PropertyKindLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2PropertyKind:= PropertyKind( lNr)
end; @#

function Str2CorrectnessKind( aStr: string): CorrectnessKind;
var lNr:integer;
begin
   lNr:= CorrectnessKindLookupTable.IndexOfStr( aStr);
   if lNr > -1 then
      Str2CorrectnessKind:= CorrectnessKind( lNr)
end;

@* [s] Parsing types.
Reading a ``term list'' just iteratively invokes \\{Read\_Term}
(\section\xref{InWSMizFileObj.Read_Term}) until all the children have
been read.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_TermList:PList;
begin
   result :=new(PList,Init(0));
   while nState <> eEnd do
      result^.Insert(Read_Term);
end;

@ An adjective is either ``positive'' (i.e., not negated) or
``negative'' (i.e., negated). We handle the first case in the ``true''
branch, and the second case in the ``false'' branch.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Adjective:AdjectiveExpressionPtr;
var lAttrNr: integer;
lPos: Position;
lNoneOcc: Boolean;
begin
   if nElName = AdjectiveSortName[wsAdjective] then
   begin
      lPos:=GetAttrPos;
      lAttrNr:=GetIntAttr(XMLAttrName[atNr]);
      NextElementState;
      result:=new(AdjectivePtr,Init(lPos,lAttrNr,Read_TermList));
      NextElementState;
   end
   else
   begin
      lPos:=GetAttrPos;
      NextElementState;
      result:=new(NegatedAdjectivePtr,Init(lPos,Read_Adjective));
      NextElementState;
   end;
end;

@ Reading a list of adjectives just iterates over the children of an element.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_AdjectiveList: PList;
begin
   result:=new(Plist,Init(0));
   NextElementState;
   while nState <> eEnd do
      result^.Insert(Read_Adjective);
   NextElementState;
end;

@
There are three valid Mizar types: ``standard'' types, structure
types, and expandable modes (i.e., a cluster of adjectives stacked
atop a type). If the \XML/ element fails to match these three, then we
should produce an ``incorrect type''.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Type: TypePtr;
var lList: Plist;
lPos: Position;
lModeSymbol:integer;
begin
   if nElName = TypeName[wsStandardType] then
   begin
      lPos:=GetAttrPos;
      lModeSymbol:=GetIntAttr(XMLAttrName[atNr]);
      NextElementState;
      result:=new(StandardTypePtr,Init(lPos,lModeSymbol,Read_TermList));
      NextElementState;
   end
   else if nElName = TypeName[wsStructureType] then
   begin
      lPos:=GetAttrPos;
      lModeSymbol:=GetIntAttr(XMLAttrName[atNr]);
      NextElementState;
      result:=new(StructTypePtr,Init(lPos,lModeSymbol,Read_TermList));
      NextElementState;
   end
   else if nElName = TypeName[wsClusteredType] then
   begin
      lPos:=GetAttrPos;
      NextElementState;
      lList:=Read_AdjectiveList;
      result:=new(ClusteredTypePtr,Init(lPos,lList,Read_Type));
      NextElementState;
   end
   else
   begin
      lPos:=GetAttrPos;
      NextElementState;
      result:=new(IncorrectTypePtr,Init(lPos));
      NextElementState;
   end
end;

@* [s] Parsing formulas.
Parsing a variable from \XML/ just requires reading the attributes,
since it is an empty-element.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Variable: VariablePtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]); @/
   NextElementState; {closes the variable's tag}
   result:=new(VariablePtr,Init(lPos,lNr)); @/
   NextElementState; {starts the next tag}
end;

@ Implicitly qualified variables are just wrappers around a variable.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_ImplicitlyQualifiedSegment: ImplicitlyQualifiedSegmentPtr;
var lPos: Position;
begin
   lPos:=GetAttrPos;
   NextElementState;
   result:=new(ImplicitlyQualifiedSegmentPtr,Init(lPos,Read_Variable));
   NextElementState;
end;

@ Recall (\section\xref{OutWSMizFileObj.Out_VariableSegment}) that a
``qualified segment'' is either implicit (i.e., a wrapper around a 
single variable) or explicit (i.e., an element whose children are
variables and a type).

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_VariableSegment: QualifiedSegmentPtr;
var lPos: Position;
lVar: VariablePtr;
lList: PList;
begin
   if nElName = SegmentKindName[ikImplQualifiedSegm] then
   begin
      result:=Read_ImplicitlyQualifiedSegment;
   end
   else if nElName = SegmentKindName[ikExplQualifiedSegm] then
   begin
      lPos:=GetAttrPos;
      NextElementState;
      lList:=new(PList,Init(0)); @/
      NextElementState; {read the variables}
      while (nState = eStart) and (nElName = XMLElemName[elVariable]) do
         lList^.Insert(Read_Variable);
      NextElementState; {read the type}
      result:=new(ExplicitlyQualifiedSegmentPtr,Init(lPos,lList,Read_Type));@/
      NextElementState; {start the next tag}
   end
end;

@ Private predicates are empty elements, so we only need to read their
attributes. 

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_PrivatePredicativeFormula:PrivatePredicativeFormulaPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   NextElementState;
   result:=new(PrivatePredicativeFormulaPtr,Init(lPos,lNr,Read_TermList));
   NextElementState;
end;

@ 

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Formula:FormulaPtr;
var lPos:Position;
lNr: integer;
lList: PList;
lFrm: FormulaPtr;
lTrm: TermPtr;
lSgm: QualifiedSegmentPtr;
begin
   case Str2FormulaKind(nElName) of
      wsNegatedFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(NegativeFormulaPtr,Init(lPos,Read_Formula));
            NextElementState;
         end; @#
 @t\4@>     @<Parse \XML/ for formula with binary connective@>; @#
      wsFlexaryConjunctiveFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(FlexaryConjunctiveFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end;
      wsFlexaryDisjunctiveFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(FlexaryDisjunctiveFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end; @#
 @t\4@>     @<Parse \XML/ for predicate-based formula@>; @#
      wsAttributiveFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lTrm:=Read_Term;
            result:=new(AttributiveFormulaPtr,Init(lPos,lTrm,Read_AdjectiveList));
            NextElementState;
         end;
      wsQualifyingFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lTrm:=Read_Term;
            result:=new(QualifyingFormulaPtr,Init(lPos,lTrm,Read_Type));
            NextElementState;
         end; @#
      wsUniversalFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lSgm:=Read_VariableSegment;
            result:=new(UniversalFormulaPtr,Init(lPos,lSgm,Read_Formula));
            NextElementState;
         end;
      wsExistentialFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lSgm:=Read_VariableSegment;
            result:=new(ExistentialFormulaPtr,Init(lPos,lSgm,Read_Formula));
            NextElementState;
         end; @#
      wsContradiction:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(ContradictionFormulaPtr,Init(lPos));
            NextElementState;
         end;
      wsThesis:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(ThesisFormulaPtr,Init(lPos));
            NextElementState;
         end;
      wsErrorFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(IncorrectFormulaPtr,Init(lPos));
            NextElementState;
         end;
   endcases;
end;

@  For formulas with binary connectives, we read both arguments.

@<Parse \XML/ for formula with binary connective@>=
      wsConjunctiveFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(ConjunctiveFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end;
      wsDisjunctiveFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(DisjunctiveFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end;
      wsConditionalFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(ConditionalFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end;
      wsBiconditionalFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lFrm:=Read_Formula;
            result:=new(BiconditionalFormulaPtr,Init(lPos,lFrm,Read_Formula));
            NextElementState;
         end

@

@<Parse \XML/ for predicate-based formula@>=
      wsPredicativeFormula:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            NextElementState; {Arguments}
            lList:=Read_TermList;
            NextElementState; {Arguments}
            NextElementState; {Arguments}
            result:=new(PredicativeFormulaPtr,Init(lPos,lNr,lList,Read_TermList));
            NextElementState;
            NextElementState;
         end;
      wsRightSideOfPredicativeFormula:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            NextElementState; {Arguments}
            result:=new(RightSideOfPredicativeFormulaPtr,Init(lPos,lNr,Read_TermList));
            NextElementState;
            NextElementState;
         end;
      wsMultiPredicativeFormula:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lList:=new(PList,Init(0));
            while nState <> eEnd do
               lList^.Insert(Read_Formula);
            result:=new(MultiPredicativeFormulaPtr,Init(lPos,lList));
            NextElementState;
         end;
      wsPrivatePredicateFormula:
         begin
            result:=Read_PrivatePredicativeFormula;
         end

@* [s] Parsing terms.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_SimpleTerm: SimpleTermPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   NextElementState;
   result:=new(SimpleTermPtr,Init(lPos,lNr));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_PrivateFunctorTerm: PrivateFunctorTermPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   NextElementState;
   result:=new(PrivateFunctorTermPtr,Init(lPos,lNr,Read_TermList));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_InternalSelectorTerm: InternalSelectorTermPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atNr]);
   NextElementState;
   result:=new(InternalSelectorTermPtr,Init(lPos,lNr));
   NextElementState;
end;

@ 

\label{InWSMizFileObj.Read_Term}

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Term: TermPtr;
var lPos,lRPos:Position;
lNr,lRNr: integer;
lList: PList;
lTrm: TermPtr;
begin
   case Str2TermKind(nElName) of
      wsPlaceholderTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            result:=new(PlaceholderTermPtr,Init(lPos,lNr));
            NextElementState;
         end;
      wsSimpleTerm:
         begin
            result:=Read_SimpleTerm;
         end;
      wsNumeralTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNumber]);
            NextElementState;
            result:=new(NumeralTermPtr, Init(lPos,lNr));
            NextElementState;
         end;
      wsInfixTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            NextElementState; {Arguments}
            lList:=Read_TermList;
            NextElementState; {Arguments}
            NextElementState; {Arguments}
            result:=new(InfixTermPtr,Init(lPos,lNr,lList,Read_TermList));
            NextElementState;
            NextElementState;
         end;
      wsCircumfixTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            NextElementState;
            lRNr:=GetIntAttr(XMLAttrName[atNr]);
            lRPos:=GetAttrPos;
            NextElementState;
            result:=new(CircumfixTermPtr,Init(lPos,lNr,lRNr,Read_TermList));
            NextElementState;
         end;
      wsPrivateFunctorTerm:
         begin
            result:=Read_PrivateFunctorTerm;
         end;
      wsAggregateTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            result:=new(AggregateTermPtr,Init(lPos,lNr,Read_TermList));
            NextElementState;
         end;
      wsSelectorTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            result:=new(SelectorTermPtr,Init(lPos,lNr,Read_Term));
            NextElementState;
         end;
      wsInternalSelectorTerm:
         result:=Read_InternalSelectorTerm;
      wsForgetfulFunctorTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            result:=new(ForgetfulFunctorTermPtr,Init(lPos,lNr,Read_Term));
            NextElementState;
         end;
      wsInternalForgetfulFunctorTerm:
         begin
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            result:=new(InternalForgetfulFunctorTermPtr,Init(lPos,lNr));
            NextElementState;
         end;
      wsFraenkelTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lList:=new(PList,Init(0));
            while (nState = eStart) and
                     ((nElName = SegmentKindName[ikImplQualifiedSegm]) or
                         (nElName = SegmentKindName[ikExplQualifiedSegm])) do
               lList^.Insert(Read_VariableSegment);
            lTrm:=Read_Term;
            result:=new(FraenkelTermPtr,Init(lPos,lList,lTrm,Read_Formula));
            NextElementState;
         end;
      wsSimpleFraenkelTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lList:=new(PList,Init(0));
            while (nState = eStart) and
                     ((nElName = SegmentKindName[ikImplQualifiedSegm]) or
                         (nElName = SegmentKindName[ikExplQualifiedSegm])) do
               lList^.Insert(Read_VariableSegment);
            lTrm:=Read_Term;
            result:=new(SimpleFraenkelTermPtr,Init(lPos,lList,lTrm));
            NextElementState;
         end;
      wsQualificationTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            lTrm:=Read_Term;
            result:=new(QualifiedTermPtr,Init(lPos,lTrm,Read_Type));
            NextElementState;
         end;
      wsExactlyTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(ExactlyTermPtr,Init(lPos,Read_Term));
            NextElementState;
         end;
      wsGlobalChoiceTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(ChoiceTermPtr,Init(lPos,Read_Type));
            NextElementState;
         end;
      wsItTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(ItTermPtr,Init(lPos));
            NextElementState;
         end;
      wsErrorTerm:
         begin
            lPos:=GetAttrPos;
            NextElementState;
            result:=new(IncorrectTermPtr,Init(lPos));
            NextElementState;
         end;
   endcases;
end;

@* [s] Parsing text items.

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_TypeList: PList;
begin
   NextElementState;
   result :=new(PList,Init(0));
   while nState <> eEnd do
      result^.Insert(Read_Type);
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Locus: LocusPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   NextElementState;
   result:=new(LocusPtr,Init(lPos,lNr));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Loci: PList;
begin
   NextElementState;
   result :=new(PList,Init(0));
   while nState <> eEnd do
      result^.Insert(Read_Locus);
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_ModePattern: ModePatternPtr;
var lPos:Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atNr]);
   NextElementState;
   result:=new(ModePatternPtr,Init(lPos,lNr,Read_Loci));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_AttributePattern: AttributePatternPtr;
var lPos:Position;
lNr: integer;
lArg: LocusPtr;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atNr]);
   NextElementState;
   lArg:=Read_Locus;
   result:=new(AttributePatternPtr,Init(lPos,lArg,lNr,Read_Loci));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_FunctorPattern: FunctorPatternPtr;
var lPos,lRPos:Position;
lNr,lRNr: integer;
lArgs: PList;
begin
   if nState= eStart then
      if nElName = FunctorPatternName[InfixFunctor] then
      begin
         lPos:=GetAttrPos;
         lNr:=GetIntAttr(XMLAttrName[atNr]);
         NextElementState;
         lArgs:=Read_Loci;
         result:=new(InfixFunctorPatternPtr,Init(lPos,lArgs,lNr,Read_Loci));
         NextElementState;
      end
      else if nElName = FunctorPatternName[CircumfixFunctor] then
      begin
         lPos:=GetAttrPos;
         lNr:=GetIntAttr(XMLAttrName[atNr]);
         NextElementState;
         lRNr:=GetIntAttr(XMLAttrName[atNr]);
         NextElementState;
         NextElementState;
         result:=new(CircumfixFunctorPatternPtr,Init(lPos,lNr,lRNr,Read_Loci));
         NextElementState;
      end;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_PredicatePattern: PredicatePatternPtr;
var lPos,lRPos:Position;
lNr,lRNr: integer;
lArgs: PList;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atNr]);
   NextElementState;
   lArgs:=Read_Loci;
   result:=new(PredicatePatternPtr,Init(lPos,lArgs,lNr,Read_Loci));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Pattern: PatternPtr;
begin
   case Str2PatterenKind(nElName) of
      itDefPred: result:=Read_PredicatePattern;
      itDefFunc: result:=Read_FunctorPattern;
      itDefMode: result:=Read_ModePattern;
      itDefAttr: result:=Read_AttributePattern;
   othercases
      if (nElName = FunctorPatternName[InfixFunctor]) or
            (nElName = FunctorPatternName[CircumfixFunctor])
      then result:=Read_FunctorPattern
      else result:=nil;
   endcases;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Definiens: DefiniensPtr;
var lPos: Position;
lKind,lShape: string;
lLab: LabelPtr;
lExpr: PObject;
lExpKind: ExpKind;
lList: PList;
lOtherwise: DefExpressionPtr;
begin
   result:=nil;
   if (nState= eStart) and (nElName = XMLElemName[elDefiniens]) then
   begin
      lPos:=GetAttrPos;
      lKind:=GetAttr(XMLAttrName[atKind]);
      lShape:=GetAttr(XMLAttrName[atShape]);
      NextElementState;
      lLab:=Read_Label;
      if lKind = DefiniensKindName[SimpleDefiniens] then
      begin
         lExpKind:=exFormula;
         if lShape = ExpName[exTerm] then
            lExpKind:=exTerm;
         case lExpKind of
            exTerm: lExpr:=Read_Term;
            exFormula: lExpr:=Read_Formula;
         endcases;
         result:=new(SimpleDefiniensPtr,Init(lPos,lLab,
                                             new(DefExpressionPtr,Init(lExpKind,lExpr))));
      end
      else
      begin
         lList:=new(Plist,Init(0));
         while (nState= eStart) and (nElName = XMLElemName[elPartialDefiniens]) do
         begin
            NextElementState;
            lExpKind:=exFormula;
            if lShape = ExpName[exTerm] then
               lExpKind:=exTerm;
            case lExpKind of
               exTerm: lExpr:=Read_Term;
               exFormula: lExpr:=Read_Formula;
            endcases;
            lList^.Insert(new(PartDefPtr,Init(new(DefExpressionPtr,Init(lExpKind,lExpr)),Read_Formula)));
            NextElementState;
         end;
         lOtherwise:=nil;
         if nState <> eEnd then
         begin
            lExpKind:=exFormula;
            if lShape = ExpName[exTerm] then
               lExpKind:=exTerm;
            case lExpKind of
               exTerm: lExpr:=Read_Term;
               exFormula: lExpr:=Read_Formula;
            endcases;
            lOtherwise:=new(DefExpressionPtr,Init(lExpKind,lExpr));
         end;
         result:=new(ConditionalDefiniensPtr,Init(lPos,lLab,lList,lOtherwise))
      end;
      NextElementState;
   end;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Label: LabelPtr;
var lLabPos: Position;
lLabId: Integer;
begin
   result:=nil;
   if (nState= eStart)  and (nElName = XMLElemName[elLabel]) then
   begin
      lLabId:=GetIntAttr(XMLAttrName[atIdNr]);
      lLabPos:=GetAttrPos;
      NextElementState;
      NextElementState;
      result:=new(LabelPtr,Init(lLabId,lLabPos));
   end;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Proposition: PropositionPtr;
var lPos: Position;
lLab: LabelPtr;
begin
   NextElementState;
   lLab:=Read_label;
   result:=new(PropositionPtr,Init(lLab,Read_Formula,lPos));
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_LocalReference: LocalReferencePtr;
var lPos: Position;
lNr: integer;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   NextElementState;
   NextElementState;
   result:=new(LocalReferencePtr, Init(lNr,lPos));
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_References: PList;
var lPos: Position;
lNr,lFileNr: integer;
begin
   result:=new(Plist,Init(0));
   while nState <> eEnd do
      if nElName = ReferenceKindName[LocalReference] then
      begin
         result^.Insert(Read_LocalReference)
      end
      else if nElName = ReferenceKindName[TheoremReference] then
      begin
         lPos:=GetAttrPos;
         lFileNr:=GetIntAttr(XMLAttrName[atNr]);
         lNr:=GetIntAttr(XMLAttrName[atNumber]);
         NextElementState;
         NextElementState;
         result^.Insert(new(TheoremReferencePtr, Init(lFileNr,lNr,lPos)))
      end
      else if nElName = ReferenceKindName[DefinitionReference] then
      begin
         lPos:=GetAttrPos;
         lFileNr:=GetIntAttr(XMLAttrName[atNr]);
         lNr:=GetIntAttr(XMLAttrName[atNumber]);
         NextElementState;
         NextElementState;
         result^.Insert(new(DefinitionReferencePtr, Init(lFileNr,lNr,lPos)))
      end;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_ReservationSegment: ReservationSegmentPtr;
var lList: PList;
begin
   lList:=new(PList,Init(0));
   NextElementState; {elVariables}
   while (nState = eStart) and (nElName = XMLElemName[elVariable]) do
      lList^.Insert(Read_Variable);
   NextElementState;
   result:=new(ReservationSegmentPtr,Init(lList,Read_Type));
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_SchemeNameInSchemeHead: SchemePtr;
var lNr: Integer;
lPos: Position;
begin
   lPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atIdNr]);
   result:=new(SchemePtr,Init(lNr,lPos,nil,nil,nil));
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_CompactStatement: CompactStatementPtr;
var lProp: PropositionPtr;
begin
   lProp:=Read_Proposition;
   result:=new(CompactStatementPtr,Init(lProp,Read_Justification));
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_StraightforwardJustification: StraightforwardJustificationPtr;
var lPos,lLinkPos: Position;
lLinked: boolean;
begin
   lPos:=GetAttrPos;
   NextElementState;
   lLinked:=false;
   lLinkPos:=lPos;
   if nelName = XMLElemName[elLink] then
   begin
      lLinked:=true;
      lLinkPos:=GetAttrPos;
      NextElementState;
      NextElementState;
   end;
   result:=new(StraightforwardJustificationPtr,Init(lPos,lLinked,lLinkPos));
   StraightforwardJustificationPtr(result)^.nReferences:=Read_References;
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_SchemeJustification: SchemeJustificationPtr;
var lInfPos,lPos: Position;
lNr,lIdNr: integer;
begin
   lInfPos:=GetAttrPos;
   lNr:=GetIntAttr(XMLAttrName[atNr]);
   lIdNr:=GetIntAttr(XMLAttrName[atIdNr]);
   lPos.Line:=GetIntAttr( XMLAttrName[atPosLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atPosCol]);
   NextElementState;
   result:=new(SchemeJustificationPtr,Init(lInfPos,lNr,lIdNr));
   SchemeJustificationPtr(result)^.nSchemeInfPos:=lPos;
   SchemeJustificationPtr(result)^.nReferences:=Read_References;
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Justification: JustificationPtr;
var lPos: Position;
begin
   if nState= eStart then
      if nElName = InferenceName[infStraightforwardJustification] then
         result:=Read_StraightforwardJustification
      else if nElName = InferenceName[infSchemeJustification] then
         result:=Read_SchemeJustification
      else if nElName = InferenceName[infError] then
      begin
         lPos:=GetAttrPos;
         NextElementState;
         result:=new(JustificationPtr,Init(infError,lPos));
         NextElementState;
      end
      else if nElName = InferenceName[infSkippedProof] then
      begin
         lPos:=GetAttrPos;
         NextElementState;
         result:=new(JustificationPtr,Init(infSkippedProof,lPos));
         NextElementState;
      end
      else
         result:=new(JustificationPtr,Init(infProof,CurPos));
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_RegularStatement(const aShape: string): RegularStatementPtr;
var lPos: Position;
lIdNr: integer;
lTrm: TermPtr;
lCStm: CompactStatementPtr;
lLab: LabelPtr;
begin
   if aShape = RegularStatementName[stDiffuseStatement] then
   begin
      lLab:=Read_Label;
      result:=new(DiffuseStatementPtr,Init(lLab,stDiffuseStatement));
   end
   else if aShape = RegularStatementName[stCompactStatement] then
   begin
      result:=Read_CompactStatement;
   end
   else if aShape = RegularStatementName[stIterativeEquality] then
   begin
      lCStm:=Read_CompactStatement;
      result:=new(IterativeEqualityPtr,Init(lCStm^.nProp,lCStm^.nJustification,new(PList,Init(0))));
      while (nState= eStart) and (nElName = XMLElemName[elIterativeStep]) do
      begin
         lPos:=GetAttrPos;
         NextElementState;
         lTrm:=Read_Term;
         IterativeEqualityPtr(result)^.nIterSteps^.Insert(new(IterativeStepPtr,Init(lPos,lTrm,Read_Justification)));
         NextElementState;
      end;
   end;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure InWSMizFileObj.Read_ItemContentsAttr(aItem: wsItemPtr; var aShape: string);
begin
   aShape:='';
   case aItem^.nItemKind of
      itIncorrItem:;
      itDefinition, itSchemeBlock, itSchemeHead, itTheorem, itAxiom,
      itReservation:;
      itSection:;
      itConclusion,
      itRegularStatement:
         aShape:=GetAttr(XMLAttrName[atShape]);
      itChoice, itReconsider,
      itPrivFuncDefinition, itPrivPredDefinition, itConstantDefinition,
      itGeneralization, itLociDeclaration,itExistentialAssumption, itExemplification,
      itPerCases, itCaseBlock:;
      itCaseHead, itSupposeHead,
      itAssumption:;
      itCorrCond:
         aItem^.nContent:=new(CorrectnessConditionPtr,
                              Init(CurPos,Str2CorrectnessKind(GetAttr(XMLAttrName[atCondition])),nil));
      itCorrectness:
         aItem^.nContent:=new(CorrectnessConditionsPtr,Init(CurPos,[],nil));
      itProperty:
         aShape:=GetAttr(XMLAttrName[atProperty]);
      itDefFunc:
         aShape:=GetAttr(XMLAttrName[atShape]);
      itDefPred, itDefMode, itDefAttr,
      itDefStruct,
      itPredSynonym, itPredAntonym, itFuncNotation, itModeNotation,
      itAttrSynonym, itAttrAntonym,
      itCluster,
      itIdentify, itReduction:;
      itPropertyRegistration:
         aShape:=GetAttr(XMLAttrName[atProperty]);
      itPragma:
         aItem^.nContent:=new(PragmaPtr,Init(XMLToStr(GetAttr(XMLAttrName[atSpelling]))));
   endcases;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure InWSMizFileObj.Read_ItemContents(aItem: wsItemPtr; const aShape: string);
var lList,lCons,lConds,lVars,lFields,lTyps,lSels: PList;
lType: TypePtr;
lNr: Integer;
lVar: VariablePtr;
lLocus: LocusPtr;
lTrm: TermPtr;
lPos,lFieldSgmPos: Position;
lRedefinition: boolean;
lPattern: PatternPtr;
lDef: HowToDefine;
lPropertySort: PropertyKind;
begin
   lPos:=CurPos;
   case aItem^.nItemKind of
      itIncorrItem:;
      itDefinition:;
      itSchemeBlock:;
      itSchemeHead:
         begin
            aItem^.nContent:=Read_SchemeNameInSchemeHead;
            NextElementState;
            NextElementState;
            NextElementState;   {elSchematicVariables}
            lList:=new(PList,Init(0));
            while (nState = eStart) and
                     ((nElName = SchemeSegmentName[PredicateSegment]) or
                         (nElName = SchemeSegmentName[FunctorSegment])) do
               if nElName = SchemeSegmentName[PredicateSegment] then
               begin
                  lPos:=GetAttrPos;
                  NextElementState;
                  lVars:=new(PList,Init(0));
                  NextElementState; {elVariables}
                  while (nState = eStart) and (nElName = XMLElemName[elVariable]) do
                     lVars^.Insert(Read_Variable);
                  NextElementState;
                  lList^.Insert(new(PredicateSegmentPtr,Init(lPos,PredicateSegment,lVars,Read_TypeList)));
                  NextElementState;
               end
               else
               begin
                  lPos:=GetAttrPos;
                  NextElementState;
                  lVars:=new(PList,Init(0));
                  NextElementState; {elVariables}
                  while (nState = eStart) and (nElName = XMLElemName[elVariable]) do
                     lVars^.Insert(Read_Variable);
                  NextElementState;
                  lTyps:=Read_TypeList;
                  NextElementState;
                  lList^.Insert(new(FunctorSegmentPtr,Init(lPos,lVars,lTyps,Read_Type)));
                  NextElementState;
                  NextElementState;
               end;
            SchemePtr(aItem^.nContent)^.nSchemeParams:=lList;
            NextElementState; {elSchematicVariables}
            SchemePtr(aItem^.nContent)^.nSchemeConclusion:=Read_Formula;
            lConds:=new(PList,Init(0));
            if (nState = eStart) and (nElName = XMLElemName[elProvisionalFormulas]) then
            begin
               NextElementState;
               while (nState = eStart) and (nElName = XMLElemName[elProposition]) do
                  lConds^.Insert(Read_Proposition);
               NextElementState;
            end;
            SchemePtr(aItem^.nContent)^.nSchemePremises:=lConds;
         end;
      itTheorem:
         aItem^.nContent:=Read_CompactStatement;
      itAxiom:
         begin
         end;
      itReservation:
         aItem^.nContent:=Read_ReservationSegment;
      itSection:;
      itChoice:
         begin
            lList:=new(PList,Init(0));
            while (nState = eStart) and
                     ((nElName = SegmentKindName[ikImplQualifiedSegm]) or
                         (nElName = SegmentKindName[ikExplQualifiedSegm])) do
               lList^.Insert(Read_VariableSegment);
            NextElementState;
            lConds:=nil;
            if nElName = XMLElemName[elProposition] then
            begin
               lConds:=new(PList,Init(0));
               while (nState = eStart) and (nElName = XMLElemName[elProposition]) do
                  lConds^.Insert(Read_Proposition);
            end;
            NextElementState;
            aItem^.nContent:=new(ChoiceStatementPtr,Init(lList,lConds,
                                                         SimpleJustificationPtr(Read_Justification)));
         end;
      itReconsider:
         begin
            lList:=new(PList,Init(0));
            while (nState = eStart) and
                     ((nElName = XMLElemName[elEquality]) or (nElName = XMLElemName[elVariable])) do
               if nElName = XMLElemName[elVariable] then
                  lList^.Insert(new(TypeChangePtr,Init(VariableIdentifier,Read_Variable,nil)))
               else
               begin
                  NextElementState;
                  lVar:=Read_Variable;
                  lList^.Insert(new(TypeChangePtr,Init(Equating,lVar,Read_Term)));
                  NextElementState;
               end;
            lType:=Read_Type;
            aItem^.nContent:=new(TypeChangingStatementPtr,
                                 Init(lList,lType,SimpleJustificationPtr(Read_Justification)));
         end;
      itPrivFuncDefinition:
         begin
            lVar:=Read_Variable;
            lList:=Read_TypeList;
            aItem^.nContent:=new(PrivateFunctorDefinitionPtr,Init(lVar,lList,Read_Term));
         end;
      itPrivPredDefinition:
         begin
            lVar:=Read_Variable;
            lList:=Read_TypeList;
            aItem^.nContent:=new(PrivatePredicateDefinitionPtr,Init(lVar,lList,Read_Formula));
         end;
      itConstantDefinition:
         begin
            lVar:=Read_Variable;
            aItem^.nContent:=new(ConstantDefinitionPtr,Init(lVar,Read_Term));
         end;
      itLociDeclaration,
      itGeneralization:
         aItem^.nContent:=Read_VariableSegment;
      itPerCases:
         aItem^.nContent:=Read_Justification;
      itCaseBlock: ;
      itCorrCond:
         begin
            CorrectnessConditionPtr(aItem^.nContent)^.nJustification:=Read_Justification;
         end;
      itCorrectness:
         begin
            NextElementState;
            while (nState = eStart) and (nElName = ItemName[itCorrectness]) do
            begin
               NextElementState;
               include(CorrectnessConditionsPtr(aItem^.nContent)^.nConditions,
                       Str2CorrectnessKind(GetAttr(XMLAttrName[atCondition])));
               NextElementState;
            end;
            NextElementState;
            CorrectnessConditionPtr(aItem^.nContent)^.nJustification:=Read_Justification;
         end;
      itProperty:
         aItem^.nContent:=new(PropertyPtr,Init(lPos,Str2PropertyKind(aShape),Read_Justification));
      itConclusion,
      itRegularStatement:
         aItem^.nContent:=Read_RegularStatement(aShape);
      itCaseHead,itSupposeHead,
      itAssumption:
         if nState= eStart then
            if nElName = AssumptionKindName[SingleAssumption] then
            begin
               lPos:=GetAttrPos;
               NextElementState;
               aItem^.nContent:=new(SingleAssumptionPtr,Init(lPos,Read_Proposition));
               NextElementState;
            end
            else if nElName = AssumptionKindName[CollectiveAssumption] then
            begin
               lPos:=GetAttrPos;
               NextElementState;
               aItem^.nContent:=new(CollectiveAssumptionPtr,Init(lPos,new(PList,Init(0))));
               NextElementState;
               while (nState = eStart) and (nElName = XMLElemName[elProposition]) do
                  CollectiveAssumptionPtr(aItem^.nContent)^.nConditions^.Insert(Read_Proposition);
               NextElementState;
               NextElementState;
            end;
      itExistentialAssumption:
         begin
            aItem^.nContent:=new(ExistentialAssumptionPtr,Init(lPos,new(PList,Init(0)),new(PList,Init(0))));
            while (nState = eStart) and
                     ((nElName = SegmentKindName[ikImplQualifiedSegm]) or
                         (nElName = SegmentKindName[ikExplQualifiedSegm])) do
               ExistentialAssumptionPtr(aItem^.nContent)^.nQVars^.Insert(Read_VariableSegment);
            NextElementState;
            while (nState = eStart) and (nElName = XMLElemName[elProposition]) do
               ExistentialAssumptionPtr(aItem^.nContent)^.nConditions^.Insert(Read_Proposition);
            NextElementState;
         end;
      itExemplification:
         begin
            lVar:=nil;
            if (nState = eStart) and (nElName = XMLElemName[elVariable]) then
               lVar:=Read_Variable;
            lTrm:=nil;
            if nState <> eEnd then
               lTrm:=Read_Term;
            aItem^.nContent:=new(ExamplePtr,Init(lVar,lTrm));
         end;
      itDefPred:
         begin
            lRedefinition:=false;
            if (nState= eStart) and (nElName = XMLElemName[elRedefine]) then
            begin
               NextElementState;
               NextElementState;
               lRedefinition:=true;
            end;
            lPattern:=Read_PredicatePattern;
            aItem^.nContent:=new(PredicateDefinitionPtr,
                                 Init(lPos,lRedefinition,PredicatePatternPtr(lPattern),
                                      Read_Definiens));
         end;
      itDefFunc:
         begin
            lRedefinition:=false;
            if (nState= eStart) and (nElName = XMLElemName[elRedefine]) then
            begin
               NextElementState;
               NextElementState;
               lRedefinition:=true;
            end;
            lPattern:=Read_FunctorPattern;
            lType:=nil;
            if (nState= eStart) and (nElName = XMLElemName[elTypeSpecification]) then
            begin
               NextElementState;
               lType:=Read_Type;
               NextElementState;
            end;
            if aShape = DefiningWayName[dfMeans] then
               lDef:=dfMeans
            else if aShape = DefiningWayName[dfEquals] then
               lDef:=dfEquals
            else lDef:=dfEmpty;
            case lDef of
               dfEquals:
                  aItem^.nContent:=new(FunctorDefinitionPtr,
                                       Init(lPos,lRedefinition,FunctorPatternPtr(lPattern),
                                            lType,lDef,Read_Definiens));
               dfMeans:
                  aItem^.nContent:=new(FunctorDefinitionPtr,
                                       Init(lPos,lRedefinition,FunctorPatternPtr(lPattern),
                                            lType,lDef,Read_Definiens));
               dfEmpty:
                  aItem^.nContent:=new(FunctorDefinitionPtr,
                                       Init(lPos,lRedefinition,FunctorPatternPtr(lPattern),
                                            lType,lDef,nil));

            endcases;
         end;
      itDefMode:
         begin
            lRedefinition:=false;
            if (nState= eStart) and (nElName = XMLElemName[elRedefine]) then
            begin
               NextElementState;
               NextElementState;
               lRedefinition:=true;
            end;
            lPattern:=Read_ModePattern;
            if (nState= eStart) and (nElName = ModeDefinitionSortName[defExpandableMode]) then
            begin
               NextElementState;
               aItem^.nContent:=new(ExpandableModeDefinitionPtr,Init(CurPos,ModePatternPtr(lPattern),Read_Type));
               NextElementState;
            end
            else if (nState= eStart) and (nElName = ModeDefinitionSortName[defStandardMode]) then
            begin
               NextElementState;
               lType:=nil;
               if (nState= eStart) and (nElName = XMLElemName[elTypeSpecification]) then
               begin
                  NextElementState;
                  lType:=Read_Type;
                  NextElementState;
               end;
               aItem^.nContent:=new(StandardModeDefinitionPtr,Init(CurPos,lRedefinition,ModePatternPtr(lPattern),
                                                                   lType,Read_Definiens));
               NextElementState;
            end;
         end;
      itDefAttr:
         begin
            lRedefinition:=false;
            if (nState= eStart) and (nElName = XMLElemName[elRedefine]) then
            begin
               NextElementState;
               NextElementState;
               lRedefinition:=true;
            end;
            lPattern:=Read_AttributePattern;
            aItem^.nContent:=new(AttributeDefinitionPtr,Init(CurPos,lRedefinition,AttributePatternPtr(lPattern),
                                                             Read_Definiens));
         end;
      itDefStruct:
         begin
            NextElementState;
            lTyps:=new(PList,Init(0));
            while nState <> eEnd do
               lTyps^.Insert(Read_Type);
            NextElementState;
            lPos:=GetAttrPos;
            lNr:=GetIntAttr(XMLAttrName[atNr]);
            NextElementState;
            lList:=nil;
            if (nState = eStart) and (nElName = XMLElemName[elLoci]) then
               lList:=Read_Loci;
            lFields:=new(PList,Init(0));
            while (nState = eStart) and (nElName = XMLElemName[elFieldSegment]) do
            begin
               lFieldSgmPos:=GetAttrPos;
               NextElementState;
               lSels:=new(PList,Init(0));
               while (nState = eStart) and (nElName = XMLElemName[elSelector]) do
               begin
                  lSels^.Insert(new(FieldSymbolPtr,Init(GetAttrPos,GetIntAttr(XMLAttrName[atNr]))));
                  NextElementState;
                  NextElementState;
               end;
               lFields^.Insert(new(FieldSegmentPtr,Init(lFieldSgmPos,lSels,Read_Type)));
               NextElementState;
            end;
            NextElementState;
            aItem^.nContent:=new(StructureDefinitionPtr,Init(lPos,lTyps,lNr,lList,lFields));
         end;
      itPredSynonym, itPredAntonym, itFuncNotation, itModeNotation,
      itAttrSynonym, itAttrAntonym:
         begin
            lPattern:=Read_Pattern;
            aItem^.nContent:= new(NotationDeclarationPtr,
                                  Init(lPos,aItem^.nItemKind,Read_Pattern,lPattern));
         end;
      itCluster:
         if nState= eStart then
            if nElName = ClusterRegistrationName[ExistentialRegistration] then
            begin
               lPos:=GetAttrPos;
               NextElementState;
               lList:=Read_AdjectiveList;
               aItem^.nContent:=new(EClusterPtr,Init(lPos,lList,Read_Type));
               NextElementState;
            end
            else if nElName = ClusterRegistrationName[ConditionalRegistration] then
            begin
               lPos:=GetAttrPos;
               NextElementState;
               lList:=Read_AdjectiveList;
               lCons:=Read_AdjectiveList;
               aItem^.nContent:=new(CClusterPtr,Init(lPos,lList,lCons,Read_Type));
               NextElementState;
            end
            else if nElName = ClusterRegistrationName[FunctorialRegistration] then
            begin
               lPos:=GetAttrPos;
               NextElementState;
               lTrm:=Read_Term;
               lCons:=Read_AdjectiveList;
               lType:=nil;
               if nState <> eEnd then
                  lType:=Read_Type;
               aItem^.nContent:=new(FClusterPtr,Init(lPos,lTrm,lCons,lType));
               NextElementState;
            end;
      itIdentify:
         begin
            lPattern:=Read_Pattern;
            aItem^.nContent:=new(IdentifyRegistrationPtr,Init(lPos,Read_Pattern,lPattern,
                                                              new(PList,Init(0))));
            while (nState = eStart) and (nElName = XMLElemName[elLociEquality]) do
            begin
               lPos:=GetAttrPos;
               NextElementState;
               lLocus:=Read_Locus;
               IdentifyRegistrationPtr(aItem^.nContent)^.nEqLociList^.Insert(new(LociEqualityPtr,Init(lPos,lLocus,Read_Locus)));
               NextElementState;
            end;
         end;
      itPropertyRegistration:
         begin
            lPropertySort:=Str2PropertyKind(aShape);
            case lPropertySort of
               sySethood:
                  begin
                     aItem^.nContent:=new(SethoodRegistrationPtr,Init(lPos,lPropertySort,Read_Type));
                     SethoodRegistrationPtr(aItem^.nContent)^.nJustification:=Read_Justification;
                  end;
            endcases;
         end;
      itReduction:
         begin
            lTrm:=Read_Term;
            aItem^.nContent:=new(ReduceRegistrationPtr,Init(lPos,Read_Term,lTrm));
         end;
      itPragma: ;
   endcases;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_TextProper: wsTextProperPtr;
var lPos: Position;
begin
   NextElementState;
   lPos.Line:=GetIntAttr( XMLAttrName[atLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atCol]);
   result:=new(wsTextProperPtr,Init(GetAttr(XMLAttrName[atArticleID]),
                                    GetAttr(XMLAttrName[atArticleExt]),lPos));
   if nDisplayInformationOnScreen then
      DisplayLine(result^.nBlockPos.Line,0);
   CurPos:=result^.nBlockPos;
   if (nState= eStart) and (nElName = BlockName[blMain]) then
   begin
      NextElementState;
      while (nState= eStart) and (nElName = XMLElemName[elItem]) do
         result^.nItems^.Insert(Read_Item);
   end;
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Block: wsBlockPtr;
var lPos: Position;
begin
   lPos.Line:=GetIntAttr( XMLAttrName[atLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atCol]);
   result:=new(WSBlockPtr,Init(Str2BlockKind(GetAttr(XMLAttrName[atKind])),lPos));
   if nDisplayInformationOnScreen then
      DisplayLine(result^.nBlockPos.Line,0);
   lPos.Line:=GetIntAttr( XMLAttrName[atPosLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atPosCol]);
   result^.nBlockEndPos:=lPos;
   CurPos:=result^.nBlockPos;
   NextElementState;
   while (nState= eStart) and (nElName = XMLElemName[elItem]) do
      result^.nItems^.Insert(Read_Item);
   CurPos:=result^.nBlockEndPos;
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function InWSMizFileObj.Read_Item: wsItemPtr;
var lStartTagNbr: integer;
lItemKind: ItemKind;
lShape: string;
lPos: Position;
begin
   lItemKind:=Str2ItemKind(GetAttr(XMLAttrName[atKind]));
   lPos.Line:=GetIntAttr( XMLAttrName[atLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atCol]);
   CurPos:=lPos;
   if nDisplayInformationOnScreen then
      DisplayLine(lPos.Line,0);
   result:=new(WSItemPtr,Init(lItemKind,lPos));
   lPos.Line:=GetIntAttr( XMLAttrName[atPosLine]);
   lPos.Col:= GetIntAttr( XMLAttrName[atPosCol]);
   result^.nItemEndPos:=lPos;
   result^.nContent:=nil;
   Read_ItemContentsAttr(result,lShape);
   NextElementState;
   lStartTagNbr := 0;
   if nState <> eEnd then
   begin
      Read_ItemContents(result,lShape);
      if (nState= eStart) and (nElName = XMLElemName[elBlock]) then
         result^.nBlock:=Read_Block
      else if result^.nContent = nil then
      begin
         repeat
            if nState = eStart then
               inc(lStartTagNbr)
            else dec(lStartTagNbr);
            NextElementState;
         until ((nState = eEnd) and (lStartTagNbr = 0)) or
            ((nState = eStart) and (nElName = XMLElemName[elBlock]));
         if (nState= eStart) and (nElName = XMLElemName[elBlock]) then
            result^.nBlock:=Read_Block;
      end;
   end;
   CurPos:=lPos;
   NextElementState;
end;
@

@<Implementation for \texttt{wsmarticle.pas}@>=
function Read_WSMizArticle(aFileName:string): wsTextProperPtr;
var lInFile: InWSMizFilePtr;
begin
   InitWSLookupTables;
   lInFile:=new(InWSMizFilePtr,OpenFile(aFileName));
   result:=lInFile^.Read_TextProper;
   dispose(lInFile,Done);
   DisposeWSLookupTables;
end;



@* [S] Prettyprinting WSM files (deferred).

@<Publicly declared types in \texttt{wsmarticle.pas}@>=
WSMizarPrinterPtr =  ^WSMizarPrinterObj; @/
WSMizarPrinterObj =
   object(TXTStreamObj) @t\1 @> @/
      nDisplayInformationOnScreen: boolean; @/
      nIndent:	integer;  {indenting}
      constructor OpenFile(const aFileName:string ); @t\2 @>
      destructor Done; virtual; @t\2 @>

      procedure Print_Char( AChar: char ); @t\2 @>
      procedure Print_NewLine; @t\2 @>
      procedure Print_Number( const aNumber: integer); @t\2 @>
      procedure Print_String( const aString: string); @t\2 @>
      procedure Print_Indent; @t\2 @>

      procedure Print_TextProper(aWSTextProper:WSTextProperPtr); virtual; @t\2 @>
      procedure Print_Item(aWSItem:WSItemPtr); virtual; @t\2 @>
      procedure Print_SchemeNameInSchemeHead(aSch: SchemePtr); virtual; @t\2 @>
      procedure Print_Block(aWSBlock:WSBlockPtr); virtual; @t\2 @>

      procedure Print_Adjective(aAttr:AdjectiveExpressionPtr ); virtual; @t\2 @>
      procedure Print_AdjectiveList( aCluster: PList ); virtual; @t\2 @>
      procedure Print_Variable( aVar: VariablePtr); virtual; @t\2 @>
      procedure Print_ImplicitlyQualifiedVariable( aSegm: ImplicitlyQualifiedSegmentPtr); virtual; @t\2 @>
      procedure Print_VariableSegment( aSegm: QualifiedSegmentPtr); virtual; @t\2 @>
      procedure Print_Type ( aTyp: TypePtr ); virtual; @t\2 @>
      procedure Print_BinaryFormula ( aFrm:BinaryFormulaPtr ); virtual; @t\2 @>
      procedure Print_PrivatePredicativeFormula ( aFrm: PrivatePredicativeFormulaPtr ); virtual; @t\2 @>
      procedure Print_Formula ( aFrm:FormulaPtr ); virtual; @t\2 @>
      procedure Print_OpenTermList ( aTrmList:PList ); virtual; @t\2 @>
      procedure Print_TermList ( aTrmList:PList ); virtual; @t\2 @>
      procedure Print_SimpleTermTerm ( aTrm: SimpleTermPtr ); virtual; @t\2 @>
      procedure Print_PrivateFunctorTerm ( aTrm: PrivateFunctorTermPtr ); virtual; @t\2 @>
      procedure Print_Term ( aTrm: TermPtr ); virtual; @t\2 @>

      procedure Print_TypeList ( aTypeList: PList ); virtual; @t\2 @>

      procedure Print_Label(aLab:LabelPtr); virtual; @t\2 @>

      procedure Print_Reference(aRef: LocalReferencePtr); virtual; @t\2 @>
      procedure Print_References(aRefs: PList); virtual; @t\2 @>
      procedure Print_StraightforwardJustification(aInf: StraightforwardJustificationPtr); virtual; @t\2 @>
      procedure Print_SchemeNameInJustification(aInf: SchemeJustificationPtr); virtual; @t\2 @>
      procedure Print_SchemeJustification(aInf: SchemeJustificationPtr); virtual; @t\2 @>
      procedure Print_Justification(aInf: JustificationPtr; aBlock:wsBlockPtr); virtual; @t\2 @>
      procedure Print_Linkage; virtual; @t\2 @>
      procedure Print_RegularStatement(aRStm:RegularStatementPtr; aBlock:wsBlockPtr); virtual; @t\2 @>
      procedure Print_CompactStatement(aCStm:CompactStatementPtr; aBlock:wsBlockPtr); virtual; @t\2 @>
      procedure Print_Proposition(aProp:PropositionPtr); virtual; @t\2 @>

      procedure Print_Conditions(aCond: PList); @t\2 @>
      procedure Print_AssumptionConditions(aCond: AssumptionPtr); virtual; @t\2 @>

      procedure Print_Pattern(aPattern: PatternPtr); virtual; @t\2 @>
      procedure Print_Locus( aLocus: LocusPtr); virtual; @t\2 @>
      procedure Print_Loci( aLoci: PList); virtual; @t\2 @>
      procedure Print_Definiens(aDef:DefiniensPtr); virtual; @t\2 @>

      procedure Print_ReservedType(aResType: TypePtr); virtual; @t\2\2\2 @>
   end;


@ \node{Constructor.}

@<Implementation for \texttt{wsmarticle.pas}@>=
constructor WSMizarPrinterObj.OpenFile(const aFileName:string);
begin
   inherited InitFile(AFileName);
   rewrite(nFile);
   nIndent := 0;
   nDisplayInformationOnScreen:=false;
end;

destructor WSMizarPrinterObj.Done;
begin
   close(nFile);
   inherited Done;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Char ( aChar: char );
begin
   write(nFile,aChar);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_NewLine;
begin
   writeln(nFile);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Number( const aNumber: integer);
begin
   write(nFile,aNumber);
   Print_Char(' ');
end;

@ The comment is translated from the Polish comment ``{?? czy na pewno
trzeba robic konwersje}'', so I may be mistranslating.

@<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_String ( const aString: string );
var i: integer;
begin
   write(nFile,XMLToStr(aString)); {Do you really need to do conversions?}
   Print_Char(' ');
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Indent;
var i:integer;
begin
   for i:=1 to nIndent do Print_Char(' ');
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Adjective(aAttr:AdjectiveExpressionPtr);
begin
   case aAttr^.nAdjectiveSort of
      wsAdjective:
         with AdjectivePtr(aAttr)^ do
      begin
         if  nArgs^.Count <> 0 then
            Print_TermList( nArgs );
         Print_String(AttributeName[nAdjectiveSymbol]);
      end;
      wsNegatedAdjective:
         begin
            Print_String(TokenName[sy_Non]);
            Print_Adjective(NegatedAdjectivePtr(aAttr)^.nArg);
         end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_AdjectiveList(aCluster: PList);
var i: integer;
begin
   with aCluster^ do
      for i:=0 to Count-1 do
      begin
         Print_Adjective( Items^[i]);
      end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Variable( aVar: VariablePtr);
begin
   with aVar ^ do
   begin
      Print_String(IdentRepr(nIdent));
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_ImplicitlyQualifiedVariable( aSegm: ImplicitlyQualifiedSegmentPtr);
begin
   Print_Variable( aSegm^.nIdentifier);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_VariableSegment( aSegm: QualifiedSegmentPtr);
var i: integer;
begin
   case aSegm^.nSegmentSort of
      ikImplQualifiedSegm:
         Print_ImplicitlyQualifiedVariable( ImplicitlyQualifiedSegmentPtr(aSegm));
      ikExplQualifiedSegm:
         with ExplicitlyQualifiedSegmentPtr(aSegm)^ do
      begin
         Print_Variable( nIdentifiers.Items^[0]);
         for i:=1 to nIdentifiers^.Count-1 do
         begin
            Print_String(',');
            Print_Variable( nIdentifiers^.Items^[i]);
         end;
         Print_String(TokenName[sy_Be]);
         Print_Type(nType);
      end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_OpenTermList ( aTrmList:PList );
var i: integer;
begin
   if aTrmList^.Count > 0 then
   begin
      Print_Term(aTrmList^.Items^[0]);
      for i:=1 to aTrmList^.Count-1 do
      begin
         Print_String(',');
         Print_Term(aTrmList^.Items^[i]);
      end;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_TermList ( aTrmList:PList );
var i: integer;
begin
   if aTrmList^.Count > 0 then
   begin
      Print_String('(');
      Print_Term(aTrmList^.Items^[0]);
      for i:=1 to aTrmList^.Count-1 do
      begin
         Print_String(',');
         Print_Term(aTrmList^.Items^[i]);
      end;
      Print_String(')');
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Type ( aTyp: TypePtr);
begin
   with aTyp^ do
   begin
      case aTyp^.nTypeSort of
         wsStandardType:
            with StandardTypePtr(aTyp)^ do
         begin
            if  nArgs^.Count = 0 then
               Print_String(ModeName[nModeSymbol])
            else
            begin
               Print_String('(');
               Print_String(ModeName[nModeSymbol]);
               Print_String(TokenName[sy_Of]);
               Print_OpenTermList(nArgs);
               Print_String(')');
            end;
         end;
         wsStructureType:
            with StructTypePtr(aTyp)^ do
         begin
            if  nArgs^.Count = 0 then
               Print_String(StructureName[nStructSymbol])
            else
            begin
               Print_String('(');
               Print_String(StructureName[nStructSymbol]);
               Print_String(TokenName[sy_Over]);
               Print_OpenTermList(nArgs);
               Print_String(')');
            end;
         end;
         wsClusteredType:
            with ClusteredTypePtr(aTyp)^ do
         begin
            Print_AdjectiveList(nAdjectiveCluster);
            Print_Type(nType);
         end;
         wsErrorType:
            begin
            end;
      endcases;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_BinaryFormula ( aFrm:BinaryFormulaPtr );
begin
   Print_String('(');
   Print_Formula(aFrm^.nLeftArg);
   case aFrm^.nFormulaSort of
      wsConjunctiveFormula: Print_String(TokenName[sy_Ampersand]);
      wsDisjunctiveFormula: Print_String(TokenName[sy_Or]);
      wsConditionalFormula: Print_String(TokenName[sy_Implies]);
      wsBiconditionalFormula: Print_String(TokenName[sy_Iff]);
      wsFlexaryConjunctiveFormula:
         begin
            Print_String(TokenName[sy_Ampersand]);
            Print_String(TokenName[sy_Ellipsis]);
            Print_String(TokenName[sy_Ampersand]);
         end;
      wsFlexaryDisjunctiveFormula:
         begin
            Print_String(TokenName[sy_Or]);
            Print_String(TokenName[sy_Ellipsis]);
            Print_String(TokenName[sy_Or]);
         end;
   endcases;
   Print_Formula(aFrm^.nRightArg);
   Print_String(')');
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_PrivatePredicativeFormula ( aFrm: PrivatePredicativeFormulaPtr );
begin
   with PrivatePredicativeFormulaPtr(aFrm)^ do
   begin
      Print_String(IdentRepr(nPredIdNr));
      Print_String('[');
      Print_OpenTermList( nArgs);
      Print_String(']');
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Formula ( aFrm: FormulaPtr );
var i: Integer;
lNeg: boolean;
lFrm: FormulaPtr;
begin
   case aFrm^.nFormulaSort of
      wsNegatedFormula:
         begin
            Print_String(TokenName[sy_Not]);
            Print_Formula(NegativeFormulaPtr(aFrm)^.nArg);
         end;
      wsConjunctiveFormula,wsDisjunctiveFormula,
      wsConditionalFormula,wsBiconditionalFormula,
      wsFlexaryConjunctiveFormula,wsFlexaryDisjunctiveFormula:
         Print_BinaryFormula(BinaryFormulaPtr(aFrm));
      wsPredicativeFormula:
         with PredicativeFormulaPtr(aFrm)^ do
      begin
         Print_String('(');
         if nLeftArgs^.Count <> 0 then
         begin
            Print_OpenTermList( nLeftArgs);
         end;
         Print_String(PredicateName[nPredNr]);
         if nRightArgs^.Count <> 0 then
         begin
            Print_OpenTermList( nRightArgs);
         end;
         Print_String(')');
      end;
      wsMultiPredicativeFormula:
         with MultiPredicativeFormulaPtr(aFrm)^ do
      begin
         Print_String('(');
         lFrm:=nScraps.Items^[0];
         lNeg:=lFrm^.nFormulaSort = wsNegatedFormula;
         if lNeg then
            lFrm:=NegativeFormulaPtr(lFrm)^.nArg;
         with PredicativeFormulaPtr(lFrm)^ do
         begin
            if nLeftArgs^.Count <> 0 then
               Print_OpenTermList( nLeftArgs);
            if lNeg then
            begin
               Print_String(TokenName[sy_Does]);
               Print_String(TokenName[sy_Not]);
            end;
            Print_String(PredicateName[nPredNr]);
            if nRightArgs^.Count <> 0 then
               Print_OpenTermList( nRightArgs);
         end;
         for i:=1 to nScraps.Count - 1 do
         begin
            lFrm:=nScraps.Items^[i];
            lNeg:=lFrm^.nFormulaSort = wsNegatedFormula;
            if lNeg then
               lFrm:=NegativeFormulaPtr(lFrm)^.nArg;
            with RightSideOfPredicativeFormulaPtr(lFrm)^ do
            begin
               if lNeg then
               begin
                  Print_String(TokenName[sy_Does]);
                  Print_String(TokenName[sy_Not]);
               end;
               Print_String(PredicateName[nPredNr]);
               if nRightArgs^.Count <> 0 then
                  Print_OpenTermList( nRightArgs);
            end;
         end;
         Print_String(')');
      end;
      wsPrivatePredicateFormula:
         Print_PrivatePredicativeFormula ( PrivatePredicativeFormulaPtr(aFrm));
      wsAttributiveFormula:
         with AttributiveFormulaPtr(aFrm)^ do
      begin
         Print_String('(');
         Print_Term(nSubject);
         Print_String(TokenName[sy_Is]);
         Print_AdjectiveList(nAdjectives);
         Print_String(')');
      end;
      wsQualifyingFormula:
         with QualifyingFormulaPtr(aFrm)^ do
      begin
         Print_String('(');
         Print_Term(nSubject);
         Print_String(TokenName[sy_Is]);
         Print_Type(nType);
         Print_String(')');
      end;
      wsUniversalFormula:
         with QuantifiedFormulaPtr( aFrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_For]);
         Print_VariableSegment(QuantifiedFormulaPtr(aFrm)^.nSegment);
         Print_String(TokenName[sy_Holds]);
         Print_Formula(QuantifiedFormulaPtr(aFrm)^.nScope);
         Print_String(')');
      end;
      wsExistentialFormula:
         with QuantifiedFormulaPtr( aFrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_Ex]);
         Print_VariableSegment(QuantifiedFormulaPtr(aFrm)^.nSegment);
         Print_String(TokenName[sy_St]);
         Print_Formula(QuantifiedFormulaPtr(aFrm)^.nScope);
         Print_String(')');
      end;
      wsContradiction:
         begin
            Print_String(TokenName[sy_Contradiction]);
         end;
      wsThesis:
         begin
            Print_String(TokenName[sy_Thesis]);
         end;
      wsErrorFormula:
         begin
         end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_SimpleTermTerm ( aTrm: SimpleTermPtr );
begin
   Print_String(IdentRepr(SimpleTermPtr(aTrm)^.nIdent));
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_PrivateFunctorTerm ( aTrm: PrivateFunctorTermPtr );
begin
   Print_String(IdentRepr(aTrm^.nFunctorIdent));
   Print_String('(');
   Print_OpenTermList(aTrm^.nArgs);
   Print_String(')');
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Term ( aTrm: TermPtr );
var i,j: integer;
lPrintWhere: boolean;
begin
   case aTrm^.nTermSort of
      wsPlaceholderTerm:
         begin
            Print_Char('$');
            Print_Number(PlaceholderTermPtr(aTrm)^.nLocusNr);
         end;
      wsSimpleTerm:
         begin
            Print_SimpleTermTerm(SimpleTermPtr(aTrm));
         end;
      wsNumeralTerm:
         begin
            Print_Number(NumeralTermPtr(aTrm)^.nValue);
         end;
      wsInfixTerm:
         with InfixTermPtr(aTrm)^ do
      begin
         Print_String('(');
         if nLeftArgs^.Count <> 0 then
         begin
            Print_TermList( nLeftArgs);
         end;
         Print_String(FunctorName[nFunctorSymbol]);
         if nRightArgs^.Count <> 0 then
         begin
            Print_TermList( nRightArgs);
         end;
         Print_String(')');
      end;
      wsCircumfixTerm:
         with CircumfixTermPtr(aTrm)^ do
      begin
         Print_String(LeftBracketName[nLeftBracketSymbol]);
         Print_OpenTermList(nArgs);
         Print_String(RightBracketName[nRightBracketSymbol]);
      end;
      wsPrivateFunctorTerm:
         Print_PrivateFunctorTerm(PrivateFunctorTermPtr(aTrm));
      wsAggregateTerm:
         with AggregateTermPtr(aTrm)^ do
      begin
         Print_String(StructureName[nStructSymbol]);
         Print_String(TokenName[sy_StructLeftBracket]);
         Print_OpenTermList( nArgs);
         Print_String(TokenName[sy_StructRightBracket]);
      end;
      wsSelectorTerm:
         with SelectorTermPtr(aTrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_The]);
         Print_String(SelectorName[nSelectorSymbol]);
         Print_String(TokenName[sy_Of]);
         Print_Term( nArg);
         Print_String(')');
      end;
      wsInternalSelectorTerm:
         with InternalSelectorTermPtr(aTrm)^ do
      begin
         Print_String(TokenName[sy_The]);
         Print_String(SelectorName[nSelectorSymbol]);
      end;
      wsForgetfulFunctorTerm:
         with ForgetfulFunctorTermPtr(aTrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_The]);
         Print_String(StructureName[nStructSymbol]);
         Print_String(TokenName[sy_Of]);
         Print_Term( nArg);
         Print_String(')');
      end;
      wsInternalForgetfulFunctorTerm:
         with InternalForgetfulFunctorTermPtr(aTrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_The]);
         Print_String(StructureName[nStructSymbol]);
         Print_String(')');
      end;
      wsFraenkelTerm:
         with FraenkelTermPtr(aTrm)^ do
      begin
         Print_String('{');
         Print_Term(nSample);
         if nPostqualification^.Count > 0 then
         begin
            lPrintWhere:=true;
            for i := 0 to nPostqualification^.Count - 1 do
               case QualifiedSegmentPtr(nPostqualification^.Items^[i])^.nSegmentSort of
                  ikImplQualifiedSegm:
                     with ImplicitlyQualifiedSegmentPtr(nPostqualification^.Items^[i])^ do
                  begin
                     Print_String(TokenName[sy_Where]);
                     Print_Variable( nIdentifier);
                  end;
                  ikExplQualifiedSegm:
                     with ExplicitlyQualifiedSegmentPtr(nPostqualification^.Items^[i])^ do
                  begin
                     if lPrintWhere then
                     begin
                        Print_String(TokenName[sy_Where]);
                        lPrintWhere:=false;
                     end;
                     Print_Variable( nIdentifiers.Items^[0]);
                     for j:=1 to nIdentifiers^.Count-1 do
                     begin
                        Print_String(',');
                        Print_Variable( nIdentifiers^.Items^[j]);
                     end;
                     Print_String(TokenName[sy_Is]);
                     Print_Type(nType);
                     if i < nPostqualification^.Count - 1 then Print_String(',');
                  end;
               endcases;
         end;
         Print_String(':');
         Print_Formula(nFormula);
         Print_String('}');
      end;
      wsSimpleFraenkelTerm:
         with SimpleFraenkelTermPtr(aTrm)^ do
      begin
         Print_String('(');
         Print_String(TokenName[sy_The]);
         Print_String(TokenName[sy_Set]);
         Print_String(TokenName[sy_Of]);
         Print_String(TokenName[sy_All]);
         Print_Term(nSample);
         if nPostqualification^.Count > 0 then
         begin
            lPrintWhere:=true;
            for i := 0 to nPostqualification^.Count - 1 do
               case QualifiedSegmentPtr(nPostqualification^.Items^[i])^.nSegmentSort of
                  ikImplQualifiedSegm:
                     with ImplicitlyQualifiedSegmentPtr(nPostqualification^.Items^[i])^ do
                  begin
                     Print_String(TokenName[sy_Where]);
                     Print_Variable( nIdentifier);
                  end;
                  ikExplQualifiedSegm:
                     with ExplicitlyQualifiedSegmentPtr(nPostqualification^.Items^[i])^ do
                  begin
                     if lPrintWhere then
                     begin
                        Print_String(TokenName[sy_Where]);
                        lPrintWhere:=false;
                     end;
                     Print_Variable( nIdentifiers.Items^[0]);
                     for j:=1 to nIdentifiers^.Count-1 do
                     begin
                        Print_String(',');
                        Print_Variable( nIdentifiers^.Items^[j]);
                     end;
                     Print_String(TokenName[sy_Is]);
                     Print_Type(nType);
                     if i < nPostqualification^.Count - 1 then Print_String(',');
                  end;
               endcases;
         end;
         Print_String(')');
      end;
      wsQualificationTerm:
         with QualifiedTermPtr(aTrm)^ do
      begin
         Print_String('(');
         Print_Term(nSubject);
         Print_String(TokenName[sy_Qua]);
         Print_Type(nQualification);
         Print_String(')');
      end;
      wsExactlyTerm:
         with ExactlyTermPtr(aTrm)^ do
      begin
         Print_Term(nSubject);
         Print_String(TokenName[sy_Exactly]);
      end;
      wsGlobalChoiceTerm:
         begin
            Print_String('(');
            Print_String(TokenName[sy_The]);
            Print_Type(ChoiceTermPtr(aTrm)^.nChoiceType);
            Print_String(')');
         end;
      wsItTerm:
         begin
            Print_String(TokenName[sy_It]);
         end;
      wsErrorTerm:
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_TypeList ( aTypeList:PList );
var i: integer;
begin
   if aTypeList^.Count > 0 then
   begin
      Print_Type(aTypeList^.Items^[0]);
      for i:=1 to aTypeList^.Count-1 do
      begin
         Print_String(',');
         Print_Type(aTypeList^.Items^[i]);
      end;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Label(aLab:LabelPtr);
begin
   if (aLab <> nil) and (aLab.nLabelIdNr > 0) then
   begin
      Print_String(IdentRepr(aLab^.nLabelIdNr));
      Print_String(':');
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Proposition(aProp:PropositionPtr);
begin
   Print_Label(aProp^.nLab);
   Print_Formula(aProp^.nSentence);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_CompactStatement(aCStm:CompactStatementPtr; aBlock:wsBlockPtr);
begin
   with aCStm^ do
   begin
      Print_Proposition(nProp);
      Print_Justification(nJustification,aBlock);
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Linkage;
begin
   Print_String(TokenName[sy_Then]);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_RegularStatement(aRStm:RegularStatementPtr; aBlock:wsBlockPtr);
var i: integer;
begin
   case aRStm^.nStatementSort of
      stDiffuseStatement:
         begin
            Print_Label(DiffuseStatementPtr(aRStm)^.nLab);
            Print_Block(aBlock);
         end;
      stCompactStatement:
         begin
            if (CompactStatementPtr(aRStm)^.nJustification^.nInfSort = infStraightforwardJustification) and
                  StraightforwardJustificationPtr(CompactStatementPtr(aRStm)^.nJustification)^.nLinked then
            begin
               Print_Linkage;
            end;
            Print_CompactStatement(CompactStatementPtr(aRStm),aBlock);
         end;
      stIterativeEquality:
         begin
            if (CompactStatementPtr(aRStm)^.nJustification^.nInfSort = infStraightforwardJustification) and
                  StraightforwardJustificationPtr(CompactStatementPtr(aRStm)^.nJustification)^.nLinked then
            begin
               Print_Linkage;
            end;
            Print_CompactStatement(CompactStatementPtr(aRStm),nil);
            with IterativeEqualityPtr(aRStm)^ do
               for i := 0 to nIterSteps^.Count - 1 do
                  with IterativeStepPtr(nIterSteps^.Items^[i])^ do
               begin
                  Print_NewLine;
                  Print_String(TokenName[sy_DotEquals]);
                  Print_Term(nTerm);
                  Print_Justification(nJustification,nil);
               end;
         end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Reference(aRef: LocalReferencePtr);
begin
   Print_String(IdentRepr(aRef^.nLabId));
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_References(aRefs: PList);
var i: integer;
begin
   for i:= 0 to aRefs^.Count-1 do
      with ReferencePtr(aRefs^.Items^[i])^ do
   begin
      case nRefSort of
         LocalReference:
            begin
               Print_Reference(aRefs^.Items^[i]);
            end;
         TheoremReference:
            begin
               Print_String(MMLIdentifierName[TheoremReferencePtr(aRefs^.Items^[i])^.nArticleNr]);
               Print_String(':');
               Print_Number(TheoremReferencePtr(aRefs^.Items^[i])^.nTheoNr);
            end;
         DefinitionReference:
            begin
               Print_String(MMLIdentifierName[DefinitionReferencePtr(aRefs^.Items^[i])^.nArticleNr]);
               Print_String(':');
               Print_String('def');
               Print_Number(DefinitionReferencePtr(aRefs^.Items^[i])^.nDEfNr);
            end;
      endcases;
      if i < aRefs^.Count-1 then
         Print_String(',');
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_StraightforwardJustification(aInf: StraightforwardJustificationPtr);
begin
   with aInf^ do
   begin
      if nReferences^.Count <> 0 then
      begin
         Print_String(TokenName[sy_By]);
         Print_References(nReferences);
      end;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_SchemeNameInJustification(aInf: SchemeJustificationPtr);
begin
   Print_String(IdentRepr(aInf^.nSchemeIdNr));
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_SchemeJustification(aInf: SchemeJustificationPtr);
begin
   with aInf^ do
   begin
      Print_String(TokenName[sy_From]);
      if nSchFileNr > 0 then
      begin
         Print_String(MMLIdentifierName[nSchFileNr]);
         Print_String(':');
         Print_String('sch');
         Print_Number(nSchemeIdNr);
      end
      else if nSchemeIdNr > 0 then
         Print_SchemeNameInJustification(aInf);
      if nReferences^.Count > 0 then
      begin
         Print_String('(');
         Print_References(nReferences);
         Print_String(')');
      end;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Justification(aInf: JustificationPtr; aBlock:wsBlockPtr);
begin
   case aInf^.nInfSort of
      infStraightforwardJustification:
         Print_StraightforwardJustification(StraightforwardJustificationPtr(aInf));
      infSchemeJustification:
         Print_SchemeJustification(SchemeJustificationPtr(aInf));
      infError,infSkippedProof:
         begin
         end;
      infProof:
         Print_Block(aBlock);
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Conditions(aCond: PList);
var i: integer;
begin
   Print_String(TokenName[sy_That]);
   Print_NewLine;
   Print_Proposition(aCond^.Items^[0]);
   for i:=1 to aCond^.Count-1 do
   begin
      Print_String(TokenName[sy_And]);
      Print_NewLine;
      Print_Proposition(aCond^.Items^[i]);
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_AssumptionConditions(aCond: AssumptionPtr);
begin
   case aCond^.nAssumptionSort of
      SingleAssumption:
         begin
            Print_Proposition(SingleAssumptionPtr(aCond)^.nProp);
         end;
      CollectiveAssumption:
         begin
            Print_Conditions(CollectiveAssumptionPtr(aCond)^.nConditions);
         end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Locus( aLocus: LocusPtr);
begin
   with aLocus ^ do
   begin
      Print_String(IdentRepr(nVarId));
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Loci( aLoci: PList);
var i: integer;
begin
   if (aLoci = nil) or (aLoci^.Count = 0) then
   else
   begin
      Print_Locus(aLoci^.Items^[0]);
      for i:=1 to aLoci^.Count-1 do
      begin
         Print_String(',');
         Print_Locus(aLoci^.Items^[i]);
      end;
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Pattern(aPattern: PatternPtr);
begin
   case aPattern^.nPatternSort of
      itDefPred:
         with PredicatePatternPtr(aPattern)^ do
      begin
         Print_Loci(nLeftArgs);
         Print_String(PredicateName[nPredSymbol]);
         Print_Loci(nRightArgs);
      end;
      itDefFunc:
         begin
            case FunctorPatternPtr(aPattern)^.nFunctKind of
               InfixFunctor:
                  with InfixFunctorPatternPtr(aPattern)^ do
               begin
                  if (nLeftArgs <> nil) and (nLeftArgs^.Count >1) then
                     Print_String('(');
                  Print_Loci(nLeftArgs);
                  if (nLeftArgs <> nil) and (nLeftArgs^.Count >1) then
                     Print_String(')');
                  Print_String(FunctorName[nOperSymb]);
                  if (nRightArgs <> nil) and (nRightArgs^.Count >1) then
                     Print_String('(');
                  Print_Loci(nRightArgs);
                  if (nRightArgs <> nil) and (nRightArgs^.Count >1) then
                     Print_String(')');
               end;
               CircumfixFunctor:
                  with CircumfixFunctorPatternPtr(aPattern)^ do
               begin
                  Print_String(LeftBracketName[nLeftBracketSymb]);
                  Print_Loci(nArgs);
                  Print_String(RightBracketName[nRightBracketSymb]);
               end;
            endcases;
         end;
      itDefMode:
         with ModePatternPtr(aPattern)^ do
      begin
         Print_String(ModeName[nModeSymbol]);
         if (nArgs <> nil) and (nArgs^.Count > 0) then
         begin
            Print_String(TokenName[sy_Of]);
            Print_Loci(nArgs);
         end;
      end;
      itDefAttr:
         with AttributePatternPtr(aPattern)^ do
      begin
         Print_Locus(nArg);
         Print_String(TokenName[sy_Is]);
         Print_Loci(nArgs);
         Print_String(AttributeName[nAttrSymbol]);
      end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Definiens(aDef:DefiniensPtr);
var i: integer;
begin
   if aDef <> nil then
      with DefiniensPtr(aDef)^ do
   begin
      case nDefSort of
         SimpleDefiniens:
            begin
               if (nDefLabel <> nil) and (nDefLabel^.nLabelIdNr > 0) then
               begin
                  Print_String(':');
                  Print_Label(nDefLabel);
               end;
               with SimpleDefiniensPtr(aDef)^,nExpression^ do
               case nExprKind of
                  exTerm: Print_Term(TermPtr(nExpr));
                  exFormula: Print_Formula(FormulaPtr(nExpr));
               endcases;
            end;
         ConditionalDefiniens:
            begin
               if (nDefLabel <> nil) and (nDefLabel^.nLabelIdNr > 0) then
               begin
                  Print_String(':');
                  Print_Label(nDefLabel);
               end;
               with ConditionalDefiniensPtr(aDef)^ do
               begin
                  for i:=0 to nConditionalDefiniensList^.Count-1 do
                  begin
                     with PartDefPtr(nConditionalDefiniensList^.Items^[I])^ do
                     begin
                        with nPartDefiniens^ do
                           case nExprKind of
                              exTerm: Print_Term(TermPtr(nExpr));
                              exFormula: Print_Formula(FormulaPtr(nExpr));
                           endcases;
                        Print_String(TokenName[sy_If]);
                        Print_Formula(nGuard);
                     end;
                     if (i>=0) and (i<nConditionalDefiniensList^.Count-1) then
                     begin
                        Print_String(',');
                        Print_NewLine;
                     end;
                  end;
                  if nOtherwise <> nil then
                     with nOtherwise^ do
                  begin
                     Print_String(TokenName[sy_Otherwise]);
                     case nExprKind of
                        exTerm: Print_Term(TermPtr(nExpr));
                        exFormula: Print_Formula(FormulaPtr(nExpr));
                     endcases;
                  end;
               end;
            end;
      end;
   endcases;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Block(aWSBlock:WSBlockPtr);
var i,lIndent: integer;
begin
   with aWSBlock^ do
   begin
      lIndent:=nIndent;
      Print_NewLine;
      Print_Indent;
      case nBlockKind of
         blDiffuse:
            begin
               Print_String(TokenName[sy_Now]);
               Print_NewLine;
            end;
         blHereby:
            begin
               Print_String(TokenName[sy_Now]);
               Print_NewLine;
            end;
         blProof:
            begin
               Print_String(TokenName[sy_Proof]);
               Print_NewLine;
            end;
         blDefinition:
            begin
               Print_String(TokenName[sy_Definition]);
               Print_NewLine;
            end;
         blNotation:
            begin
               Print_String(TokenName[sy_Notation]);
               Print_NewLine;
            end;
         blRegistration:
            begin
               Print_String(TokenName[sy_Registration]);
               Print_NewLine;
            end;
         blCase:
            Print_String(TokenName[sy_Case]);
         blSuppose:
            Print_String(TokenName[sy_Suppose]);
         blPublicScheme:
            ;
      endcases;
      for i := 0 to nItems^.Count - 1 do
      begin
         Print_Item(nItems^.Items^[i]);
      end;
      nIndent:=lIndent;
      Print_Indent;
      Print_String(TokenName[sy_End]);
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_TextProper(aWSTextProper:WSTextProperPtr);
var i: integer;
begin
   with aWSTextProper^ do
   begin
      for i := 0 to nItems^.Count - 1 do
         Print_Item(nItems^.Items^[i]);
   end;
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_ReservedType(aResType: TypePtr);
begin
   Print_Type(aResType);
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_SchemeNameInSchemeHead(aSch: SchemePtr);
begin
   Print_String(IdentRepr(aSch^.nSchemeIdNr));
end;

@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure WSMizarPrinterObj.Print_Item(aWSItem:WSItemPtr);
var i,j,lIndent: integer;
begin
   with aWSItem^ do
   begin
      CurPos:=nItemPos;
      if nDisplayInformationOnScreen then
         DisplayLine(CurPos.Line,ErrorNbr);
      case nItemKind of
         itDefinition:
            begin
               Print_Block(nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itSchemeBlock:
            begin
               Print_Block(nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itSchemeHead:
            with SchemePtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Scheme]);
            Print_SchemeNameInSchemeHead(SchemePtr(nContent));
            Print_String('{');
            for j:=0 to nSchemeParams^.Count-1 do
            begin
               case SchemeSegmentPtr(nSchemeParams^.Items^[j])^.nSegmSort of
                  PredicateSegment:
                     with PredicateSegmentPtr(nSchemeParams^.Items^[j])^ do
                  begin
                     Print_Variable( nVars^.Items^[0]);
                     for i:=1 to nVars^.Count-1 do
                     begin
                        Print_String(',');
                        Print_Variable( nVars^.Items^[i]);
                     end;
                     Print_String('[');
                     Print_TypeList(nTypeExpList);
                     Print_String(']');
                  end;
                  FunctorSegment:
                     with FunctorSegmentPtr(nSchemeParams^.Items^[j])^ do
                  begin
                     Print_Variable( nVars^.Items^[0]);
                     for i:=1 to nVars.Count-1 do
                     begin
                        Print_String(',');
                        Print_Variable( nVars^.Items^[i]);
                     end;
                     Print_String('(');
                     Print_TypeList(nTypeExpList);
                     Print_String(')');
                     Print_String(TokenName[sy_Arrow]);
                     Print_Type(nSpecification);
                  end;
               endcases;
               if (j >= 0) and (j < nSchemeParams^.Count-1) then
                  Print_String(',');
            end;
            Print_String('}');
            Print_String(':');
            Print_Newline;
            Print_Formula(nSchemeConclusion);
            Print_NewLine;
            if (nSchemePremises <> nil) and (nSchemePremises^.Count > 0) then
            begin
               Print_String(TokenName[sy_Provided]);
               Print_Proposition(nSchemePremises^.Items^[0]);
               for i:=1 to nSchemePremises^.Count-1 do
               begin
                  Print_String(TokenName[sy_And]);
                  Print_NewLine;
                  Print_Proposition(nSchemePremises^.Items^[i]);
               end;
            end;
            Print_String(TokenName[sy_Proof]);
            Print_NewLine;
         end;
         itTheorem:
            with CompactStatementPtr(nContent)^ do
         begin
            Print_NewLine;
            nIndent:=0;
            Print_String(TokenName[sy_Theorem]);
            Print_Label(nProp^.nLab);
            Print_NewLine;
            nIndent:=2;
            Print_Indent;
            Print_Formula(nProp^.nSentence);
            nIndent:=0;
            Print_Justification(nJustification,nBlock);
            Print_String(';');
            Print_NewLine;
         end;
         itAxiom:
            begin
               
            end;
         itReservation:
            with ReservationSegmentPtr(nContent)^ do
         begin
            Print_NewLine;
            Print_String(TokenName[sy_reserve]);
            Print_Variable( nIdentifiers.Items^[0]);
            for i:=1 to nIdentifiers^.Count-1 do
            begin
               Print_String(',');
               Print_Variable( nIdentifiers^.Items^[i]);
            end;
            Print_String(TokenName[sy_For]);
            Print_ReservedType(nResType);
            Print_String(';');
            Print_NewLine;
         end;
         itSection:
            begin
               Print_NewLine;
               Print_String(TokenName[sy_Begin]);
               Print_NewLine;
            end;
         itRegularStatement:
            begin
               Print_RegularStatement(RegularStatementPtr(nContent),nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itChoice:
            with ChoiceStatementPtr(nContent)^ do
         begin
            if (nJustification^.nInfSort = infStraightforwardJustification) and
                  StraightforwardJustificationPtr(nJustification)^.nLinked then
            begin
               Print_Linkage;
            end;
            Print_String(TokenName[sy_Consider]);
            Print_VariableSegment( nQualVars^.Items^[0]);
            for i:= 1 to  nQualVars^.Count-1 do
            begin
               Print_String(',');
               Print_VariableSegment( nQualVars^.Items^[i]);
            end;
            if (nConditions <> nil) and (nConditions^.Count > 0) then
            begin
               Print_String(TokenName[sy_Such]);
               Print_Conditions(nConditions);
            end;
            Print_Justification(nJustification,nil);
            Print_String(';');
            Print_NewLine;
         end;
         itReconsider:
            with TypeChangingStatementPtr(nContent)^ do
         begin
            if (nJustification^.nInfSort = infStraightforwardJustification) and
                  StraightforwardJustificationPtr(nJustification)^.nLinked then
            begin
               Print_Linkage;
            end;
            Print_String(TokenName[sy_Reconsider]);
            for i:=0 to nTypeChangeList^.Count-1 do
            begin
               case TypeChangePtr(nTypeChangeList^.Items^[i])^.nTypeChangeKind of
                  Equating:
                     begin
                        Print_Variable(TypeChangePtr(nTypeChangeList^.Items^[i])^.nVar);
                        Print_String('=');
                        Print_Term(TypeChangePtr(nTypeChangeList^.Items^[i])^.nTermExpr);
                     end;
                  VariableIdentifier:
                     begin
                        Print_Variable(TypeChangePtr(nTypeChangeList.Items^[i])^.nVar);
                     end;
               endcases;
               if (i >= 0) and (i < nTypeChangeList^.Count-1) then
                  Print_String(',');
            end;
            Print_String(TokenName[sy_As]);
            Print_Type(nTypeExpr);
            Print_Justification(nJustification,nil);
            Print_String(';');
            Print_NewLine;
         end;
         itPrivFuncDefinition:
            with PrivateFunctorDefinitionPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_DefFunc]);
            Print_Variable(nFuncId);
            Print_String('(');
            Print_TypeList(nTypeExpList);
            Print_String(')');
            Print_String('=');
            Print_Term(nTermExpr);
            Print_String(';');
            Print_NewLine;
         end;
         itPrivPredDefinition:
            with PrivatePredicateDefinitionPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_DefPred]);
            Print_Variable(nPredId);
            Print_String('[');
            Print_TypeList(nTypeExpList);
            Print_String(']');
            Print_String(TokenName[sy_Means]);
            Print_Formula(nSentence);
            Print_String(';');
            Print_NewLine;
         end;
         itConstantDefinition:
            with ConstantDefinitionPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Set]);
            Print_Variable(nVarId);
            Print_String('=');
            Print_Term(nTermExpr);
            Print_String(';');
            Print_NewLine;
         end;
         itLociDeclaration,
         itGeneralization:
            begin
               Print_String(TokenName[sy_Let]);
               Print_VariableSegment( QualifiedSegmentPtr(nContent));
               Print_String(';');
               Print_NewLine;
            end;
         itAssumption:
            begin
               Print_String(TokenName[sy_Assume]);
               Print_AssumptionConditions(AssumptionPtr(nContent));
               Print_String(';');
               Print_NewLine;
            end;
         itExistentialAssumption:
            with ExistentialAssumptionPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Given]);
            Print_VariableSegment( nQVars^.Items^[0]);
            for i := 1 to  nQVars^.Count-1 do
            begin
               Print_String(',');
               Print_VariableSegment( nQVars^.Items^[i]);
            end;
            Print_String(TokenName[sy_Such]);
            Print_String(TokenName[sy_That]);
            Print_NewLine;
            Print_Proposition(nConditions^.Items^[0]);
            for i:=1 to nConditions^.Count-1 do
            begin
               Print_String(TokenName[sy_And]);
               Print_NewLine;
               Print_Proposition(nConditions^.Items^[i]);
            end;
            Print_String(';');
            Print_NewLine;
         end;
         itExemplification:
            with ExamplePtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Take]);
            if nVarId <> nil then
            begin
               Print_Variable(nVarId);
               if nTermExpr <> nil then
               begin
                  Print_String('=');
               end;
            end;
            if nTermExpr <> nil then
               Print_Term(nTermExpr);
            Print_String(';');
            Print_NewLine;
         end;
         itPerCases:
            begin
               if (JustificationPtr(nContent)^.nInfSort = infStraightforwardJustification) and
                     StraightforwardJustificationPtr(nContent)^.nLinked then
               begin
                  Print_Linkage;
               end;
               Print_String(TokenName[sy_Per]);
               Print_String(TokenName[sy_Cases]);
               Print_Justification(JustificationPtr(nContent),nil);
               Print_String(';');
               Print_NewLine;
            end;
         itConclusion:
            begin
               Print_String(TokenName[sy_Thus]);
               Print_RegularStatement(RegularStatementPtr(nContent),nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itCaseBlock:
            begin
               Print_Block(nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itCaseHead,
         itSupposeHead:
            begin
               Print_AssumptionConditions(AssumptionPtr(nContent));
               Print_String(';');
               Print_NewLine;
            end;
         itCorrCond:
            begin
               Print_String(CorrectnessName[CorrectnessConditionPtr(nContent)^.nCorrCondSort]);
               Print_Justification(CorrectnessConditionPtr(nContent)^.nJustification,nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itCorrectness:
            begin
               Print_String(TokenName[sy_Correctness]);
               Print_Justification(CorrectnessPtr(nContent)^.nJustification,nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itProperty:
            begin
               Print_String(PropertyName[PropertyPtr(nContent)^.nPropertySort]);
               Print_Justification(PropertyPtr(nContent)^.nJustification,nBlock);
               Print_String(';');
               Print_NewLine;
            end;
         itDefMode:
            with ModeDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
            begin
               Print_String(TokenName[sy_Redefine]);
            end;
            Print_String(TokenName[sy_Mode]);
            Print_Pattern(nDefModePattern);
            case nDefKind of
               defExpandableMode:
                  begin
                     Print_String(TokenName[sy_Is]);
                     Print_Type(ExpandableModeDefinitionPtr(nContent)^.nExpansion);
                  end;
               defStandardMode:
                  with StandardModeDefinitionPtr(nContent)^ do
               begin
                  if nSpecification <> nil then
                  begin
                     Print_String(TokenName[sy_Arrow]);
                     Print_Type(nSpecification);
                  end;
                  if nDefiniens <> nil then
                  begin
                     Print_String(TokenName[sy_Means]);
                     Print_NewLine;
                     Print_Definiens(nDefiniens);
                  end;
               end;
            endcases;
            Print_String(';');
            Print_NewLine;
         end;
         itDefAttr:
            with AttributeDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
            begin
               Print_String(TokenName[sy_Redefine]);
            end;
            Print_String(TokenName[sy_Attr]);
            Print_Pattern(nDefAttrPattern);
            Print_String(TokenName[sy_Means]);
            Print_NewLine;
            Print_Definiens(nDefiniens);
            Print_String(';');
            Print_NewLine;
         end;
         itDefPred:
            with PredicateDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
            begin
               Print_String(TokenName[sy_Redefine]);
            end;
            Print_String(TokenName[sy_Pred]);
            Print_Pattern(nDefPredPattern);
            if nDefiniens <> nil then
            begin
               Print_String(TokenName[sy_Means]);
               Print_NewLine;
               Print_Definiens(nDefiniens);
            end;
            Print_String(';');
            Print_NewLine;
         end;
         itDefFunc:
            with FunctorDefinitionPtr(nContent)^ do
         begin
            if nRedefinition then
            begin
               Print_String(TokenName[sy_Redefine]);
            end;
            Print_String(TokenName[sy_Func]);
            Print_Pattern(nDefFuncPattern);
            if nSpecification <> nil then
            begin
               Print_String(TokenName[sy_Arrow]);
               Print_Type(nSpecification);
            end;
            case nDefiningWay of
               dfEmpty:;
               dfMeans:
                  begin
                     Print_String(TokenName[sy_Means]);
                     Print_NewLine;
                  end;
               dfEquals:
                  begin
                     Print_String(TokenName[sy_Equals]);
                  end;
            endcases;
            Print_Definiens(nDefiniens);
            Print_String(';');
            Print_NewLine;
         end;
         itDefStruct:
            with StructureDefinitionPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Struct]);
            if nAncestors^.Count > 0 then
            begin
               Print_String('(');
               Print_Type(nAncestors^.Items^[0]);
               for i := 1 to nAncestors^.Count - 1 do
               begin
                  Print_String(',');
                  Print_Type(nAncestors^.Items^[i]);
               end;
               Print_String(')');
            end;
            Print_String(StructureName[nDefStructPattern^.nModeSymbol]);
            if (nDefStructPattern^.nArgs <> nil) and (nDefStructPattern^.nArgs^.Count > 0) then
            begin
               Print_String(TokenName[sy_Over]);
               Print_Loci(nDefStructPattern^.nArgs);
            end;
            Print_String(TokenName[sy_StructLeftBracket]);
            for i := 0 to nSgmFields^.Count - 1 do
               with FieldSegmentPtr(nSgmFields^.Items^[i])^ do
            begin
               Print_String(SelectorName[FieldSymbolPtr(nFields^.Items^[0])^.nFieldSymbol]);
               for j := 1 to nFields^.Count - 1 do
                  with FieldSymbolPtr(nFields^.Items^[j])^ do
               begin
                  Print_String(',');
                  Print_String(SelectorName[nFieldSymbol]);
               end;
               Print_String(TokenName[sy_Arrow]);
               Print_Type(nSpecification);
               if (i >= 0) and (i < nSgmFields^.Count-1) then
                  Print_String(',');
            end;
            Print_String(TokenName[sy_StructRightBracket]);
            Print_String(';');
            Print_NewLine;
         end;
         itPredSynonym,
         itFuncNotation, itModeNotation,
         itAttrSynonym:
            with NotationDeclarationPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Synonym]);
            Print_Pattern(nNewPattern);
            Print_String(TokenName[sy_For]);
            Print_Pattern(nOriginPattern);
            Print_String(';');
            Print_NewLine;
         end;
         itPredAntonym,itAttrAntonym:
            with NotationDeclarationPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Antonym]);
            Print_Pattern(nNewPattern);
            Print_String(TokenName[sy_For]);
            Print_Pattern(nOriginPattern);
            Print_String(';');
            Print_NewLine;
         end;
         itCluster:
            begin
               Print_String(TokenName[sy_Cluster]);
               case ClusterPtr(nContent)^.nClusterKind of
                  ExistentialRegistration:
                     with EClusterPtr(nContent)^ do
                  begin
                     Print_AdjectiveList(nConsequent);
                     Print_String(TokenName[sy_For]);
                     Print_Type(nClusterType);
                  end;
                  ConditionalRegistration:
                     with CClusterPtr(nContent)^ do
                  begin
                     Print_AdjectiveList(nAntecedent);
                     Print_String(TokenName[sy_Arrow]);
                     Print_AdjectiveList(nConsequent);
                     Print_String(TokenName[sy_For]);
                     Print_Type(nClusterType);
                  end;
                  FunctorialRegistration:
                     with FClusterPtr(nContent)^ do
                  begin
                     Print_Term(nClusterTerm);
                     Print_String(TokenName[sy_Arrow]);
                     Print_AdjectiveList(nConsequent);
                     if nClusterType <> nil then
                     begin
                        Print_String(TokenName[sy_For]);
                        Print_Type(nClusterType);
                     end;
                  end;
               endcases;
               Print_String(';');
               Print_NewLine;
            end;
         itIdentify:
            with IdentifyRegistrationPtr(nContent)^ do
         begin
            Print_String(TokenName[sy_Identify]);
            Print_Pattern(nNewPattern);
            Print_String(TokenName[sy_With]);
            Print_Pattern(nOriginPattern);
            if (nEqLociList <> nil) and (nEqLociList^.Count > 0) then
            begin
               Print_String(TokenName[sy_When]);
               for i := 0 to nEqLociList^.Count - 1 do
                  with LociEqualityPtr(nEqLociList^.Items^[i])^ do
               begin
                  Print_Locus(nLeftLocus);
                  Print_String('=');
                  Print_Locus(nRightLocus);
                  if (i >= 0) and (i < nEqLociList^.Count-1) then
                     Print_String(',');
               end;
            end;
            Print_String(';');
            Print_NewLine;
         end;
         itPropertyRegistration:
            case PropertyRegistrationPtr(nContent)^.nPropertySort of
               sySethood:
                  with SethoodRegistrationPtr(nContent)^ do
               begin
                  Print_String(PropertyName[nPropertySort]);
                  Print_String(TokenName[sy_Of]);
                  Print_Type(nSethoodType);
                  Print_Justification(nJustification,nBlock);
                  Print_String(';');
                  Print_NewLine;
               end;
            endcases;
         itReduction:
            begin
               with ReduceRegistrationPtr(nContent)^ do
               begin
                  Print_String(TokenName[sy_Reduce]);
                  Print_Term(nOriginTerm);
                  Print_String(TokenName[sy_To]);
                  Print_Term(nNewTerm);
               end;
               Print_String(';');
               Print_NewLine;
            end;
         itPragma:
            begin
               Print_NewLine;
               Print_String('::'+PragmaPtr(nContent)^.nPragmaStr);
               Print_NewLine;
            end;
         itIncorrItem:;
      end;
   endcases;
end;


@ @<Implementation for \texttt{wsmarticle.pas}@>=
procedure Print_WSMizArticle(aWSTextProper:wsTextProperPtr; aFileName:string);
var lWSMizOutput: WSMizarPrinterPtr;
begin
   InitScannerNames;
   lWSMizOutput:=new(WSMizarPrinterPtr,OpenFile(aFileName));
   lWSMizOutput^.Print_TextProper(aWSTextProper);
   dispose(lWSMizOutput,Done);
end;


@* [F] Detour: Pragmas.
This chapter is a ``detour'' because it is out of order for the
compiler, but it is a dependency for the next file
(\texttt{parseradditions.pas}). 

The \texttt{base/pragmas.pas} contains the global variables
which are toggled by pragmas like ``\texttt{::\$P+}''. This will
toggle the \\{ProofPragma}. In particular, when \\{ProofPragma} is
true, then Mizar will double check the proofs. When \\{ProofPragma} is
false, Mizar will skip the proofs.

@<pragmas.pas@>=
@<GNU License@>
unit pragmas;

interface

uses mobjects;

var
  @! VerifyPragmaOn,@!VerifyPragmaOff : NatSet;
  @! VerifyPragmaIntervals: NatFunc;
  @! SchemePragmaOn,@!SchemePragmaOff: NatSet;
  @! SchemePragmaIntervals : NatFunc;
  @! ProofPragma: Boolean = true; {check the proofs?} @#

procedure @? SetParserPragma(aPrg: string); @t\2@>
procedure @? InsertPragma(aLine: integer; aPrg: string); @t\2@>
procedure @? CompletePragmas(aLine: integer); @t\2@> @#

procedure @? CanceledPragma(@+const aPrg:string;@+ var aKind: char;@+ var aNbr: integer); @t\2@>

implementation @|@#

uses mizenv; @#


@ Cancelling a definition or theorem is handled with the
``\texttt{::\$C}'' pragma, which is administered only by the editors
of the MML. For example ``\texttt{::\$CD}'' will cancel a definition,
``\texttt{CT}'' will cancel a theorem, and ``\texttt{CS}'' cancels a scheme.

@p
procedure CanceledPragma(@+const aPrg:string;@+ var aKind: char;@+ var aNbr: integer);
 var lStr: string;
     k,lCod: integer;
begin
 aKind:=' ';
 if (Copy(aPrg,1,2) = '$C') then
  begin
   if (length(aPrg) >= 3) and (aPrg[3] in ['D','S','T']) then
    begin
     aKind:=aPrg[3];
     lStr:=TrimString(Copy(aPrg,4,length(aPrg)-3));
     aNbr:=1;
     if length(lStr) > 0 then
      begin
       k:=1;
       while (k <= length(lStr)) and (lStr[k] in ['0'..'9']) do inc(k);
       delete(lStr,k,length(lStr));
       if length(lStr) > 0 then
        Val(lStr,aNbr,lCod);
      end;
    end;
  end;
end;

@ The ``\texttt{::\$P+}'' pragma instructs Mizar to start checking the
proofs for correctness. The ``\texttt{::\$P-}'' pragma instructs Mizar
to skip checking proofs.

\label{SetParserPragma}

@p
procedure SetParserPragma(aPrg: string);
begin
   if copy(aPrg,1,3)='$P+' then 
   begin
      ProofPragma:=true;
   end;
   if copy(aPrg,1,3)='$P-' then
   begin
      ProofPragma:=false;
   end;
end;

@ The ``\texttt{::\$S+}'' pragma will tell Mizar to check the scheme references,
whereas ``\texttt{::\$S-}'' pragma tells Mizar to stop verifying
scheme references.

The ``\texttt{::\$V+}'' pragma enables the verifier, and the
``\texttt{::\$V-}'' pragma disables the verifier (skipping all
verification until it is re-enabled). 

@p
procedure InsertPragma(aLine: integer; aPrg: string);
begin
   if copy(aPrg,1,3)='$V+' then
   begin
      VerifyPragmaOn.InsertElem(aLine); @+
   end;
   if copy(aPrg,1,3)='$V-' then
   begin
      VerifyPragmaOff.InsertElem(aLine); @+
   end;

   if copy(aPrg,1,3)='$S+' then
   begin
      SchemePragmaOn.InsertElem(aLine); @+
   end;
   if copy(aPrg,1,3)='$S-' then
   begin
      SchemePragmaOff.InsertElem(aLine); @+
   end;
end;

@ The \\{CompletePragmas} function will compute the intervals for
which the pragmas are ``active'', then check whether the given line
number falls within the ``active range''.

@p
procedure CompletePragmas(aLine: integer);
var i,j,a,b : integer; f:boolean;
begin
  for i:=0 to VerifyPragmaOff.Count-1 do
   begin
     f:=false;
     a:=VerifyPragmaOff.Items^[i].X;
     for j:=0 to VerifyPragmaOn.Count-1 do
      begin
       b:=VerifyPragmaOn.Items^[j].X;
       if b >= a then
        begin
         VerifyPragmaIntervals.Assign(a,b);
         f:=true;
         break; @+
        end;
      end;
     if not f then VerifyPragmaIntervals.Assign(a,aLine);
   end;
  for i:=0 to SchemePragmaOff.Count-1 do
   begin
     f:=false;
     a:=SchemePragmaOff.Items^[i].X;
     for j:=0 to SchemePragmaOn.Count-1 do
      begin
       b:=SchemePragmaOn.Items^[j].X;
       if b >= a then
        begin
         SchemePragmaIntervals.Assign(a,b);
         f:=true;
         break; @+
        end;
      end;
     if not f then SchemePragmaIntervals.Assign(a,aLine);
   end;
end;

@ Now we initialize the global variables declared in this module.

@p
begin

   VerifyPragmaOn.Init(10,10);
   VerifyPragmaOff.Init(10,10);
   VerifyPragmaIntervals.InitNatFunc(10,10);
   SchemePragmaOn.Init(10,10);
   SchemePragmaOff.Init(10,10);
   SchemePragmaIntervals.InitNatFunc(10,10);

end.


@* [F] Detour: Parser additions.
This chapter is a ``detour'' because we are ``going out of [compiler] order'' to
discuss \texttt{parseradditions.pas}. Why? Well, because the file provides
subclasses to those introduced in the abstract syntax unit, and are
necessary for understanding the \texttt{parser.pas} unit.

One of the difficulties with this file is that there are 37 global
variables declared here, and 46 module-wide variables, declared
here. It's hard to juggle that knowledge! These ``global'' variables
really describe the state of the Parser, and do not seem to be used
anywhere else.

For what it's worth, this appears to be conventional among compilers
in the 1990s to use global variables to control the state of the
compiler. For example David Hanson and Christopher Fraser's
\emph{A Retargetable C Compiler: Design and Implementation}
(Addison-Wesley, 1995) has quite a few global variables. If we were
starting from scratch, it would be more idiomatic to put the state in
a \\{Parser} class instance, and we could then use this to unit test
the parser. This would become conventional more than a decade after
Hanson and Fraser's book was published.

\Ithink{It would probably be wise to refactor the design to isolate
these variables inside a \texttt{Parser} class, so they are not
randomly distributed throughout this part of the program.}

C{\sc ONVENTIONS}:
The classes have methods prefixed by \\{Start}, \\{Process},
and \\{Finish}.
\bul The \\{Start} methods reset the state variables needed
to parse the syntactic entity.

\bul The \\{Process} methods usually update the state variables,
either allocating new objects or transferring the current contents of a
state variable in a different state variable.

\bul The \\{Finish} methods construct
a \WSM/ abstract syntax tree for the parsed entity.

@<parseraddition.pas@>=
@<GNU License@>
unit parseraddition; @#

interface @|@#


uses syntax, errhan, mobjects, mscanner, abstract_syntax, wsmarticle, xml_inout; @#

procedure InitWsMizarArticle; @t\2@> @#

type @|@/
@<Extended block class declaration@>@;
@<Extended item class declaration@>@;
@<Extended subexpression class declaration@>@;
@<Extended expression class declaration@>@; @#

   function @? GetIdentifier:integer; @t\2@>
   function @? CreateArgs(aBase:integer): PList; @t\2@> @#

var
@<Global variables introduced in \texttt{parseraddition.pas}@>@; @#

implementation @|@#
uses mizenv, mconsole, parser, _formats, pragmas
mdebug ,info @+ end_mdebug; @#

const
   MaxSubTermNbr   =   64;

var
   @<Local variables for parser additions@>@; @#

   @<Implementation of parser additions@> @t\2@>@;
end.

@ @<Implementation of parser additions@>=
@<Get the identifier number for current word@>@;

@<Initialize WS Mizar article@>;

@<Extended block implementation@>@;

@<Extended item implementation@>@;

@<Extended subexpression implementation@>@;

@<Extended expression implementation@>@;

@ When the current token is an identifier, we should obtain its
number. If the current token is not an identifier, we should return 0.
Since the ID numbers for variables (and types and\dots) are nonzero,
returning 0 indicates the current token is not an identifier.

\label{GetIdentifier}

@<Get the identifier number for current word@>=
function GetIdentifier:integer;
begin
   result:=0;
   if CurWord.Kind = Identifier then result:=CurWord.Nr
end;

@ Initializing a weakly-strict Mizar article requires setting the
values for some of the global variables. Importantly, this will
initialize the \\{gBlockPtr} in the Parser to be an \\{extBlockObj}
instance. Note that this will create ``the'' |blMain| block object.

The \\{gLastWSItem} state variable tracks the last \emph{statement item}.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gWSTextProper: wsTextProperPtr; { article's text body AST }
  @! gLastWSBlock: WSBlockPtr; { block statement AST }
  @! gLastWSItem: WSItemPtr; { statement AST }

@ @<Initialize WS Mizar article@>=
procedure InitWsMizarArticle;
begin {inintialize global variables which were declared
   in \texttt{parseraddition}}
   gWSTextProper:=new(wsTextProperPtr,Init(ArticleID,ArticleExt,CurPos));
   gLastWSBlock:=gWSTextProper;
   gLastWSItem:=nil; @/
   gBlockPtr:=new(extBlockPtr, Init(blMain)); {initialize other global variables}
end;

@* [S] Extended block class.
We extend the \\{Block} class (\section\xref{BlockObj:syntax.pas})
introduced in the \texttt{syntax.pas} unit. Also recall
the \\{wsBlock} class (\section\xref{wsTextProper:ast}) and
the \\{wsItem} class (\section\xref{TextItem:ast}).
\medbreak
\figure
\centerline{\graphics{img/classdiagram-4}}
\caption{Class hierarchy for \\{extBlockObj}, methods omitted.}
\endfigure
\medbreak\noindent%

@ @<Extended block class declaration@>=
   extBlockPtr = ^extBlockObj; @/
   extBlockObj = object(BlockObj) @t\1@> @/
      nLastWSItem: WSItemPtr;
      nLastWSBlock: WSBlockPtr; @#
      
      nLinked: Boolean; {is block prefixed by ``\texttt{then}''?}
      nLinkAllowed: Boolean; {isn't this a duplicate of next field?}
      nLinkProhibited: Boolean; {can statement kind be prefixed by ``\texttt{then}''?}
      nLinkPos:Position; @#
      
      nInDiffuse:boolean;
      nLastSentence: FormulaPtr; @#
      
      nHasAssumptions: Boolean; @#
      
      constructor Init(fBlockKind:BlockKind); @t\2@>
      procedure @? Pop; virtual; @t\2@>
      procedure @? StartProperText; virtual; @t\2@>
      procedure @? ProcessRedefine; virtual; @t\2@>
      procedure @? ProcessLink; virtual; @t\2@>
      procedure @? ProcessBegin; virtual; @t\2@>
      procedure @? ProcessPragma; virtual; @t\2@>
      procedure @? StartSchemeDemonstration; virtual; @t\2@>
      procedure @? FinishSchemeDemonstration; virtual; @t\2@>
      procedure @? CreateItem(fItemKind:ItemKind); virtual; @t\2@>
      procedure @? CreateBlock(fBlockKind:BlockKind); virtual; @t\2\2\2@>
   end;

@ \node{Constructor.}
The constructor for an extended block object invokes the parent
class's constructor (\section\xref{BlockObj.Init}), initializes the
instance variables, then its behaviour depends on whether we are
constructing a ``main'' block or not.

@<Extended block implementation@>=
constructor @? extBlockObj.Init(fBlockKind:BlockKind);
begin
   inherited Init(fBlockKind); @/
   @<Initialize default values for \\{extBlock} instance@>;
   if nBlockKind = blMain then
   @<Initialize \texttt{main} \\{extBlock} instance@>
   else
   @<Initialize ``proper text'' \\{extBlock} instance@>;
end;

@ We have the default values suppose links are prohibited for the
block, and there are no assumptions for the block. The last |wsItem|
and |wsBlock| pointers are set to the global |gLastWSItem| and
|gLastWSBlock| variables, respectively.

@<Initialize default values for \\{extBlock} instance@>=
   nLinked:=false;
   nLinkPos:=CurPos;
   nLinkAllowed:=false;
   nLinkProhibited:=true;
   nHasAssumptions:=false;
   gRedefinitions:=false; @#

   nLastWSItem:=gLastWSItem;
   nLastWSBlock:=gLastWSBlock;

@ The ``main'' block of text needs to load the formats file, and
populate the \\{gFormatsColl} (\section\xref{gFormatsColl}) and
the \\{gFormatsBase} (\emph{ibid}.) global
variables. The \texttt{parseraddition.pas} unit's \\{gProofCnt} global
variable is initialized to zero here.

@<Initialize \texttt{main} \\{extBlock} instance@>=
   begin
      nInDiffuse:=true;
      gProofCnt:=0; @/
      FileExam(EnvFileName+'.frm');
      gFormatsColl.LoadFormats(EnvFileName+'.frm');
      gFormatsBase:=gFormatsColl.Count;
      setlength(Term,MaxSubTermNbr);
   end

@ @<Local variables for parser additions@>=
  @! Term: array of TermPtr; {(\section\xref{uml-class-diagram-for-term-ast})}

@ @<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gProofCnt: integer;

@ The ``proper text'' branch updates the \\{gLastWSBlock} global
variable. For most of the kinds of blocks, we will have to
toggle \\{nInDiffuse} to be true or false. For proof blocks, we will
need to increment the ``depth'' counter tracking the proof block
``nestedness''.

Only the ``\texttt{case}'' and ``\texttt{suppose}'' blocks, when
determining if they are in ``diffuse mode'' or not, need to
confer with the previous block. (Recall (\section\xref{StackedObj}),
\\{StackedObj} classes has a \\{Previous} pointer.)

@<Initialize ``proper text'' \\{extBlock} instance@>=
   begin
      gLastWSBlock:=gWsTextProper^.NewBlock(nBlockKind,CurPos);
      mizassert(2341,gLastWSItem<>nil);
      if gLastWSItem^.nItemKind in [itDefinition,itRegularStatement,itSchemeBlock,
                                    itTheorem,itConclusion,itCaseBlock,itCorrCond,
                                    itCorrectness,itProperty,itPropertyRegistration] then
         wsItemPtr(gLastWSItem).nBlock:=gLastWSBlock;
      case nBlockKind of
         blDefinition: nInDiffuse:=false;
         blNotation: nInDiffuse:=false;
         blDiffuse: nInDiffuse:=true;
         blHereby: nInDiffuse:=true;
         blProof:
            begin
               nLastSentence:=gLastFormula;
               inc(gProofCnt); @+
            end;
         blCase: nInDiffuse:=extBlockPtr(Previous)^.nInDiffuse;
         blSuppose: nInDiffuse:=extBlockPtr(Previous)^.nInDiffuse;
         blRegistration: nInDiffuse:=false;
         blPublicScheme: nInDiffuse:=false;
      endcases;
   end

@ \node{Popping a block.} When we ``pop'' a proof block, we need to
track the formula that was just proven and store it in the global
variable \\{gLastFormula}.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gLastFormula: FormulaPtr;
   
@ This actually implements the \\{Pop} method for blocks. When a block
``closes'' (i.e., the corresponding ``\texttt{end}'' statement has
been encountered), we restore the global
state's \\{gLastWSItem} and \\{gLastWSBlock} pointers. When a proof
block closes, we also restore the \\{gLastFormula} state.

Also note: the parent class's method (\section\xref{BlockObj.Pop})
does nothing. This will be invoked in the \\{KillBlock}
(\section\xref{KillBlock}). 

@<Extended block implementation@>=
procedure @? extBlockObj.Pop;
begin
   gLastWSBlock^.nBlockEndPos:=CurPos;
   case nBlockKind of
      blProof:
         begin
            gLastFormula:=nLastSentence;
            dec(gProofCnt); @+
         end;
   endcases; @/
   gLastWSItem:=nLastWSItem;
   gLastWSBlock:=nLastWSBlock; {restore the ``last'' pointers}
   inherited Pop;
end;

@ \node{Process ``begin''.}
Mizar uses ``\texttt{begin}'' to start a new ``section'' at the
top-level of an article. Recall the grammar for this bit of Mizar:
$$\vbox{\halign{$#$\hfil\cr
\<Text-Proper> ::= \<Section>\ \LB\ \<Section>\ \RB\ .\cr
\<Section> ::= \hbox{\texttt{"begin"} } \LB\ \<Text-Item>\ \RB\ .\cr
}}$$
There are zero or more Text-Items in a section.

We should note that the main text is not organized as a linked list of
``main'' blocks. Instead, we have a single ``main'' block, and we just
push an \\{itSection} item to its contents.

@! @:extBlockObj.ProcessBegin}{\\{extBlockObj.ProcessBegin}@>

\label{extBlockObj.ProcessBegin}
@<Extended block implementation@>=
procedure @? extBlockObj.@!ProcessBegin;
begin
   nLinkAllowed:=false;
   nLinkProhibited:=true;
   gLastWSItem:=gWsTextProper^.NewItem(itSection,CurPos);
   nLastWSItem:=gLastWSItem;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
end;

@ This will add a pragma item to the current block.
The Parser's \\{ProcessPragmas} (\section\xref{ProcessPragmas:parser})
invokes this method.

\label{extBlockObj.ProcessPragma}

@<Extended block implementation@>=
procedure @? extBlockObj.@!ProcessPragma;
begin
   nLinkAllowed:=false;
   nLinkProhibited:=true; @/
   {Create a new item}
   gLastWSItem:=gWsTextProper^.NewItem(itPragma,CurPos);
   gLastWSItem^.nContent:=new(PragmaPtr,Init(CurWord.Spelling)); @/
   {Insert the pragma, update last item in block}
   nLastWSItem:=gLastWSItem;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
end;

@ Starting the proper text will just update the \\{nBlockPos} field to
whatever the current position is.
\label{extBlockObj.StartProperText}

@<Extended block implementation@>=
procedure @? extBlockObj.StartProperText;
begin
   gWSTextProper^.nBlockPos:=CurPos; @+
end;

@ Processing redefinitions sets the global variable \\{gRedefinitions}
to the result of comparing the current word to the
``\texttt{redefine}'' keyword.

@<Extended block implementation@>=
procedure @? extBlockObj.@!ProcessRedefine;
begin
   gRedefinitions:=CurWord.Kind = sy_Redefine; @+
end;

@ When a block statement is linked, but it should not, then we raise
a \texttt{164} error. Otherwise, be sure to mark the block as linked
(i.e., toggle \\{nLinked} to be true) and assign the \\{nLinkPos} to
be the current position.

@<Extended block implementation@>=
procedure @? extBlockObj.@!ProcessLink;
begin
   if CurWord.Kind in [sy_Then,sy_Hence] then
   begin
      if nLinkProhibited then ErrImm(164);
      nLinked:=true;
      nLinkPos:=CurPos;
   end;
end;

@ \node{Proof of a scheme.} We should increment the proof depth global
variable. 

Recall that \\{ProofPragma} means ``check the proof is valid?'' In
other words, when \\{ProofPragma} is false, we are skipping the
proofs.

\label{thesis-formula:macro-def}

@d thesis_formula == new(ThesisFormulaPtr,Init(CurPos))
@d thesis_prop == new(PropositionPtr,
                      Init(new(LabelPtr,Init(0,CurPos)),
                           thesis_formula,CurPos))
@d skipped_proof_justification ==  new(JustificationPtr,Init(infSkippedProof,CurPos))

@<Extended block implementation@>=
procedure @? extBlockObj.@!StartSchemeDemonstration;
begin
   inc(gProofCnt);
   if not ProofPragma then
   @<Mark schema proof as ``skipped''@>;
end;

@ When we skip the proof (due to pragmas being set), we just add the
scheme as a compact statement whose justification is the ``skipped
proof justification''.

First, we create a new text item for the proper text global variable. Then
we set its content to the compact statement with the ``skipped''
justification. Finally we add this item to the ``last''
(latest) \\{wsBlock} global variable.

@<Mark schema proof as ``skipped''@>=
   begin
      gLastWSItem:=gWsTextProper^.NewItem(itConclusion,CurPos);
      gLastWSItem^.nContent:=
         new(CompactStatementPtr,
             Init(thesis_prop,
                  skipped_proof_justification));@/
      gLastWSBlock^.nItems.Insert(gLastWSItem);
   end

@ Finishing the proof for a scheme should decrement the global ``proof depth''
counter.

@<Extended block implementation@>=
procedure @? extBlockObj.@!FinishSchemeDemonstration;
begin
   dec(gProofCnt); @+
end;

@ The factory method for \\{extBlock} creating an item will update the
global \\{gItemPtr} variable (\section\xref{gSubexpPtr}).

@<Extended block implementation@>=
procedure @? extBlockObj.@!CreateItem(fItemKind:ItemKind);
begin
   gItemPtr:=new(extItemPtr, Init(fItemKind)); @+
end;

@ The factory method for \\{extBlock} creating a new block will update
the \\{gBlockPtr} global variable (\section\xref{gSubexpPtr}).

@<Extended block implementation@>=
procedure @? extBlockObj.@!CreateBlock(fBlockKind:BlockKind);
begin
   gBlockPtr:=new(extBlockPtr,Init(fBlockKind)) @+
end;

@* [S] Extended item class.
The class diagram for extended items looks like:
\medbreak
\figure
\centerline{\graphics{img/classdiagram-5}}
\caption{Class hierarchy for \\{extItemObj}. The base \\{MObject} class omitted from the hierarchy.}
\endfigure
\medbreak\noindent%
Recall (\section\xref{RegularStatementKind}) the regular statement
kind is one of three possibilities: diffuse statement, compact
statement, iterative equality.

The ``Finish'' methods updates the contents of the \\{extItem} class
with a \WSM/ abstract syntax tree for the statement.

Since this is a ``stub'', I will just leave the placeholder chunk for
the methods overriden by the extended Item class here (remove later).

@<Methods overriden by extended Item class@>=

@ @<Extended item class declaration@>=
  @! extItemPtr = ^extItemObj; @/
  @! extItemObj = object(ItemObj) @t\1@> @/

     @! nItemPos:Position;
     @! nLastWSItem: WSItemPtr; @#

     @! nLabelIdNr: integer;
     @! nLabelIdPos:Position;
     @! nLabel: LabelPtr; @#

     @! nPropPos: Position; @#

     @! nInference: JustificationPtr; @/
     @! nLinkable: boolean; @#

     @! nRegularStatementKind: RegularStatementKind; @#

     @! nItAllowed: boolean; @#

      constructor @? Init(fKind:ItemKind); @t\2@>
      procedure @? Pop; virtual; @t\2@> @#

@t\4@>  @<Methods overriden by extended Item class@> @t\2\2@> @;

   end;

@* [s] Constructor.
There are a number of comments in Polish which I haphazardly
translated into English (``Przygotowanie definiensow:'' translates as
``Preparation of definiens:''; ``Ew.\ zakaz przy obiektach ekspandowanych''
translates as ``Possible ban on expanded facilities'')

@<Extended item implementation@>=
constructor @? extItemObj.Init(fKind:ItemKind);
begin
   inherited Init(fKind); @/
   @<Initialize the fields for newly allocated \\{extItem} object@>@;
   mizassert(2343,gLastWSBlock<>nil);
   if not (nItemKind in [itReservation,itConstantDefinition,itExemplification,
                         itGeneralization,itLociDeclaration]) then
   begin
      gLastWSItem:=gWsTextProper^.NewItem(fKind,CurPos);
      nLastWSItem:=gLastWSItem;
   end;
   case nItemKind of
      @<Initialize extended item by \\{ItemKind}@>@;
   endcases;
   if not (nItemKind in [itReservation,itConstantDefinition,itExemplification,
                         itGeneralization,itLociDeclaration]) then
      gLastWSBlock^.nItems.Insert(gLastWSItem);
end;

@ \node{Initializing the fields.}
The |it_Allowed| global variable is toggled on and off when the
Parser encounters ``guards'' in conditional definitions, whereas the
|nItAllowed| fields reflects whether the sort of definition allows
``\texttt{it}'' in the definiens.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! dol_Allowed: Boolean;
  @! it_Allowed: Boolean;
  @! in_AggrPattern: Boolean; @#

  @! gLastType: TypePtr;
  @! gLastTerm: TermPtr;
  @! gDefiningWay: HowToDefine;

@ @<Local variables for parser additions@>=
  @! gClusterSort: ClusterRegistrationKind;
  @! gDefiniens: DefiniensPtr;
  @! gPartialDefs: PList;
  @! nDefiniensProhibited: boolean;
  @! gSpecification: TypePtr;

@ @<Initialize the fields for newly allocated \\{extItem} object@>=
   nItemPos:=CurPos;
   gClusterSort:=ExistentialRegistration;
   nItAllowed:=false;
   it_Allowed:=false; {global variable!}
   in_AggrPattern:=false;
   dol_Allowed:=false;
   gSpecification:=nil;
   gLastType:=nil;
   gLastFormula:=nil;
   gLastTerm:=nil; @/
   { Preparation of definiens: }
   nDefiniensProhibited:=false; @/
   { Possible ban on expanded facilities }
   gDefiningWay:=dfEmpty;
   gDefiniens:=nil;
   gPartialDefs:=nil;
   nLinkable:=false;

@ \node{Kind-specific initialization.} Each kind of item may need some
specific initialization. We work through all the cases. The first two
cases considered are generalization (``\texttt{let} $\langle$\textit{Qualified Variables}$\,\rangle$
\texttt{be} [\texttt{such} $\langle$\textit{Conditions}$\,\rangle$]'')
and existential assumptions (``\texttt{given}
$\langle$\textit{Qualified Variables}$\,\rangle$
\texttt{such}
$\langle\,$\textit{Conditions}$\,\rangle$''). Existential assumptions
need to toggle the ``has assumptions'' field to true for the global
block pointer.

@<Initialize extended item by \\{ItemKind}@>=
      itGeneralization: ; {\texttt{let} statements}
      itExistentialAssumption: ExtBlockPtr(gBlockPtr)^.nHasAssumptions:=true;

@ \node{Property initialization.}
Initializing a property statement \\{Item} should raise an error
when the property does not appear in the correct block.

\bul Defining a predicate can support the following properties:
symmetry, reflectivity, irreflexivity, transitivity, conectedness, asymmetry.
\bul Functors can support: associativity, commutativity, idempotence,
involutiveness, and projectivity properties. 
\bul Modes can support the sethood property.

\medbreak
In all other situations, an error should be flagged (the user is
trying to assert an invalid property).

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gDefKind: ItemKind;

@ @<Local variables for parser additions@>=
  @! gExpandable:boolean;
  @! gPropertySort: PropertyKind;
  
@ @<Initialize extended item by \\{ItemKind}@>=
      itProperty:
         begin
            gPropertySort:=PropertyKind(CurWord.Nr);
            case PropertyKind(CurWord.Nr) of
               sySymmetry,syReflexivity,syIrreflexivity,syTransitivity,syConnectedness,syAsymmetry:@|@/
                  if gDefKind<>itDefPred then begin ErrImm(81); gPropertySort:=sErrProperty;@+ end;
               syAssociativity,syCommutativity,syIdempotence:
                  if gDefKind<>itDefFunc then begin ErrImm(82); gPropertySort:=sErrProperty;@+ end;
               syInvolutiveness,syProjectivity:
                  if gDefKind<>itDefFunc then begin ErrImm(83); gPropertySort:=sErrProperty;@+ end;
               sySethood:
                  if (gDefKind<>itDefMode) or gExpandable then begin ErrImm(86); gPropertySort:=sErrProperty;@+ end;
            endcases;
         end;

@ \node{Reconsider initialization.} We need to allocate a new (empty)
list for the list of terms being reconsidered.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gReconsiderList: PList;

@ @<Initialize extended item by \\{ItemKind}@>=
      itReconsider:
         gReconsiderList:=new(PList,Init(0));

@ We can have in Mizar ``\texttt{suppose that}
$\langle\textit{statement\/}\rangle$'' (as well as ``\texttt{case that}\dots'').
But in those cases, the statement cannot be linked to the next
statement (i.e., the next statement cannot begin with ``\texttt{then}\dots'').
Assumptions without ``\texttt{that}'' are always linkable.r

Theorems, ``regular statements'', and conclusions are always linkable.

@ @<Initialize extended item by \\{ItemKind}@>=
      itRegularStatement: nLinkable:=true;
      itConclusion:
         nLinkable:=true;
      itPerCases: ;
      itCaseHead:
         if AheadWord.Kind <> sy_That then nLinkable:=true;
      itSupposeHead:
         if AheadWord.Kind <> sy_That then nLinkable:=true;
      itTheorem:
         nLinkable:=true;
      itAxiom:
         if not AxiomsAllowed then ErrImm(66);
      itChoice: ;

@ \node{Initializing an assumption.} Collective assumptions
(``\texttt{assume that} $\langle$\textit{formula}$\rangle$'') are not
linkable, but
single assumptions (``\texttt{assume} $\langle$\textit{Proposition}$\rangle$'')
are linkable. The statement will introduce a list of premises, which
will be tracked in the \\{gPremises} local variable for the module.

@<Local variables for parser additions@>=
  @! gPremises: PList;

@ @<Initialize extended item by \\{ItemKind}@>=
      itAssumption:
         begin
            if AheadWord.Kind <> sy_That then nLinkable:=true;
            gPremises:=nil;
         end;


@ \node{Definition items.}
Definition items need to be initialized with some nuance. Some
definitions permit ``\texttt{it}'' to be used in the definiens, but
others do not. Mizar toggles the global variables tracking this
here. There is a common set of things toggled which we have isolated
as the \WEB/ macro |initialize_definition_item| common to initializing
all definition items.

The correctness conditions are determined at this point, as well.

@d initialize_definition_item == 
            gCorrectnessConditions:=[];
            gDefPos:=CurPos;
            gDefKind:=nItemKind

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gCorrectnessConditions : CorrectnessConditionsSet;

@ @<Local variables for parser additions@>=
  @! gDefPos: Position;
  @! gStructPrefixes: PList;

@ @<Initialize extended item by \\{ItemKind}@>=
      itLociDeclaration: ;
      itDefMode:
         begin
            nItAllowed:=true;
            gExpandable:=false;
            initialize_definition_item @+
         end;
      itDefAttr:
         begin
            initialize_definition_item @+
         end;
      itAttrSynonym:
         begin
            initialize_definition_item @+
         end;
      itAttrAntonym:
         begin
            initialize_definition_item @+
         end;
      itModeNotation:
         begin
            initialize_definition_item @+
         end;
      itDefFunc:
         begin
            nItAllowed:=true;
            initialize_definition_item @+
         end;
      itFuncNotation:
         begin
             initialize_definition_item; @+
         end;
      itDefPred,
      itPredSynonym,
      itCluster,
      itIdentify,
      itReduction: @|@/
         begin  initialize_definition_item; @+
         end;
      itPropertyRegistration:
         begin
            initialize_definition_item;
            gPropertySort:=PropertyKind(CurWord.Nr);
         end;
      itDefStruct:
         begin
            initialize_definition_item;
            gStructPrefixes:=new(PList,Init(0)); @+
         end;
      itCanceled:
         begin
            ErrImm(88); @+
         end;

@ \node{Correctness conditions.} Registrations and definitions need
correctness conditions to ensure the well-definedness of adjective
clusters and terms. The correctness conditions needed for a definition
(or registration) are inserted into
the \\{gCorrectnessConditions} variable. When the correctness
condition is found, we remove it from the \\{gCorrectnessConditions} set.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gRedefinitions: boolean;

@ @<Local variables for parser additions@>=
  @! gCorrCondSort: CorrectnessKind;

@<Initialize extended item by \\{ItemKind}@>=
      itCorrCond:
         if CorrectnessKind(CurWord.Nr) in gCorrectnessConditions then
         begin
            exclude(gCorrectnessConditions,CorrectnessKind(CurWord.Nr));
            gCorrCondSort:=CorrectnessKind(CurWord.Nr);
            if (gRedefinitions and (gCorrCondSort=syCoherence) and ExtBlockPtr(gBlockPtr)^.nHasAssumptions) then ErrImm(243);
         end
         else
         begin
            ErrImm(72);
            gCorrCondSort:=CorrectnessKind(0); @+
         end;
      itCorrectness: if (gRedefinitions and ExtBlockPtr(gBlockPtr)^.nHasAssumptions) then ErrImm(243);

@ The last statement needing attention will be the \texttt{scheme}
block. Note that \\{gLocalScheme} is not used anywhere.

@<Local variables for parser additions@>=
  @! gLocalScheme: boolean;
  @! gSchemePos: Position;

@ @<Initialize extended item by \\{ItemKind}@>=
      itDefinition, itSchemeHead, itReservation,
      itPrivFuncDefinition, itPrivPredDefinition,
      itConstantDefinition, itExemplification:;
      itCaseBlock:;
      itSchemeBlock:
         begin
            gLocalScheme:=CurWord.Kind <> sy_Scheme;
            gSchemePos:=CurPos; @+
         end;


@ \node{Popping an extended item.}

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gSchemeParams: PList;

@ @<Local variables for parser additions@>=
  @! gPatternPos: Position;
  @! gPattern: PatternPtr;
  @! gNewPatternPos: Position;
  @! gNewPattern: PatternPtr;

  @! gSchemeIdNr: integer;
  @! gSchemeIdPos: Position;
  @! gSchemeConclusion: FormulaPtr;
  @! gSchemePremises: PList;

@* [s] Popping.
Popping an item is invoked as part of \\{KillItem}, which occurs
whenever (1) a semicolon is encountered, 
or (2) when starting a proof environment.

The contract for popping an item ensures the \\{nContent} field shall
be populated for valid items.

N{\sc OTE}: \PASCAL/ has a set operation $\\{include} (\\{set},\\{element})$
which adjoins an \\{element} to a \\{set}.

@<Extended item implementation@>=
procedure @? extItemObj.Pop;
var k:integer;
begin
   gLastWSItem^.nItemEndPos:=PrevPos; 
   @<Check for errors with definition items@>@;
   @<Update content of |nLastWSItem| based on type of item popped@>; @/
   @<Check the popped item's linkages are valid@>;
   if gDefiningWay <> dfEmpty then
   begin
      if gDefiniens^.nDefSort = ConditionalDefiniens then
         include(gCorrectnessConditions,syConsistency);
      if gRedefinitions then
         include(gCorrectnessConditions,syCompatibility);
   end;
   inherited Pop; {(\section\xref{ItemObj.Pop})}
end;

@ We will update the caller's \\{nLastWSItem}'s contents in most cases.

@<Update content of |nLastWSItem| based on type of item popped@>=
   case nItemKind of
      itTheorem:
         nLastWSItem^.nContent:=
         new(CompactStatementPtr,
             Init(new(PropositionPtr,Init(nLabel,
                                          gLastFormula,nPropPos)),
                  nInference)); @#
@t\4@>      @<Pop a proof step@>@; @#
      itConclusion,
      itRegularStatement:
      @<Pop a conclusion or regular statement@>@;
      itGeneralization,
      itLociDeclaration:
      @<Pop a ``\texttt{let}'' statement@>@; @#
@t\4@>      @<Pop a definition item@>@;@#
      itPredSynonym, itPredAntonym, itFuncNotation, itModeNotation,
      itAttrSynonym, itAttrAntonym:
         nLastWSItem^.nContent:=
                        new(NotationDeclarationPtr,
                            Init(gNewPatternPos,nItemKind,gNewPattern,gPattern));@#
@t\4@>      @<Pop a registration item@>@;@#
      itCorrCond:
         nLastWSItem^.nContent:=new(CorrectnessConditionPtr,
                                    Init(nItemPos,gCorrCondSort,nInference));
      itCorrectness:
         nLastWSItem^.nContent:=new(CorrectnessConditionsPtr,
                                    Init(nItemPos,gCorrectnessConditions,nInference));
      itProperty:
         nLastWSItem^.nContent:=new(PropertyPtr,Init(nItemPos,gPropertySort,nInference));
      itSchemeHead:
         nLastWSItem^.nContent:=
         new(SchemePtr,Init(gSchemeIdNr,gSchemeIdPos,gSchemeParams,gSchemePremises,gSchemeConclusion));@#
@t\4@>      @<Pop \&{skip}s remaining cases@>@;
   endcases

@ @<Pop \&{skip}s remaining cases@>=
      itPrivFuncDefinition,
      itPrivPredDefinition,
      itPragma,
      itDefinition,
      itSchemeBlock,
      itReservation,
      itExemplification,
      itCaseBlock:;

@ \node{Check for errors.} We need to flag a 253 or 254 error when the user
tries to introduce an axiom (which shouldn't occur much anymore, since
axioms are not even documented anywhere).

@<Local variables for parser additions@>=
  @! gMeansPos: Position;

@ @<Check for errors with definition items@>=
   case nItemKind of
      itDefPred, itDefFunc, itDefMode, itDefAttr:
         begin
            if gDefiningWay <> dfEmpty then
            begin
               if nDefiniensProhibited and not AxiomsAllowed then
               begin
                  Error(gMeansPos,254);
                  gDefiningWay:=dfEmpty; @+
               end;
            end
            else if not gRedefinitions and not nDefiniensProhibited and not AxiomsAllowed then
               SemErr(253);
         end;
   endcases;

@ \node{Pop a proof step.} Popping a proof step should assign to the
contents of the caller's \\{nLastWsItem} some kind of inference justification,
usually in the form of a statement in the \WSM/ syntax tree.

@<Pop a proof step@>=
      itPerCases:
         nLastWSItem^.nContent:=nInference;

@ \node{Popping a reconsideration.} We should assign
a \\{TypeChangingStatement} to the content of the caller's last item, using
the \\{nInference} field of the caller as the justification.

@<Pop a proof step@>=
      itReconsider:
         nLastWSItem^.nContent:=
         new(TypeChangingStatementPtr,
             Init(gReconsiderList,gLastType,SimpleJustificationPtr(nInference)));

@ \node{Popping existential elimination and introduction.} We assign
a \texttt{consider} (or \texttt{given}) \WSM/ statement to the
caller's previous \\{WSItem}'s contents when popping a
choice (resp., existential assumption) item.

We should remind the reader of the grammar here:

\smallbreak
{\advance\leftskip3pc\parindent=0pt
$\langle$\textit{Qualified-Segment\/}$\rangle$ $::=$ $\langle$\textit{Variables\/}$\rangle$ $\langle$\textit{Qualification\/}$\rangle$

$\langle$\textit{Variables\/}$\rangle$ $::=$ $\langle$\textit{Variable\/}$\rangle$ $\LB$ \texttt{","} $\langle$\textit{Variable\/}$\rangle$ $\RB$

$\langle$\textit{Qualification\/}$\rangle$ $::=$
(\texttt{"being"} \pipe\ \texttt{"be"}) $\langle$\textit{Type-Expression\/}$\rangle$
\par}
\smallbreak\noindent%
And, of course, a qualified-segment list is just a comma-separated
list of qualified-segments.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gQualifiedSegmentList: PList;

@ @<Pop a proof step@>=
      itChoice:
         begin
            nLastWSItem^.nContent:=
               new(ChoiceStatementPtr,
                   Init(gQualifiedSegmentList,gPremises,SimpleJustificationPtr(nInference)));
            gPremises:=nil;
         end;
      itExistentialAssumption:
         begin
            nLastWSItem^.nContent:=
               new(ExistentialAssumptionPtr,
                   Init(nItemPos,gQualifiedSegmentList,gPremises));
            gPremises:=nil;
         end;

@ \node{Popping a stipulation.} When we pop
a \texttt{case}, \texttt{suppose}, or \texttt{assume} --- some kind of
``assumption''-like statement --- we are assigning
either a \\{CollectiveAssumption} object or a \\{SingleAssumption}
object to the content of the \emph{current} \\{WSItem} \textbf{global}
variable.

@<Local variables for parser additions@>=
  @! gThatPos: Position;

@ @<Pop a proof step@>=
      itSupposeHead,itCaseHead,
      itAssumption:
         if gPremises <> nil then
         begin
            gLastWSItem^.nContent:=new(CollectiveAssumptionPtr,Init(gThatPos,gPremises));
            gPremises:=nil;
         end
         else
            gLastWSItem^.nContent:=
               new(SingleAssumptionPtr,Init(nItemPos,
                                            new(PropositionPtr,Init(nLabel,
                                                                    gLastFormula,nPropPos))));

@ \node{Pop a conclusion or regular statement.} We assign an
appropriate \WSM/ statement node to the previous item's contents.

@<Local variables for parser additions@>=
  @! gIterativeSteps: PList;
  @! gIterativeLastFormula: FormulaPtr;
  @! gInference: JustificationPtr;

@ @<Pop a conclusion or regular statement@>=
         case nRegularStatementKind of
            stDiffuseStatement:
               nLastWSItem^.nContent:=
               new(DiffuseStatementPtr,Init(nLabel,
                                            stDiffuseStatement));
            stCompactStatement:
               nLastWSItem^.nContent:=
               new(CompactStatementPtr,
                   Init(new(PropositionPtr,Init(nLabel,
                                                gLastFormula,nPropPos)),
                        nInference));
            stIterativeEquality:
               nLastWSItem^.nContent:=
               new(IterativeEqualityPtr,
                   Init(new(PropositionPtr,Init(nLabel,
                                                gIterativeLastFormula,nPropPos)),
                        gInference,gIterativeSteps));
         endcases;

@ \node{Pop a `let' statement.} For generic let statements of the form
$$\texttt{let}~\vec{x}_{1}~\texttt{be}~T_{1},\dots,\vec{x}_{n}~\texttt{be}~T_{n}$$
we transform it to $n$ statements of the form ``\texttt{let}
$\vec{x}$ \texttt{be} $T$'', then add these to the \\{gLastWSBlock}'s
items. When we have
$$\texttt{let}~\vec{x}~\texttt{be}~T~\hbox{\texttt{such that}}~\Phi$$
we need to  add a \\{CollectiveAssumption} node to
the \textbf{global} \\{gLastWSBlock}'s items.

\label{pop-let-statement}

@<Local variables for parser additions@>=
  @! gSuchPos: Position;
  
@ @<Pop a ``\texttt{let}'' statement@>=
         begin
            for k := 0 to gQualifiedSegmentList^.Count-1 do
            begin
               gLastWSItem:=gWsTextProper^.NewItem(nItemKind,
                                                   QualifiedSegmentPtr(gQualifiedSegmentList^.Items^[k])^.nSegmPos);
               nLastWSItem:=gLastWSItem;
               gLastWSItem^.nContent:=gQualifiedSegmentList^.Items^[k];
               if k = gQualifiedSegmentList^.Count-1 then
                  gLastWSItem^.nItemEndPos:=PrevPos
               else
                  gLastWSItem^.nItemEndPos:=QualifiedSegmentPtr(gQualifiedSegmentList^.Items^[k+1])^.nSegmPos;
               gQualifiedSegmentList^.Items^[k]:=nil;
               gLastWSBlock^.nItems.Insert(gLastWSItem);
            end;
            dispose(gQualifiedSegmentList,Done);
            if gPremises <> nil then
            begin
               gLastWSItem:=gWsTextProper^.NewItem(itAssumption,gSuchPos);
               gLastWSItem^.nContent:=new(CollectiveAssumptionPtr,Init(gThatPos,gPremises));
               gPremises:=nil;
               gLastWSItem^.nItemEndPos:=PrevPos;
               nLastWSItem:=gLastWSItem;
               gLastWSBlock^.nItems.Insert(gLastWSItem);
            end;
         end;

@ \node{Pop a mode definition.} A mode is either expandable (an
abbreviation) or nonexpandable. For expandable modes, we just add a
new \\{ExpandableModeDefinition} \WSM/ object to the
caller's \\{nLastWSItem}'s contents.

On the other hand, non-expandable modes should add to the
caller's \\{nLastWSItem}'s contents a new \\{StandardModeDefinition}
object. If this is not a redefinition, then we must add the
``\texttt{existence}'' correctness condition to the global
variable \\{gCorrectnessConditions}. 

@<Pop a definition item@>=
      itDefMode:
         begin
            if gExpandable  then
               nLastWSItem^.nContent:=
                  new(ExpandableModeDefinitionPtr,
                      Init(gPatternPos,ModePatternPtr(gPattern),gLastType))
            else
            begin
               nLastWSItem^.nContent:=
                  new(StandardModeDefinitionPtr,
                      Init(gPatternPos,gRedefinitions,ModePatternPtr(gPattern),
                           gSpecification,gDefiniens));
               if not gRedefinitions then
                  include(gCorrectnessConditions,syExistence);
            end;
         end;

@ \node{Pop a functor definition.} When popping a functor definition,
we just add a \\{FunctorDefinition} object to the
caller's \\{nLastWSItem}'s contents.

@<Pop a definition item@>=
      itDefFunc:
         begin
            nLastWSItem^.nContent:=
               new(FunctorDefinitionPtr,
                   Init(gPatternPos,gRedefinitions,FunctorPatternPtr(gPattern),
                        gSpecification,gDefiningWay,gDefiniens));

         end;

@ \node{Pop an attribute definition.} We just need to add
an \\{AttributeDefinition} object to the caller's \\{nLastWSItem}'s
contents.

@<Pop a definition item@>=
      itDefAttr:
         begin
            nLastWSItem^.nContent:=
               new(AttributeDefinitionPtr,
                   Init(gPatternPos,gRedefinitions,AttributePatternPtr(gPattern),gDefiniens));
         end;

@  \node{Pop a predicate definition.} We just need to add
a \\{PredicateDefinition} object to the caller's \\{nLastWSItem}'s
contents.

@<Pop a definition item@>=
      itDefPred:
         begin
            nLastWSItem^.nContent:=
               new(PredicateDefinitionPtr,
                   Init(gPatternPos,gRedefinitions,PredicatePatternPtr(gPattern),gDefiniens));
         end;

@ \node{Popping a structure definition.} We just need to add
a \\{StructureDefinition} object to the caller's \\{nLastWSItem}'s
contents.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gConstructorNr: integer;

@ @<Local variables for parser additions@>=
  @! gParams: PList;
  @! gStructFields: PList;

@ @<Pop a definition item@>=
      itDefStruct:
         begin
            nLastWSItem^.nContent:=
               new(StructureDefinitionPtr,
                   Init(gPatternPos,gStructPrefixes,gConstructorNr,gParams,gStructFields));
         end;

@ \node{Pop a cluster registration item.} A ``cluster'' registration
(i.e., a existential, conditional, or functor registration) adds to
the caller's \\{nLastWSItem}'s contents a new cluster object (of
appropriate kind). The \\{gClusterSort} is populated when the Parser
finishes a cluster registration when
invoking \\{extItemObj.FinishAntecedent}
(\section\xref{extItemObj.FinishAntecedent}) or similar methods.

The \\{gClusterTerm} is populated in
the \\{extItemObj.FinishClusterTerm} method
(\section\xref{extItemObj.FinishClusterTerm}). 

@<Local variables for parser additions@>=
  @! gAntecedent,gConsequent: PList;
  @! gClusterTerm: TermPtr;

@ @<Pop a registration item@>=
      itCluster:
         begin
            case gClusterSort of
               ExistentialRegistration:
                  begin
                     nLastWSItem^.nContent:=new(EClusterPtr,Init(nItemPos,gConsequent,gLastType));
                     include(gCorrectnessConditions,syExistence)
                  end;
               ConditionalRegistration:
                  begin
                     nLastWSItem^.nContent:=
                        new(CClusterPtr,Init(nItemPos,gAntecedent,gConsequent,gLastType));
                     include(gCorrectnessConditions,syCoherence);
                  end;
               FunctorialRegistration:
                  begin
                     nLastWSItem^.nContent:=
                        new(FClusterPtr,Init(nItemPos,gClusterTerm,gConsequent,gLastType));
                     include(gCorrectnessConditions,syCoherence);
                  end;
            endcases;
         end;

@ \node{Pop a registration item.} For an \texttt{identify}
or \texttt{reduce} registration, we assign the content of the
caller's \\{nLastWSItem} a new \\{IdentifyRegistration}
(resp., \\{ReduceRegistration}) object. Identify registrations use
the \\{gIdentifyEqLociList} local variable, while the reduction
registrations use the \\{gLeftTermInReduction} module-wide variable.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gLeftTermInReduction: TermPtr;

@ @<Local variables for parser additions@>=
  @! gIdentifyEqLociList: PList;

@ @<Pop a registration item@>=
      itIdentify:
         begin
            nLastWSItem^.nContent:=
               new(IdentifyRegistrationPtr,Init(nItemPos,gNewPattern,gPattern,gIdentifyEqLociList));
            include(gCorrectnessConditions,syCompatibility);
         end;
      itReduction:
         begin
            nLastWSItem^.nContent:=
               new(ReduceRegistrationPtr,Init(nItemPos,gLeftTermInReduction,gLastTerm));
            include(gCorrectnessConditions,syReducibility);
         end;
      itPropertyRegistration:
         SethoodRegistrationPtr(nLastWSItem^.nContent)^.nJustification:=nInference;


@ \node{Check linkages are valid.} When popping an item, we should
check if the block containing the caller is \\{nLinked}. If so, flag a
``178'' error and assign |nLinked := false|. Update the block's
|nLinkAllowed| depending on the caller's |nLinkable| field. But if the
Parser is in panic mode, the containing block's |nLinkAllowed| and
|nLinkProhibited| are both assigned to false. \Ithink{This
configuration appears to encode a particular state which feels a bit
of a ``kludge'' to me\dots}

@^Error, 178@>

@<Check the popped item's linkages are valid@>=
   with extBlockPtr(gBlockPtr)^ do
   begin
      if nLinked then
      begin
         Error(nLinkPos,178);
         nLinked:=false @+
      end;
      nLinkAllowed:=nLinkable;
      nLinkProhibited:=not nLinkable;
      if not StillCorrect then
      begin
         nLinkAllowed:=false;
         nLinkProhibited:=false @+
      end;
   end

@* [s] Registrations and notations.
\node{Processing synonyms.} We need to update the \\{gNewPatternPos}
and \\{gNewPattern} global variables when processing a synonym.

@d process_notation_item ==
   gNewPatternPos:=gPatternPos;
   gNewPattern:=gPattern

@<Extended item implementation@>=
procedure @? extItemObj.ProcessModeSynonym;
begin process_notation_item; @+
end; @#

procedure @? extItemObj.ProcessAttrSynonym;
begin process_notation_item; @+
end; @#

procedure @? extItemObj.ProcessAttrAntonym;
begin process_notation_item; @+
end; @#

procedure @? extItemObj.ProcessPredSynonym;
begin process_notation_item; @+
end; @#

procedure @? extItemObj.ProcessPredAntonym;
begin process_notation_item; @+
end; @#

procedure @? extItemObj.ProcessFuncSynonym;
begin process_notation_item; @+
end; @#

@ \node{Starting attributes.} This is used when the Parser encounters
a cluster registration
(\section\xref{RegisterCluster:parser.pas}). The \\{gAttrColl} is
populated in the \\{extSubexpObj.CompleteAdjectiveCluster}
(\section\xref{extSubexpObj.CompleteAdjectiveCluster}) method.

\label{extItemObj.StartAttributes}

@<Local variables for parser additions@>=
  @! gAttrColl: PList;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartAttributes;
begin
   gAttrColl:=new(PList,Init(6));
end;

@ \node{Starting a sentence.} We just need to populate the
caller's \\{nPropPos}, assigning to it the current position of the
Parser.

\label{extItemObj.StartSentence}

@<Extended item implementation@>=
procedure @? extItemObj.StartSentence;
begin
   nPropPos:=CurPos;
end;

@ \node{Processing conditional registration.} This populates
the \\{gClusterSort} and the related global variables, as the Parser
finishes parsing the antecedent and consequent to the cluster.

\label{extItemObj.FinishAntecedent}

@<Extended item implementation@>=
procedure @? extItemObj.FinishAntecedent;
begin
   gClusterSort:=ConditionalRegistration;
   gAntecedent:=gAttrColl;
end; @#

procedure @? extItemObj.FinishConsequent;
begin
   gConsequent:=gAttrColl;
end;

@ \node{Finishing a cluster.} This populates the \\{gClusterSort} and
the \\{gClusterTerm}.

\label{extItemObj.FinishClusterTerm}

@<Extended item implementation@>=
procedure @? extItemObj.FinishClusterTerm;
begin
   gClusterSort:=FunctorialRegistration;
   gClusterTerm:=gLastTerm;
end;

@ \node{Identify registration.} Schematically, we have the
registration statement look like (using global variable names for the
subexpressions): 
$$\texttt{identify}~\langle\textit{gNewPattern\/}\rangle~\texttt{with}~\langle\textit{gPattern}\rangle~[\texttt{when}~\langle\textit{gIdentifyEqLociList\/}\rangle]\texttt{;}$$
We store the first pattern in the \\{gNewPattern} global variable,
then the second pattern in the \\{gPattern} global
variable. Completing the identify registration will check if the
current word is ``\texttt{when}'' and, if so, start a list of loci equalities.

@<Extended item implementation@>=
procedure @? extItemObj.StartFuncIdentify;
begin
end; @#

procedure @? extItemObj.ProcessFuncIdentify;
begin
   gNewPatternPos:=gPatternPos;
   gNewPattern:=gPattern;
end; @#

procedure @? extItemObj.CompleteFuncIdentify;
begin
   gIdentifyEqLociList:=nil;
   if CurWord.Kind = sy_When then
      gIdentifyEqLociList:=new(PList,Init(0));
end;

@ \node{``Reduces to'' registrations.}
Recall, these schematically look like
$$\hbox{\texttt{reduce}\ }\langle\textit{gLeftLocus\/}\rangle\hbox{ \texttt{to} }\langle\textit{Locus\/}\rangle\hbox{\texttt{;}}$$
Mizar will populate \\{gLeftLocus}. The gambit will be to treat this
as a functor pattern; i.e., the \\{gLeftLocus} will be used to
populate \\{gNewPattern} in the method
\\{extItemObj.FinishFunctorPattern} (\section\xref{extItemObj.FinishFunctorPattern}).

@<Local variables for parser additions@>=
  @! gLeftLocus: LocusPtr;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessLeftLocus;
begin
   gLeftLocus:=new(LocusPtr,Init(CurPos,GetIdentifier));
end; @#

procedure @? extItemObj.ProcessRightLocus;
begin
   gIdentifyEqLociList.Insert(new(LociEqualityPtr,
                                 Init(PrevPos,gLeftLocus,new(LocusPtr,Init(CurPos,GetIdentifier)))));
end; @#

procedure @? extItemObj.StartFuncReduction;
begin
end; @#

procedure @? extItemObj.ProcessFuncReduction;
begin
   gNewPatternPos:=gPatternPos;
   gLeftTermInReduction:=gLastTerm;
end;

@* [s] Processing definitions.
The terminology used by the Parser appears to be
(\section\section\xref{FixedVariables:parser.pas} \textit{et seq.}):
$$\hbox{\texttt{let} }\langle\textit{Fixed\ Variables}\rangle\hbox{\texttt{;}}$$
and
$$\hbox{\texttt{consider} }\langle\textit{Fixed\ Variables}\rangle\hbox{ \texttt{such that}}\dots$$
This would mean that we would have ``fixed variables'' refer to a list
of qualified segments. We remind the reader of the grammar
$$\vbox{\halign{$#$\hfil\cr
\<Fixed-Variables>\ ::= \<Implicitly-Qualified-Variables>\ \LB\ \hbox{\texttt{","}}\ \<Fixed-Variables>\ \RB\cr
\hphantom{\<Fixed-Variables>\ ::}\mid \<Explicitly-Qualified-Variables>\ \LB\ \hbox{\texttt{","}}\ \<Fixed-Variables>\ \RB\cr
\<Implicitly-Qualified-Variables> ::= \<Variables>\cr
\<Explicitly-Qualified-Variables> ::= \<Qualified-Segment>\ \LB \hbox{\texttt{","}}
\<Qualified-Segment>\ \RB\cr
\<Qualified-Segment> ::= \<Variables>\ \<Qualification>\cr
\<Variables> ::= \<Variable>\ \LB\ \hbox{\texttt{","}}\ \<Variable>\ \RB\cr
\<Qualification> ::= (\hbox{\texttt{"be"}}\ \pipe\ \hbox{\texttt{"being"}})\ \<Type>\cr}}$$
The ``fixed variables'' routine in the Parser will parse a
comma-separated list of qualified variables.

\CAUTION/: The grammar in the \texttt{syntax.txt} file is actually
more strict than this, because it actually states the following:
$$\<Loci-Declaration> ::= \hbox{\texttt{"let"} } \<Qualified-Variables> [ \hbox{ \texttt{"such"} } \<Conditions> \hbox{ }] \hbox{ \texttt{;}}$$
The grammar for a qualified segment \emph{requires} implicitly
qualified variables appear at the very end.

\label{extItemObj.StartFixedVariables}

@<Extended item implementation@>=
procedure @? extItemObj.StartFixedVariables;
begin
   gQualifiedSegmentList:=new(PList,Init(0));
end;

@ @<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gQualifiedSegment: MList;
  @! gSegmentPos: Position;

@ \node{Fixed segments.} This refers to each ``explicitly qualified segment''
or ``implicitly qualified segment'' appearing in the fixed variables
portion. The fixed segments are separated by commas.

@<Extended item implementation@>=
procedure @? extItemObj.StartFixedSegment;
begin
   gQualifiedSegment.Init(0);
   gSegmentPos:=CurPos;
end;

@ When parsing fixed variables, and the Parser has just entered the
loop to parse fixed variables, this function will be invoked.

@<Extended item implementation@>=
procedure @? extItemObj.ProcessFixedVariable;
begin
   gQualifiedSegment.Insert(new(VariablePtr,Init(CurPos,GetIdentifier)));
end;

@ This ``clears the cache'' for assigning the type in an explicitly
qualified segment (appearing in a fixed variable segment).

@<Extended item implementation@>=
procedure @? extItemObj.ProcessBeing;
begin
   gLastType:=nil;
end;

@ The last statement in the Parser loop when parsing ``fixed
variables'' is to push the ``fixed segment'' onto
the \\{gQualifiedSegmentList} global variable. There are two cases to
consider: the implicitly qualified variables and the explicitly
qualified variables.

The implicitly qualified case simple \emph{moves} the pointers around
``manually'', so we need to update every entry
of \\{gQualifiedSegment.Items} to be nil. The explicitly qualified
case moves the pointers around using the \\{MList} constructor,
mutating \\{gQualifiedSegment} into a list of |nil| pointers.

@<Extended item implementation@>=
procedure @? extItemObj.FinishFixedSegment;
var k:integer;
begin
   if gLastType <> nil then {explicitly qualified case}
   begin
      gQualifiedSegmentList^.Insert(new(ExplicitlyQualifiedSegmentPtr,
                                        Init(gSegmentPos,new(PList,MoveList(gQualifiedSegment)),gLastType)));
      gQualifiedSegment.DeleteAll;
   end
   else
   begin
      for k := 0 to gQualifiedSegment.Count - 1 do
      begin
         gQualifiedSegmentList^.Insert(new(ImplicitlyQualifiedSegmentPtr,
                                           Init(VariablePtr(gQualifiedSegment.Items^[k])^.nVarPos,
                                                gQualifiedSegment.Items^[k])));
         gQualifiedSegment.Items^[k]:=nil;
      end;
   end;
   gQualifiedSegment.Done;
end;

@ When we finish parsing fixed variables, we need to ``unset''
the \\{gPremises} global variable. The Parser will either be looking
at a semicolon token or at ``\texttt{such} \<Conditions>''. The reader
should note that \\{gSuchThatOcc} is not used in the Parser, nor
anywhere else in Mizar. But we recall (\section\xref{pop-let-statement})
the \\{gSuchPos} is used when popping a \texttt{let} statement.

\label{extItemObj.FinishFixedVariables}

@<Local variables for parser additions@>=
  @! gSuchThatOcc: boolean; {not used}

@ @<Extended item implementation@>=
procedure @? extItemObj.FinishFixedVariables;
begin
   gSuchThatOcc:=CurWord.Kind = sy_Such;
   gSuchPos:=CurPos;
   gPremises:=nil;
end;

@ When the Parser encounters the statement:
$$\hbox{\texttt{let }} \<Fixed-Variables> \hbox{\texttt{ such that }} \<Assumption>\texttt{;}$$
The first things it does when encountering the ``\texttt{such}'' token
is move to the next token (``\texttt{that}'') and then invoke
the \\{StartAssumption} method. We should allocate a fresh list
for \\{gPremises} and mark the position of the ``\texttt{that}'' token.

@<Extended item implementation@>=
procedure @? extItemObj.StartAssumption;
begin
   gPremises:=new(PList,Init(0));
   gThatPos:=CurPos;
end;

@ Finishing an assumption will update the global
variable \\{gBlockPtr}'s field reflecting it has assumptions.

@<Extended item implementation@>=
procedure @? extItemObj.FinishAssumption;
begin
   ExtBlockPtr(gBlockPtr)^.nHasAssumptions:=true;
end;

@ When the Mizar Parser has encountered
$$\hbox{\texttt{assume that }} \<Conditions> \texttt{;}$$
we start a collective assumption when the Parser has just encountered
the ``\texttt{that}'' token. As with the ``\texttt{let} statement with
assumptions'', we need to allocate a new list for \\{gPremises} and
assign the \\{gThatPos} to the current position.

\label{extItemObj.StartCollectiveAssumption}

@<Extended item implementation@>=
procedure @? extItemObj.StartCollectiveAssumption;
begin
   gPremises:=new(PList,Init(0));
   gThatPos:=CurPos;
end;

@ \node{Processing copula in a definition.} When defining a
(nonexpandable) mode, a functor, a predicate, or an attribute, we have
$$\<Pattern> \hbox{ \texttt{means} } \<Expression>\texttt{;}$$
or
$$\<Pattern> \hbox{ \texttt{equals} } \<Expression>\texttt{;}$$
The expression may or may not be labeled, we may or may not have the
definition-by-cases. Whatever the situation, we should initialize the
variables describing the definiens:
\bul the \\{gDefLabId} should be reset to zero (and populated in
the \\{ProcessDefLabel} method);
\bul the \\{gDefLabPos} should be reset to the current position (and
populated in the \\{ProcessDefLabel} method);
\bul the \\{gDefiningWay} should be assigned to \\{dfMeans}
or \\{dfEquals} depending on the copula used in the definition;
\bul the \\{gOtherwise} pointer should be assigned to |nil|;
\bul the \\{gMeansPos} position should be assigned to the current position.

\medbreak\noindent%
Following tradition in logic, we will refer to ``\texttt{means}'' and
``\texttt{equals}'' as the \define{Copula} in the definition.

@^Copula@>

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gDefLabId:integer;
  @! gDefLabPos: Position;
   
@ @<Local variables for parser additions@>=
  @! gOtherwise: PObject;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessMeans;
begin
   gDefLabId:= 0;
   gDefLabPos:=CurPos;
   gDefiningWay:=dfMeans;
   gOtherwise:=nil;
   gMeansPos:=CurPos
end; @#

procedure @? extItemObj.ProcessEquals;
begin
   gDefLabId:= 0;
   gDefLabPos:=CurPos;
   gDefiningWay:=dfEquals;
   gOtherwise:=nil;
   gMeansPos:=CurPos;
end;

@ When parsing a definition-by-cases, the cases are terminated with an
``\texttt{otherwise}'' keyword. Recall the grammar for such
definitions looks like:
$$ \<Partial-Definiens-List> \hbox{ \texttt{"otherwise"} } \<Expression>\texttt{;}$$
What happens depends on whether the definition uses ``\texttt{means}''
or ``\texttt{equals}'': in the former case, we should update
the \\{gOtherwise} pointer to be the \\{gLastFormula}; in the latter
case, we should update the \\{gOtherwise} to be the \\{gLastTerm}.

@<Extended item implementation@>=
procedure @? extItemObj.FinishOtherwise;
begin
   if gDefiningWay = dfEquals then
      gOtherwise:=gLastTerm
   else gOtherwise:=gLastFormula;
end;

@ Starting a definiens should mutate the |it_Allowed| global variable
to be equal to the caller's |nItAllowed| field. The |it_Allowed|
global variable is toggled on and off when the Parser encounters ``guards'' in
conditional definitions, whereas the |nItAllowed| fields reflects
whether the sort of definition allows ``\texttt{it}'' in the definiens.

@<Extended item implementation@>=
procedure @? extItemObj.StartDefiniens;
begin
   it_Allowed:=nItAllowed;
end;

@ ``Guards'' refers to the conditions in a
definition-by-cases. Specifically, we have
$$\<Partial-Definiens> ::= \<Expression> \hbox{ \texttt{"if"} } \<Guard-Formula>$$
be the grammar for one particular case. We have a comma-separated list
of partial definiens, so whenever the Parser (a) first encounters the
``\texttt{if}'' keyword in a definiens, or (b) has already encountered
the ``\texttt{if}'' keyword and now has encountered a comma --- these
are the two cases to start a new guard.

@<Local variables for parser additions@>=
  @! gPartDef: PObject;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartGuard;
begin
   if gPartialDefs = nil then
      gPartialDefs:=new(PList,Init(0));
   it_Allowed:=false;
   if gDefiningWay = dfMeans  then
      gPartDef:=gLastFormula
   else gPartDef:=gLastTerm;
end;

@ After parsing a formula, then the Parser will invoke \\{FinishGuard}.
This will append to \\{gPartialDefs} a new partial definiens.

@<Extended item implementation@>=
procedure @? extItemObj.FinishGuard;
begin
   it_Allowed:=nItAllowed;
   case gDefiningWay of
      dfMeans:
         gPartialDefs.Insert(new(PartDefPtr,Init(new(DefExpressionPtr,Init(exFormula,gPartDef)),gLastFormula)));
      dfEquals:
         gPartialDefs.Insert(new(PartDefPtr,Init(new(DefExpressionPtr,Init(exTerm,gPartDef)),gLastFormula)));
   endcases;
end;

@ Recall for functor definitions we have something like:
$$ \hbox{\texttt{func }} \<Pattern> \hbox{ \texttt{->} } \<Type> \hbox{ ( \texttt{means} \pipe\ \texttt{equals} ) }\dots$$
Similarly, nonexpandable modes look like
$$ \hbox{\texttt{mode }} \<Pattern> \hbox{ \texttt{->} } \<Type> \hbox{ \texttt{means} } \dots$$
The ``\texttt{->} \<Type>'' is called the [type] \emph{specification} for the
definition. We should update the \\{gSpecification} global variable to
point to whatever the last type parsed was --- which is stored in
the \\{gLastType} global variable.

@<Extended item implementation@>=
procedure @? extItemObj.FinishSpecification;
begin
   gSpecification:=gLastType;
end;

@ ``Construction type'' is the term used by the Parser for
``nonexpandable modes''. They, too, have a type
specification. The \\{FinishConstructionType} populates
the \\{gSpecification} global variable with this type.

\label{extItemObj.FinishConstructionType}

@<Extended item implementation@>=
procedure @? extItemObj.FinishConstructionType;
begin
   gSpecification:=gLastType;
end;

@ Expandable mode definitions, after encountering the ``\texttt{is}''
keyword, invokes the \\{StartExpansion} method. This just ensures
there is no definiens, and the \\{gExpandable} global variable is
assigned to ``true''.

@<Extended item implementation@>=
procedure @? extItemObj.StartExpansion;
begin
   if gRedefinitions then  ErrImm(271);
   nDefiniensProhibited:=true;
   gExpandable:=true;
end;

@ The Parser, when determining the pattern for an attribute (\section\xref{GetAttrPattern:parser.pas}), resets the state when
starting to determine the pattern for the attribute. This is handled
by the \\{StartAttribute} method.

We should remind the reader that attributes can only have
arguments \emph{to its left}.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gParamNbr: integer;

@ @<Local variables for parser additions@>=
  @! gLocus: LocusPtr;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartAttributePattern;
begin
   gParamNbr:=0;
   gParams:=nil;
   gLocus:=new(LocusPtr,Init(CurPos,GetIdentifier));
end;

@ Since an attribute can only have attributes to its left, it's pretty
clear when the attribute pattern has been parsed: the Parser has found
the attribute being defined. In that case (assuming we're not
panicking), we should add the attribute format to the \\{gFormatsColl}
dictionary and update the global variables.

@<Extended item implementation@>=
procedure @? extItemObj.FinishAttributePattern;
var lFormatNr: integer;
begin
   lFormatNr:=0;
   if (CurWord.Kind = AttributeSymbol) and stillcorrect then
      lFormatNr:=gFormatsColl.CollectPrefixForm('V',CurWord.Nr,gParamNbr);
   gPatternPos:=CurPos;
   gConstructorNr:=CurWord.Nr;
   gPattern:=new(AttributePatternPtr,Init(gPatternPos,gLocus,gConstructorNr,gParams));
end;

@ A mode definition may include a ``\texttt{sethood}'' property. This
particular function is used when registering sethood in a registration
block. 

@<Extended item implementation@>=
procedure @? extItemObj.FinishSethoodProperties;
begin
   nLastWSItem^.nContent:=
      new(SethoodRegistrationPtr,Init(nItemPos,gPropertySort,gLastType));
end;

@ We remind the reader the grammar for a mode pattern
$$ \<Mode-Pattern> ::= \<Mode-Symbol>\;[\hbox{ \texttt{"of"} } \<Loci>\;] $$
The loci parameters can only appear \emph{after} the mode symbol (and
before the ``\texttt{of}'' reserved keyword). Starting a mode pattern
should reset the relevant global variables.

\label{extItemObj.StartModePattern}

@<Extended item implementation@>=
procedure @? extItemObj.StartModePattern;
begin
   gParamNbr:=0;
   gParams:=nil;
   gPatternPos:=CurPos;
   gConstructorNr:=CurWord.Nr;
end;

@ Finishing a mode pattern should build a new \\{ModePatternObj}, and
store it in the \\{gPattern} global variable. And if we are not
panicking, we should add it to the \\{gFormatsColl} dictionary.

\label{extItemObj.FinishModePattern}

@<Extended item implementation@>=
procedure @? extItemObj.FinishModePattern;
var lFormatNr: integer;
begin
   lFormatNr:=0;
   if StillCorrect then
      lFormatNr:=gFormatsColl.CollectPrefixForm('M',gConstructorNr,gParamNbr);
   gPattern:=new(ModePatternPtr,Init(gPatternPos,gConstructorNr,gParams));
end;

@ When Parser starts parsing a new predicate pattern, we should reset
the relevant global variables.

@<Extended item implementation@>=
procedure @? extItemObj.StartPredicatePattern;
begin
   gParamNbr:=0;
   gParams:=nil;
end;

@ When the Parser tries to parse a ``predicative formula'' (i.e., a
formula involving a predicate) --- including predicate patterns ---
the first thing it does is invoke this \\{ProcessPredicateSymbol} method.
This resets the global variables needed to populate the arguments to
the predicate in the formula.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gLeftLociNbr: integer;

@ @<Local variables for parser additions@>=
  @! gLeftLoci: PList;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessPredicateSymbol;
begin
   gPatternPos:=CurPos;
   gLeftLociNbr:=gParamNbr;
   gLeftLoci:=gParams;
   gParamNbr:=0;
   gParams:=nil;
   gConstructorNr:=CurWord.Nr;
end;

@ Finishing a predicate pattern will create a new \\{PredicatePattern}
object, update the \\{gPattern} global variable to point to it, and
(if the Parser is not panicking) add the predicate's format to
the \\{gFormatsColl} dictionary.

@<Extended item implementation@>=
procedure @? extItemObj.FinishPredicatePattern;
var lFormatNr: integer;
begin
   lFormatNr:=0;
   if StillCorrect then
      lFormatNr:=gFormatsColl.CollectPredForm(gConstructorNr,gLeftLociNbr,gParamNbr);
   gPattern:=new(PredicatePatternPtr,Init(gPatternPos,gLeftLoci,gConstructorNr,gParams));
end;

@ Functor patterns a bit trickier. When starting one, what should
occur depends on the type of functor being defined. Specifically, we
handle brackets differently than other functors, and within the
brackets we handle braces (i.e., definitions like $\LB x_{1},\dots,x_{n}\RB$)
differently than square brackets ($\hbox{\texttt{[}}x_{1},\dots,x_{n}\hbox{\texttt{]}}$)
differently than everything other functor bracket.

In all cases, even non-bracket functors, we need to reset
the \\{gParamNbr} and \\{gParams} global variables so they may be
populated correctly.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gSubItemKind: TokenKind;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartFunctorPattern;
begin
   gPatternPos:=CurPos;
   gSubItemKind:=CurWord.Kind;
   case CurWord.Kind of
      LeftCircumfixSymbol: gConstructorNr:=CurWord.Nr;
      sy_LeftSquareBracket:
         begin
            gSubItemKind:=LeftCircumfixSymbol;
            gConstructorNr:=SquareBracket
         end;
      sy_LeftCurlyBracket:
         begin
            gSubItemKind:=LeftCircumfixSymbol;
            gConstructorNr:=CurlyBracket
         end;
   othercases gConstructorNr:=0;
   endcases;
   gParamNbr:=0;
   gParams:=nil;
end;

@ For ``non-bracket'' functors (i.e., infix operators), the functor
pattern is processed by (1) getting the left parameters, (2)
processing the functor symbol, (3) getting the right parameters. This
function is precisely step (2).

\label{extItemObj.ProcessFunctorSymbol}
@<Extended item implementation@>=
procedure @? extItemObj.@!ProcessFunctorSymbol;
begin
   gPatternPos:=CurPos;
   if CurWord.Kind = InfixOperatorSymbol then
   begin
      gSubItemKind:=InfixOperatorSymbol;
      gConstructorNr:=CurWord.Nr;
      gLeftLociNbr:=gParamNbr;
      gLeftLoci:=gParams;
      gParamNbr:=0;
      gParams:=nil;
   end;
end;

@ When defining a bracket functor pattern, we add a new bracket
format to the \\{gFormatsColl} dictionary, and then set \\{gPattern}
to a newly allocated Bracket pattern.

When defining an infix functor, we add a new functor format to
the \\{gFormatsColl} dictionary, and then we set the \\{gPattern} to a
newly allocated infix functor pattern.

The ``other cases'' constructs an infix functor pattern, but does not
add the form to the \\{gFormatsColl} dictionary.

\label{extItemObj.FinishFunctorPattern}
@<Extended item implementation@>=
procedure @? extItemObj.FinishFunctorPattern;
var lConstructorNr,lFormatNr: integer;
begin
   lFormatNr:=0;
   case gSubItemKind of
      LeftCircumfixSymbol:
         begin
            lConstructorNr:=CurWord.Nr;
            if StillCorrect then
               lFormatNr:=gFormatsColl.CollectBracketForm(gConstructorNr,lConstructorNr,gParamNbr,0,0);
            gPattern:=new(CircumfixFunctorPatternPtr,Init(gPatternPos,gConstructorNr,lConstructorNr,gParams));
         end;
      InfixOperatorSymbol:
         begin
            if StillCorrect then
               lFormatNr:=gFormatsColl.CollectFuncForm(gConstructorNr,gLeftLociNbr,gParamNbr);
            gPattern:=new(InfixFunctorPatternPtr,Init(gPatternPos,gLeftLoci,gConstructorNr,gParams));
         end;
   othercases
      gPattern:=new(InfixFunctorPatternPtr,Init(gPatternPos,gLeftLoci,gConstructorNr,gParams));
   endcases;
end;

@ The Parser's \\{ReadVisible} procedure begins by invoking
this \\{StartVisible} method. The \\{ReadVisible} procedure occurs
when getting most patterns.

@<Extended item implementation@>=
procedure @? extItemObj.StartVisible;
begin
   gParams:=new(PList,Init(0));
end;

@ The Parser iteratively calls its \\{GetVisible} (\section\xref{GetVisible:parser.pas}) procedure
when \\{ReadVisible} arguments in a pattern. The \\{GetVisible}
procedure in turn invokes this \\{ProcessVisible}, which increments
the number of parameters, and pushes a new \\{Locus} object onto
the \\{gParams} stack.

\label{extItemObj.ProcessVisible}

@<Extended item implementation@>=
procedure @? extItemObj.ProcessVisible;
begin
   inc(gParamNbr);
   if gParams<>nil then
      gParams^.Insert(new(LocusPtr,Init(CurPos,GetIdentifier)));
end;

@ Recall a structure definition, when it has ancestors, looks like
$$\hbox{\texttt{struct (}} \<Ancestors> \hbox{\texttt{) }} \<Structure-Symbol>\cdots$$
The \<Ancestors> field is considered the ``prefix'' to the structure
definition. The Parser parses a type (thereby populating
the \\{gLastType} global variable), then invokes the \\{FinishPrefix}
method, then iterates if it encounters a comma.

The \\{FinishPrefix} method pushes the \\{gLastType} global variable
to the \\{gStructPrefixes} state variable.

@<Extended item implementation@>=
procedure @? extItemObj.FinishPrefix;
begin
   gStructPrefixes.Insert(gLastType);
end;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessStructureSymbol;
var lFormatNr: integer;
begin
   gConstructorNr:=0;
   gPatternPos:=CurPos;
   if CurWord.Kind = StructureSymbol then gConstructorNr:=CurWord.Nr;
   lFormatNr:=gFormatsColl.CollectPrefixForm('J',gConstructorNr,1);
   gParamNbr:=0;
   gParams:=nil;
end;

@ When the Parser has just finished parsing the ancestors to a
structure, but has not parsed the visible arguments. Then the Parser
prepares for reading the visible arguments and then the fields by
invoking this method.
This initializes the \\{gStructFields} state variable as well as
the \\{gFieldsNbr} state variable.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gFieldsNbr:integer;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartFields;
var lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.CollectPrefixForm('L',gConstructorNr,gParamNbr);
   in_AggrPattern:=true;
   gStructFields:=new(PList,Init(0));
   gFieldsNbr:=0;
end;

@ The Parser has just encountered the end structure bracket
(``\texttt{\#)}'') token, so we want to add the format to
the \\{gFormatsColl} dictionary.

@<Extended item implementation@>=
procedure @? extItemObj.FinishFields;
var lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.CollectPrefixForm('G',gConstructorNr,gFieldsNbr);
end;

@ Recall that each field-segment looks like
$$\<Field-Segment> ::= \<Selector-Symbol>\ \LB\hbox{\texttt{","} } \<Selector-Symbol>\RB\ \<Specification>$$
Before parsing the field-segment, the \\{StartAggrPattSegment} is
invoked. 

@<Local variables for parser additions@>=
  @! gStructFieldsSegment: PList;
  @! gSgmPos: Position;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartAggrPattSegment;
begin
   gStructFieldsSegment:=new(Plist,Init(0));
   gSgmPos:=CurPos;
end;

@ For each selector-symbol the Parser encounters, it invokes
the \\{ProcessField}. 

@<Extended item implementation@>=
procedure @? extItemObj.ProcessField;
var lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.CollectPrefixForm('U',CurWord.Nr,1);
   gStructFieldsSegment^.Insert(new(FieldSymbolPtr,Init(CurPos,CurWord.Nr)));
   inc(gFieldsNbr);
end;

@ After each field has been parsed, the Parser invokes this method to
update the \\{gStructFields} will push a new field segment object onto it.

@<Extended item implementation@>=
procedure @? extItemObj.FinishAggrPattSegment;
begin
   gStructFields.Insert(new(FieldSegmentPtr,Init(gSgmPos,gStructFieldsSegment,gLastType)));
end;

@* [s] Processing remaining statements.
\node{Processing schemes.}
Most of these methods are used in parsing a scheme block
(\section\xref{SchemeBlock:parser.pas}). It will be useful to examine
that function to see where these methods are invoked.

When the Parser starts a new scheme,
several state variables need to be reset. The \\{gSchemeIdNr} is
populated by the \\{GetIdentifier} (\section\xref{GetIdentifier}) procedure,
the \\{gSchemeIdPos} is assigned the current position, and
the \\{gSchemeParams} should be allocated to an empty list.

@<Extended item implementation@>=
procedure @? extItemObj.ProcessSchemeName;
begin
   gSchemeIdNr:=GetIdentifier;
   gSchemeIdPos:=CurPos;
   gSchemeParams:=new(PList,Init(0));
end;

@ A scheme qualification segment looks like, for predicates:
$$\<Variable>\ \LB\ \hbox{ \texttt{","} } \<Variable>\ \RB\ \hbox{\texttt{"["}}
[\<Type-Expression-List>] \hbox{\texttt{"]"}}$$
And for functors:
$$\<Variable>\ \LB\ \hbox{ \texttt{","} } \<Variable>\ \RB\ \hbox{ \texttt{"("} } [\<Type-Expression-List>] \hbox{ \texttt{")"}}$$
When the comma-separated list of identifiers have all been read, but
before either ``\texttt{(}'' or ``\texttt{[}'' has been discerned, the
Parser invokes \\{StartSchemeQualification}.

This will assign the current word kind to \\{gSubItemKind}, and then
initialize the \\{gTypeList} to 4 items.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gTypeList: MList;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartSchemeQualification;
begin
   gSubItemKind:=CurWord.Kind;
   gTypeList.Init(4);
end;

@ After the type-list has been parsed, but before the closing
parentheses or bracket has been encountered, the Parser invokes
the \\{FinishSchemeQualification} method. This assigns the current
position to the \\{gSubItemPos}.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gSubItemPos: Position;

@ @<Extended item implementation@>=
procedure @? extItemObj.FinishSchemeQualification;
begin
   gSubItemPos:=CurPos
end;

@ Starting a scheme segment describes the situation where we
are \emph{just about} to start parsing the comma-separated list of
identifiers for the scheme parameters. This just assigns the current
position to the \\{gSubItemPos}, then initializes \\{gSchVarIds} to 2 spots.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gSchVarIds: MList;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartSchemeSegment;
begin
   gSubItemPos:=CurPos;
   gSchVarIds.Init(2);
end;

@ After parsing the identifier for an entry in the comma-separated
list of scheme variables, the Parser invokes \\{ProcessSchemeVariable}
to add the recently parsed identifier to the \\{gSchVarIds} state
variable. 

@<Extended item implementation@>=
procedure @? extItemObj.ProcessSchemeVariable;
begin
   gSchVarIds.Insert(new(VariablePtr,Init(CurPos,GetIdentifier)));
end;

@ Once the list of scheme variables and their type specification has
been parsed, then the Parser invokes the \\{FinishSchemeSegment} method.
This just turns the \\{gSchVarIds} list into a Predicate segment or a
Functor segment, using the type list the Parser just finished parsing.

@<Extended item implementation@>=
procedure @? extItemObj.FinishSchemeSegment;
begin
   case gSubItemKind of
      sy_LeftParanthesis:
         begin
            gSchemeParams.Insert(new(FunctorSegmentPtr,Init(gSubItemPos,
                                                            new(PList,MoveList(gSchVarIds)),
                                                            new(PList,MoveList(gTypeList)),gLastType)));
         end;
      sy_LeftSquareBracket:
         begin
            gSchemeParams.Insert(new(SchemeSegmentPtr,Init(gSubItemPos,PredicateSegment,
                                                           new(PList,MoveList(gSchVarIds)),
                                                           new(PList,MoveList(gTypeList)))));
         end;
   endcases;
end;

@ The ``scheme thesis'' is the formula statement of the
scheme. Informally, a scheme looks like:
$$ \hbox{\texttt{scheme} }\LB\<Scheme-Parameters>\RB\ \<Scheme-thesis>\ \hbox{\texttt{"provided"}}\ \<Scheme-premises>$$
This means the \\{gLastFormula} state variable contains the scheme's
thesis. But the Parser has not yet started the list of premises. This
is when the Parser invokes the \\{FinishSchemeThesis} method, which
assigns the \\{gLastFormula} to \\{gSchemeConclusion}, then allocates
a new empty list for the \\{gSchemePremises}.

@<Extended item implementation@>=
procedure @? extItemObj.FinishSchemeThesis;
begin
   gSchemeConclusion:=gLastFormula;
   gSchemePremises:=new(Plist,Init(0));
end;

@ The premises for a scheme consists of finitely many formulas
separated by ``\texttt{and}'' keywords. The Parser enters into a loop
invoking this method \emph{after} parsing the formula
but \emph{before} checking the next word is ``\texttt{and}'' 
(and iterating loop). We just need to push the formula onto
the \\{gSchemePremises} list.

@<Extended item implementation@>=
procedure @? extItemObj.FinishSchemePremise;
begin
   gSchemePremises^.Insert(new(PropositionPtr,
                               Init(nLabel,
                                    gLastFormula,nPropPos)));
end;

@ \node{Reserved variables.} These methods are invoked only when the
Parser parses a reservation (\section\xref{Reservation:parser.pas}). A
``reservation segment'' refers to the comma-separated list of
variables and the type.

Starting a reservation segment allocates a new (empty) list
for \\{gResIdents}, and assigns the \\{gResPos} to the current
position. Each variable encountered in the comma-separated list of
variables is appended to the \\{gResIdents} list using
the \\{ProcessReservedIdentifier} method.

Mizar treats each reservation segment as a separate statement. So
there is no difference between:
\smallbreak
{\advance\leftskip3pc\obeylines\parindent=0pt\tt
reserve G for Group, x,y,z for Element of G;
\par}
\smallbreak\noindent%
\dots and\dots
\smallbreak
{\advance\leftskip3pc\obeylines\parindent=0pt\tt
reserve G for Group;

reserve x,y,z for Element of G;
\par}
\smallbreak\noindent%
Finishing a reservation mutates both the \\{gLastWSItem}
and \\{gLastWSBlock} global variables. Specifically, we allocate a new
reservation \\{Item}, then update \\{gLastWSItem} to point to it. The
caller's \\{nLastWSItem} is updated to point to it, too. We assign the
content of this newly allocated reservation \\{Item} based on
the \\{gResIdents} list. We insert this \\{Item} to the end of
the \\{gLastWSBlock}'s items.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
   @!gResIdents: PList;
   @!gResPos: Position;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartReservationSegment;
begin
   gResIdents:=new(Plist,Init(0));
   gResPos:=CurPos;
end; @#

procedure @? extItemObj.ProcessReservedIdentifier;
begin
   gResIdents^.Insert(new(VariablePtr,Init(CurPos,GetIdentifier)));
end; @#

procedure @? extItemObj.FinishReservationSegment;
begin
   gLastWSItem:=gWsTextProper^.NewItem(itReservation,gResPos);
   nLastWSItem:=gLastWSItem;
   gLastWSItem^.nContent:=new(ReservationSegmentPtr,Init(gResIdents,gLastType));
   gLastWSItem^.nItemEndPos:=PrevPos;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
end;

@ Both ``\texttt{defpred}'' and ``\texttt{deffunc}''
invokes \\{StartPrivateDefiniendum} to initialize the \\{gTypeList},
store the identifier in the \\{gPrivateId}, and assign the current
position to the \\{gPrivateIdPos}. Further, |dol_Allowed| 
is toggled to \\{true} --- placeholder variables are going to be
allowed in the type declarations of the private functor or private
predicate (for example ``\texttt{defpred Foo[set, Element of \$1]}'').

@<Global variables introduced in \texttt{parseraddition.pas}@>=
   @!gPrivateId: Integer;
   @!gPrivateIdPos: Position;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartPrivateDefiniendum;
begin
   gPrivateId:=GetIdentifier;
   gPrivateIdPos:=CurPos;
   dol_Allowed:=true;
   gTypeList.Init(4);
end;

@ Reading a ``type list'' (for scheme parameters or for private
definitions) loops over reading a type, then pushing it onto
the \\{gTypeList}. The parser delegates that latter ``push work'' to
the \\{FinishLocusType} method.

@<Extended item implementation@>=
procedure @? extItemObj.FinishLocusType;
begin
   gTypeList.Insert(gLastType);
end;

@ The life-cycle of expressions is a little convoluted. The \\{Item}
will allocate a new \\{extExpression} object and assign it to
the \\{gExpPtr}. Later, almost always, the \\{gExpPtr} will invoke a
method to create a subexpression. This subexpression will be
populated, then the \\{gLastTerm} (or \\{gLastFormula}) will be
updated to point to this subexpression object. The expression object
will be freed.

\label{extItemObj.CreateExpression}
@<Extended item implementation@>=
procedure @? extItemObj.CreateExpression(fExpKind:ExpKind);
begin
   gExpPtr:=new(extExpressionPtr,Init(fExpKind));
end;

@ Recall the ``set'' statement is of the form
$$\hbox{\texttt{"set"} } \<Variable> \hbox{ \texttt{"="} } \<Term>\ \LB\ \hbox{\texttt{","} } \<Variable> \hbox{ \texttt{"="} } \<Term>\ \RB$$
The Parser parses this as a loop of assignments of terms to
identifiers. Before iterating, the Parser invokes
the \\{FinishPrivateConstant} method. This allocates a new item for
the constant definition, then assigns it to the \\{gLastWSItem} and to
the caller's \\{nLastWSItem} field. Then the content for the new item
is allocated to be a constant definition object using
the \\{VariablePtr} state variable and the \\{gLastTerm} state
variable. The \\{gLastBlock} global variable pushes the new constant
definition item to its contents.

@<Extended item implementation@>=
procedure @? extItemObj.FinishPrivateConstant;
begin
   gLastWSItem:=gWsTextProper^.NewItem(itConstantDefinition,nItemPos);
   nLastWSItem:=gLastWSItem;
   gLastWSItem^.nContent:=
      new(ConstantDefinitionPtr,
          Init(new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),gLastTerm));
   gLastWSItem^.nItemEndPos:=PrevPos;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
   nItemPos:=CurPos;
end;

@ When the Parser is about to start parsing an assignment
``\<Variable> \texttt{=} \<Term>'' in a ``\texttt{set}'' statement,
the Parser invokes this method. The caller assigns the \\{gPrivateId}
state variable to be the result of \\{GetIdentifier}, and
the \\{gPrivateIdPos} state variable to be the current position.

@<Extended item implementation@>=
procedure @? extItemObj.StartPrivateConstant;
begin
   gPrivateId:=GetIdentifier;
   gPrivateIdPos:=CurPos;
end;

@ For a ``\texttt{defpred}'' and a ``\texttt{deffunc}'', before
parsing the definiens, we need to set the |dol_Allowed| global
variable to true (to allow placeholder variables).

@<Extended item implementation@>=
procedure @? extItemObj.StartPrivateDefiniens;
begin
   dol_Allowed:=true;
end;

@ After parsing the definiendum term for a ``\texttt{deffunc}'', the
Parser invokes this \\{FinishPrivateFuncDefinienition} method. This
assigns the contents of the caller to a \WSM/ private functor
definition syntax tree.

@<Extended item implementation@>=
procedure @? extItemObj.FinishPrivateFuncDefinienition;
begin
   nLastWSItem^.nContent:=
      new(PrivateFunctorDefinitionPtr,
          Init(new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),
               new(PList,MoveList(gTypeList)),gLastTerm));
end;

@ When finishing the definiendum formula for a ``\texttt{defpred}'',
the Parser invokes this \\{FinishPrivatePredDefinienition} method.

@<Extended item implementation@>=
procedure @? extItemObj.FinishPrivatePredDefinienition;
begin
   nLastWSItem^.nContent:=
      new(PrivatePredicateDefinitionPtr,
          Init(new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),
               new(PList,MoveList(gTypeList)),gLastFormula));
end;

@ \node{Reconsider statements.}

@<Extended item implementation@>=
procedure @? extItemObj.ProcessReconsideredVariable;
begin
   gPrivateId:=GetIdentifier;
   gPrivateIdPos:=CurPos;
end; @#

procedure @? extItemObj.FinishReconsideredTerm;
begin
   gReconsiderList^.Insert(new(TypeChangePtr,
                               Init(Equating,new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),gLastTerm)));
end;

@ This is invoked when parsing a private item which is a
``\texttt{reconsider}'' statement.

@<Extended item implementation@>=
procedure @? extItemObj.FinishDefaultTerm;
begin
   gReconsiderList^.Insert(new(TypeChangePtr,Init(VariableIdentifier,
                                                  new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),nil)));
end;

@ When the Parser finishes parsing a formula in
``\texttt{consider} \<Segment> \texttt{such that} \<Formula> $\LB$\texttt{and} \<Formula>$\RB$'',
the Parser invokes the \\{FinishCondition} method. This checks
that \\{gPremises} has been allocated, then pushes a new labeled
formula into it.

@<Extended item implementation@>=
procedure @? extItemObj.FinishCondition;
begin
   if gPremises = nil then
      gPremises:=new(PList,Init(0));
   gPremises^.Insert(new(PropositionPtr,
                         Init(nLabel,
                              gLastFormula,nPropPos)));
end;

@ In statements of the form
$$\texttt{assume\ } \<Formula>\texttt{;}$$
Or of the form
$$\texttt{assume\ } \<Formula> \texttt{\ and\ } \<Formula> \texttt{\ and\ } \dots \texttt{\ and\ } \<Formula>\texttt{;}$$
After each formula parsed, the Parser invokes
the \\{FinishHypothesis}. This just inserts a new labeled formula into
the \\{gPremises} state variable, when the \\{gPremises} state
variable is not |nil|.

\label{extItemObj.FinishHypothesis}

@<Extended item implementation@>=
procedure @? extItemObj.FinishHypothesis;
begin
   if gPremises <> nil then
      gPremises^.Insert(new(PropositionPtr,
                            Init(nLabel,
                                 gLastFormula,nPropPos)));
end;

@ \node{``Take'' statements.} For statements of the form
$$\texttt{take\ }\<Variable>\texttt{\ =\ }\<Term>\texttt{;}$$
The Parser invokes the \\{ProcessExemplifyingVariable} method, then
parses the term, and then constructs the AST by invoking \\{FinishExemplifyingVariable}.

Finishing a ``\texttt{take}'' statement
mutates both the \\{gLastWSItem} and the \\{gLastWSBlock} global variables.

@<Extended item implementation@>=
procedure @? extItemObj.ProcessExemplifyingVariable;
begin
   gPrivateId:=GetIdentifier;
   gPrivateIdPos:=CurPos;
end; @#

procedure @? extItemObj.FinishExemplifyingVariable;
begin
   gLastWSItem:=gWsTextProper^.NewItem(itExemplification,nItemPos);
   nLastWSItem:=gLastWSItem;
   gLastWSItem^.nContent:=new(ExamplePtr,Init(new(VariablePtr,
                                                  Init(gPrivateIdPos,gPrivateId)),gLastTerm));
   gLastWSItem^.nItemEndPos:=PrevPos;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
   nItemPos:=CurPos;
end;

@ In statements of the form
$$\texttt{take\ }\<Term>\texttt{;}$$
the Parser begins by invoking \\{StartExemplifyingTerm}, parses the
term, then \\{FinishExemplifyingTerm}.

@<Extended item implementation@>=
procedure @? extItemObj.StartExemplifyingTerm;
begin
   if (CurWord.Kind=Identifier) and extBlockPtr(gBlockPtr)^.nInDiffuse and
         ((AheadWord.Kind=sy_Comma) or (AheadWord.Kind=sy_Semicolon)) then
   begin
      gPrivateId:=GetIdentifier;
      gPrivateIdPos:=CurPos;
   end
   else gPrivateId:=0;
end; @#

procedure @? extItemObj.FinishExemplifyingTerm;
begin
   gLastWSItem:=gWsTextProper^.NewItem(itExemplification,nItemPos);
   nLastWSItem:=gLastWSItem;
   if gPrivateId <> 0 then
      gLastWSItem^.nContent:=
         new(ExamplePtr,Init(new(VariablePtr,Init(gPrivateIdPos,gPrivateId)),nil))
   else
      gLastWSItem^.nContent:=new(ExamplePtr,Init(nil,gLastTerm));
   gLastWSItem^.nItemEndPos:=PrevPos;
   gLastWSBlock^.nItems.Insert(gLastWSItem);
   nItemPos:=CurPos;
end;

@ When the Parser examines the correctness conditions
(\section\xref{Correctness:parser.pas}), it loops over the correctness
conditions and justifications. Afterwards, it invokes
the \\{ProcessCorrectness} method, which tests that the Parser is not
current looking at a correctness keyword. Then it tests if
|gCorrectnessConditions| is empty or |AxiomsAllowed| (in which case,
correctness has been satisfies, so the Parser moves happily
along). But if $\\{gCorrectnessConditions}\neq\emptyset$ or axioms are
not allowed, then a 73 error is raised.

@:Error, 073}{Error, 73@>

\label{extItemObj.ProcessCorrectness}

@<Extended item implementation@>=
procedure @? extItemObj.ProcessCorrectness;
begin
   if CurWord.Kind <> sy_Correctness then
      if (gCorrectnessConditions <> []) and not AxiomsAllowed then
         Error(gDefPos,73);
end;

@ A ``construction type'' appears in a redefinition where the type is
redefined. In such a situation, we need to add ``\texttt{coherence}''
as a correctness condition. The \\{StartConstructionType} handles this
task. 

\label{extItemObj.StartConstructionType}

@<Extended item implementation@>=
procedure @? extItemObj.StartConstructionType;
begin
   if gRedefinitions and (CurWord.Kind = sy_Arrow) then
      include(gCorrectnessConditions,syCoherence);
end;

@ This is used in the Parser's \\{ProcessLab} procedure. Really, all
the work is being done here: the \\{nLabel} field of the caller is
assigned to a newly allocated \\{Label} object.

\label{extItemObj.ProcessLabel}

@<Extended item implementation@>=
procedure @? extItemObj.ProcessLabel;
begin
   nLabelIdNr:=0;
   nLabelIdPos:=CurPos;
   if (CurWord.Kind=Identifier) and (AheadWord.Kind=sy_Colon) then
      nLabelIdNr:=CurWord.Nr;
   nLabel:=new(LabelPtr,Init(nLabelIdNr,nLabelIdPos));
end;

@ A regular statement is either a ``diffuse'' statement (which occurs
with the ``\texttt{now}'' keyword) or else it's a ``compact'' statement.

@<Extended item implementation@>=
procedure @? extItemObj.StartRegularStatement;
begin
   if CurWord.Kind=sy_Now then
      nRegularStatementKind:=stDiffuseStatement
   else nRegularStatementKind:=stCompactStatement;
end;

@ If the Parser encounters a colon after the copula, then it invokes
this method to construct a label for the Definiens.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
   @!gDefLabel: LabelPtr;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessDefiniensLabel;
begin
   gDefLabId:= 0;
   gDefLabPos:=CurPos;
   if (CurWord.Kind=Identifier) and (AheadWord.Kind=sy_Colon) then
      gDefLabId:= CurWord.Nr;
   gDefLabel:= new(LabelPtr,Init(gDefLabId,gDefLabPos));
end;

@ The Parser, having encountered ``\texttt{from}'' and a non-MML
reference, tries to treat the identifier as the label for a scheme
declared in the current article. The \\{nInference} field would be
a \\{SchemeJustification} object, so we just populate
its \\{nSchemeIdNr} and position fields.

@<Extended item implementation@>=
procedure @? extItemObj.ProcessSchemeReference;
begin
   if CurWord.Kind = Identifier then
   begin
      SchemeJustificationPtr(nInference)^.nSchemeIdNr:=CurWord.Nr;
      SchemeJustificationPtr(nInference)^.nSchemeInfPos:=CurPos;
   end;
end;

@ When a ``\texttt{by}'' refers to a theorem or definition from an
article in the MML, the Parser invokes the \\{StartLibraryReference} method.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gTHEFileNr:integer;

@ @<Extended item implementation@>=
procedure @? extItemObj.StartLibraryReferences;
begin
   gTHEFileNr:=CurWord.Nr;
end;

@ The Parser has already encountered a ``\texttt{from}'' and then an
MML article identifier. Before continuing to parse the scheme number,
the Parser invokes this method to initialize the relevant state variables.

@<Extended item implementation@>=
procedure @? extItemObj.StartSchemeLibraryReference;
begin
   gTHEFileNr:=CurWord.Nr;
end;

@ For references to labels found in the article being processed
(``private references''), this method is invoked.

@<Extended item implementation@>=
procedure @? extItemObj.ProcessPrivateReference;
begin
   SimpleJustificationPtr(nInference)^.nReferences^.Insert(new(LocalReferencePtr,
                                                               Init(GetIdentifier,CurPos)));
end;

@ When using a definition from an MML article in a scheme reference
(something like\hfill\break
``\texttt{from MyScheme(ARTICLE:def 5,\dots)}''), well, the Parser
stores this fact in a state
variable \\{gDefinitional}. The \\{ProcessDef} method populates this
state variable correctly.

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gDefinitional: boolean;

@ @<Extended item implementation@>=
procedure @? extItemObj.ProcessDef;
begin
   gDefinitional:=(CurWord.Kind = ReferenceSort) and (CurWord.Nr = ord(syDef))
end;

@ When accumulating the references in a Scheme-Justification, and a
reference is from an MML article, \\{ProcessTheoremNumber} transforms
it into a newly allocated reference object. The
caller's \\{nInference} then adds the newly allocated object to
its \\{nReferences} collection. 

@^Error, 146@>

@<Extended item implementation@>=
procedure @? extItemObj.ProcessTheoremNumber;
var lRefPtr: ReferencePtr;
begin
   if CurWord.Kind <> Numeral then exit;
   if CurWord.Nr = 0 then
   begin
      ErrImm(146);
      exit
   end;
   if gDefinitional then
      lRefPtr:=new(DefinitionReferencePtr, Init(gTHEFileNr,CurWord.Nr,CurPos))
   else
      lRefPtr:=new(TheoremReferencePtr, Init(gTHEFileNr,CurWord.Nr,CurPos));
   SimpleJustificationPtr(nInference)^.nReferences^.Insert(lRefPtr);
end;

@ When a Scheme-Justification uses a local reference, the Parser
delegates the work to the \\{Item}'s \\{ProcessSchemeNumber} method. This updates
the caller's \\{nInference} field.

@^Error, 146@>

@<Extended item implementation@>=
procedure @? extItemObj.ProcessSchemeNumber;
begin
   if CurWord.Kind <> Numeral then exit;
   if CurWord.Nr = 0 then
   begin
      ErrImm(146);
      exit
   end;
   with SchemeJustificationPtr(nInference)^ do
   begin
      nSchFileNr:=gTHEFileNr;
      nSchemeIdNr:=CurWord.Nr;
      nSchemeInfPos:=PrevPos;
   end;
end;

@ This appears when the Parser starts its \\{Justification}
(\section\xref{Justification:parser.pas}) procedure, or in the
\\{RegularStatement}
(\section\xref{RegularStatement:parser.pas}) procedure.

This clears the \\{nInference}, reassigning it to the |nil| pointer.

For nested ``\texttt{proof}'' blocks, check if the `check proofs'
(``\texttt{::\$P+}'') pragma has been enabled --- if so, just set the
caller's \\{nInference} to be a new Justification object with a
`proof' tag. Otherwise, we're skipping the proofs, so
set \\{nInference} to be the `skipped' justification.

@<Extended item implementation@>=
procedure @? extItemObj.StartJustification;
begin
   nInference:=nil;
   if CurWord.Kind = sy_Proof then
   begin
      if ProofPragma then
         nInference:=new(JustificationPtr,Init(infProof,CurPos))
      else
         nInference:=new(JustificationPtr,Init(infSkippedProof,CurPos))
   end;
end;

@ A simple justification is either a Scheme-Justification
(``\texttt{from}\dots''), a Straightforward-Justification
(``\texttt{by}\dots''), or\dots somethign else?

@<Extended item implementation@>=
procedure @? extItemObj.@!StartSimpleJustification;
begin
   case CurWord.Kind of
      sy_From:
         nInference:=new(SchemeJustificationPtr,Init(CurPos,0,0));
      sy_By:
         with extBlockPtr(gBlockPtr)^ do
         nInference:=new(StraightforwardJustificationPtr,Init(CurPos,nLinked,nLinkPos));
   othercases
      with extBlockPtr(gBlockPtr)^ do
         nInference:=new(StraightforwardJustificationPtr,Init(PrevPos,nLinked,nLinkPos));
   endcases;
end;

@ We should update the \\{nInference} field's sort to be \\{infError}
when, well, the inference is an error (e.g., the Parser is in panic
mode). We should set the \\{gBlockPtr}'s \\{nLinked} field to false
when we just added a straightforward justification (or an erroneous
justification). 

@d is_inference_error == not StillCorrect or@|
       ((CurWord.Kind <> sy_Semicolon) and (CurWord.Kind <> sy_DotEquals)) or@|
       ((nInference^.nInfSort = infStraightforwardJustification) and (byte(nLinked) > byte(nLinkAllowed))) or@|
       ((nInference^.nInfSort = infSchemeJustification) and (SchemeJustificationPtr(nInference)^.nSchemeIdNr = 0))

@<Extended item implementation@>=
procedure @? extItemObj.@!FinishSimpleJustification;
begin
   with extBlockPtr(gBlockPtr)^ do
   begin
      if is_inference_error
      then nInference^.nInfSort:=infError;
   end;
   if (nInference^.nInfSort = infStraightforwardJustification) or (nInference^.nInfSort = infError)
   then extBlockPtr(gBlockPtr)^.nLinked:=false;
end;

@ For iterative equalities, we should recall that it looks like
\smallbreak
{\advance\leftskip5pc\tt\obeylines\parindent=0pt
LHS = RHS \<Justification>

\ \ \ .= RHS2

\ \ \ .= \dots;\par}

\smallbreak\noindent%
This matters because, well, when the Parser has parsed ``\texttt{LHS = RHS} \<Justification>'',
the Parser believes it is a compact statement. Until the Parser looks
at the next token, it does not know whether this is a
Compact-Statement or an iterated equality. The \\{FinishCompactMethod}
peeks at the token, and when the token is an iterated equality
(``\texttt{.=}'') updates the caller's fields as well as initialize
the \\{gIterativeLastFormula}, \\{gIterativeSteps}, and \\{gInference}
state variables. The \\{gBlockPtr} is updated to make its \\{nLinked}
field false.

@<Extended item implementation@>=
procedure @? extItemObj.@!FinishCompactStatement;
begin
   if CurWord.Kind = sy_DotEquals then
   begin
      gIterativeLastFormula:=gLastFormula;
      nRegularStatementKind:=stIterativeEquality;
      extBlockPtr(gBlockPtr)^.nLinked:=false;
      gIterativeSteps:=new(PList,Init(0));
      gInference:=nInference;
   end;
end;

@ Every time the Parser encounters the ``\texttt{.=}'' token, it
immediately invokes the \\{StartIterativeStep} method. This just
updates the \\{gIterPos} state variable to the current position.

@<Local variables for parser additions@>=
  @! gIterPos: Position;

@ @<Extended item implementation@>=
procedure @? extItemObj.@!StartIterativeStep;
begin
   gIterPos:=CurPos; @+
end;

@ Right before the Parser iterates the loop checking if
``\texttt{.=}'' is the next token for an iterative equation, the
Parser invokes the \\{FinishIterativeStep} method. This just adds a
new \\{IterativeStep} object, an AST node representing the preceding
``\texttt{.= RHS by} \<Justification>''.

@<Extended item implementation@>=
procedure @? extItemObj.@!FinishIterativeStep;
begin
   gIterativeSteps^.Insert(new(IterativeStepPtr,Init(gIterPos,gLastTerm,nInference)));
end;

@ In a definition, after the Parser finishes parsing the definiens, we
construct the AST node for it with the \\{FinishDefiniens} method.

For each copula (``\texttt{means}'' and ``\texttt{equals}''), the
algorithm is the same: if we just had a definition-by-cases, then
store the ``\texttt{otherwise}'' clause in \\{lExp} and assign
the \\{gDefiniens} state variable to a newly allocated conditional
definiens object. If the definiens is not a definition-by-cases (i.e.,
it's a ``simple'' definition), then just assign \\{gDefiniens} a newly
allocated \\{SimpleDefiniens} object.

For functor definitions (not redefinitions),
the \\{gCorrectnessConditions} are assigned here.

@^Correctness Conditions@>

@<Extended item implementation@>=
procedure @? extItemObj.@!FinishDefiniens;
var lExp: DefExpressionPtr;
begin
   case gDefiningWay of
      dfMeans:@|@/
         if gPartialDefs <> nil then
         begin
            lExp:=nil;
            if gOtherwise <> nil then
               lExp:=new(DefExpressionPtr,Init(exFormula,gOtherwise));
            gDefiniens:=new(ConditionalDefiniensPtr,Init(gMeansPos,gDefLabel,gPartialDefs,lExp))
         end
         else
            gDefiniens:=new(SimpleDefiniensPtr,Init(gMeansPos,gDefLabel,
                                                    new(DefExpressionPtr,Init(exFormula,gLastFormula))));
      dfEquals:@|@/
         if gPartialDefs <> nil then
         begin
            lExp:=nil;
            if gOtherwise <> nil then
               lExp:=new(DefExpressionPtr,Init(exTerm,gOtherwise));
            gDefiniens:=new(ConditionalDefiniensPtr,Init(gMeansPos,gDefLabel,gPartialDefs,lExp))
         end
         else
            gDefiniens:=new(SimpleDefiniensPtr,Init(gMeansPos,gDefLabel,new(DefExpressionPtr,Init(exTerm,gLastTerm))));
   endcases;
   if not gRedefinitions and (nItemKind = itDefFunc) then
   begin
      if gDefiningWay = dfMeans then
         gCorrectnessConditions:=[syExistence,syUniqueness]
      else if gDefiningWay = dfEquals then
         gCorrectnessConditions:=[syCoherence];
   end;
end;


@* [S] Extended subexpression class.
\node{Aside: refactoring.}
We should probably refactor a private procedure \\{PushTermStack} to
push a new term onto the term stack, and a private
function \\{PopTermStack} to return the top of the term stack (and
mutate the term stack), and possibly a \\{ResetTermStack} procedure
(which will clear the term stack and possibly the objects stored in it?).

We see that \\{TermNbr} is
decremented when popping the \\{Term} stack (via \\{FinishTerm});
when \\{FinishQualifyingFormula} is invoked, it decrements the \\{TermNbr};
when \\{FinishAttributiveFormula} is invoked, it decrements the \\{TermNbr};
but these latter two methods can (and should) be refactored to use
the \\{FinishTerm} to pop the term stack and decrement the \\{TermNbr}
state variable.

Assigning the \\{TermNbr} occurs
when \\{CreateArgs} method is invoked;
the \\{InsertIncorrBasic} method resets the \\{TermNbr} to the \\{nTermBase};
the \\{ProcessAtomicFormula}, when a 157 error is raised, will reset
the \\{TermNbr} to the \\{nTermBase};
when the constructor for an \\{extExpression} object is invoked, it
resets the \\{TermNbr} to zero (which happens in
the \\{extItem}'s \\{CreateExpression} method---which occurs
frequently enough to be a worry).

The only time when the \\{TermNbr} is incremented is when we push a
new term onto the \\{Term} stack.


@
There is a comment in Polish ``teraz jest to kolekcja
MultipleTypeExp'', which Google translates to ``now it is a
MultipleTypeExp collection''. I have made this replacement in the code
below, prefixed with a ``+'' sign (to distinguish it from the other
comment already in English).

Also note: the \\{nRestriction} refers to the subformula in a
universally quantified formula
$$\hbox{\texttt{for }}\<Variables>\hbox{ \texttt{st} }\<Restriction>\hbox{ \texttt{holds} }\dots$$

\label{extSubexprObj:class}

@d arg_type == record Start,Length: integer; end
@d func_type == record Instance,SymPri: integer; FuncPos: Position; end

@<Methods implemented by subclasses of |SubexpObj|@>=

@ @<Extended subexpression class declaration@>=
   @! extSubexpPtr = ^extSubexpObj; @/
   @! extSubexpObj = object(SubexpObj) @t\1@> @/
      @! nTermBase, @! nRightArgBase: integer;
      @! nSubexpPos,@! nNotPos,@! nRestrPos: Position;
      @! nQuaPos:Position;
      @! nSpelling: Integer;
      @! nSymbolNr, @!nRSymbolNr: integer;
      @! nConnective, @! nNextWord: TokenKind;
      @! nModeKind: TokenKind;
      @! nModeNr: integer;
      @! nRightSideOfPredPos: Position;
      @! nMultipredicateList:MList; @#
      
      @! nSample: TermPtr; {for Fraenkel terms}
      @! nAllPos: Position;
      @! nPostQualList: MList; {+ now it is a MultipleTypeExp collection}
      @! nQualifiedSegments: MList;
      @! nSegmentIdentColl: MList; {quantified variables, keeps spellings of vars}
      @! nSegmentPos: Position; @#

      @! nFirstSententialOperand: FormulaPtr;
      @! nRestriction: FormulaPtr; @#

      @! nAttrCollection: MList; @#

      @! nNoneOcc: boolean;
      @! nNonPos:Position;
      @! nPostNegated: boolean; @#

      @! nArgListNbr: integer; {position in a term (\section\xref{AppendFunc:parser.pas})}
      @! nArgList: array of arg_type;
      @! nFunc: array of func_type; @#

      constructor @? Init; @t\2@> @/

@t\4@> @<Methods implemented by subclasses of |SubexpObj|@>@t\2\2@>@;
   end;


@ The |TermNbr| is used to treat a list of terms as a stack data
structure. Specifically, the \\{Term} array is treated as a stack, and
the \\{TermNbr} is the index of the ``top'' of the stack.

@<Local variables for parser additions@>=
  @! TermNbr: integer;

@ @<Extended subexpression implementation@>=
{{\it Subexpressions handling}}

constructor @? extSubexpObj.Init;
const MaxArgListNbr = 20;
begin
   inherited Init;
   nRestriction:=nil;
   nTermBase:=TermNbr;
   nArgListNbr:=0;
   setlength(nArgList,MaxArgListNbr+1);
   setlength(nFunc,MaxArgListNbr+1);
   nArgList[0].Start:=TermNbr+1;
end;


@ When the Parser is about to parse a stack of attributes, either in a
registration or on a type, we need to initialize the appropriate state
variables. We also need the caller's \\{nAttrCollection} to be
initialized with an empty list.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartAttributes;
begin
   nAttrCollection.Init(0);
   gLastType:=nil;
end;

@ When the Parser expects an adjective, and the caller is used to
store the adjective or attribute, we need to check if it is
negated. This handles it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessNon;
begin
   nNoneOcc:=CurWord.Kind = sy_Non;
   nNonPos:=CurPos;
end;

@ \node{Pop arguments from term stack.} This will take some
parameter \\{aBase} and copy pointers to each element of |Term[aBase .. TermNbr]| into a new list. 
Then the \\{TermNbr} state variable is updated to be $\\{aBase}-1$.

This means that executing ``|list1 := CreateArgs(aBase); list2 := CreateArgs(aBase);|''
will have |list2 = nil|.

Bug: when |aBase <= 0|, this will set |TermNbr| to a negative number.

\label{CreateArgs}
@<Extended subexpression implementation@>=
function CreateArgs(aBase:integer): PList;
var k:integer;
lList: PList;
begin
   lList:=new(PList,Init(TermNbr-aBase));
   for k:=aBase to TermNbr do
      lList.Insert(Term[k]);
   TermNbr:=aBase-1;
   CreateArgs:=lList;
end;

@ The ``process (singular) attribute'' method is invoked in
the ``process (plural) attributes'' procedure (\section\xref{ProcessAttributes:parser.pas}), and in the \\{ATTSubexpression} procedure (\section\xref{ATTSubexpression}).
This method will be invoked when the Parser is looking at an attribute
token.

When there is no format recorded for such an attribute, then a 175
error will be raised.

This will allocate a new Adjective object, store it in
the \\{gLastAdjective} state variable, then append it to
the \\{nAttrCollection} field of the caller.

@^Error, 175@>

@<Global variables introduced in \texttt{parseraddition.pas}@>=
  @! gLastAdjective: AdjectiveExpressionPtr;

@ @<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessAttribute;
var lFormatNr:integer;
begin
   if CurWord.Kind = AttributeSymbol then
   begin
      lFormatNr:=gFormatsColl.LookUp_PrefixFormat('V',CurWord.Nr,TermNbr-nTermBase+1);
      if lFormatNr = 0 then {format not found!}
      begin
         gLastAdjective:=new(AdjectivePtr,Init(CurPos,0,CreateArgs(nTermBase+1)));
         Error(CurPos,175)
      end
      else
      begin
         gLastAdjective:=new(AdjectivePtr,Init(CurPos,CurWord.Nr,CreateArgs(nTermBase+1)));
         if nNoneOcc then
            gLastAdjective:=new(NegatedAdjectivePtr,Init(nNonPos,gLastAdjective));
      end;
   end
   else {needed for \\{ATTSubexpression} adjective cluster handling}
   begin
      gLastAdjective:=new(AdjectivePtr,Init(CurPos,0,CreateArgs(nTermBase+1)));
   end; @/
   nAttrCollection.Insert(gLastAdjective);
end;

@ These next next method is invoked before the Parser parses arguments
for an attribute.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartAttributeArguments;
begin
   nTermBase:=TermNbr;
end;

@ The next two methods are invoked after the Parser has finished
parsing the arguments for an attribute.

I am confused why there is
duplicate code here, and the naming conventions suggest
the \\{FinishAttributeArguments} method should be preferred.

\label{extSubexpObj.CompleteAttributeArguments}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.CompleteAttributeArguments;
begin
   nSubexpPos:=CurPos;
   nRightArgBase:=TermNbr;
end; @#

procedure @? extSubexpObj.FinishAttributeArguments;
begin
   nSubexpPos:=CurPos;
   nRightArgBase:=TermNbr;
end;

@ This allocates a new list of pointers, moves the
caller's \\{nAttrCollection} into the list, and updates the \\{gAttrColl}
state variable to point at them.

Again, this should be named \\{FinishedAdjectiveCluster} to be
consistent with the naming conventions seemingly adopted.

\label{extSubexpObj.CompleteAdjectiveCluster}
@<Extended subexpression implementation@>=
procedure @? extSubexpObj.CompleteAdjectiveCluster;
begin
   gAttrColl:=new(PList,MoveList(nAttrCollection));
end;

@ When the Parser works its way through a registration block, check
that the \\{TermNbr} points to not farther ahead than one more token 
ahead from the caller's \\{nTermBase} field. Raise an error if that
happens.

This method is only invoked in the Parser module's
the \\{RegisterCluster} (\section\xref{RegisterCluster:parser.pas}) procedure.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.CompleteClusterTerm;
begin
   if TermNbr-nTermBase > 1 then
   begin
      ErrImm(379);
      gLastTerm:=new(IncorrectTermPtr,Init(CurPos));
   end;
end;

@ A ``simple term'' appears to be a variable. This is used when the
Parser parses an identifier as a closed term
(\section\xref{GetClosedSubterm:identifier:parser.pas}). The state
variable |gLastTerm| is updated to point to a newly
allocated \\{SimpleTerm} AST node (\section\xref{ast:SimpleTerm}).

This method should probably be moved closer to the other methods
used when parsing terms.

\label{extSubexpObj.ProcessSimpleTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessSimpleTerm;
begin
   gLastTerm:=new(SimpleTermPtr,Init(CurPos,GetIdentifier));
end;

@ \node{Qualified terms.} The Parser invokes \\{ProcessQua} when it is
looking directly at a ``\texttt{qua}'' token, specifically in
the \\{AppendQua} (\section\xref{AppendQua})
procedure. The \\{ProcessQua} method is used nowhere else. It is
solely responsible for ``marking the current position'' of the Parser,
and storing that in the caller's \\{nQuaPos} field.

\label{extSubexpObj.ProcessQua}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessQua;
begin
   nQuaPos:=CurPos
end;

@ The Parser invokes the \\{FinishedQualifiedTerm} method after
encountering a ``\texttt{qua}'' and after parsing the type. This
method constructs a new \\{QualifiedTerm} object reflecting the top of
the \\{Term} stack is taken ``\texttt{qua}'' the \\{gLastType}, and
the mutates the top of the \\{Term} stack to be this newly
allocated \\{QualifiedTerm} object.

This method does not push anything new to
the term stack, but it does mutate the \\{Term} stack.

This method is used nowhere else other than the Parser's \\{AppendQua}
(\section\xref{AppendQua}) procedure.

\label{extSubexpObj.FinishQualifiedTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishQualifiedTerm;
begin
   Term[TermNbr]:=new(QualifiedTermPtr, Init(nQuaPos,Term[TermNbr],gLastType));
end;

@ Although the ``\texttt{exactly}'' reserved keyword is not used for
anything, the method for \\{ProcessExactly} marks the current position
and stores it in the caller's \\{nQuaPos}, then \emph{updates}
(\textbf{not} pushes) to the top of the term
stack by turning the top of the stack into an \\{ExactlyTerm} object.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessExactly;
begin
   nQuaPos:=CurPos;
   Term[TermNbr]:=new(ExactlyTermPtr, Init(nQuaPos,Term[TermNbr]));
end;

@ \node{Arguments to a term.} The \\{CheckTermLimit} procedure is a
``private helper function'' for the \\{FinishArgument} method.

@<Extended subexpression implementation@>=
procedure CheckTermLimit;
var l: integer;
begin
   if TermNbr >= length(Term) then
   begin
      l:=2*length(Term);
      setlength(Term,l);
   end;
end;

@ \node{Pushing the Term stack.}
This method pushes the \\{gLastTerm} state variable's contents to
the \\{Term} stack, mutating the \\{TermNbr} and \\{Term} module-local variables.

\label{extSubexpObj.FinishArgument}
@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishArgument;
begin
   CheckTermLimit;
   inc(TermNbr);
   Term[TermNbr]:=gLastTerm;
end;

@ \node{Pop the Term stack.} The evil twin to ``pushing'' an element
onto a stack, ``popping'' a stack removes the top element. We pop
the \\{Term} stack whenever we finish the term.

This is only used in \\{AppendFunc} (\section\xref{AppendFunc:parser.pas}).

This should probably check that the \\{Term} stack is not empty before
being invoked.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishTerm;
begin
   gLastTerm:=Term[TermNbr];
   dec(TermNbr);
end;

@* [s] Parsing Types.
When we start parsing a new type, we make sure the \\{gLastType}
state variable is not caching an old type. We assign it to be the |nil|
pointer. 

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartType;
begin
   gLastType:=nil;
end;

@ This is invoked only by the Parser's \\{RadixTypeSubexpression}
(\section\xref{RadixTypeSubexpression:parser.pas}) procedure. The
Parser delegates the work of storing the mode information to this
method. In turn, the caller's \\{nModeKind} field stores the current word's
token \\{Kind}, and the caller's \\{nModeNr} field stores the current
word's number. The Parser's current position is marked and stored in
the caller's \\{nSubexpPos} field.

But no state variables are mutated by this method.

\label{extSubexpObj.ProcessModeSymbol}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessModeSymbol;
begin
   nModeKind:=CurWord.Kind;
   nModeNr:=CurWord.Nr;
   if (CurWord.Kind = sy_Set) {?|and (AheadWord.Kind <> sy_Of)|?} then
      nModeKind:=ModeSymbol;
   nSubexpPos:=CurPos;
end;

@ The Parser has just finished parsing a type and its arguments ---
``\<Mode> \texttt{of} \<Term-list>'' or ``\<Structure> \texttt{over} \<Term-list>''.
The data has been accumulated into the caller, which will now be
constructed into an AST object. The newly allocated AST node will be
stored in the \\{gLastType} state variable.

If the caller is trying to construct a mode which does not match the
format recorded in the \\{gFormatsColl}, a 151 error will be raised.

Similarly, if the caller is trying to construct a structure which does
not match the format recorded in the \\{gFormatsColl}, a 185 error
will be raised.

@^Error, 151@>
@^Error, 185@>

This is invoked only by the Parser's \\{RadixTypeSubexpression}
(\section\xref{RadixTypeSubexpression:parser.pas}) procedure.
@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishType;
var lFormatNr: integer;
begin
   case nModeKind of
      ModeSymbol:
         begin
            lFormatNr:=gFormatsColl.LookUp_PrefixFormat('M',nModeNr,TermNbr-nTermBase);
            if lFormatNr=0 then Error(nSubexpPos,151); {format missing}
            gLastType:=new(StandardTypePtr,Init(nSubexpPos,nModeNr,CreateArgs(nTermBase+1)));
         end;
      StructureSymbol:
         begin
            lFormatNr:=gFormatsColl.LookUp_PrefixFormat('L',nModeNr,TermNbr-nTermBase);
            if lFormatNr = 0 then SemErr(185); {format missing}
            gLastType:=new(StructTypePtr,Init(nSubexpPos,nModeNr,CreateArgs(nTermBase+1)));
         end;
   othercases
   begin
      gLastType:=new(IncorrectTypePtr, Init(CurPos)); @+
   end;
   endcases;
end;

@ If the Parser has the misfortune of trying to make sense of a
malformed type expression, then with a heavy heart it invokes this
method to update the \\{gLastType} state variable to be an incorrect
type expression at the current position.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.InsertIncorrType;
begin
   gLastType:=new(IncorrectTypePtr, Init(CurPos));
end;

@ When the Parser encounters a qualifying formula
(``\<Term> \texttt{is} \<Type>'') or is parsing a type for a cluster
(the ``\texttt{cluster} \dots \texttt{for} \<Type>''), after parsing
the type, this method is invoked to \textbf{update} the \\{gLastType} state
variable to store the \\{ClusteredType} AST node (which decorates a
type --- the contents of \\{gLastType} at the time of calling --- with
a bunch of attributes).

The caller's \\{nAttrCollection} is transferred to the \\{gLastType}.
At the end of the method, the caller's \\{nAttrCollection} (array of
pointers) is freed. This does not free the objects referenced by the
pointers, however.

If |gLastType = nil|, then the Parser has somehow failed to parse the
type expression. An error should be raised.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.CompleteType;
var j: integer;
begin
   mizassert(5433,gLastType <> nil);
   if nAttrCollection.Count > 0 then
   begin
      gLastType:=new(ClusteredTypePtr,Init(gLastType^.nTypePos,
                                           new(PList,Init(nAttrCollection.Count)),gLastType));
      for j := 0 to nAttrCollection.Count-1 do
         ClusteredTypePtr(gLastType)^.nAdjectiveCluster^.Insert(PObject(nAttrCollection.Items^[j]));
      nAttrCollection.DeleteAll;
   end;
end;

@* [s] Parsing operator precedence.
Mario Carneiro's ``Mizar in Rust'' (\section6.2) gives an overview of
this parsing routine (see also his \texttt{mizar-rs/src/parser/miz.rs}
for the Rust version of the same code). It is a constrained
optimization problem. We shall take care to dissect this routine.
This appears to be where operator precedence, the \\{gPriority}
(\section\xref{gFormatsColl}) global variable, comes into play.


@ \node{Starting a ``long term''.}

We can observe that \\{nTermBase} is initialized upon construction to \\{TermNbr};
in \\{ProcessAtomicFormula} and \\{StartPrivateFormula} it is assigned to \\{TermNbr}.


\label{extSubexpObj.StartLongTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartLongTerm;
begin
   nArgListNbr:=0;
   nArgList[0].Length:=TermNbr-nTermBase;
end;

@ \node{Malformed term errors.}

We should remind the reader, errors 165--175 are ``unknown functor format'',
errors 176 is ``unknown attribute format'', and error 177 is ``unknown
structure format''. Only when such an error occurs, the flow experiences a
|goto AfterBalance|.

For an example of a 168, 169 error:
\medbreak
{\obeylines\tt
for x being Nat

holds (id + x +) = x;
\par}
\medbreak\noindent%
For an example of a 170, 171 error (the first \texttt{0} will be
flagged 170, the second \texttt{0} will be flagged as 171):
\medbreak
{\obeylines\tt
for x being Nat

holds 0 0 + x = x;

\par}
\medbreak\noindent%
For an example of a 172, 173 error:
\medbreak
{\obeylines\tt
for x being Nat

holds x + / = x;\par}

\medbreak\noindent%
For an example of a 174, 175 error:

\medbreak
{\obeylines\tt
for x being Nat

holds x + (1,2) + x = x;\par}

@ We can recall that a ``generic'' term looks like an infixed operator
of the form
$$ (t^{(\ell)}_{1},\dots,t^{(\ell)}_{m})\;t\;(t^{(r)}_{1},\dots,t^{(r)}_{n}) $$
The parentheses are optional. Constants will have $m=n=0$ and look
like $()\;t\;()$. Function-like terms will have $m=0$ and look like
$()\;t\;(t^{(r)}_{1},\dots,t^{(r)}_{n})$.
The problem statement could be re-phrased as: given several infixed
terms without parentheses inserted anywhere, determine how to cluster
terms together.

@ The problem statement for constructing the syntax tree for a term is
something like the following: we have an expression of the form
$$ x^{(0)}_{1},\dots,x^{(0)}_{k_{0}}\;F_{1}\; x^{(1)}_{1},\dots,x^{(1)}_{k_{1}}\;F_{2}\;\cdots \;F_{n}\; x^{(n)}_{1},\dots,x^{(n)}_{k_{n}}$$
We want to produce a suitable binary tree with $F_{i}$ on the internal
nodes and the $(x^{(i)}_{j})_{j\leq k_{i}}$ on the leafs, respecting
precedence such that each $F_{i}$ is applied to the correct number of arguments.

Mario Carneiro noted (\arXiv{2304.08391}, \section6.2) the existence of an $O(n^{4})$ algorithm using
dynamic programming techniques. The trick is to compute the minimal
``cost'' [number of violations] for each substring of nodes
$F_{a}\cdots F_{b}$ for each $1\leq a\leq i\leq b\leq n$ with node
$F_{i}$ being the root of the subtree. There are $O(n^{3})$ such
subproblems, and they can be calculated from smaller subproblems in $O(n)$.
This might seem alarmingly large, but usually the terms in Mizar are
sufficiently small.

It is interesting to see how other languages tackle this problem, so I
am going to give a haphazard literature review:
\enumerate
\item Nils Anders Danielsson and Ulf Norell's ``Parsing Mixfix Operators''
(in SB.\ Scholz and O.\ Chitil (eds.), \emph{Symposium on Implementation and Application of Functional Languages},
Springer 2008, pp.\ 80--99; \doi{10.1007/978-3-642-24452-0_5})
discuss how Agda approaches parsing mixfix operators with different precedence.
\item The Isabelle proof assistant uses a modified version of Earley
parsing of terms, supporting precedence between 0 to 1000.
\endenumerate

@ The only two place where \\{FinishLongTerm} is invoked is in
the \\{AppendFunc} procedure (\section\xref{AppendFunc:parser.pas})
in \texttt{parser.pas}.

This relies on |MFormatsList.LookUpFuncFormat| (\section\xref{MFormatsList.LookUp_FuncFormat}),
which attempts to look up an \\{MInfixFormatObj}
(\section\xref{MInfixFormatObj}) with a given id number as well as
number of left and right arguments.

We will need to populate |ArgsLength| and |To_Right| to determine the
syntax tree for the term (which is our real goal here). The
|ArgsLength| encodes the number of terms are to the left and right of
each ``internal node''. The |To_Right| controls associativity (which
is how Mizar handles operator precedence): if node $F_{k+1}$ is higher
precedence than node $F_{k}$, then |To_Right(k)| is true.

The |Exchange(i)| procedure will make node $i$ a child of $i-1$
(when node $i$ is a child of $i-1$), and vice-versa. 
Visually, this means we transform the tree as:
$$\bigl(\cdots F_{i-1}\;x_{1},\dots,x_{\ell}\bigr),x_{\ell+1},\dots,x_{n}\; F_{i}\cdots\longleftrightarrow\cdots F_{i-1}\;x_{1},\dots,x_{\ell-1},\bigl(x_{\ell},x_{\ell+1},\dots,x_{n}\; F_{i}\cdots\bigr)$$
Observe that ``|Exchange(i);Exchange(i)|'' is equivalent to doing nothing.

We should recall (\section\xref{extSubexprObj:class})
that \\{nArgList} is an array of ``|record Instance,SymPri: integer; FuncPos: Position; end|''.

\label{extSubexpObj.FinishLongTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishLongTerm;
var
   ArgsLength: array of record l,r: integer; end;
To_Right: array of boolean@t\1@>; 
procedure Exchange(i:integer);
var l: integer;
begin
   l:=ArgsLength[i].l;
   ArgsLength[i].l:=ArgsLength[i-1].r;
   ArgsLength[i-1].r:=l;
   To_Right[i-1]:=not To_Right[i-1];
end; @t\2@>
var
   Bl,new_Bl: integer; {indexes |nFunc|, |ArgsLength|}
   i,j,k: integer; {various indices}
   @<Variables for finishing a long term in a subexpression@>
label Corrected,AfterBalance;@t\2@>
begin
   @<Rebalance the long term tree@>@;
AfterBalance:
   @<Construct the term's syntax tree after balancing arguments among subterms@>
end;

@ \node{Rebalancing the term tree.}

Note that \\{nArgListNbr} is mutated only in \\{extSubexpObj.ProcessFunctorSymbol}
(\section\xref{extSubexpObj.ProcessFunctorSymbol}), and
in \\{ProcessAtomicFormula}
(\section\xref{extSubexpObj.ProcessAtomicFormula}) it is reset to zero.

@d missing_functor_format == gFormatsColl.LookUp_FuncFormat(Instance,l,r) = 0

@<Rebalance the long term tree@>=
   @<Initialize |To_Right| and |ArgsLength| arrays@>@;
   @<Initialize |Bl|, |goto AfterBalance| if term has at most one argument@>@; @/
   {|Bl = 1 or Bl = 2|}
   for k:=2 to nArgListNbr-1 do
      with nFunc[k], ArgsLength[k] do
   begin
      if missing_functor_format then
      @<Guess the $k^{th}$ functor format@>@;
      Corrected:
   end;
   for j:=nArgListNbr downto Bl+1 do
      with nFunc[j], ArgsLength[j] do
   begin
      if not missing_functor_format then goto AfterBalance;
      Exchange(j);
      @<Check for 172/173 error, |goto AfterBalance| if erred@>@;
   end;
   @<Check for 174/175 error, |goto AfterBalance| if erred@>@;

@ @<Check for 172/173 error, |goto AfterBalance| if erred@>=
      if missing_functor_format then
      begin
         Error(FuncPos,172);
         Error(nFunc[nArgListNbr].FuncPos,173);
         goto AfterBalance; @+
      end;

@ @<Check for 174/175 error, |goto AfterBalance| if erred@>=
   with nFunc[Bl], ArgsLength[Bl] do
      if missing_functor_format then
      begin
         Error(FuncPos,174);
         Error(nFunc[nArgListNbr].FuncPos,175);
         goto AfterBalance; @+
      end;

@ We first allocate the arrays, the we initialize the values.

@<Initialize |To_Right| and |ArgsLength| arrays@>=
   setlength(ArgsLength,nArgListNbr+1);
   setlength(To_Right,nArgListNbr+1);
   setlength(Depo,nArgListNbr+1); 

@ The
initial guess depends on whether $F_{k}$ has precedence over $F_{k+1}$
or not.

If $F_{k+1}$ has higher precedence than $F_{k}$, then the initial
guess groups terms as:
$$ \cdots F_{k} \;\;\bigl((x_{1}^{(k)},\dots,x^{(k)}_{m_{k}}) F_{k+1} (\cdots)\bigr)\cdots,\quad\hbox{and}\quad\\{To\_Right}[k]=\\{true}.$$
On the other hand, if $F_{k+1}$ \emph{does not} have higher precedence
than $F_{k}$, then we guess the terms are grouped as
$$ \cdots \bigl(\cdots F_{k} (x_{1}^{(k)},\dots,x^{(k)}_{m_{k}})\bigr)\;\; F_{k+1} \cdots,\quad\hbox{and}\quad\\{To\_Right}[k]=\\{false}.$$
This is a first stab, but sometimes we get lucky and it's correct.

@d next_term_has_higher_precedence(#) == @/
  gPriority.Value(ord('O'),nFunc[#].Instance) < gPriority.Value(ord('O'),nFunc[#+1].Instance)

@<Initialize |To_Right| and |ArgsLength| arrays@>=
   ArgsLength[1].l:=nArgList[0].Length;
   To_Right[0]:=true;
   for k:=1 to nArgListNbr-1 do
      with ArgsLength[k] do
         if next_term_has_higher_precedence(k) then
         begin
            r:=1;
            ArgsLength[k+1].l:=nArgList[k].Length;
            To_Right[k]:=true @+
         end
         else
         begin
            r:=nArgList[k].Length;
            ArgsLength[k+1].l:=1;
            To_Right[k]:=false @+
         end;
   ArgsLength[nArgListNbr].r:=nArgList[nArgListNbr].Length;
   To_Right[nArgListNbr]:=false;

@ The first situation we encounter is if the user tries to tell Mizar
to evaluate something like:

\medbreak
{\obeylines\tt
for x being Nat

holds x + (1,2) = x;
\par}
\medbreak\noindent%
Mizar will not understand ``{\tt x + (1,2)}'' because it is an invalid
functor format --- the format would look something like
$\langle\hbox{``\texttt{+}''}, {\rm left}: 1, {\rm right}: 1\rangle$ but
the format of the expression is $\langle {\rm left}: 1, {\rm right}: 2\rangle$.
The mismatch on the ``right'' values in the formats will raise a 165 error.

For a 166 error example,
\medbreak
{\obeylines\tt
for x being Nat

holds + / = x;
\par}
\medbreak\noindent%
Mizar will not like the leading ``{\tt + /}'' expression, and flag
this with the 166 error.

Mizar will flag ``{\tt + 0}'' as a 165 error.

@<Initialize |Bl|, |goto AfterBalance| if term has at most one argument@>=
   with nFunc[1], ArgsLength[1] do
   begin
      if nArgListNbr = 1 then
      begin
         if missing_functor_format then
         begin
            Error(FuncPos,165);
            goto AfterBalance @+
         end;
         goto AfterBalance;
      end;
      Bl:=1;
      if missing_functor_format then
      begin
         Exchange(2);
         Bl:=2;
         if missing_functor_format then
         begin
            Error(FuncPos,166);
            goto AfterBalance @+
         end;
      end;
   end;

@ @<Guess the $k^{th}$ functor format@>=
      begin
         Exchange(k+1);
         new_Bl:=Bl;
         if missing_functor_format then
         begin
            if Bl = k then
            begin
               Error(nFunc[k-1].FuncPos,168);
               Error(FuncPos,169);
               goto AfterBalance; @+
            end;
            Exchange(k+1);
            Exchange(k);
            new_Bl:=k;
            if missing_functor_format then
            begin
               Exchange(k+1);
               new_Bl:=k+1;
               if missing_functor_format then
               begin
                  Error(FuncPos,167);
                  goto AfterBalance @+
               end;
            end;
            for j:=k-1 downto Bl+1 do
               with nFunc[j], ArgsLength[j] do
            begin
               if not missing_functor_format then goto Corrected;
               Exchange(j);
               if missing_functor_format then
               begin
                  Error(FuncPos,168);
                  Error(nFunc[k].FuncPos,169);
                  goto AfterBalance; @+
               end;
            end;
            @<Check term |Bl| has valid functor format, |goto AfterBalance| if not@>@;
         end;
         Bl:=new_Bl;
      end;

@ @<Check term |Bl| has valid functor format, |goto AfterBalance| if not@>=
            with nFunc[Bl], ArgsLength[Bl] do
               if missing_functor_format then
               begin
                  Error(FuncPos,170);
                  Error(nFunc[k].FuncPos,171);
                  goto AfterBalance; @+
               end;

@ \node{Constructing the syntax tree.} The second half of finishing a
long term constructs the syntax tree for the term.

@<Variables for finishing a long term in a subexpression@>=
   ak,pl,ll,kn: integer;
   lTrm: TermPtr;
   lLeftArgs,lRightArgs: PList;
   DepoNbr: integer;
   Depo: array of record FuncInstNr:integer; dArgList:PList; end;

@ @<Construct the term's syntax tree after balancing arguments among subterms@>=
   @<Initialize symbol priorities, determine last |ll|, |pl| values@>@;
   DepoNbr:=0;
   for kn:=nArgListNbr downto 2 do
      if To_Right[kn-1] then {if |kn| node is parent of |kn-1| node}
      begin
         with nFunc[kn] do
         begin
            lRightArgs:=CreateArgs(nArgList[kn].Start); { (\section\xref{CreateArgs}) }
            lLeftArgs:=CreateArgs(nArgList[kn-1].Start);
            lTrm:=new(InfixTermPtr,Init(FuncPos,Instance,lLeftArgs,lRightArgs));
         end;
         for j:=DepoNbr downto 1 do
            with Depo[j], nFunc[FuncInstNr] do
         begin
            if symPri <= nFunc[kn-1].SymPri then break;
            dec(DepoNbr);
            lLeftArgs:=new(PList,Init(1));
            lLeftArgs^.Insert(lTrm);
            lTrm:=new(InfixTermPtr,Init(FuncPos,Instance,lLeftArgs,dArgList));
         end;
         gLastTerm:=lTrm; @/
         gSubexpPtr^.FinishArgument;
      end
      else
      begin
         inc(DepoNbr);
         with Depo[DepoNbr] do
         begin
            FuncInstNr:=kn;
            dArgList:=CreateArgs(nArgList[kn].Start); @+
         end;
      end;
   with nFunc[1] do
   begin
      lRightArgs:=CreateArgs(nArgList[1].Start);
      lLeftArgs:=CreateArgs(nArgList[0].Start);
      lTrm:=new(InfixTermPtr,Init(FuncPos,Instance,lLeftArgs,lRightArgs));
   end;
   for j:=DepoNbr downto 1 do
      with Depo[j], nFunc[FuncInstNr] do
   begin
      lLeftArgs:=new(PList,Init(1));
      lLeftArgs^.Insert(lTrm);
      lTrm:=new(InfixTermPtr,Init(FuncPos,Instance,lLeftArgs,dArgList));
   end;
   gLastTerm:=lTrm;

@ @<Initialize symbol priorities, determine last |ll|, |pl| values@>=
   for ak:=1 to nArgListNbr do
   begin
      ll:=1;
      pl:=1;
      if To_Right[ak-1] then ll:=nArgList[ak-1].Length;
      if not To_Right[ak] then pl:=nArgList[ak].Length;
      with nFunc[ak] do
      begin
         symPri:=gPriority.Value(ord('O'),Instance); @+
      end;
   end;

@* [s] Processing subexpressions.
Note that \\{ProcessFunctorSymbol} is the only place where
|nArgListNbr| is incremented. Processing functor symbols occurs in the
Parser's \\{AppendFunc} (\section\xref{AppendFunc:parser.pas}) in a loop.

\label{extSubexpObj.ProcessFunctorSymbol}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.@!ProcessFunctorSymbol;
var l: integer;
begin
   inc(nArgListNbr);
   if nArgListNbr >= length(nFunc) then
   begin
      l:=2*length(nFunc)+1;
      setlength(nArgList,l);
      setlength(nFunc,l);
   end;
   nArgList[nArgListNbr].Start:=TermNbr+1;
   nFunc[nArgListNbr].FuncPos:=CurPos;
   nFunc[nArgListNbr].Instance:=CurWord.Nr;
end;

@ The Parser is in the middle of \\{AppendFunc} and has just finished
parsing a term $t$ or a tuple of 
terms \hbox{\texttt{(} $t_{1}$, \dots, $t_{n}$ \texttt{)}}. Before the
Parser checks if it's looking at an infixed functor operator or not,
the Parser invokes the \\{FinishArgList} method. It's the only time
where the \\{FinishArgList} method is invoked.

This allocates either 1 or $n$ to the length of |nArgList[nArgListNbr]|,
to store the information for the term(s).

\label{extSubexpObj.FinishArgList}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishArgList;
begin
   nArgList[nArgListNbr].Length:=TermNbr-nArgList[nArgListNbr].Start+1;
end;

@ The Parser is looking at ``\texttt{where}'' or (when the variables
are all reserved) a colon ``\texttt{:}'', the Parser invokes
the \\{StartFraenkelTerm} which will store the previous term in
the \\{nSample} field --- so schematically, the Fraenkel term could
look like
$$\LB\<nSample>\hbox{ \texttt{where} }\<Postqualification> : \<Formula>\RB$$

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartFraenkelTerm;
begin
   nSample:=gLastTerm;
end;

@ This is only invoked in the Parser's \\{ProcessPostqualification}
(\section\xref{ProcessPostqualification}) procedure, which is only
invoked after the Parser calls the \\{extSubexp}
object's \\{StartFraenkelTerm} method.

\label{extSubexpObj.StartPostqualification}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartPostqualification;
begin
   nPostQualList.Init(0);
end;

@ The Parser is looking at the post-qualified segment of a Fraenkel
operator. This will be a list of variables ``\texttt{being}'' a type,
we allocate an array for the variables. This is handled by
the \\{StartPostQualifyingSegment} method.

\label{extSubexpObj.StartPostQualifyingSegment}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartPostQualifyingSegment;
begin
   nSegmentIdentColl.Init(2);
end;

@ While looping over the comma-separated list of variables in a
post-qualified segment (in a Fraenkel term), the Parser invokes
the \\{ProcessPostqualifiedVariable} on each iteration until it has
parsed all the variables. This allocates a new \\{Variable} object,
and pushes it onto the \\{nSegmentIdentColl} ``stack''.

\label{extSubexpObj.ProcessPostqualifiedVariable}
@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessPostqualifiedVariable;
begin
   nSegmentIdentColl.Insert(new(VariablePtr,Init(CurPos,GetIdentifier)));
end;

@ The Parser is looking at ``\texttt{is}'' or ``\texttt{are}'' in a
Fraenkel term's post-qualification segment, but has not yet parsed the
type. This method will assign the \\{nSegmentPos} field to be the
current position, and assign the \\{gLastType} state variable to be
the \&{nil} pointer.

\label{extSubexpObj.StartPostqualificationSpecyfication}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartPostqualificationSpecyfication;
begin
   nSegmentPos:=CurPos;
   gLastType:=nil;
end;

@ The Parser has just parsed either (1) a comma-separated list of variables, the
copula ``\texttt{is}'' or ``\texttt{are}'', and the type; or (2) a
comma-separated list of reserved variables (but no copula and no
type). We just need to construct an appropriate node for the abstract
syntax tree. This method will append a new Segment to the \\{nPostQualList}.

\label{extSubexpObj.FinishPostQualifyingSegment}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishPostQualifyingSegment;
var k: integer;
lSegment: ExplicitlyQualifiedSegmentPtr;
begin
   if gLastType <> nil then
   begin
      lSegment:=new(ExplicitlyQualifiedSegmentPtr,
                    Init(nSegmentPos,new(PList,Init(0)),gLastType));
      nPostQualList.Insert(lSegment);
      for k := 0 to nSegmentIdentColl.Count - 1 do
      begin
         ExplicitlyQualifiedSegmentPtr(lSegment)^.nIdentifiers.Insert(nSegmentIdentColl.Items^[k]);
      end;
   end
   else
   begin
      for k := 0 to nSegmentIdentColl.Count - 1 do
      begin
         nPostQualList.Insert(new(ImplicitlyQualifiedSegmentPtr,
                                  Init(VariablePtr(nSegmentIdentColl.Items^[k])^.nVarPos,
                                       nSegmentIdentColl.Items^[k])));
      end;
   end;
   nSegmentIdentColl.DeleteAll;
   nSegmentIdentColl.Done;
end;

@ The Parser has just finished the formula in a Fraenkel term, and it
is staring at the closet ``$\RB$'' bracket. The Parser invokes this
method to construct a new \\{FraenkelTerm} AST node, and updates
the \\{gLastTerm} to point at it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishFraenkelTerm;
begin
   gLastTerm:=new(FraenkelTermPtr,Init(CurPos,new(PList,MoveList(nPostQualList)),
                                       nSample,gLastFormula));
end;

@ The Parser has already encountered ``\texttt{the set}'' and the next
token is ``\texttt{of}'', which means the Parser has encountered a
``simple'' Fraenkel term of the form ``\texttt{the set of all} \<Term>\dots''.
This method will be invoked once the Parser has stumbled across the
``\texttt{all}''. The caller updates its \\{nAllPos} to the Parser's
current position.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartSimpleFraenkelTerm;
begin
   nAllPos:=CurPos;
end;

@ The Parser has just finished parsing the post-qualification to the
simple Fraenkel term, which means it has finished parsing the simple
Fraenkel term. This method allocates a new \\{SimpleFraenkelTerm} AST
node with the accumulated AST nodes, then updates the \\{gLastTerm} to
point to the allocated \\{SimpleFraenkelTerm} node.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishSimpleFraenkelTerm;
begin
   gLastTerm:=new(SimpleFraenkelTermPtr,Init(nAllPos,new(PList,MoveList(nPostQualList)),nSample));
end;

@ The Parser is looking at a closed term of the form ``\<Identifier> \texttt{(}\dots'',
and so it looks like a private functor. This method updates the
caller's \\{nSubexpPos} to the Parser's current position, and
the \\{nSpelling} is assigned to the identifier's number (for the
private functor).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartPrivateTerm;
begin
   nSubexpPos:=CurPos;
   nSpelling:=CurWord.Nr;
end;

@ The Parser just finished parsing all the arguments to the private
functor, and is looking at the closing parentheses for the private
functor. This method allocates a new \\{PrivateFunctorTerm} object,
using the arguments just parsed, and updates the \\{gLastTerm} state
variable to point to it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishPrivateTerm;
begin
   gLastTerm:=new(PrivateFunctorTermPtr,Init(nSubexpPos,nSpelling,CreateArgs(nTermBase+1)));
end;

@ The Parser has just encountered either a left bracket term or the
opening left bracket for a set ``$\LB$''. The Parser calls this
method, which just updates the caller's \\{nSymbolNr} to be whatever
the current token's numeric ID value is.

\label{extSubexpObj.StartBracketedTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartBracketedTerm;
begin
   nSymbolNr:=CurWord.Nr;
end;

@ If the Parser is in panic mode, this method does nothing.

Either the Parser has finished parsing an enumerated set
$\LB\,x_{1},\dots,x_{n}\,\RB$ or a bracketed term. We need to double
check the format for the bracket matches what is stored in
the \\{gFormatsColl}, and raise a 152 error if there's a
mismatch. Otherwise, allocate a new AST node for the bracketed term,
and use \\{CreateArgs} on the terms contained within the brackets.

\label{extSubexpObj.FinishBracketedTerm}

@^Error, 152@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishBracketedTerm;
var lFormatNr: integer;
begin
   if StillCorrect then
   begin
      nRSymbolNr:=CurWord.Nr;
      lFormatNr:=gFormatsColl.LookUp_BracketFormat(nSymbolNr,nRSymbolNr,TermNbr-nTermBase,0,0);
      if lFormatNr=0 then SemErr(152);
      gLastTerm:=new(CircumfixTermPtr, Init(CurPos,nSymbolNr,nRSymbolNr,CreateArgs(nTermBase+1)));
   end;
end;

@ Remember that Mizar calls ``an instance of structure''
an \define{Aggregate}. When the Parser is parsing for a closed subterm
and has stumbled across a structure constructor (\section\xref{ClosedSubter:structure:parser.pas}), it first invokes this
method. This stores the ID number for the structure in the
caller's \\{nSymbolNr}. 

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartAggregateTerm;
begin
   nSymbolNr:=CurWord.Nr;
end;

@ The Parser has just parsed the arguments for the structure
constructor, and the Parser is now looking at the ``\texttt{\#)}''
token. This method is invoked.

We should check the format for the structure constructor is stored in
the \\{gFormatsColl}. If not, raise a 176 error. Otherwise, we
allocate a new \\{AggregateTerm} with the parsed arguments, and then
update the \\{gLastTerm} pointer to point at it.

@^Error, 176@>

\label{extSubexpObj.FinishAggregateTerm}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishAggregateTerm;
var lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.LookUp_PrefixFormat('G',nSymbolNr,TermNbr-nTermBase);
   if lFormatNr = 0 then Error(CurPos,176); {missing format error}
   gLastTerm:=new(AggregateTermPtr, Init(CurPos,nSymbolNr,CreateArgs(nTermBase+1)));
end;

@ The Parser is parsing for a closed subterm, and has stumbled across
``\texttt{the}'' and is looking at a selector token
(\section\xref{GetClosedSubterm:the:parser.pas}). This method is
invoked. We assign the caller's \\{nSymbolNr} to the ID number for the
selector token, assign the caller's \\{nSubexpPos} to the Parser's
current position, and store the next token's kind (i.e., the
``\texttt{of}'' token's kind) in the \\{nNextWord}
field.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartSelectorTerm;
begin
   nSymbolNr:=CurWord.Nr;
   nSubexpPos:=CurPos;
   nNextWord:=AheadWord.Kind;
end;

@ The Parser has just parsed ``\texttt{the} \<Selector> \texttt{of} \<Term>''.
Now this method is invoked to assemble the parsed data into an AST
node.

If there is no selector with this matching format, then a 182 error
will be raised.

If the caller's \\{nNextWord} is an ``\texttt{of}'' token's kind, then
we're describing a selector term. We update the \\{gLastTerm} state
variable to point to a newly allocated \\{SelectorTerm} object with
the appropriate data set.

On the other hand, \define{internal selectors} occur when defining a
structure. For example,

\smallbreak
{\tt\obeyspaces\obeylines\parindent=0pt\advance\leftskip3pc
\noindent struct (1-sorted) multMagma \hbox{(\#}

\quad carrier -> set,

\quad multF -> BinOp of the carrier

\ \hbox{\#);}
\par}

\smallbreak\noindent%
Observe the \texttt{multF} specification is \texttt{BinOp of the carrier}.
That ``\texttt{the carrier}'' is an internal selector. In this case,
allocate a new \\{InternalSelectorTerm} object, and update
the \\{gLastTerm} state variable to point to it.

If, for some reason, the Parser is in neither situation, then
just \\{gLastTerm} state variable to be an incorrect term.

@^Error, 182@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishSelectorTerm;
var lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.LookUp_PrefixFormat('U',nSymbolNr,1);
   if lFormatNr = 0 then Error(nSubexpPos,182); {missing format error}
   if nNextWord = sy_Of then
      gLastTerm:=new(SelectorTermPtr, Init(nSubexpPos,nSymbolNr,gLastTerm))
   else
      if in_AggrPattern then
         gLastTerm:=new(InternalSelectorTermPtr, Init(nSubexpPos,nSymbolNr))
      else
      begin
         gLastTerm:=new(IncorrectTermPtr, Init(nSubexpPos));
         Error(nSubexpPos,329)
      end;
end;

@ The Parser is about to start parsing a forgetful functor
(\section\xref{GetClosedSubterm:forgetful-functor:parser.pas}) --- for
example ``\texttt{the multMagma of REAL.TopGroup}''. This
method is invoked. The caller's \\{nSymbolNr} field is updated to the
current token's ID Number, the \\{nSubexpPos} field is assigned the
Parser's current position, and the \\{nNextWord} field is assigned to
the token kind of the next token --- this is expected to be ``\texttt{of}''.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartForgetfulTerm;
begin
   nSymbolNr:=CurWord.Nr;
   nSubexpPos:=CurPos;
   nNextWord:=AheadWord.Kind;
end;

@ The Parser just finished parsing a forgetful functor. If the Parser
is not panicking, check the format for the forgetful functor matches
what is stored in the \\{gFormatsColl} state variable. If the format
is invalid, raise a 184 error.

Whether the Parser is panicking or not, allocate a
new \\{ForgetfulFunctor} term, and update the \\{gLastTerm} to point
to it.

@^Error, 184@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishForgetfulTerm;
var lFormatNr: integer;
begin
   lFormatNr:=0;
   if StillCorrect then
   begin
      lFormatNr:=gFormatsColl.LookUp_PrefixFormat('J',nSymbolNr,1);
      if lFormatNr = 0 then Error(nSubexpPos,184); {missing format}
   end;
   gLastTerm:= new(ForgetfulFunctorTermPtr, Init(nSubexpPos,nSymbolNr,gLastTerm));
end;

@ There are several situations where this is invoked:
\enumerate
\item The Parser has just parsed ``\texttt{the}'' but is not looking
  at a selector symbol (``\texttt{the multF of}\dots''), nor is the
  Parser looking at a forgetful functor (``\texttt{the multMagma of}\dots'').
  Then this is interpreted as looking at a choice operator
  (\section\xref{GetClosedSubterm:the:parser.pas}).
\item The Parser has just parsed ``\texttt{the}'' but is not looking
  at a forgetful functor, so the Parser believes it must be looking at
  a choice operator
  (\section\xref{GetClosedSubterm:forgetful-functor:parser.pas}). 
\item The Parser has just parsed ``\texttt{the}'' and is now looking
  at ``\texttt{set}'' --- so this is invoking the axiom of choice to
  pick ``\texttt{the set}'' (\section\xref{ParseSimpleFraenkelExprOrTheSet:parser.pas}).
\endenumerate
\smallbreak\noindent%
In these three situations, the Parser invokes this method. It just
updates the caller's \\{nSubexpPos} field to point to the Parser's
current position.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartChoiceTerm;
begin
   nSubexpPos:=CurPos;
end;

@ The Parser has just parsed a type, and now believes it has finished
parsing a choice expression. Then it invokes this method to construct
an appropriate AST node for the term, by specifically allocating a
new \\{ChoiceTerm} for the \\{gLastType} type. We then update
the \\{gLastTerm} state variable to point to this newly allocated term.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishChoiceTerm;
begin
   gLastTerm:=new(ChoiceTermPtr,Init(nSubexpPos,gLastType));
end;

@ When the Parser encounters a numeral while seeking a closed subterm
(\section\xref{GetClosedSubterm:parser.pas}), it invokes this method
to allocate a new \\{NumeralTerm}. The \\{gLastTerm} state variable is
updated to point to this newly allocated numeral object.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessNumeralTerm;
begin
   gLastTerm:=new(NumeralTermPtr, Init(CurPos,CurWord.Nr));
end;

@ The Parser tries to parse a closed subterm
(\section\xref{GetClosedSubterm:parser.pas}) and encounters the
``\texttt{it}'' token. Well, if the |it_Allowed| state variable is
true, then we should allocate a new \\{ItTerm} and update
the \\{gLastTerm} state variable to point to it.

Otherwise, when the |it_Allowed| state variable is false, we should
raise a 251 error.

@^Error, 251@>
@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessItTerm;
begin
   if it_Allowed then gLastTerm:=new(ItTermPtr, Init(CurPos))
   else
   begin
      gLastTerm:=new(IncorrectTermPtr, Init(CurPos));
      ErrImm(251)
   end;
end;

@ The Parser tries parsing for a closed subterm and has encountered a
placeholder term for a private functor (e.g., ``\texttt{\$1}''). If
the |dol_Allowed| state variable is true, then allocate a
new \\{PlaceholderTerm} object and update the \\{gLastTerm} state
variable to point at it.

If the |dol_Allowed| state variable is false, then we should raise a
181 error.

@^Error, 181@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessLocusTerm;
begin
   if dol_Allowed then
      gLastTerm:=new(PlaceholderTermPtr, Init(CurPos,CurWord.Nr))
   else
   begin
      gLastTerm:=new(IncorrectTermPtr, Init(CurPos));
      ErrImm(181)
   end;
end;

@ Calamity! An incorrect expression has crossed the Parser's
path. Allocate an \\{IncorrectTerm} object located at the Parser's
current position, then update the \\{gLastTerm} state variable to
point to it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.InsertIncorrTerm;
begin
   gLastTerm:=new(IncorrectTermPtr, Init(CurPos));
end;

@* [s] Parsing formulas.
The Parser is trying to parse an atomic formula
(\section\xref{CompleteAtomicFormula:parser.pas}), but something has
gone awry. Allocate a new \\{IncorrectFormula} object located at the
Parser's current position, update the \\{gLastFormula} state variable
to point to it, and ``reset'' the \\{TermNbr} state variable to point
to where the caller's \\{nTermBase} is located.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.InsertIncorrBasic;
begin
   gLastFormula:=new(IncorrectFormulaPtr,Init(CurPos));
   TermNbr:=nTermBase;
end;

@ While the Parser was trying to parse a formula, it found something
which ``doesn't quite fit''. Allocate a new \\{IncorrectFormula}
object, then update the \\{gLastFormula} state variable to point to it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.InsertIncorrFormula;
begin
   gLastFormula:=new(IncorrectFormulaPtr,Init(CurPos));
end;

@ If we are in a proof, allocate a new \\{ThesisFormula} object
(recall the \WEB/ macro for this \section\xref{thesis-formula:macro-def}).
Otherwise, raise a 65 error.

@:Error, 065}{Error, 65@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessThesis;
begin
   if gProofCnt > 0 then
      gLastFormula:=thesis_formula
   else
   begin
      ErrImm(65);
      gLastFormula:=new(IncorrectFormulaPtr,Init(CurPos));
   end;
end;

@ The Parser has encountered ``\<Term> \texttt{is}'', or some other
generic atomic formula
(\section\xref{CompleteAtomicFormula:parser.pas}), this method is invoked.

If more than one term appears before the ``\texttt{is}'' token (i.e.,
if |TermNbr - nTermBase <> 1|), then a 157 error is raised.
There is a Polish comment here, ``Trzeba chyba wstawic recovery dla |TermNbr = nTermBase|'',
which I translated to English.

This will initialize the fields for the caller in preparation for
parsing some atomic formula.
In particular, this is the only place where \\{TermNbr} is initialized
to a nonzero value (and isn't in an incorrect formula).

@^Error, 157@>

\label{extSubexpObj.ProcessAtomicFormula}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.@!ProcessAtomicFormula;
const MaxArgListNbr = 20;
begin
   nSubexpPos:=CurPos;
   nSymbolNr:=0;
   case CurWord.Kind of
      sy_Is:
         if TermNbr - nTermBase <> 1 then
         begin
            ErrImm(157);
            TermNbr:=nTermBase;
            InsertIncorrTerm;
            FinishArgument;
            { I think you need to insert recovery for |TermNbr = nTermBase| }
         end;
   endcases; @/
   nRightArgBase:=TermNbr;
   nTermBase:=TermNbr;
   nPostNegated:=false;
   nArgListNbr:=0;
   nArgList[0].Start:=TermNbr+1;
end;

@ The Parser is either finishing a ``predicative formula'' (\section\xref{CompletePredicativeFormula:parser.pas}) or it's parsing a predicate pattern (\section\xref{GetPredPattern:parser.pas}),
it invokes this method to initialize the fields needed when forming an
AST node. Specifically, the \\{nSubexpPos} is assigned to the Parser's
current position, the \\{nSymbolNr} is updated either to the current
token's ID number (if the current token is ``\texttt{=}'' or a
predicate) or else assigned to be zero. Last, the \\{nRightArgBase} is
assigned to equal the \\{TermNbr} state variable.

\label{extSubexpObj.ProcessPredicateSymbol}

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessPredicateSymbol;
begin
   nSubexpPos:=CurPos;
   case CurWord.Kind of
      sy_Equal,PredicateSymbol: nSymbolNr:=CurWord.Nr;
   othercases nSymbolNr:=0;
   endcases; @/
   nRightArgBase:=TermNbr;
end;

@ The Parser is parsing a ``predicate formula'' which has arguments on
the righthand side of the predicate symbol (\section\xref{CompleteRightSideOfThePredicativeFormula:parser.pas}).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessRightSideOfPredicateSymbol;
begin
   nRightSideOfPredPos:=CurPos;
   case CurWord.Kind of
      sy_Equal,PredicateSymbol: nSymbolNr:=CurWord.Nr;
   othercases nSymbolNr:=0;
   endcases; @/
   nRightArgBase:=TermNbr;
end;

@ The Parser has just finished a ``predicate formula''
(\section\xref{CompletePredicativeFormula:parser.pas}), then this
method is invoked to construct an AST for the formula. First we check
if the format is valid. If the format for the formula is not found in
the \\{gFormatsColl}, then we must raise a 153 error.
Otherwise, we construct two lists (one for the left arguments, another
for the right arguments), and use them to construct a
new \\{PredicativeFormula} object. We update the \\{gLastFormula}
state variable to point to the newly allocated formula object.

@^Error, 153@>

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishPredicativeFormula;
var lLeftArgs,lRightArgs: PList;
lFormatNr: integer;
begin
   lFormatNr:=gFormatsColl.LookUp_PredFormat(nSymbolNr,nRightArgBase-nTermBase,TermNbr-nRightArgBase);
   if lFormatNr = 0 then Error(nSubexpPos,153); {missing format}
   lRightArgs:=CreateArgs(nRightArgBase+1);
   lLeftArgs:=CreateArgs(nTermBase+1);
   gLastFormula:=new(PredicativeFormulaPtr,Init(nSubexpPos,nSymbolNr,lLeftArgs,lRightArgs));
end;

@ The Parser tries to construct an AST when finishing up the
right-hand side of a predicative formula
(\section\xref{CompleteRightSideOfThePredicativeFormula:parser.pas}),
it invokes this method after the \\{extSubexpObj.FinishPredicativeFormula}
has been invoked.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishRightSideOfPredicativeFormula;
var lRightArgs: PList;
lLeftArgsNbr,lFormatNr: integer;
lFrm:FormulaPtr;
begin
   lFrm:=gLastFormula;
   if lFrm^.nFormulaSort = wsNegatedFormula then
      lFrm:=NegativeFormulaPtr(lFrm)^.nArg;
   lLeftArgsNbr:=RightSideOfPredicativeFormulaPtr(lFrm)^.nRightArgs^.Count;
   lFormatNr:=gFormatsColl.LookUp_PredFormat(nSymbolNr,lLeftArgsNbr,TermNbr-nRightArgBase);
   if lFormatNr = 0 then Error(nSubexpPos,153); {missing format}
   lRightArgs:=CreateArgs(nRightArgBase+1);
   gLastFormula:=new(RightSideOfPredicativeFormulaPtr,Init(nSubexpPos,nSymbolNr,lRightArgs));
   nMultiPredicateList.Insert(gLastFormula);
end;

@ When the Parser is parsing an atomic formula, when it has parsed a
formula and encounters another predicate, it defaults to
thinking that it is starting a ``multi-predicative formula''
(\section\xref{CompleteMultiPredicativeFormula:parser.pas}), and it
invokes this method. This initializes the \\{nMultiPredicateList} to
an empty list of length 4, and the first entry points to the same
formula pointed to by the \\{gLastFormula} state variable.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartMultiPredicativeFormula;
begin
   nMultiPredicateList.Init(4);
   nMultiPredicateList.Insert(gLastFormula);
end;

@ Finishing a ``multi-predicative formula'' allocates a
new \\{MultiPredicativeFormula} object, and moves the contents of the
caller's \\{nMultiPredicateList} to the newly minted
formula. The \\{gLastFormula} state variable is updated to point to
this newly allocated formula object.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishMultiPredicativeFormula;
begin
   gLastFormula:=new(MultiPredicativeFormulaPtr,Init(nSubexpPos,new(PList,MoveList(nMultiPredicateList))));
end;

@ The Parser has just parsed ``\<Term> \texttt{is} \<Type>'', and now
we need to store the accumulated data into a Formula AST. Of course,
if the \\{gLastType} variable is not pointing to a type object, then
we should raise an error (clearly something has gone wrong somewhere).

If we have accumulated attributes while parsing, then we should update
the \\{gLastType} to be a clustered type object (and we should move
the attributes over).

We should allocate a \\{QualifiedFormula} object, update
the \\{gLastFormula} state variable to point to it. If the Parser has
encountered ``\<Term> \texttt{is not} \<Type>'', then it will tell the
caller to toggle the \\{nPostNegated} to be true --- and in that case,
we should negate the \\{gLastFormula} state variable.

We mutate the \\{TermNbr} state variable, decrementing it by one
(since we consumed the top of the term stack).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishQualifyingFormula;
var j: integer;
begin
   mizassert(5430,gLastType <> nil);
   if nAttrCollection.Count > 0 then
   begin
      gLastType:=new(ClusteredTypePtr,
                     Init(gLastType^.nTypePos,new(PList,Init(nAttrCollection.Count)),gLastType));
      for j := 0 to nAttrCollection.Count-1 do
         ClusteredTypePtr(gLastType)^.nAdjectiveCluster^.Insert(PObject(nAttrCollection.Items^[j]));
   end;
   gLastFormula:=new(QualifyingFormulaPtr,Init(nSubexpPos,Term[TermNbr],gLastType));
   if nPostNegated then
      gLastFormula:=new(NegativeFormulaPtr,Init(nNotPos,gLastFormula));
   dec(TermNbr);
end;

@ The Parser has just finished parsing ``\<Term> \texttt{is} \<Attribute>''
or ``\<Term> \texttt{is not} \<Attribute>'', and so it invokes this
method. We allocate a new \\{AttributiveFormula} object, and negate it
if needed. We also decrement the \\{TermNbr} state variable (since we
consumed one element of the term stack).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishAttributiveFormula;
begin
   gLastFormula:=
      new(AttributiveFormulaPtr,Init(nSubExpPos,Term[TermNbr],new(PList,MoveList(nAttrCollection))));
   if nPostNegated then
      gLastFormula:=new(NegativeFormulaPtr,Init(nNotPos,gLastFormula));
   dec(TermNbr);
end;

@ While the Parser is working its way through a formula, and it is
looking at an identifier and the next token is a square bracket
``\texttt{[}'', then the Parser invokes this method to initialize the
relevant fields to store accumulated data.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartPrivateFormula;
begin
   nTermBase:=TermNbr;
   nSubexpPos:=CurPos;
   nSpelling:=CurWord.Nr;
end;

@ The Parser has just encountered ``\texttt{]}'' and now we assemble
the accumulated data into a formula. This allocates a
new \\{PrivatePredicativeFormula}, moves the arguments encountered
since starting the private predicate into a list
(\section\xref{CreateArgs}) owned by the formula
object. The \\{gLastFormula} is updated to point to the newly
allocated formula object.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishPrivateFormula;
begin
   gLastFormula:=new(PrivatePredicativeFormulaPtr,Init(nSubexpPos,nSpelling,CreateArgs(nTermBase+1)));
end;

@ The Parser has encountered the ``\texttt{contradiction}'' token, so
it invokes this method, which allocates a \\{ContradictionFormula} and
updates the \\{gLastFormula} state variable to point to it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessContradiction;
begin
   gLastFormula:=new(ContradictionFormulaPtr,Init(CurPos));
end;

@ The Parser routinely allocates a formula object, then realizes later
it should negate that formula object. This is handled by storing the
formula object in the \\{gLastFormula} object, then this method
allocates a new formula (which is the negation of
the \\{gLastFormula}) and updates the \\{gLastFormula} to point to the
newly allocated negated formula.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessNegative;
begin
   gLastFormula:=new(NegativeFormulaPtr,Init(CurPos,gLastFormula));
end;

@ When the Parser has encountered the ``\texttt{not}'' reserved
keyword, it invokes the \\{ProcessNegation} method which just toggles
the \\{nPostNegated} field of the caller, and assigns the \\{nNotPos}
field to the Parser's current position.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessNegation;
begin
   nPostNegated:=not nPostNegated;
   nNotPos:=CurPos;
end;

@ When the Parser is looking at a binary connective token
(e.g., ``\texttt{implies}'', ``\texttt{or}'', etc.), this method is
invoked to store the connective kind as well as the ``left-hand side'' to the
binary connective in the \\{nFirstSententialOperand} field. 

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessBinaryConnective;
begin
   nConnective:=CurWord.Kind;
   nFirstSententialOperand:=gLastFormula;
   nSubexpPos:=CurPos;
end;

@ The Parser has seen ``\<Formula> \texttt{or} \texttt{...} \texttt{or}''. 
Then this method will be invoked to store that first formula parsed in
the caller's \\{nFirstSententialOperand} field.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessFlexDisjunction;
begin
   nFirstSententialOperand:=gLastFormula;
end;

@ The Parser has seen ``\<Formula> \texttt{\AM} \texttt{...} \texttt{\AM}''. 
Then this method will be invoked to store that first formula parsed in
the caller's \\{nFirstSententialOperand} field.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessFlexConjunction;
begin
   nFirstSententialOperand:=gLastFormula;
end;

@ The Parser has parsed ``\texttt{for} \<Qualified-Variables> \texttt{st}'',
and it is staring at the ``\texttt{st}'' token. Then it will invoke
this method to mark the \\{nRestrPos}, setting it equal to the
Parser's current position.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartRestriction;
begin
   nRestrPos:=CurPos;
end;

@ The Parser has just parsed the formula appearing after
``\texttt{st}'', so this method is invoked to store that formula in
the caller's \\{nRestriction} field (for later use when constructing
an AST).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishRestriction;
begin
   nRestriction:=gLastFormula;
end;

@ The Parser has finished parsing a formula involving binary
connectives, then it invokes this method to construct the formula AST.

If somehow the connective is not ``\texttt{implies}'',
``\texttt{iff}'', ``\texttt{or}'', or ``\texttt{\AM}'', then we should
raise an error.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishBinaryFormula;
begin
   case nConnective of
      sy_Implies:
         gLastFormula:=new(ConditionalFormulaPtr,Init(nSubExpPos,nFirstSententialOperand,gLastFormula));
      sy_Iff:
         gLastFormula:=new(BiconditionalFormulaPtr,Init(nSubexpPos,nFirstSententialOperand,gLastFormula));
      sy_Or:
         gLastFormula:=new(DisjunctiveFormulaPtr,Init(nSubexpPos,nFirstSententialOperand,gLastFormula));
      sy_Ampersand:
         gLastFormula:=new(ConjunctiveFormulaPtr,Init(nSubexpPos,nFirstSententialOperand,gLastFormula));
   othercases
      RunTimeError(3124);
   endcases;
end;

@ We have parsed ``\<Formula> \texttt{or ... or} \<Formula>'', and the
Parser invokes this method to construct an AST for the formula. This
method allocates a new \\{FlexaryDisjunctive} formula object, and
updates the \\{gLastFormula} state variable to point to it.

There is a comment in Polish, ``polaczyc z flexConj'', which Google
translates to ``connect to flexConj''.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishFlexDisjunction; {polaczyc z flexConj}
begin
   gLastFormula:=new(FlexaryDisjunctiveFormulaPtr,
                     Init(CurPos,nFirstSententialOperand,gLastFormula));
end;

@ We have parsed ``\<Formula> \texttt{\AM\ ... \AM} \<Formula>'', and
the Parser invokes this method to construct an AST for the
formula. This allocates a new \\{FlexaryConjunctive} formula object,
and updates the \\{gLastFormula} state variable to point to it.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishFlexConjunction;
begin
   gLastFormula:=new(FlexaryConjunctiveFormulaPtr,
                     Init(CurPos,nFirstSententialOperand,gLastFormula));
end;

@ The Parser is looking at the ``\texttt{ex}'' token, then invokes
this method to reset the caller's fields in preparation for
accumulating data needed when constructing the formula's AST.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartExistential;
begin
   nQualifiedSegments.Init(0);
   nSubexpPos:=CurPos;
end;

@ The Parser is looking at the ``\texttt{for}'' token, and it invokes
this method to reset the relevant fields in the caller.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartUniversal;
begin
   nQualifiedSegments.Init(0);
   nSubexpPos:=CurPos;
end;

@ After the Parser has invoked \\{StartUniversal}
or \\{StartExistential}, it parses the quantified variables (which
begins by invoking this method).

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartQualifiedSegment;
begin
   nSegmentIdentColl.Init(2);
   nSegmentPos:=CurPos;
end;

@ The Parser has parsed a comma-separated list and is expecting either
``\texttt{be}'' or ``\texttt{being}'', but before parsing for that
copula the Parser invokes the \\{StartQualifyingType} method to update
the \\{gLastType} state variable to point to \&{nil}.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.StartQualifyingType;
begin
   gLastType:=nil;
end;

@ The Parser has just finished parsing quantified variables. There are
two possible situations:
\enumerate
\item We have just parsed reserved variables, so the types are all
known. Then the |gLastType = nil|.
\item We have parsed an explicitly typed list of variables, so the
|gLastType <> nil|.
\endenumerate

\smallbreak\noindent In the first case, we should allocate
an \\{ImplicitlyQualifiedSegment} object and move all the segment's
identifiers to this object. Then we clean up the
caller's \\{nSegmentIdentColl} field (since it's an array of \&{nil}
pointers). 

In the second case, we can just move the identifiers when allocating a
new \\{ExplicitlyQualifiedSegment} object.

In both cases, the new allocated \\{QuantifiedSegment} object is
appended to the caller's \\{nQualifiedSegments} field.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishQualifiedSegment;
var k: integer;
begin
   if gLastType = nil then
   begin
      for k := 0 to nSegmentIdentColl.Count - 1 do
      begin
         nQualifiedSegments.Insert(new(ImplicitlyQualifiedSegmentPtr,
                                       Init(VariablePtr(nSegmentIdentColl.Items^[k])^.nVarPos,
                                            nSegmentIdentColl.Items^[k])));
         nSegmentIdentColl.Items^[k]:=nil;
      end;
      nSegmentIdentColl.Done;
   end
   else
   begin
      nQualifiedSegments.Insert(new(ExplicitlyQualifiedSegmentPtr,
                                    Init(nSegmentPos,new(PList,MoveList(nSegmentIdentColl)),gLastType)));
   end;
end;

@ When the Parser is parsing quantified variables, specifically when
it is parsing a comma-separated list of variables, it will invoke this
method, then check if the next token is a comma (and if so
iterate). This \\{ProcessVariable} method should accumulate
a \\{Variable} object with the current token's identifier, then insert
it into the caller's \\{nSegmentIdentColl} field.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.ProcessVariable;
begin
   nSegmentIdentColl.Insert(new(VariablePtr,Init(CurPos,GetIdentifier)));
end;

@ The Parser has just finished something like
$$\hbox{\texttt{ex }} \<Qualified-Variables>\hbox{ \texttt{,} }\dots\hbox{ \texttt{,} }\<Qualified-Variables>\hbox{ \texttt{st} }\<Formula>$$
Now we assemble it as
$$\hbox{\texttt{ex }} \<Qualified-Variables>\hbox{ \texttt{st} }\bigl(\hbox{\texttt{ex }}\dots\hbox{ \texttt{st} }(\hbox{\texttt{ex} }\<Qualified-Variables>\hbox{ \texttt{st} }\<Formula>)\bigr)$$
starting with the innermost existentially quantified formula, working
our ways outwards.

Importantly, assembling the AST reflects the quantified variables has
the grammar

\smallbreak
{\obeylines\parindent=0pt\advance\leftskip3pc

\<Qualified-Variables> = \<Implicitly-Qualified-Variables>

\hskip3pc\pipe\ \<Explicitly-Qualified-Variables>

\hskip3pc\pipe\ \<Explicitly-Qualified-Variables> \texttt{","} \<Implicitly-Qualified-Variables>
\par}

\smallbreak\noindent%


@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishExistential;
var k:integer;
begin
   for k:=nQualifiedSegments.Count-1 downto 1 do {from inside outwards}
   begin
      gLastFormula:=new(ExistentialFormulaPtr,
                        Init(QualifiedSegmentPtr(nQualifiedSegments.Items^[k])^.nSegmPos,
                             nQualifiedSegments.Items^[k],gLastFormula));
      nQualifiedSegments.Items^[k]:=nil;
   end;
   if nQualifiedSegments.Count > 0 then
   begin
      gLastFormula:=new(ExistentialFormulaPtr,
                        Init(nSubexpPos,nQualifiedSegments.Items^[0],gLastFormula));
      nQualifiedSegments.Items^[0]:=nil;
   end;
   nQualifiedSegments.Done;
end;

@ Universally quantified formulas first transforms
$$\hbox{\texttt{for }}\<Qualified-Variables>\hbox{ \texttt{st} }\<Formula>_{1} \hbox{ \texttt{holds} }\<Formula>_{2}$$
into
$$\hbox{\texttt{for }}\<Qualified-Variables>\hbox{ \texttt{holds} }\<Formula>_{1} \hbox{ \texttt{implies} }\<Formula>_{2}$$
which is handled immediately.

The remainder of the method iteratively constructs the universally
quantified formulas by ``unrolling'' the qualified segments, just as
we did for existentially quantified formulas.

@<Extended subexpression implementation@>=
procedure @? extSubexpObj.FinishUniversal;
var k:integer;
begin
   if nRestriction <> nil then {transform \texttt{st} into \texttt{implies}}
      gLastFormula:=new(ConditionalFormulaPtr,Init(nRestrPos,nRestriction,gLastFormula));
   for k:=nQualifiedSegments.Count-1 downto 1 do
   begin
      gLastFormula:=new(UniversalFormulaPtr,
                        Init(QualifiedSegmentPtr(nQualifiedSegments.Items^[k])^.nSegmPos,
                             nQualifiedSegments.Items^[k],gLastFormula));
      nQualifiedSegments.Items^[k]:=nil;
   end;
   if nQualifiedSegments.Count > 0 then
   begin
      gLastFormula:=new(UniversalFormulaPtr,
                        Init(nSubexpPos,nQualifiedSegments.Items^[0],gLastFormula));
      nQualifiedSegments.Items^[0]:=nil;
   end;
end;

@* [S] Extended expression class.
When an expression is needed, the \\{gExpPtr} state variable is used
to build it out of subexpressions. The \\{gExpPtr} state variable is
an instance of the \\{extExpression} class.

@<Extended expression class declaration@>=
   extExpressionPtr = ^extExpressionObj; @/
   extExpressionObj = object(ExpressionObj) @t\1@>
      constructor Init(fExpKind:ExpKind); @t\2@>
      procedure CreateSubexpression; virtual; @t\2\2\2@>
   end;

@ \node{Constructor.} This just invokes the parent class's constructor
(\section\xref{ExpressionObj.Init}), then resets the module-wide
variable \\{TermNbr} to zero.

@<Extended expression implementation@>=
constructor extExpressionObj.Init(fExpKind:ExpKind);
begin
   inherited Init(fExpKind);
   TermNbr:=0;
end;

@ An \\{extExpression} creating a subexpression \emph{overrides} the
parent class's method (\section\xref{ExpressionObj.CreateSubexpression}),
and sets the global \\{gSubexpPtr} to point to a new \\{extSubexp}
object.

\label{extExpressionObj.CreateSubexpression}

@<Extended expression implementation@>=
procedure extExpressionObj.CreateSubexpression;
begin
   gSubexpPtr:=new(extSubexpPtr,Init)
end;


@* [F] Parser.
The Parser has a ``big red button'': a single ``obvious'' function for
the user to, you know, push. Namely, the |Parse| procedure
(\section\section\xref{parser.pas::Parse} \emph{et seq.}). Everything else is just a helper
function.

The design of the Parser appears to be a recursive descent Parser on
statements, with parsing expressions handled specially.

Note that the \texttt{base/parser.pas} file appears to be naturally
divided up into sections, with comments which appear to use the
Germanic ``s~p~a~c~i~n~g \ f~o~r \ i~t~a~l~i~c~s'' (which I have just
replaced with more readable \emph{italicized} versions). I have used
these cleavages to organize the discussion of this file.

The |StillCorrect| global variable is \\{false} when the Parser has
entered what programmers call \define{Panic Mode}: something has gone
awry, and the Parser is trying to recover gracefully. For a friendly
review of panicking, see Bob Nystrom's \emph{Crafting Interpreters}
(\href{https://craftinginterpreters.com/parsing-expressions.html}{Chaper~6}, Section~3).

@^Panic mode@>

@<parser.pas@>=
@<GNU License@>
unit parser;

interface @|@#

uses mscanner; @#

var StillCorrect: boolean = true; @#

type ReadTokenProcedure = Procedure; @#

const ReadTokenProc: ReadTokenProcedure = ReadToken; {from mscanner.pas}

procedure Parse; @t\2@>
procedure SemErr(fErrNr: integer); @t\2@>

implementation @|@#

uses syntax,errhan,pragmas
mdebug ,info @+end_mdebug;

@<Implementation of parser.pas@>@;

@ We have a few constants, but the implementation is loosely organized
around parsing expressions (terms and formulas), statements, and then
blocks.


@<Implementation of parser.pas@>=
@<Local constants for parser.pas@>;

@<Parse expressions (\texttt{parser.pas})@>@;

@<Communicate with items (\texttt{parser.pas})@>@;

@<Process miscellany (\texttt{parser.pas})@>@;

@<Parse simple justifications (\texttt{parser.pas})@>@;

@<Parse statements and reasoning (\texttt{parser.pas})@>@;

@<Parse patterns (\texttt{parser.pas})@>@;

@<Parse definitions (\texttt{parser.pas})@>@;

@<Parse scheme block (\texttt{parser.pas})@>@;

@<Main parse method (\texttt{parser.pas})@>@;

@ We have error codes for syntactically invalid situations. These are
all different ways for panic to occur (hence the ``pa-'' prefix). We
will introduce the error codes when they are first used. The unused
error codes are listed below.

@<Local constants for parser.pas@>=
const
   @<Error codes for parser@>@;

@ @<Error codes for parser@>=
   paUnexpAntonym1       = 198; 
   paUnexpAntonym2       = 198; 
   paUnexpSynonym        = 199; 
   paUnexpHereby         = 216; 
   paUnexpReconsider     = 228; 
   paIdentExp5           = 300; 
   paIdentExp12          = 300; 
   paWrongRightBracket1  = 311; 
   paWrongRightBracket2  = 311; 
   paWrongPattBeg3       = 314; 
   paRightSquareExp1     = 371; 
   paRightSquareExp3     = 371; 
   paRightCurledExp2     = 372; 
   paWrongAttrPrefixExpr = 375; 
   paWrongAttrArgumentSuffix = 376; 
   paTypeExpInAdjectiveCluster = 377; 
   paTypeUnexpInClusterRegistration = 405; 

@ @<Implementation of parser.pas@>=
var gAddSymbolsSet: set of char = []; {not used anywhere}

@ Syntax errors do three things:
\enumerate
\item Marks \\{StillCorrect} to be false (i.e., enters panic mode)
\item Reports the error with the \\{ErrImm} (\section\xref{ErrImm}) function. 
\item Skips ahead until we find a token in the \\{gMainSet}, then try
to proceed like things are still alright (so we ``fail gracefully'').
\endenumerate


@<Implementation of parser.pas@>=
procedure SynErr(fPos:Position; fErrNr:integer);
begin
   if StillCorrect then
   begin
      StillCorrect:=false; @#
      if CurWord.Kind = sy_Error then
      begin
         if CurWord.Nr <> scTooLongLineErrorNr then ErrImm(CurWord.Nr)
         else Error(fPos,fErrNr);
      end
      else Error(fPos,fErrNr); @#
      while not (CurWord.Kind in gMainSet) do ReadTokenProc;
   end;
end;


@ What constants are good ``check-in points'' for the Parser to
recover at? The beginning of blocks, the end of statements (especially
semicolons), and the end of text.

Note: \\{gMainSet} is only used in the \\{SynErr} procedure, and
nowhere else in Mizar.

@<Local constants for parser.pas@>=
const
   gMainSet: set of TokenKind =
      [ sy_Begin,sy_Semicolon,sy_Proof,sy_Now,sy_Hereby,sy_Definition,
        sy_End, sy_Theorem,sy_Reserve,
        sy_Notation,sy_Registration,
        sy_Scheme,EOT,
        sy_Deffunc,sy_Defpred,
        sy_Reconsider,sy_Consider,sy_Then,
        sy_Per,sy_Case,sy_Suppose
      ];

@ We have a few more methods for \emph{specific situations} where errors 
are likely to occur.

@<Implementation of parser.pas@>=
procedure MissingWord(fErrNr:integer);
var lPos: Position;
begin
   lPos:=PrevPos;
   inc(lPos.Col);
   SynErr(lPos,fErrNr)
end; @#

procedure WrongWord(fErrNr:integer);
begin
   SynErr(CurPos,fErrNr)
end;

@ We will want to assert the Parser has encountered a specific token
(like a semicolon or ``\texttt{end}'') and raise an error if it has
not. This will make for much more readable code later on. We should
recall \\{KillItem} (\section\xref{KillItem:syntax.pas}) mutates the
global state.

\Ithink{The \\{Semicolon} procedure should probably match
the \\{AcceptEnd} procedure --- i.e., it should be of the form ``\&{if} \<Current
token is semicolon> \&{then} \\{ReadTokenProc} \&{else} \<Flag error>''.}

@<Implementation of parser.pas@>=
procedure Semicolon;
begin
   KillItem;
   if CurWord.Kind <> sy_Semicolon then
      MissingWord(paSemicolonExp); @^Error, 330@>
   if CurWord.Kind = sy_Semicolon then ReadTokenProc;
end; @#

procedure AcceptEnd(fPos:Position);
begin
   if CurWord.Kind = sy_End then ReadTokenProc else
   begin
      Error(fPos,paEndExp); @^Error, 215@>
      MissingWord(paUnpairedSymbol) @^Error, 214@>
   end;
end;

@ @<Error...@>=
   paUnpairedSymbol      = 214;
   paEndExp              = 215;
   paSemicolonExp        = 330;

@ Due to the structure of \PASCAL/, the Parser will frequently be in
situations where we consider the \&{case} of the current kind of
token, and for ``valid'' branches we will want the Parser to consume
the current token and move on. For example, if the Parser is looking
at an open bracket.

But if the Parser is a panicking mess, then we should raise an error
to alert the user.

\Ithink{Either some explanation should be offered for the magic number
$2546=\H{9f2}$, or it should be stored in a constant (or a \WEB/ macro).}

@<Implementation of parser.pas@>=
procedure ReadWord;
begin
   Mizassert(2546,StillCorrect);
   ReadTokenProc
end; @#

@ These previous methods can be generalized to an \\{Accept}
procedure which checks whether a given |TokenKind| has
``occurred''. If so, just read the next word. Otherwise, flag an error.

When will an error be flagged? If the Parser is panicking, or if the
current token does not match the expected token.

@<Implementation of parser.pas@>=
function Occurs(fW:TokenKind): boolean;
begin
   Occurs:=false;
   if CurWord.Kind=fW then
   begin
      ReadWord;
      Occurs:=true @+
   end
end; @#

procedure Accept(fCh:TokenKind; fErrNr:integer);
begin
   if not Occurs(fCh) then MissingWord(fErrNr)
end;

@ Flagging a semantic error should first check if we are in ``panic mode''
or not. If we are already panicking, there's no reason to heap more
panicky error messages onto the screen.

@<Implementation of parser.pas@>=
procedure SemErr(fErrNr:integer);
begin
   if StillCorrect then ErrImm(fErrNr)
end;

@ \node{Exercise:} For each procedure and function we are about to
define in the rest of the Parser, when will an error be raised and by
which of these functions?

@* [S] Expressions.
The syntactic classes we're interested in (terms, types, formulas)
almost always appear as subexpressions in a formula or some other
expression. The Parser works with various procedures to parse these
guys as
subexpressions: \\{TermSubexpression} (\section\xref{TermSubexpression:parser.pas}),
\\{TypeSubexpression} (\section\xref{TypeSubexpression:parser.pas}),
\\{FormulaSubexpression} (\section\xref{FormulaSubexpression:parser.pas}). 
When we need a term (or type or formula) as an expression, as we will
in the next section, we use
these procedures to construct the abstract syntax tree.

@* [s] Terms.
We have a few token kinds which indicate the start of a term:
\enumerate
\item identifiers (for variables and private functors),
\item infixed operators,
\item numerals,
\item left and right brackets of all sorts, 
\item the anaphoric ``\texttt{it}'' constant used in definitions,
\item ``\texttt{the}'' choice operator, 
\item placeholder variables appearing in private functors and predicates,
\item structure symbols.
\endenumerate

\label{TermBegSys}

@<Parse expressions (\texttt{parser.pas})@>=
 {{\it Expressions}}

const
   TermBegSys:set of TokenKind =
      [Identifier,InfixOperatorSymbol,Numeral,LeftCircumfixSymbol,sy_LeftParanthesis,
       sy_It,sy_LeftCurlyBracket,sy_LeftSquareBracket,sy_The,sy_Dolar,Structuresymbol];

@ We have a few helper function for |Accept|-ing parentheses.
This invokes the |ProcessLeftParenthesis| method for the |gSubexpPtr|
(\section\xref{gSubexpPtr}) global variable which we recall
(\section\xref{SubexpObj.abstract-methods}) is an empty virtual
method. So the Parser just ``consumes'' a left parentheses, and will
continue to read tokens while they are left parentheses.
The argument passed in will be mutated to track the number of left
parentheses consumed.

Similarly, the |CloseParenth| method will have the compiler consume
right parentheses, mutating the argument passed in (to decrement the
number of right parentheses consumed). This will let us track
mismatched parentheses errors.

\Ithink{The |ClosedParenth| method should raise an error when the user
passes a negative value for |fParenthCnt|, but that may be ``too defensive''.}

\label{OpenParenth:parser.pas}
\label{ClosedParenth:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure OpenParenth(var fParenthCnt:integer);
begin
   fParenthCnt:=0;
   while CurWord.Kind = sy_LeftParanthesis do
   begin
      gSubexpPtr^.ProcessLeftParenthesis;
      ReadWord;
      inc(fParenthCnt);
   end; { |fParenthCnt >= 0| }
end; @#

procedure CloseParenth(var fParenthCnt:integer);
begin
   while (CurWord.Kind = sy_RightParanthesis) and (fParenthCnt > 0) do
   begin
      dec(fParenthCnt);
      gSubexpPtr^.ProcessRightParenthesis;
      ReadWord;
   end; { \texttt{\BS old}|(fParenthCnt)>=0| implies |fParenthCnt>=0| }
end;

@ \node{Qualified expressions.} Parsing qualified expressions includes
a control flow for ``exactly'' qualified expressions.

We should recall from ``Mizar in a nutshell'' that the
``\texttt{exactly}'' keyword is reserved but not currently used for
anything. The global subexpression pointer is invoking empty virtual
methods (\section\xref{SubexpObj.abstract-methods}). So what's going
on?

Well, the only work being done here is in the branch handling
``\texttt{qua}'', specifically the \\{gSubexpPtr} state variable marks
the ``\texttt{qua}'' position (\section\xref{extSubexpObj.ProcessQua}),
the next word is read, and then control
is handed off to the Parser's |TypeSubexpression| procedure. The AST
is assembled with the |FinishQualifiedTerm|
(\section\xref{extSubexpObj.FinishQualifiedTerm}) method.

\label{AppendQua}

@<Parse expressions (\texttt{parser.pas})@>=
procedure @? TypeSubexpression; forward; @t\2@> @#

procedure AppendQua;
begin
   while CurWord.Kind = sy_Qua do
   begin
      gSubexpPtr^.ProcessQua;
      ReadWord;
      TypeSubexpression;
      gSubexpPtr^.FinishQualifiedTerm;
   end;
   if CurWord.Kind = sy_Exactly then
   begin
      gSubexpPtr^.ProcessExactly;
      ReadWord
   end;
end;

@ Parsing \emph{the contents of} a bracketed term starts a bracketed term
(\section\xref{extSubexpObj.StartBracketedTerm}), reads the next word after
the start of the bracket, then consumes the maximum number of visible
arguments (\section\xref{MaxVisArgNbr}). The \\{gSubexpPtr} constructs
the AST for the bracketed term and its contents
(\section\xref{extSubexpObj.FinishBracketedTerm}). 

The contract for this function is that a left bracket token has been
encountered, the Parser has moved on to the next token, and then invoked
this function. 

\label{BracketedTerm}

@<Parse expressions (\texttt{parser.pas})@>=
procedure @? GetArguments(const fArgsNbr:integer); forward; @t\2@> @#

procedure BracketedTerm;
begin
   gSubexpPtr^.StartBracketedTerm;
   ReadWord;
   GetArguments(MaxVisArgNbr);
   gSubexpPtr^.FinishBracketedTerm;
end;

@ Parsing post-qualified variables (i.e., variables which appear in a
Fraenkel term's ``\texttt{where}'' clause) which consists of a
comma-separated list of post-qualified segments.

\label{ProcessPostqualification}

@<Parse expressions (\texttt{parser.pas})@>=
procedure @? TermSubexpression; forward; @t\2@>

procedure @? FormulaSubexpression; forward; @t\2@>

procedure @? ArgumentsTail(fArgsNbr:integer); forward; @t\2@> @#

procedure ProcessPostqualification;
begin
   gSubexpPtr^.StartPostqualification; {(\section\xref{extSubexpObj.StartPostqualification})}
   while CurWord.Kind = sy_Where do
   begin
      repeat
         @<Process post-qualified segment@>@;
      until CurWord.Kind <> sy_Comma;
   end;
end;

@ Each ``segment'' in a post-qualification looks like:
$$\langle\textit{variable}\rangle\ \LB\hbox{\texttt{","} } \langle\textit{variable}\rangle\RB\ (\hbox{\texttt{"is"} } \pipe \hbox{ \texttt{"being"}})\ \langle\textit{type}\rangle$$
We can process the comma-separated list of variables, then the type
ascription term (``is'' or ``being''), then process the type.

@d parse_post_qualified_type == @+
         begin
            ReadWord;
            TypeSubexpression; @+
         end
@<Process post-qualified segment@>=
         gSubexpPtr^.StartPostQualifyingSegment; {(\section\xref{extSubexpObj.StartPostQualifyingSegment})}@+ 
         ReadWord; @/
         @<Parse post-qualified comma-separated list of variables@>; @/
         gSubexpPtr^.StartPostqualificationSpecyfication; {(\section\xref{extSubexpObj.StartPostqualificationSpecyfication})}
         if CurWord.Kind in [sy_Is,sy_are] then parse_post_qualified_type;
         gSubexpPtr^.FinishPostqualifyingSegment; {(\section\xref{extSubexpObj.FinishPostQualifyingSegment})}

@ @<Parse post-qualified comma-separated list of variables@>=
         repeat
            gSubexpPtr^.ProcessPostqualifiedVariable; {(\section\xref{extSubexpObj.ProcessPostqualifiedVariable})}@+
            Accept(Identifier,paIdentExp1); @^Error, 300@>
         until not Occurs(sy_Comma)
@ @<Error...@>=
   paIdentExp1           = 300;
   paRightParenthExp1    = 370;

@ Getting a closed subterm is part of the loop for parsing a term. The
intricate relationship of mutually recursive function calls looks
something like the following (assuming there are no parsing errors):

\medbreak
\figure
\centerline{\graphics{img/img-0}}
\caption{Control flow when parsing a term.}\label{fig:flow-of-parsing-term}
\endfigure
\medbreak\noindent%
The \\{GetArguments} parses a comma-separated list of terms. Since
each term in the comma-separated list will be a \emph{subterm} of a
larger expression, we parse it with \\{TermSubexpression} (which
invokes \\{GetClosedSubterm} in a mutually recursive relation). If
there is a chain of infix operators (like $x + y - z \times\omega$), then
\\{AppendFunc} is invoked on the infixed operators.

\label{GetClosedSubterm:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure GetClosedSubterm;
begin
   case CurWord.Kind of
      @<Get closed subterm of identifier@>;
      @<Get closed subterm of structure@>;
      Numeral:
         begin
            gSubexpPtr^.ProcessNumeralTerm;
            ReadWord @+
         end;
      @<Get closed subterm of bracketed expression@>;
      sy_It:
         begin
            gSubexpPtr^.ProcessItTerm;
            ReadWord @+
         end;
      sy_Dolar:
         begin
            gSubexpPtr^.ProcessLocusTerm;
            ReadWord @+
         end;
      @<Get closed subterm of Fraenkel operator or enumerated set@>;
      @<Get closed subterm of choice operator@>;
   othercases RunTimeError(2133);
   endcases;
end;

@ If we treat an identifier as a term, then it is either a private
functor or it is a variable. How do we tell the difference? A private
functor starts with an identifier followed by a left parentheses.

Remember, private functors which omit the closing right parentheses
should be flagged with a 370 error.
@^Error, 370@>

\label{GetClosedSubterm:identifier:parser.pas}

@<Get closed subterm of identifier@>=
      Identifier:
         if AheadWord.Kind = sy_LeftParanthesis then {treat identifier as private functor}
         begin
            gSubexpPtr^.StartPrivateTerm;
            ReadWord;
            ReadWord;
            if CurWord.Kind <> sy_RightParanthesis then GetArguments(MaxVisArgNbr);
            gSubexpPtr^.FinishPrivateTerm;
            Accept(sy_RightParanthesis,paRightParenthExp2);
         end
         else {treat identifier as variable}
         begin
            gSubexpPtr^.ProcessSimpleTerm; {(\section\xref{extSubexpObj.ProcessSimpleTerm})}@+
            ReadWord
         end
@ @<Error codes for parser@>=
   paRightParenthExp2    = 370;

@ If the Parser stumbles across the name of a structure when expecting
a term, then the Parser should treat it as constructing a new instance
of the structure. A 363 error will be raised if the
``\hbox{\texttt{(\#}}'' is missing, and a 373 error will be raised if the
``\hbox{\texttt{\#)}}'' structure bracket is missing.

\label{ClosedSubter:structure:parser.pas}

@<Get closed subterm of structure@>=
      StructureSymbol:
         begin
            gSubexpPtr^.StartAggregateTerm;
            ReadWord;
            Accept(sy_StructLeftBracket,paLeftDoubleExp1); @^Error, 363@>
            GetArguments(MaxVisArgNbr);
            gSubexpPtr^.FinishAggregateTerm; {(\section\xref{extSubexpObj.FinishAggregateTerm})}@+
            Accept(sy_StructRightBracket,paRightDoubleExp1); @^Error, 373@>
         end

@ @<Error codes for parser@>=
   paLeftDoubleExp1      = 363;
   paRightDoubleExp1     = 373;

@ Encountering a left bracket of some kind --- specifically a
user-defined left bracket or a ``\texttt{[}'' --- should cause the Parser to
look for the contents of a bracketed term (\section\xref{BracketedTerm}),
then a right bracket.

@<Get closed subterm of bracketed expression@>=
      LeftCircumfixSymbol,sy_LeftSquareBracket:
         begin
            BracketedTerm;
            case Curword.Kind of
               sy_RightSquareBracket,sy_RightCurlyBracket,sy_RightParanthesis: ReadWord;
            othercases Accept(RightCircumfixSymbol,paRightBraExp1); @^Error, 310@>
            endcases;
         end
@ @<Error...@>=
   paRightBraExp1        = 310;

@ When the Parser runs into a left curly bracket ``$\LB$'', we either
have encountered a Fraenkel operator \emph{or} we have encountered a
finite set.

@<Get closed subterm of Fraenkel operator or enumerated set@>=
      sy_LeftCurlyBracket:
         begin
            gSubexpPtr^.StartBracketedTerm; {(\section\xref{extSubexpObj.StartBracketedTerm})}
            ReadWord;
            TermSubexpression; {(\section\xref{TermSubexpression:parser.pas})}
            if (CurWord.Kind = sy_Colon) or (CurWord.Kind = sy_Where) then
            @<Parse a Fraenkel operator@>
            else
            @<Parse an enumerated set@>;
         end

@ 
Parsing a Fraenkel operator, well, we recall Fraenkel operators look
like
$$\LB\langle\textit{term\/}\rangle\langle\hbox{\textit{post-qualified\ segment\/}}\rangle\hbox{\texttt{ ":" }}\langle\textit{formula\/}\rangle\RB$$

@^Error, 372@>
@^Error, 384@>

@<Parse a Fraenkel operator@>=
            begin
               gSubexpPtr^.StartFraenkelTerm;
               ProcessPostqualification;
               gSubexpPtr^.FinishSample;
               Accept(sy_Colon,paColonExp1); @^Error, 372@>
               FormulaSubexpression;
               gSubexpPtr^.FinishFraenkelTerm;
               Accept(sy_RightCurlyBracket,paRightCurledExp1); @^Error, 384@>
            end

@ @<Error...@>=
   paRightCurledExp1     = 372;
   paColonExp1            = 384;

@ The Parser can also run into a finite set $\LB x_{1},\dots,x_{n}\RB$.
The braces are treated like any other functor bracket, in the sense
that if the right brace $\RB$ is missing, then a 310 error will be raised.

@^Error, 310@>

@<Parse an enumerated set@>=
            begin
               gSubexpPtr^.FinishArgument;
               ArgumentsTail(MaxVisArgNbr-1);
               gSubexpPtr^.FinishBracketedTerm;
               case Curword.Kind of
                  sy_RightSquareBracket,sy_RightCurlyBracket,sy_RightParanthesis: ReadWord;
               othercases Accept(RightCircumfixSymbol,paRightBraExp1);
               endcases;
            end


@ Mizar allows ``\texttt{the}'' to be used for selector functors,
forgetful functors, choice operators, or simple Fraenkel terms.

Note we are generous \emph{here} with what situations leads to
treating ``\texttt{the}'' as a choice operator, because in other
parsing procedures any mistakes will be caught there.

\label{GetClosedSubterm:the:parser.pas}

@d choice_operator_cases == ModeSymbol,AttributeSymbol,sy_Non,sy_LeftParanthesis,Identifier,
               InfixOperatorSymbol,Numeral,LeftCircumfixSymbol,sy_It,sy_LeftCurlyBracket,
               sy_LeftSquareBracket,sy_The,sy_Dolar

@<Get closed subterm of choice operator@>=
      sy_The:
         begin
            gSubexpPtr^.ProcessThe;
            ReadWord;
            case CurWord.Kind of
               SelectorSymbol:
                  @<Parse selector functor@>;
               StructureSymbol:
                  @<Parse forgetful functor or choice of structure type@>;
               sy_Set:
                  @<Parse simple Fraenkel expression or ``the set''@>;
               choice_operator_cases:
                  begin
                     gSubexpPtr^.StartChoiceTerm;
                     TypeSubexpression;
                     gSubexpPtr^.FinishChoiceTerm;
                  end
            othercases
            begin
               gSubexpPtr^.InsertIncorrTerm;
               WrongWord(paWrongAfterThe) @^Error, 320@>
            end;
            endcases;
         end

@ @<Error...@>=
   paWrongAfterThe       = 320;

@ @<Parse selector functor@>=
   begin
      gSubexpPtr^.StartSelectorTerm;
      ReadWord; {parses ``\texttt{the} \<selector>''}
      if Occurs(sy_Of) then TermSubexpression; {parses ``\texttt{of} \<Term>''}
      gSubexpPtr^.FinishSelectorTerm; {builds AST subtree}
   end

@ A forgetful functor always looks like
$$\hbox{\texttt{"the" }}\langle\textit{structure\/}\rangle\hbox{\texttt{ "of" }}\langle\textit{term\/}\rangle$$
On the other hand, the choice operator acting on a structure type
looks similar. We should distinguish these two by the presence of the
keyword \texttt{"of"}.

@^Error, 256@>

\label{GetClosedSubterm:forgetful-functor:parser.pas}

@<Parse forgetful functor or choice of structure type@>=
                  if AheadWord.Kind = sy_Of then {forgetful functor}
                  begin
                     gSubexpPtr^.StartForgetfulTerm;
                     ReadWord;
                     Accept(sy_Of,paOfExp); @^Error, 256@>
                     TermSubexpression;
                     gSubexpPtr^.FinishForgetfulTerm;
                  end
                  else {choice operator, e.g., ``\texttt{the multMagma}''}
                  begin
                     gSubexpPtr^.StartChoiceTerm;
                     TypeSubexpression;
                     gSubexpPtr^.FinishChoiceTerm;
                  end

@ @<Error...@>=
   paOfExp               = 256;


@ Mizar allows ``\texttt{the set of}'' to start a simple Fraenkel
expression. But we could also refer to ``\texttt{the set}'' as the set
chosen by the axiom of choice.

@^Error, 275@>

\label{ParseSimpleFraenkelExprOrTheSet:parser.pas}

@<Parse simple Fraenkel expression or ``the set''@>=
                  if AheadWord.Kind = sy_Of then {simple Fraenkel expression}
                  begin
                     ReadWord; {set}
                     ReadWord; {of}
                     gSubexpPtr^.StartSimpleFraenkelTerm;
                     Accept(sy_All,paAllExp);
                     TermSubexpression;
                     gSubexpPtr^.StartFraenkelTerm;
                     ProcessPostqualification;
                     gSubexpPtr^.FinishSimpleFraenkelTerm;
                  end
                  else {``the set''}
                  begin
                     gSubexpPtr^.StartChoiceTerm;
                     TypeSubexpression;
                     gSubexpPtr^.FinishChoiceTerm;@+
                  end
@ @<Error...@>=
   paAllExp              = 275;

@ Subexpression object's \\{FinishArgument} 
(\section\xref{extSubexpObj.FinishArgument}) is invoked, which pushes
a term onto the \\{Term} stack. This will invoke
the \\{AppendQua} (\section\xref{AppendQua}) method and expect a
closed parentheses afterwards (\section\xref{ClosedParenth:parser.pas}).

Possible bug: what should happen when \\{fParenthCnt} is zero or negative?

\label{CompleteArgument:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure CompleteArgument(var fParenthCnt:integer);
begin
   gSubexpPtr^.FinishArgument;
   repeat
      AppendQua;
      CloseParenth(fParenthCnt);
   until CurWord.Kind<>sy_Qua; {|and (CurWord.Kind <> sy_Exactly)|}
end;

@ Keep parsing ``infixed operators''. When the current token is an
infixed operator, this will consume the arguments to its right, then
iterate. It's also worth remembering that \\{gExpPtr}
(\section\xref{gSubexpPtr}) was a global variable declared back
in \texttt{syntax.pas}, and the \\{CreateSubexpression}
(\section\xref{extExpressionObj.CreateSubexpression}) mutates
the \\{gSubexpPtr} variable. Now we see it in action.

This invokes the |ProcessLeftParenthesis| method for the |gSubexpPtr|
(\section\xref{gSubexpPtr}) global variable which we recall
(\section\xref{SubexpObj.abstract-methods}) is an empty virtual
method. So the Parser just ``consumes'' a left parentheses.

Note that the |case| expression considers the type of |TokenKind|
(\section\xref{TokenKind}) of the current word. But it is not exhaustive.

There is a comment in Polish, ``Chyba po prostu TermSubexpression'',
which Google translated into English as ``I guess it's just Term Subexpression''.
I swapped this in the code below.

@^Error, 370@>

\label{AppendFunc:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure AppendFunc(var fParenthCnt: integer);
begin
   while CurWord.Kind = InfixOperatorSymbol do
   begin
      gSubexpPtr^.StartLongTerm; { (\section\xref{extSubexpObj.StartLongTerm}) }
      repeat
         gSubexpPtr^.ProcessFunctorSymbol; { (\section\xref{extSubexpObj.ProcessFunctorSymbol}) }
         ReadWord;
         case CurWord.Kind of
            sy_LeftParanthesis:@|@/
               begin {parenthetised term(s)}
                  gSubexpPtr^.ProcessLeftParenthesis; 
                  ReadWord; {consume the left paren}
                  GetArguments(MaxVisArgNbr); { (\section\xref{GetArguments:parser.pas}) }
                  gSubexpPtr^.ProcessRightParenthesis;
                  Accept(sy_RightParanthesis,paRightParenthExp3); {consume matching right paren}
               end; @#
            Identifier,Numeral,LeftCircumfixSymbol,sy_It,sy_LeftCurlyBracket,
            sy_LeftSquareBracket,sy_The,sy_Dolar,StructureSymbol:
               { I guess it's just Term Subexpression }
               begin
                  gExpPtr^.CreateSubexpression; { (\section\xref{extExpressionObj.CreateSubexpression}) }
                  GetClosedSubterm; { (\section\xref{GetClosedSubterm:parser.pas}) }
                  gSubexpPtr^.FinishArgument; { (\section\xref{extSubexpObj.FinishArgument}) }
                  KillSubexpression; { (\section\xref{KillSubexpression}) }
               end;
         endcases; @/
         gSubexpPtr^.FinishArgList; { (\section\xref{extSubexpObj.FinishArgList}) }
      until CurWord.Kind <> InfixOperatorSymbol;
      gSubexpPtr^.FinishLongTerm; { (\section\xref{extSubexpObj.FinishLongTerm}) }
      CompleteArgument(fParenthCnt); { (\section\xref{CompleteArgument:parser.pas}) }
   end;
end;

@ @<Error...@>=
   paRightParenthExp3    = 370;

@ Parse terms with infix operators. Note this appears to parse infixed
operators as left-associative (e.g., $x+y+z$ is parsed as $(x+y)+z$).

@<Parse expressions (\texttt{parser.pas})@>=
procedure ProcessArguments;
var lParenthCnt: integer;
begin
   OpenParenth(lParenthCnt);
   case CurWord.Kind of
      Identifier,Numeral,LeftCircumfixSymbol,sy_It,sy_LeftCurlyBracket,
      sy_LeftSquareBracket,sy_The,sy_Dolar,StructureSymbol: @|@/
         begin
            GetClosedSubterm;
            CompleteArgument(lParenthCnt);@+
         end;
      InfixOperatorSymbol:;
   othercases
   begin
      gSubexpPtr^.InsertIncorrTerm;
      gSubexpPtr^.FinishArgument;
      WrongWord(paWrongTermBeg); @^Error, 397@>
   end;
   endcases; @|@/
   @<Keep parsing as long as there is an infixed operator to the right@>;
   @<Check every remaining open (left) parentheses has a corresponding partner@>;
end;

@ @<Error...@>=
   paWrongTermBeg         = 397;

@ @<Keep parsing as long as there is an infixed operator to the right@>=
   repeat
      AppendFunc(lParenthCnt);
      if CurWord.Kind = sy_Comma then
      begin
         ArgumentsTail(MaxVisArgNbr-1);
         if (lParenthCnt > 0) and (CurWord.Kind = sy_RightParanthesis) then
         begin
            dec(lParenthCnt);
            gSubexpPtr^.ProcessRightParenthesis;
            ReadWord;
         end;
      end;
   until CurWord.Kind <> InfixOperatorSymbol

@ @<Check every remaining open (left) parentheses has a corresponding partner@>=
   while lParenthCnt > 0 do
   begin
      gSubexpPtr^.ProcessRightParenthesis;
      Accept(sy_RightParanthesis,paRightParenthExp1);
      dec(lParenthCnt);
   end

@ \node{Term subexpressions.}
The Parser wants a term as a subexpression in a formula or attribute
cluster or some similar situation. The term specifically is just
a \emph{component} of the expression.
We should recall from Figure~\ref{fig:flow-of-parsing-term} (\section\xref{GetClosedSubterm:parser.pas}) that
this is a critical part of parsing terms.

\label{TermSubexpression:parser.pas}

@<Parse term subexpressions (\texttt{parser.pas})@>=
procedure TermSubexpression;
var lParenthCnt: integer;
begin
   gExpPtr^.CreateSubexpression;
   OpenParenth(lParenthCnt); { (\section\xref{OpenParenth:parser.pas}) }
   case CurWord.Kind of
      Identifier,Numeral,LeftCircumfixSymbol,sy_It,sy_LeftCurlyBracket,
      sy_LeftSquareBracket,sy_The,sy_Dolar,StructureSymbol: @|@/
         begin
            GetClosedSubterm;
            CompleteArgument(lParenthCnt); {(\section\xref{CompleteArgument:parser.pas})}
         end;
      InfixOperatorSymbol: {skip}@+;
   othercases @<Raise error over invalid term subexpression@>;
   endcases; @/
   AppendFunc(lParenthCnt); { (\section\xref{AppendFunc:parser.pas}) }
   while lParenthCnt > 0 do
   @<Parse arguments to the right@>;
   gSubexpPtr^.FinishTerm;
   KillSubexpression;
end;

@ @<Raise error over invalid term subexpression@>=
   begin
      gSubexpPtr^.InsertIncorrTerm;
      gSubexpPtr^.FinishArgument;
      WrongWord(paWrongTermBeg); @^Error, 397@>
   end

@ @<Parse arguments to the right@>=
   begin
      ArgumentsTail(MaxVisArgNbr-1);
      dec(lParenthCnt);
      gSubexpPtr^.ProcessRightParenthesis;
      Accept(sy_RightParanthesis,paRightParenthExp10);
      if CurWord.Kind <> InfixOperatorSymbol then MissingWord(paFunctExp3); @^Error, 302@>
      AppendFunc(lParenthCnt);
   end

@ @<Error...@>=
   paFunctExp3           = 302;
   paRightParenthExp10   = 370;

@* [s] Types and Attributes.
Types and attributes are closely related, when it comes to parsing
Mizar. After all, we can add an adjective to a type and we expect it
to be ``a type''.

An adjective cluster is just one or more (possibly negated) attribute.

@<Parse expressions (\texttt{parser.pas})@>=
@<Process attributes (\texttt{parser.pas})@>@;@#

procedure GetAdjectiveCluster;
begin
   gSubexpPtr^.StartAdjectiveCluster;
   ProcessAttributes;
   gSubexpPtr^.FinishAdjectiveCluster;
end;

@ Parsing an attribute amounts to:
\enumerate
\item handling a leading ``\texttt{non}''
\item handling attribute arguments (which always occurs \emph{before}
the attribute)
\item handling the attribute.
\endenumerate

\label{ProcessAttributes:parser.pas}

@d kind_is_radix_type(#) == (# in [sy_Set,ModeSymbol,StructureSymbol])
@d ahead_is_attribute_argument == @/
      (CurWord.Kind in (TermBegSys - [sy_LeftParanthesis,StructureSymbol])) or@|
      ((CurWord.Kind = sy_LeftParanthesis) and
          not(kind_is_radix_type(AheadWord.Kind))) or@|
      ((CurWord.Kind =  StructureSymbol) and (AheadWord.Kind = sy_StructLeftBracket))

@<Process attributes (\texttt{parser.pas})@>=
procedure ProcessAttributes;
begin
   while (CurWord.Kind in [AttributeSymbol,sy_Non]) or ahead_is_attribute_argument
   do
   begin
      gSubexpPtr^.ProcessNon;
      if CurWord.Kind = sy_Non then ReadWord;
      if ahead_is_attribute_argument
      then
      begin
         gSubexpPtr^.StartAttributeArguments;
         ProcessArguments;
         gSubexpPtr^.CompleteAttributeArguments;
      end;
      if CurWord.Kind = AttributeSymbol then
      begin
         gSubexpPtr^.ProcessAttribute;
         ReadWord; @+
      end
      else
      begin
         SynErr(CurPos,paAttrExp1) @^Error, 306@>
      end;
   end;
end;

@ @<Error...@>=
   paAttrExp1            = 306;

@ \node{Parsing a radix type.} For Mizar, a Radix type is either a
structure type or a mode (or it's the ``\texttt{set}'' type).

@^Radix type@>
@^Type, radix@>

There is a comment in Polish, ``zawieszone na czas zmiany semantyki'',
which is translated into English.

\label{RadixTypeSubexpression:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure RadixTypeSubexpression;
var lSymbol,lParenthCnt: integer;
begin
   lParenthCnt:=0;
   @<Parse optional left-paren@>;
   gSubexpPtr^.ProcessModeSymbol; {(\section\xref{extSubexpObj.ProcessModeSymbol})}
   case CurWord.Kind of
      sy_Set:
         begin ReadWord; {? if Occurs(syOf) then TypeSubexpression
                          suspended while semantics change}
         end;
      ModeSymbol:
         @<Parse mode as radix type@>;
      StructureSymbol:
         @<Parse structure as radix type@>;
   othercases
   begin
      MissingWord(paWrongRadTypeBeg); @^Error, 398@>
      gSubexpPtr^.InsertIncorrType @+
   end;
   endcases; @|@/
   @<Close the parentheses@>;
   gSubexpPtr^.FinishType;
end;

@ @<Error...@>=
   paWrongRadTypeBeg      = 398;

@ @<Parse mode as radix type@>=
         begin lSymbol:=CurWord.Nr; ReadWord;
         if CurWord.Kind = sy_Of then
            if ModeMaxArgs.fList^[lSymbol] = 0 then WrongWord(paUnexpOf) @^Error, 183@>
            else begin ReadWord; GetArguments(ModeMaxArgs.fList^[lSymbol]) @+ end;
         end

@ @<Error...@>=
   paUnexpOf             = 183;


@ @<Parse structure as radix type@>=
         begin
            lSymbol:=CurWord.Nr;
            ReadWord;
            if CurWord.Kind = sy_Over then
               if StructModeMaxArgs.fList^[lSymbol] = 0
               then WrongWord(paUnexpOver) @^Error, 184@>
               else
               begin
                  ReadWord;
                  GetArguments(StructModeMaxArgs.fList^[lSymbol]) @+ 
               end;
         end

@ @<Error...@>=
   paUnexpOver           = 184;

@ @<Parse optional left-paren@>=
   if  CurWord.Kind = sy_LeftParanthesis then
   begin
      gSubexpPtr^.ProcessLeftParenthesis;
      ReadWord;
      inc(lParenthCnt);
   end

@ @<Close the parentheses@>=
   if lParenthCnt > 0 then
   begin
      gSubexpPtr^.ProcessRightParenthesis;
      Accept(sy_RightParanthesis,paRightParenthExp1);
   end

@ \node{Type subexpressions.}
Now the Parser needs a type as a subexpression in a larger
expression (e.g., the specification for a definition, or in a formula
of the form ``\<Term> \texttt{is} \<Type>''). We basically get the adjectives
with \\{GetAdjectiveCluster}, then we get the radix type 
with \\{RadixTypeSubexpression}.

\label{TypeSubexpression:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure TypeSubexpression;
begin
   gExpPtr^.CreateSubexpression;
   gSubexpPtr^.StartType;
   gSubexpPtr^.StartAttributes; @/
   GetAdjectiveCluster;
   RadixTypeSubexpression; @/
   gSubexpPtr^.CompleteAttributes;
   gSubexpPtr^.CompleteType; @/
   KillSubexpression;
end;

@ \node{Aside: parsing term subexpressions.}
The code for parsing term subexpressions (\section\xref{TermSubexpression:parser.pas})
appears here in the code for the Parser, but it felt out of place. I
thought it best to place it at the end of the subsection on parsing
Term expressions (as it is the pinnacle of Term parsing), rather
than leave it here.

@<Parse expressions (\texttt{parser.pas})@>=
@<Parse term subexpressions (\texttt{parser.pas})@>@;

@ This will parse \\{fArgsNbr} comma separated terms. It's used to
parse the arguments ``to the right'' of a term, for parsing the
contents of an enumerated set (e.g., $\{x,y,z,w\}$), among many other places.

We should recall that the \\{StartArgument} method is empty.

@<Parse expressions (\texttt{parser.pas})@>=
procedure ArgumentsTail(fArgsNbr:integer);
begin
   while (fArgsNbr > 0) and Occurs(sy_Comma) do
   begin
      gSubexpPtr^.StartArgument;
      TermSubexpression;
      gSubexpPtr^.FinishArgument;
      dec(fArgsNbr);
   end;
end;

@ Attributes, terms, predicates have terms as arguments. This relies
upon the \\{FinishArguments} method (\section\xref{extSubexpObj.FinishArgument}).

\label{GetArguments:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure GetArguments(const fArgsNbr:integer);
begin
   if fArgsNbr > 0 then
   begin
      TermSubexpression;
      gSubexpPtr^.FinishArgument;
      ArgumentsTail(fArgsNbr-1);
   end;
end;

@* [s] Formulas.
Quantified variables looks like
$$\<Variable>\ \LB\hbox{ \texttt{","} }\<Variable>\RB\ [(\hbox{\texttt{"be"}}\pipe\hbox{\texttt{"being"}})\ \<Type>]$$
The parsing routine follows the grammar fairly faithfully.

@<Parse expressions (\texttt{parser.pas})@>=
procedure QuantifiedVariables;
begin
   repeat
      gSubexpPtr^.StartQualifiedSegment;
      ReadWord;
      @<Parse comma-separated variables for quantified variables@>;
      gSubexpPtr^.StartQualifyingType;
      if Occurs(sy_Be) or Occurs(sy_Being) then TypeSubexpression;
      gSubexpPtr^.FinishQualifiedSegment;
   until CurWord.Kind <> sy_Comma;
end;

@ @<Parse comma-separated variables for quantified variables@>=
      repeat
         gSubexpPtr^.ProcessVariable;
         Accept(Identifier,paIdentExp2);
      until not Occurs(sy_Comma)

@ @<Error...@>=
   paIdentExp2           = 300;

@ The existential formula looks like
$$\hbox{\texttt{ex} }\<Quantified-Variables>\hbox{ \texttt{st} }\<Formula>$$
The Parser implements it quite faithfully.

@<Parse expressions (\texttt{parser.pas})@>=
procedure ExistentialFormula;
begin
   gSubexpPtr^.StartExistential;
   QuantifiedVariables;@/
   gSubexpPtr^.FinishQuantified;
   Accept(sy_St,paStExp); @^Error, 387@>
   FormulaSubexpression;@/
   gSubexpPtr^.FinishExistential;
end;

@ @<Error...@>=
   paStExp                = 387;

@ Universally quantified formulas are tricky because both
$$\hbox{\texttt{for }}\<Quantified-Variables>\hbox{ \texttt{holds} }\<Formula>$$
and
$$\hbox{\texttt{for }}\<Quantified-Variables>\hbox{ \texttt{st} }\<Formula>\hbox{ \texttt{holds} }\<Formula>$$
are acceptable. Furthermore, we may include multiple ``\texttt{for} \<Quantified-Variables>''
(possibly with ``\texttt{st} \<Formula>'' restrictions)
before arriving at the single ``\texttt{holds} \<Formula>''.
The trick is to parse this as
$$\hbox{\texttt{for }}\<Quantified-Variables>\ [\hbox{\texttt{st} }\<Formula>]\ [\hbox{\texttt{holds}}]\ \<Formula>$$
so the recursive call to parse the final formula enables us to parse
another quantified formula.

@<Parse expressions (\texttt{parser.pas})@>=
procedure UniversalFormula;
begin
   gSubexpPtr^.StartUniversal;
   QuantifiedVariables;
   gSubexpPtr^.FinishQuantified;
   if CurWord.Kind = sy_St then
   begin
      gSubexpPtr^.StartRestriction;
      ReadWord;
      FormulaSubexpression;
      gSubexpPtr^.FinishRestriction;
   end;
   case CurWord.Kind of
      sy_Holds:
         begin
            gSubexpPtr^.ProcessHolds;
            ReadWord @+
         end;
      sy_For, sy_Ex: ; {fallthrough}
   othercases
   begin
      gSubexpPtr^.InsertIncorrFormula;
      MissingWord(paWrongScopeBeg) @^Error, 340@>
   end;
   endcases;@#
   FormulaSubexpression;
   gSubexpPtr^.FinishUniversal;
end;

@ @<Error...@>=
   paWrongScopeBeg       = 340;

@ The Parser's current token is either ``\texttt{=}'' or a predicate
symbol. Then we should parse ``the right-hand side'' of the equation
(or formula). The current token's Symbol number is passed as the
argument to this procedure.

It's worth recalling the definition of \\{TermBegSys}
(\section\xref{TermBegSys}) which is all the token kinds for starting
a term. If the next token is a term, then |GetArguments| is invoked to
parse them.

\label{CompleteRightSideOfThePredicativeFormula:parser.pas}
@<Parse expressions (\texttt{parser.pas})@>=
procedure @? ConditionalTail; forward; @t\2@>@#

procedure CompleteRightSideOfThePredicativeFormula(aPredSymbol:integer);
begin
   gSubexpPtr^.ProcessRightSideOfPredicateSymbol;
   ReadWord;
   if CurWord.Kind in TermBegSys then
      GetArguments(PredMaxArgs.fList^[aPredSymbol]);
   gSubexpPtr^.FinishRightSideOfPredicativeFormula;
end;

@ Recall a ``multi-predicative formula'' is something of the form
$a\leq x\leq b$. More generally, we could imagine the grammar for such
a formula resembles:
$$ \<Formula>\ \LB\ \<Multi-Predicate>\ \<Term-List>\ \RB$$
The Parser's current token is \<Multi-Predicate>, and we want to keep
parsing until the entire multi-predicative formula has been parsed.

We should mention (because I have not seen it discussed anywhere)
Mizar allows ``\texttt{does not}'' and ``\texttt{do not}'' in formulas
(for example, ``\texttt{Y does not overlap X /\BS\ Z}''), but
Mizar \textbf{does not} support ``\texttt{does}'' (or ``\texttt{do}'')
without the ``\texttt{not}''. A 401 error would be raised.

Grammatically, this is known as ``do-support'', and Mizar uses it for
negating predicates. The verb following the ``do'' is a ``bare
infinitive'' (which is why Mizar allows an ``infinitive'' for
predicates). This makes sense when the predicate uses a ``finite
verb''. For ``non-finite verb forms'', it is idiomatic English to just negate
the verb (as in ``\emph{Not knowing} what that means, I just smile and nod''
and ``It would be a crime \emph{not to learn} grammar'').

@^Error, 401@>
@^Infinitive@>
@^Grammar, English@>
@:do}{\texttt{do}@>
@:does}{\texttt{does}@>
@^Do-support@>

\label{CompleteMultiPredicativeFormula:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure CompleteMultiPredicativeFormula;
begin
   gSubexpPtr^.StartMultiPredicativeFormula;
   repeat
      case CurWord.Kind of
         sy_Equal, PredicateSymbol:
            CompleteRightSideOfThePredicativeFormula(CurWord.Nr);
         sy_Does,sy_Do:
            @<Parse multi-predicate with ``\texttt{does}'' or ``\texttt{do}'' in copula@>;
      endcases;
   until not (CurWord.Kind in [sy_Equal,PredicateSymbol,sy_Does,sy_Do]);
   gSubexpPtr^.FinishMultiPredicativeFormula;
end;

@ @<Parse multi-predicate with ``\texttt{does}'' or ``\texttt{do}'' in copula@>=
            begin
               @<Consume ``\texttt{does not}'' or ``\texttt{do not}'', raise error otherwise@>;
               if CurWord.Kind in [PredicateSymbol,sy_Equal] then
               begin
                  CompleteRightSideOfThePredicativeFormula(CurWord.Nr);
                  gSubexpPtr^.ProcessNegative; @+
               end
               else
               begin
                  gSubExpPtr^.InsertIncorrFormula;
                  SynErr(CurPos,paInfinitiveExp) @^Error, 402@>
               end;
            end

@ @<Consume ``\texttt{does not}'' or ``\texttt{do not}'', raise error otherwise@>=
               gSubexpPtr^.ProcessDoesNot;
               ReadWord;
               Accept(sy_Not,paNotExpected) @^Error, 401@>

@ @<Error...@>=
   paNotExpected          = 401;
   paInfinitiveExp        = 402;

@ The Parser is trying to parse a predicate and has just parsed a
comma-separated list of terms. Now, the Parser's is
either (1) looking at a predicate or equality, or (2) has matched
``\texttt{does not}'' or ``\texttt{do not}'' and is now looking at a
predicate or equality. In both cases, the Parser tries to complete the
formula with the \\{CompletePredicativeFormula} procedure.

\label{CompletePredicativeFormula:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure CompletePredicativeFormula(aPredSymbol:integer);
begin
   gSubexpPtr^.ProcessPredicateSymbol; {(\section\xref{extSubexpObj.ProcessPredicateSymbol})}
   ReadWord;
   if CurWord.Kind in TermBegSys then
      GetArguments(PredMaxArgs.fList^[aPredSymbol]);
   gSubexpPtr^.FinishPredicativeFormula;
end;
@

\label{CompleteAtomicFormula:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure CompleteAtomicFormula(var aParenthCnt:integer);
var lPredSymbol: integer;
label Predicate; {not actually used}
begin
   @<Parse left arguments in a formula@>;
   case CurWord.Kind of
      sy_Equal,PredicateSymbol:
         @<Parse equation or (possibly infixed) predicate@>;
      sy_Does,sy_Do:
         @<Parse formula with ``\texttt{does not}'' or ``\texttt{do not}''@>;
      sy_Is:
         @<Parse formula with ``\texttt{is not}'' or ``\texttt{is not}''@>;
   othercases
   begin
      gSubexpPtr^.ProcessAtomicFormula;
      MissingWord(paWrongPredSymbol); @^Error, 321@>
      gSubexpPtr^.InsertIncorrBasic;
   end;
   endcases;
end;

@ @<Error...@>=
   paWrongPredSymbol     = 321;

@ @<Parse left arguments in a formula@>=
   repeat
      AppendFunc(aParenthCnt);
      if CurWord.Kind = sy_Comma then
      begin
         ArgumentsTail(MaxVisArgNbr-1);
         if (aParenthCnt > 0) and (CurWord.Kind = sy_RightParanthesis) then
         begin
            dec(aParenthCnt);
            gSubexpPtr^.ProcessRightParenthesis;
            ReadWord;
            if CurWord.Kind <> InfixOperatorSymbol then MissingWord(paFunctExp1); @^Error, 302@>
         end;
      end;
   until CurWord.Kind <> InfixOperatorSymbol

@ @<Error...@>=
   paFunctExp1           = 302;

@ @<Parse equation or (possibly infixed) predicate@>=
         begin
            CompletePredicativeFormula(CurWord.Nr);
            if CurWord.Kind in [sy_Equal,PredicateSymbol,sy_Does,sy_Do] then
               CompleteMultiPredicativeFormula
         end

@ @<Parse formula with ``\texttt{does not}'' or ``\texttt{do not}''@>=
         begin
            gSubexpPtr^.ProcessDoesNot;
            ReadWord;
            Accept(sy_Not,paNotExpected); @^Error, 401@>
            if CurWord.Kind in [PredicateSymbol,sy_Equal] then
            begin
               CompletePredicativeFormula(CurWord.Nr);
               gSubexpPtr^.ProcessNegative;
               if CurWord.Kind in [sy_Equal,PredicateSymbol,sy_Does,sy_Do] then
                  CompleteMultiPredicativeFormula
            end
            else
            begin
               gSubExpPtr^.InsertIncorrFormula;
               SynErr(CurPos,paInfinitiveExp) @^Error, 402@>
            end;
         end

@ @<Parse formula with ``\texttt{is not}'' or ``\texttt{is not}''@>=
         begin
            gSubexpPtr^.ProcessAtomicFormula;
            ReadWord;
            if (CurWord.Kind = sy_Not) and
                  (AheadWord.Kind in TermBegSys+
                      [ModeSymbol,StructureSymbol,sy_Set,AttributeSymbol,sy_Non]) or
                  (CurWord.Kind in TermBegSys+
                      [ModeSymbol,StructureSymbol,sy_Set,AttributeSymbol,sy_Non]) then
            begin
               gSubexpPtr^.StartType;
               gSubexpPtr^.StartAttributes;
               if CurWord.Kind = sy_Not then
               begin
                  gSubexpPtr^.ProcessNegation;
                  ReadWord; @+
               end;
               GetAdjectiveCluster;
               case CurWord.Kind of
                  sy_LeftParanthesis,ModeSymbol,StructureSymbol,sy_Set:
                     begin
                        RadixTypeSubexpression;
                        gSubexpPtr^.CompleteAttributes;
                        gSubexpPtr^.CompleteType;
                        gSubexpPtr^.FinishQualifyingFormula;
                     end;
               othercases
               begin
                  gSubexpPtr^.CompleteAttributes;
                  gSubexpPtr^.FinishAttributiveFormula; @+
               end;
               endcases;
            end
            else
            begin
               gSubExpPtr^.InsertIncorrFormula;
               WrongWord(paTypeOrAttrExp); @^Error, 309@>
            end;
         end

@ @<Error...@>=
   paTypeOrAttrExp       = 309;

@ There is a comment in Polish, a single word (``Kolejnosc'') which
translates into English as ``Order''.

@d starts_with_term_token == Numeral,LeftCircumfixSymbol,sy_It,sy_LeftCurlyBracket,sy_LeftSquareBracket,
      sy_The,sy_Dolar,StructureSymbol 

@<Parse expressions (\texttt{parser.pas})@>=
procedure ViableFormula;
var lParenthCnt:integer;
label NotPrivate;
begin
   gExpPtr^.CreateSubexpression;
   OpenParenth(lParenthCnt);
   case CurWord.Kind of
      sy_For: UniversalFormula;
      sy_Ex: ExistentialFormula;
      { !!!!!!!!!!!!!!! Order }
      sy_Contradiction:
         begin
            gSubexpPtr^.ProcessContradiction;
            ReadWord; @+
         end;
      sy_Thesis:
         begin
            gSubexpPtr^.ProcessThesis;
            ReadWord; @+
         end;
      sy_Not:
         begin
            gSubexpPtr^.ProcessNot;
            ReadWord;
            ViableFormula;
            KillSubexpression;
            gSubexpPtr^.ProcessNegative;
         end;
      Identifier:
         if AheadWord.Kind = sy_LeftSquareBracket then
         @<Parse private formula@>
         else goto NotPrivate;
      starts_with_term_token:@t\1@> @|@/
         NotPrivate:
            begin
               gSubexpPtr^.StartAtomicFormula;
               { ??? TermSubexpression }
               GetClosedSubterm;
               CompleteArgument(lParenthCnt);
               CompleteAtomicFormula(lParenthCnt);
            end@t\2@>;
      InfixOperatorSymbol,PredicateSymbol,sy_Does,sy_Do,sy_Equal:
         begin
            gSubexpPtr^.StartAtomicFormula;
            CompleteAtomicFormula(lParenthCnt);
         end;
   othercases
   begin
      gSubexpPtr^.InsertIncorrFormula;
      WrongWord(paWrongFormulaBeg) @^Error, 396@>
   end;
   endcases;
   @<Close parentheses for formula@>;
end;

@ @<Error...@>=
   paWrongFormulaBeg      = 396;

@ @<Parse private formula@>=
         begin
            gSubexpPtr^.StartPrivateFormula;
            ReadWord;
            ReadWord;
            if CurWord.Kind <> sy_RightSquareBracket
            then GetArguments(MaxVisArgNbr);
            Accept(sy_RightSquareBracket,paRightSquareExp2); @^Error, 371@>
            gSubexpPtr^.FinishPrivateFormula;
         end

@ @<Error...@>=
   paRightSquareExp2     = 371;

@ @<Close parentheses for formula@>=
   while lParenthCnt > 0 do
   begin
      ConditionalTail;
      gSubexpPtr^.ProcessRightParenthesis;
      Accept(sy_RightParanthesis,paRightParenthExp4); @^Error, 370@>
      dec(lParenthCnt);
      CloseParenth(lParenthCnt);
   end

@ @<Error...@>=
   paRightParenthExp4    = 370;

@ \node{Precedence for logical connectives.}
We will now ``hardcode'' the precedence for logical connectives into
the Mizar Parser. Negations (``\texttt{not}'') binds tighter than
conjunction (``\texttt{\AM}''), which binds tighter than disjunction
(``\texttt{or}''), which binds tighter than implication
(``\texttt{implies}'' and ``\texttt{iff}'').

At this point, for the formula ``\texttt{A \AM\ B}'', the Parser has
parsed a formula (``\texttt{A}''), and we want to parse possible
conjunctions. The current token will be ``\texttt{\AM}''. If not, then
the Parser does nothing: it's ``done''.

We will parse conjunction as left associative --- so
``\texttt{A \AM\ B \AM\ C}'' parses as ``\texttt{(A \AM\ B) \AM\ C}''.

@<Parse expressions (\texttt{parser.pas})@>=
procedure ConjunctiveTail;
begin
   while (CurWord.Kind = sy_Ampersand) and (AheadWord.Kind <> sy_Ellipsis) do
   begin
      gSubexpPtr^.ProcessBinaryConnective;
      ReadWord;
      ViableFormula;
      KillSubexpression;
      gSubexpPtr^.FinishBinaryFormula;
   end;
end;

@ Mizar parses flexary conjunctions (``$\Phi[0]$ \texttt{\AM\ \dots\ \AM}
$\Phi[n]$'') as weaker than ``ordinary conjunction''.
For example
``$\Psi$ \texttt{\AM} $\Phi[0]$ \texttt{\AM\ \dots\ \AM} $\Phi[n]$''
parses as 
``($\Psi$ \texttt{\AM} $\Phi[0]$) \texttt{\AM\ \dots\ \AM} $\Phi[n]$''.

If the user accidentally forgets the ampersand after the ellipses
(``$\Phi[0]$ \texttt{\AM\ \dots} $\Phi[n]$''), a 402 error will be
raised.

@^Error, 402@>

@<Parse expressions (\texttt{parser.pas})@>=
procedure FlexConjunctiveTail;
begin
   ConjunctiveTail;
   if CurWord.Kind = sy_Ampersand then
   begin
      Assert(AheadWord.Kind=sy_Ellipsis);
      ReadWord; ReadWord;
      Accept(sy_Ampersand,402);
      gSubexpPtr^.ProcessFlexConjunction;
      ViableFormula;
      ConjunctiveTail;
      KillSubexpression;
      gSubexpPtr^.FinishFlexConjunction;
   end;
end;

@ Disjunction binds weaker than flexary conjunction (which binds
weaker than ordinary conjunction).

As for ordinary conjunction, Mizar parses multiple disjunctions as
left associative. So ``\texttt{A or B or C}'' parses as ``\texttt{(A or B) or C}''.

@<Parse expressions (\texttt{parser.pas})@>=
procedure DisjunctiveTail;
begin
   FlexConjunctiveTail;
   while (CurWord.Kind = sy_Or) and (AheadWord.Kind <> sy_Ellipsis) do
   begin
      gSubexpPtr^.ProcessBinaryConnective;
      ReadWord;
      ViableFormula;
      FlexConjunctiveTail;
      KillSubexpression;
      gSubexpPtr^.FinishBinaryFormula;
   end;
end;

@ Parsing a disjunction will have the Parser's current token be
``\texttt{or}'' only if the next token is an ellipsis (``\texttt{...}''),
which is precisely the signal for a flexary disjunction. When the
current token is not an ``\texttt{or}'', then the Parser does nothing
(its work is done).

When the user forgets an ``\texttt{or}'' after ellipsis (e.g., writing
``\texttt{A or ... C}''), a 401 error will be raised.

@^Error, 401@>

@<Parse expressions (\texttt{parser.pas})@>=
procedure FlexDisjunctiveTail;
begin DisjunctiveTail;
if CurWord.Kind = sy_Or then
begin
   Assert(AheadWord.Kind=sy_Ellipsis);
   ReadWord; ReadWord;
   Accept(sy_Or,401);
   gSubexpPtr^.ProcessFlexDisjunction;
   ViableFormula;
   DisjunctiveTail;
   KillSubexpression;
   gSubexpPtr^.FinishFlexDisjunction;
end;
end;

@ Mizar parses ``\texttt{implies}'' and ``\texttt{iff}'' with lower
precedence than ``\texttt{or}'', matching common Mathematical
practice. Working Mathematicians read ``\texttt{A or B implies C}'' 
as ``\texttt{(A or B) implies C}''. We impose this precedence with the
|FlexDisjunctiveTail| parsing the remaining disjunctions before
checking for ``\texttt{iff}'' or ``\texttt{implies}''.

Mizar accepts one ``topmost'' implication connective. So
``\texttt{A implies B implies C}'' would be illegal (a 336 error would
be raised). You would have to insert parentheses to make this
parseable by Mizar (i.e., ``\texttt{A implies (B implies C)}'').
This makes sense for implication, but there is a
compelling argument that ``\texttt{A iff B iff C}'' could be parsed as
``\texttt{(A iff B) \AM\ (B iff C)}'' --- that latter
formula \emph{could} be parsed properly by Mizar.

@^Error, 336@>

@<Parse expressions (\texttt{parser.pas})@>=
procedure ConditionalTail;
begin
   FlexDisjunctiveTail;
   case CurWord.Kind of
      sy_Implies,sy_Iff:
         begin
            gSubexpPtr^.ProcessBinaryConnective;
            ReadWord;
            ViableFormula;
            FlexDisjunctiveTail;
            KillSubexpression;
            gSubexpPtr^.FinishBinaryFormula;
            case CurWord.Kind of
               sy_Implies, sy_Iff: WrongWord(paUnexpConnective); @^Error, 336@>
            endcases;
         end;
   endcases;
end;

@ @<Error...@>=
   paUnexpConnective     = 336;

@ \node{Formula subexpressions.} When the Parser needs a formula as a
subexpression for a larger expression --- like when it parses a
Fraenkel term (an expression), the Parser will need to parse
$$\LB\<Term>\ \<Qualifying-Segment>\hbox{ \texttt{:} }\<Formula-Subexpression>\RB$$
This will also serve as the ``workhorse'' for parsing a formula
expression. 

\label{FormulaSubexpression:parser.pas}

@<Parse expressions (\texttt{parser.pas})@>=
procedure FormulaSubexpression;
begin
   ViableFormula;
   ConditionalTail;
   KillSubexpression;
end;

@* [S] Communication with items.
When the Parser constructs the AST for a term, the workflow is as
follows:
\smallbreak
\enumerate
\item Allocate a new \\{extExpression} object, and update \\{gExprPtr}
to point at it.
\item Using the \\{gExprPtr} to allocate a new \\{extSubexp} object,
and update the \\{gSubexpPtr} to point at it.
\item The Parser will invoke methods for the \\{gSubexpPtr}'s
reference to build the AST. The result will be stored in a state
variable (like \\{gLastTerm} or \\{gLastType}).
\item There will be residual objects allocated, stored in the fields
of \\{gSubexpPtr} and \\{gExpPtr}. We need to clean those up, freeing
them, by invoking \\{KillExpression} and \\{KillSubexpression}.
\endenumerate
\smallbreak\noindent%
So each of these methods have the following template: allocate a new
expression object, update the \\{gExpPtr} to point to it, parse
something, then free the \\{gExpPtr} using the \\{KillExpression} procedure.

@<Communicate with items (\texttt{parser.pas})@>=
{{\it Communication with items}}

procedure TermExpression;
begin
   gItemPtr^.CreateExpression(exTerm);
   TermSubexpression;
   KillExpression;
end; @#

procedure TypeExpression;
begin
   gItemPtr^.CreateExpression(exType);
   TypeSubexpression;
   KillExpression;
end; @#

procedure FormulaExpression;
begin
   gItemPtr^.CreateExpression(exFormula);
   FormulaSubexpression;
   KillExpression;
end;

@* [S] Miscellaneous.
\node{Parsing a label.}
When the Parser is looking at a label, the \\{gItemPtr} will construct
the label. The Parser still needs to move past the ``\<identifier>\texttt{:}''
two tokens.

@<Process miscellany (\texttt{parser.pas})@>=
{{\it Miscellaneous}}

procedure ProcessLab;
begin
   gItemPtr^.ProcessLabel; {(\section\xref{extItemObj.ProcessLabel})}
   if (CurWord.Kind=Identifier) and (AheadWord.Kind=sy_Colon) then
   begin
      ReadWord;
      ReadWord @+
   end;
end;

@ Telling the \\{gItemPtr} state variable we are about to parse a
sentence just invokes the \\{StartSentence}
(\section\xref{extItemObj.StartSentence}) method, then the Parser
parses the formula, and the \\{gItemPtr} ``finishes'' the sentence
(which is an empty method).

@<Process miscellany (\texttt{parser.pas})@>=
procedure ProcessSentence;
begin
   gItemPtr^.StartSentence;
   FormulaExpression;
   gItemPtr^.FinishSentence;
end;

@ When the Parser expected a sentence but something unexpected
happened, specifically an unexpected statement has cross the Parser's
path. When that statement has encountered an unjustified ``\texttt{per cases}''.
We just create a new formula expression, and specifically an
``incorrect formula''.

@<Process miscellany (\texttt{parser.pas})@>=
procedure InCorrSentence;
begin
   gItemPtr^.StartSentence;
   gItemPtr^.CreateExpression(exFormula);
   gExpPtr^.CreateSubexpression;
   gSubexpPtr^.InsertIncorrFormula;
   KillSubexpression;
   KillExpression;
   gItemPtr^.FinishSentence;
end;

@ The Parser attempts to recover (or at least, report) an unexpected
item when expecting a statement. Specifically, a ``\texttt{per cases}''
appears when it should not.

@<Process miscellany (\texttt{parser.pas})@>=
procedure InCorrStatement;
begin
   gItemPtr^.ProcessLabel;
   gItemPtr^.StartRegularStatement;
   InCorrSentence;
end;

@ The Parser is looking at either
$$\hbox{\texttt{let} }\<Variables>\hbox{ \texttt{being} }\<Type>\hbox{ \texttt{such that} }\<Hypotheses>$$
or
$$\hbox{\texttt{assume that} }\<Hypotheses>$$
Specifically, the Parser has arrived at the ``\<Hypotheses>'' bit and
needs to parse it. The \<Hypotheses> generically looks like
$$\<Hypotheses> = [\<label>]\ \<Formula>\ \LB\hbox{ \texttt{and} }\<Hypotheses>\ \RB$$
That is to say, a bunch of (possibly labeled) formulas joined together
by ``\texttt{and}'' keywords.

@<Process miscellany (\texttt{parser.pas})@>=
procedure ProcessHypotheses;
begin
   repeat
      ProcessLab;
      ProcessSentence;
      gItemPtr^.FinishHypothesis;
   until not Occurs(sy_And)
end;

@ An assumption is either collective (using hypotheses) or singular (a
single, possibly labeled, formula).

@<Process miscellany (\texttt{parser.pas})@>=
procedure Assumption;
begin
   if CurWord.Kind = sy_That then
   @<Parse collective assumption@>
   else @<Parse singule assumption@>;
   gItemPtr^.FinishAssumption;
end;

@ @<Parse collective assumption@>=
   begin
      gItemPtr^.StartCollectiveAssumption; @t\unskip\hskip-1pc @> {(\section\xref{extItemObj.StartCollectiveAssumption})}@+
      ReadWord;
      ProcessHypotheses
   end

@ @<Parse singule assumption@>=
   begin
      ProcessLab;
      ProcessSentence;
      gItemPtr^.FinishHypothesis; @t\unskip\hskip-1pc @> {(\section\xref{extItemObj.FinishHypothesis})}
   end

@ \node{Fixed variables.} Existential elimination in Mizar looks like
$$\hbox{\texttt{consider} }\<Fixed-variables>\hbox{ \texttt{such that} }\<Formula>$$
The \<Fixed-variables> is just a comma-separated list of segments.

\label{FixedVariables:parser.pas}
@<Process miscellany (\texttt{parser.pas})@>=
procedure FixedVariables;
begin
   gItemPtr^.StartFixedVariables;
   repeat
      @<Parse segment of fixed variables@>;
   until not Occurs(sy_Comma);
   gItemPtr^.FinishFixedVariables;
end;

@ And a ``fixed'' segment is just a comma-separated list of variables.
This is either implicitly qualified (i.e., they are all reserved
variables) or explicitly qualified (i.e., there is a
``\texttt{being}'' or ``\texttt{be}'', followed by a type). A 300
error will be raised if the comma-separated list of variables
encounters something other than an identifier.

@^Error, 300@>

@<Parse segment of fixed variables@>=
      gItemPtr^.StartFixedSegment;
      repeat
         gItemPtr^.ProcessFixedVariable;
         Accept(Identifier,paIdentExp4);
      until not Occurs(sy_Comma);
      gItemPtr^.ProcessBeing; {parse the type qualification}
      if Occurs(sy_Be) or Occurs(sy_Being) then TypeExpression;
      gItemPtr^.FinishFixedSegment

@ @<Error...@>=
   paIdentExp4           = 300;

@ \node{Parsing `consider' statements.}
The Parser is trying to parse a ``\texttt{consider}'' statement or a
``\texttt{given}'' statement. The Parser will try to parse
$$\<Fixed-Variables>\hbox{ \texttt{such that} }\<Formula>\ \LB\hbox{ \texttt{and} }\<Formula>\ \RB$$
If the user forgot the ``\texttt{such}'' keyword, a 403 error will be
raised. If the user forgot the ``\texttt{that}'' keyword, a 350 error
will be raised.

@^Error, 350@>

@<Process miscellany (\texttt{parser.pas})@>=
procedure ProcessChoice;
begin
   FixedVariables;
   Accept(sy_Such,paSuchExp); @^Error, 403@>
   Accept(sy_That,paThatExp2); @^Error, 350@>
   repeat 
      gItemPtr^.StartCondition;
      ProcessLab;
      ProcessSentence;
      gItemPtr^.FinishCondition;
   until not Occurs(sy_And);
   gItemPtr^.FinishChoice;
end;

@ @<Error...@>=
   paThatExp2            = 350;
   paSuchExp              = 403;

@ \node{Parsing `let' statements.}
The Parser is looking at the ``\texttt{let}'' token. There are two
possible statements
$$\hbox{\texttt{let }}\<Fixed-variables>\hbox{\texttt{;}}$$
or possibly with assumptions
$$\hbox{\texttt{let }}\<Fixed-variables>\hbox{ \texttt{such that} }\<Hypotheses>\hbox{\texttt{;}}$$
If the user forgot ``\texttt{that}'' but included a ``\texttt{such}''
after the fixed-variables, a 350 error is raised.

@^Error, 350@>

@<Process miscellany (\texttt{parser.pas})@>=
procedure Generalization;
begin
   ReadWord;
   FixedVariables;
   if Occurs(sy_Such) then
   begin
      gItemPtr^.StartAssumption;
      Accept(sy_That,paThatExp1); @^Error, 350@>
      ProcessHypotheses;
      gItemPtr^.FinishAssumption;
   end;
end;

@ @<Error...@>=
   paThatExp1            = 350;

@ \node{Parsing `given' statements.}
The Parser is looking at the ``\texttt{given}'' token
currently. This is the same as ``\texttt{assume ex}
$\vec{x}$ \texttt{st} $\Phi[\vec{x}]$\texttt{; then consider}
$\vec{x}$ \texttt{such that} $\Phi[\vec{x}]$\texttt{;}''. 

@<Process miscellany (\texttt{parser.pas})@>=
procedure ExistentialAssumption;
begin
   gBlockPtr^.CreateItem(itExistentialAssumption);
   ReadWord;
   ProcessChoice;
end;

@ The Parser is looking at either ``\texttt{canceled;}'' or ``\texttt{canceled}
\<number>\texttt{;}''. 

@<Process miscellany (\texttt{parser.pas})@>=
procedure Canceled;
begin
   gBlockPtr^.CreateItem(itCanceled);
   ReadWord;
   if CurWord.Kind = Numeral then ReadWord;
   gItemPtr^.FinishTheorem;
end;

@* [S] Simple justifications.
The Parser is looking at ``\texttt{by}'' and now needs to parse the
list of references. If the user tries to use something other than a
label's identifier as a reference, then a 308 error will be raised.

@^Error, 308@>

@<Parse simple justifications (\texttt{parser.pas})@>=
{{\it Simple Justifications}}

procedure GetReferences;
begin
   gItemPtr^.StartReferences;
   repeat
      ReadWord;
      @<Parse single reference@>;
   until CurWord.Kind <> sy_Comma;
   gItemPtr^.FinishReferences;
end;

@ @<Parse single reference@>=
      case CurWord.Kind of
         MMLIdentifier:
            @<Parse library references@>;
         Identifier:
            begin
               gItemPtr^.ProcessPrivateReference;
               ReadWord @+
            end;
      othercases WrongWord(paWrongReferenceBeg); @^Error, 308@>
      endcases

@ @<Error...@>=
   paWrongReferenceBeg   = 308;

@ Mizar supports multiple references from the same article to
``piggieback'' off the same article ``anchor''. For example,
``\texttt{GROUP\_1:13,def 3,17}'' refers to theorems 13 and 17 and
definition 3 from the MML Article \texttt{GROUP\_1}.

If the user forgot to include the theorem or definition number ---
so they just wrote ``\<Article>'' instead of ``\<Article>\texttt{:}\<Number>''
or ``\<Article>\texttt{:def }\<Number>'' --- then Mizar flags this
with a 384 error.

@d no_longer_referencing_article == (CurWord.Kind <> sy_Comma) or@|
                     (AheadWord.Kind = Identifier) or (AheadWord.Kind = MMLIdentifier)

@<Parse library references@>=
            begin
               gItemPtr^.StartLibraryReferences;
               ReadWord;
               if CurWord.Kind = sy_Colon then
                  repeat
                     ReadWord;
                     gItemPtr^.ProcessDef;
                     if CurWord.Kind = ReferenceSort then
                     begin
                        if CurWord.Nr <> ord(syDef) then ErrImm(paDefExp); @^Error, 312@>
                        ReadWord;
                     end;
                     gItemPtr^.ProcessTheoremNumber;
                     Accept(Numeral,paNumExp); @^Error, 307@>
                  until no_longer_referencing_article
               else MissingWord(paColonExp4); @^Error, 384@>
               gItemPtr^.FinishTheLibraryReferences;
            end

@ @<Error...@>=
   paNumExp              = 307;
   paDefExp              = 312;
   paColonExp4            = 384;

@ The Parser is currently looking at ``\texttt{from}'', which means a
reference to a scheme identifier will be given next (possibly followed
with a comma-separated list of references in parentheses).

If the user
tries to give something else (instead of an identifier of a scheme),
then a 308 error will be raised. Also, if the user forgot the closing
parentheses around the references for the scheme (e.g., ``\texttt{from MyScheme(A1,A2}''),
then 370 error will be raised.

@^Error, 308@>
@^Error, 370@>

@<Parse simple justifications (\texttt{parser.pas})@>=
procedure GetSchemeReference;
begin
   gItemPtr^.StartSchemeReference;
   ReadWord;
   case CurWord.Kind of
      MMLIdentifier:
         @<Parse reference to scheme from MML@>;
      Identifier:
         begin
            gItemPtr^.ProcessSchemeReference;
            ReadWord @+
         end;
   othercases WrongWord(paWrongReferenceBeg); @^Error, 308@>
   endcases;
   if CurWord.Kind = sy_LeftParanthesis then
   begin
      GetReferences;
      Accept(sy_RightParanthesis,paRightParenthExp7) @^Error, 370@>
   end;
   gItemPtr^.FinishSchemeReference;
end;

@ @<Error...@>=
   paRightParenthExp7    = 370;

@ Mizar expects scheme references to the MML to be of the form
``\texttt{from} \<Article>\texttt{:sch }\<Number>''. If the user
forgot the ``\texttt{sch}'' (after the colon), a 313 error will be
raised. If the user supplies something other than a \emph{number} for
the scheme, a 307 error will be raised.

@^Error, 307@>
@^Error, 313@>

@<Parse reference to scheme from MML@>=
         begin
            gItemPtr^.StartSchemeLibraryReference;
            ReadWord;
            if CurWord.Kind = sy_Colon then
            begin
               ReadWord;
               gItemPtr^.ProcessSch;
               if CurWord.Kind = ReferenceSort then
               begin
                  if CurWord.Nr <> ord(sySch) then ErrImm(paSchExp); @^Error, 313@>
                  ReadWord;
               end
               else ErrImm(paSchExp); @^Error, 313@>
               gItemPtr^.ProcessSchemeNumber;
               Accept(Numeral,paNumExp); @^Error, 307@>
            end
            else MissingWord(paColonExp4);
            gItemPtr^.FinishSchLibraryReferences;
         end

@ @<Error...@>=
   paSchExp              = 313;

@ The Parser expects a simple justification --- i.e., either a
``\texttt{by}'' followed by some references, or ``\texttt{from}''
followed by a scheme reference. For some ``obvious'' inferences, no
justification may be needed.

@<Parse simple justifications (\texttt{parser.pas})@>=
procedure SimpleJustification;
begin
   gItemPtr^.StartSimpleJustification;
   case CurWord.Kind of
      sy_By: GetReferences;
      sy_Semicolon,sy_DotEquals: ;
      sy_From: GetSchemeReference;
   othercases WrongWord(paWrongJustificationBeg); @^Error, 395@>
   endcases;
   gItemPtr^.FinishSimpleJustification;
end;

@ @<Error...@>=
   paWrongJustificationBeg = 395;

@* [S] Statements and Reasonings.
Pragmas have been enabled which tells Mizar to skip the proof. The
Parser simply stores a counter (initialized to 1), and increments it
every time a ``\texttt{proof}'' token has been encountered, but
decrements it every time an ``\texttt{end}'' token has been encountered.
When the counter has reached zero, the proof has ended, and the Parser
can stop skipping things.

There are, of course, other blocks which use ``\texttt{end}'' to
terminate it. For example, definitions. But if the Parser should
encounter such tokens, then things have gone so horribly awry, the
Parser should just quit here and now.

@<Parse statements and reasoning (\texttt{parser.pas})@>=
{{\it Statements   \AM\   Reasonings}}

procedure @? Reasoning; forward; @t\2@>@#

procedure IgnoreProof;
var lCounter: integer; ReasPos:Position;
begin
   gBlockPtr^.StartAtSignProof;
   ReasPos:=CurPos;
   ReadTokenProc;
   lCounter:=1;
   repeat
      case CurWord.Kind of
         sy_Proof,sy_Now,sy_Hereby,sy_Case,sy_Suppose: inc(lCounter);
         sy_End: dec(lCounter);
         sy_Reserve,sy_Scheme,sy_Theorem,sy_Definition,sy_Begin,sy_Notation,
         sy_Registration,EOT:
            begin
               AcceptEnd(ReasPos);
               exit
            end;
      endcases;
      ReadTokenProc;
   until lCounter=0;
   gBlockPtr^.FinishAtSignProof;
end;

@ Parsing either a ``\texttt{by}'' justification (or a
``\texttt{from}'' justification) or a nested
``\texttt{proof}'' block. If the Parser is looking at neither
situation, the \\{SimpleJustification} procedure will raise errors.

\label{Justification:parser.pas}

@d parse_proof == 
         if ProofPragma then Reasoning
         else IgnoreProof

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure Justification;
begin
   gItemPtr^.StartJustification;
   case CurWord.Kind of
      sy_Proof: parse_proof;
   othercases SimpleJustification;
   endcases;
   gItemPtr^.FinishJustification;
end;

@ For private predicates (``\texttt{defpred}'') and private functors
(``\texttt{deffunc}''), there will be a list of comma-separated types
for the arguments of the private definition.

@d parse_comma_separated_types ==
      repeat
         TypeExpression;
         gItemPtr^.FinishLocusType
      until not Occurs(sy_Comma)
@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure ReadTypeList;
begin
   case CurWord.Kind of
      sy_RightSquareBracket,sy_RightParanthesis:;
   othercases parse_comma_separated_types;
   endcases;
end;

@ A \define{Private Item} is a statement (``item'') which introduces a
new constant local (``private'') to the block or article.

@d other_regular_statements == 
      Identifier,sy_Now,sy_For,sy_Ex,sy_Not,sy_Thesis,sy_LeftSquareBracket,
      sy_Contradiction,PredicateSymbol,sy_Does,sy_Do,sy_Equal,InfixOperatorSymbol,
      Numeral,LeftCircumfixSymbol,sy_LeftParanthesis,sy_It,sy_Dolar,
      StructureSymbol,sy_The,sy_LeftCurlyBracket,sy_Proof

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure @? RegularStatement; forward@t\2@>; {(\section\xref{RegularStatement:parser.pas})} 

procedure PrivateItem;
begin
   gBlockPtr^.ProcessLink;
   if CurWord.Kind = sy_Then then ReadWord;
   case CurWord.Kind of
      sy_Deffunc:
         @<Parse a ``\texttt{deffunc}''@>;
      sy_Defpred:
         @<Parse a ``\texttt{defpred}''@>;
      sy_Set:
         @<Parse a ``\texttt{set}'' constant definition@>;
      sy_Reconsider:
         @<Parse a ``\texttt{reconsider}'' statement@>;
      sy_Consider:
         begin
            gBlockPtr^.CreateItem(itChoice);
            ReadWord;
            ProcessChoice;
            SimpleJustification;
         end;
      other_regular_statements:
         begin
            gBlockPtr^.CreateItem(itRegularStatement);
            RegularStatement; @+
         end;
   othercases
   begin
      gBlockPtr^.CreateItem(itIncorrItem);
      WrongWord(paWrongItemBeg); @^<Error, 391@>
   end;
   endcases;
end;

@ @<Error...@>=
   paWrongItemBeg         = 391;

@ @<Parse a ``\texttt{deffunc}''@>=
         begin
            gBlockPtr^.CreateItem(itPrivFuncDefinition);
            ReadWord;
            gItemPtr^.StartPrivateDefiniendum;
            Accept(Identifier,paIdentExp6);
            Accept(sy_LeftParanthesis,paLeftParenthExp);
            ReadTypeList;
            Accept(sy_RightParanthesis,paRightParenthExp8);
            gItemPtr^.StartPrivateDefiniens;
            Accept(sy_Equal,paEqualityExp1); @^Error, 380@>
            TermExpression;
            gItemPtr^.FinishPrivateFuncDefinienition;
         end

@ @<Error...@>=
   paIdentExp6           = 300; @^Error, 300@>
   paLeftParenthExp      = 360; @^Error, 360@>
   paRightParenthExp8    = 370; @^Error, 370@>
   paEqualityExp1         = 380; @^Error, 380@>

@ @<Parse a ``\texttt{defpred}''@>=
         begin
            gBlockPtr^.CreateItem(itPrivPredDefinition);
            ReadWord;
            gItemPtr^.StartPrivateDefiniendum;
            Accept(Identifier,paIdentExp7);
            Accept(sy_LeftSquareBracket,paLeftSquareExp);
            ReadTypeList;
            Accept(sy_RightSquareBracket,paRightSquareExp4);
            gItemPtr^.StartPrivateDefiniens;
            Accept(sy_Means,paMeansExp);
            FormulaExpression;
            gItemPtr^.FinishPrivatePredDefinienition;
         end

@ @<Error...@>=
   paIdentExp7           = 300; @^Error, 300@>
   paLeftSquareExp       = 361; @^Error, 361@>
   paRightSquareExp4     = 371; @^Error, 371@>
   paMeansExp             = 386; @^Error, 386@>

@ @<Parse a ``\texttt{set}'' constant definition@>=
         begin
            gBlockPtr^.CreateItem(itConstantDefinition);
            ReadWord;
            repeat
               gItemPtr^.StartPrivateConstant;
               Accept(Identifier,paIdentExp8);
               Accept(sy_Equal,paEqualityExp2); @^Error, 380@>
               TermExpression;
               gItemPtr^.FinishPrivateConstant;
            until not Occurs(sy_Comma);
         end
@ @<Error...@>=
   paIdentExp8           = 300; @^Error, 300@>
   paEqualityExp2         = 380; @^Error, 380@>

@ @<Parse a ``\texttt{reconsider}'' statement@>=
         begin
            gBlockPtr^.CreateItem(itReconsider);
            ReadWord;
            repeat
               gItemPtr^.ProcessReconsideredVariable;
               Accept(Identifier,paIdentExp9); @^Error, 300@>
               case CurWord.Kind of
                  sy_Equal:
                     begin
                        ReadWord;
                        TermExpression;
                        gItemPtr^.FinishReconsideredTerm;
                     end;
               else gItemPtr^.FinishDefaultTerm;
               end;
            until not Occurs(sy_Comma);
            gItemPtr^.StartNewType;
            Accept(sy_As,paAsExp); @^Error, 388@>
            TypeExpression;
            gItemPtr^.FinishReconsidering;  
            SimpleJustification;
         end

@ @<Error...@>=
   paIdentExp9           = 300; @^Error, 300@>
   paAsExp                = 388; @^Error, 388@>

@ The \\{SetParserPragma} toggles the state variables for skipping
proofs, and storing the pragma in the AST is handled by
the \\{gBlockPtr}'s method call.

\label{ProcessPragmas:parser}

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure ProcessPragmas;
begin
   while CurWord.Kind = Pragma do
   begin
      SetParserPragma(CurWord.Spelling); {(\section\xref{SetParserPragma})}
      gBlockPtr^.ProcessPragma; {(\section\xref{extBlockObj.ProcessPragma})}
      ReadTokenProc;
   end;
end;

@ \node{Reasoning items.} The ``linear reasoning'' portion of the
Parser corresponds to what ``Mizar in a Nutshell'' refers to as a
sequence of ``Reasoning Items''. Basically, everything exception
``\texttt{per cases}''.

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure LinearReasoning;
begin
   while CurWord.Kind <> sy_End do
   begin
      StillCorrect:=true;
      ProcessPragmas;
      @<Parse statement of linear reasoning@>; @/
      Semicolon;
   end;
end;

@ Most statements are delegated to their own dedicated function.

@<Parse statement of linear reasoning@>=
      case CurWord.Kind of
         sy_Let:
            begin
               gBlockPtr^.CreateItem(itGeneralization);
               Generalization; @+
            end;
         sy_Given: ExistentialAssumption;
         sy_Assume:
            begin
               gBlockPtr^.CreateItem(itAssumption);
               ReadWord;
               Assumption; @+
            end;
         sy_Take:
            @<Parse ``\texttt{take}'' statement for linear reasoning@>;
         sy_Hereby:
            begin
               gBlockPtr^.CreateItem(itConclusion);
               Reasoning; @+
            end;
@t\4@>    @<Parse ``\texttt{thus}'' and ``\texttt{hence}'' for linear reasoning@>;
         sy_Per: exit;
         sy_Case,sy_Suppose: exit;
         sy_Reserve,sy_Scheme,sy_Theorem,sy_Definition,sy_Begin,sy_Notation,
         sy_Registration,EOT: exit;
         sy_Then:
            @<Parse ``\texttt{then}'' for linear reasoning@>;
      othercases
         PrivateItem;
      endcases

@ \node{Take statements.}
We recall the syntax for a ``\texttt{take}'' statement:
$$\hbox{\texttt{take} }(\<Term>\ \pipe\ \<Variable> = \<Term>)\ \LB\hbox{\texttt{","} }(\<Term>\ \pipe\ \<Variable> = \<Term>)\RB$$
That is, a comma-separated list of either (1) terms, or (2) a variable
equal to a term.

@<Parse ``\texttt{take}'' statement for linear reasoning@>=
            begin
               gBlockPtr^.CreateItem(itExemplification);
               ReadWord;
               repeat
                  if (CurWord.Kind=Identifier) and (AheadWord.Kind=sy_Equal) then
                  begin
                     gItemPtr^.ProcessExemplifyingVariable;
                     ReadWord;
                     ReadWord;
                     TermExpression;
                     gItemPtr^.FinishExemplifyingVariable;
                  end
                  else
                  begin
                     gItemPtr^.StartExemplifyingTerm;
                     TermExpression;
                     gItemPtr^.FinishExemplifyingTerm;
                  end;
               until not Occurs(sy_Comma);
            end

@ \node{Thus statements.} Both ``\texttt{thus}'' and
``\texttt{hence}'' (which is syntactic sugar for ``\texttt{then
thus}'') are parsed similarly. So it bears studying them in parallel.
The ``heavy lifting'' is handled by the \\{RegularStatement} for
parsing the formula. But the \\{gBlockPtr} state variable ``primes the pump''
by creating a ``conclusion'' statement.

@<Parse ``\texttt{thus}'' and ``\texttt{hence}'' for linear reasoning@>=
         sy_Hence:
            begin
               gBlockPtr^.ProcessLink;
               ReadWord;
               gBlockPtr^.CreateItem(itConclusion);
               RegularStatement;
            end;
         sy_Thus:
            begin
               ReadWord;
               gBlockPtr^.ProcessLink;
               if CurWord.Kind = sy_Then then ReadWord;
               gBlockPtr^.CreateItem(itConclusion);
               RegularStatement;
            end

@ \node{Parsing `then' linked statements.}

@<Parse ``\texttt{then}'' for linear reasoning@>=
            begin
               if AheadWord.Kind = sy_Per then
               begin
                  gBlockPtr^.ProcessLink;
                  ReadWord;
                  exit; @+
               end
               else
                  PrivateItem;
            end


@ \node{Non-block Reasoning.} The Parser has just encountered a
``\texttt{per cases}'' statement. Now it must parse
``\texttt{suppose}'' items.


@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure NonBlockReasoning;
var CasePos: Position; lCaseKind:TokenKind;
   @<Process ``\texttt{case}'' (local procedure)@>;

begin
   case CurWord.Kind of
      sy_Per,sy_Case,sy_Suppose:
         begin
            gBlockPtr^.CreateItem(itPerCases);
            @<Consume ``\texttt{per cases}'', raise an error if they're missing@>;
            if (CurWord.Kind <> sy_Case) and (CurWord.Kind <> sy_Suppose) then
            @<Try to synchronize after failing to find initial `\texttt{case}' or `\texttt{suppose}'@>;
            repeat
               @<Parse ``\texttt{suppose}'' or ``\texttt{case}'' block@>;
            until (Curword.Kind = sy_End);
         end;
   endcases;
end;

@ Each ``\texttt{case}'' or ``\texttt{suppose}'' block consists of
zero or more linear reasoning items, followed possibly by an optional
``non-block reasoning'' proof (i.e., another nested ``\texttt{per cases}''
proof by cases).

@<Process ``\texttt{case}'' (local procedure)@>=
   procedure ProcessCase;
   begin
      Assumption;
      Semicolon;
      LinearReasoning;
      if CurWord.Kind = sy_Per then
         NonBlockReasoning;
      KillBlock;
      AcceptEnd(CasePos);
      Semicolon;
   end

@ The Parser looks for ``\texttt{per cases}'' tokens, and some simple
justification for the statement. If ``\texttt{per}'' is missing, a 231
error is raised. If the ``\texttt{cases}'' is missing, a 351 error is raised.
When this code chunk is done, the Parser is looking at either a
``\texttt{suppose}'' token or a ``\texttt{case}'' token.

@^Error, 231@>
@^Error, 351@>

@<Consume ``\texttt{per cases}'', raise an error if they're missing@>=
            Accept(sy_Per,paPerExp); @^Error, 231@>
            Accept(sy_Cases,paCasesExp); @^Error, 351@>
            SimpleJustification; 
            Semicolon;
            lCaseKind:=CurWord.Kind

@ @<Error...@>=
   paPerExp              = 231;
   paCasesExp            = 351;

@ The Parser is expecting ``\texttt{suppose}'' or ``\texttt{case}''
after the ``\texttt{per cases}'' statement. But if the Parser fails to
find either of these tokens, it \emph{should} enter panic mode.

Like a person falling off a cliff reaches out for something to grab,
the Parser in panic mode seeks something to ``grab on to'' so the
Parser can ``soldier on''. The technical term for this situation is
that the Parser is trying to ``synchronize'' (usually people just talk
about ``synchronization'').

Mizar raises a 232 error.

@^Error, 232@>

@<Try to synchronize after failing to find initial `\texttt{case}' or `\texttt{suppose}'@>=
            begin
               MissingWord(paSupposeOrCaseExp); @^Error, 232@>
               lCaseKind:=sy_Suppose;
               gBlockPtr^.CreateItem(itCaseBlock);
               gBlockPtr^.CreateBlock(blSuppose);
               gBlockPtr^.CreateItem(itSupposeHead);
               StillCorrect:=true;
               CasePos:=CurPos;
               ProcessCase;
            end

@ @<Error...@>=
   paSupposeOrCaseExp    = 232;

@ @<Parse ``\texttt{suppose}'' or ``\texttt{case}'' block@>=
               while (CurWord.Kind = sy_Case) or (CurWord.Kind = sy_Suppose) do
               @<Parse contents of ``\texttt{suppose}'' block@>;
               case Curword.Kind of
                  sy_Reserve,sy_Scheme,sy_Theorem,sy_Definition,sy_Begin,sy_Notation,
                  sy_Registration,EOT: exit;
                  sy_End: ;
               othercases
               @<Synchronize after missing `\texttt{suppose}' or `\texttt{case}' token@>;
               endcases

@ Parsing the contents of a ``\texttt{suppose}'' or ``\texttt{case}''
block requires creating a new block (for the, you know, block) and
creating a new item for the ``\texttt{suppose} \<Formula>'' or
``\texttt{case} \<Formula>'' statement.

If the user tries to ``mix and match'' the different kind of
suppositions (i.e., ``\texttt{case}'' and ``\texttt{suppose}''), then
a 58 error should be raised.

@:Error, 058}{Error, 58@>

@d create_supposition_block ==
                  if lCaseKind = sy_Case then gBlockPtr^.CreateBlock(blCase)
                  else gBlockPtr^.CreateBlock(blSuppose)
@d create_supposition_head ==
                  if lCaseKind = sy_Case then gBlockPtr^.CreateItem(itCaseHead)
                  else gBlockPtr^.CreateItem(itSupposeHead)
@<Parse contents of ``\texttt{suppose}'' block@>=
               begin
                  gBlockPtr^.CreateItem(itCaseBlock);
                  create_supposition_block;
                  CasePos:=CurPos;
                  StillCorrect:=true;
                  create_supposition_head;
                  if CurWord.Kind <> lCaseKind then ErrImm(58); 
                  ReadWord;
                  ProcessCase;
               end

@ @<Synchronize after missing `\texttt{suppose}' or `\texttt{case}' token@>=
               begin
                  MissingWord(paSupposeOrCaseExp);  @^Error, 232@>
                  gBlockPtr^.CreateItem(itCaseBlock);
                  create_supposition_block;
                  create_supposition_head;
                  StillCorrect:=true;
                  CasePos:=CurPos;
                  ProcessCase;
               end

@ \node{Reasoning.} The Parser is looking at ``\texttt{proof}'',
``\texttt{hereby}'', or ``\texttt{now}''. The syntax for Mizar says
that we should expect linear reasoning statements, followed by
non-block reasoning (i.e., at most
one ``\texttt{per cases}'' statement, and then ``\texttt{suppose}'' or
``\texttt{case}'' blocks).

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure Reasoning;
var ReasPos: Position;
begin
   ReasPos:=CurPos;
   case CurWord.Kind of
      sy_Proof:
         begin
            gBlockPtr^.CreateBlock(blProof);
            ReadTokenProc; @+
         end;
      sy_Hereby:
         begin
            gBlockPtr^.CreateBlock(blHereby);
            ReadTokenProc; @+
         end;
      sy_Now:
         begin
            gBlockPtr^.CreateBlock(blDiffuse);
            ReadTokenProc; @+
         end;
   othercases
   begin
      gBlockPtr^.CreateBlock(blProof);
      WrongWord(paProofExp); @^Error, 389@>
   end;
   endcases; @#
   LinearReasoning;
   NonBlockReasoning;
   KillBlock;
   AcceptEnd(ReasPos);
end;

@ @<Error...@>=
   paProofExp             = 389;

@ \node{Regular statements.} A regular statement is one of the
following:
\enumerate
\item ``\texttt{now}'' followed by reasoning;
\item A sentence (i.e., possibly labeled formula) followed by a
  ``\texttt{proof}'' block;
\item Iterative equalities.
\endenumerate

\label{RegularStatement:parser.pas}

@<Parse statements and reasoning (\texttt{parser.pas})@>=
procedure RegularStatement;
begin
   ProcessLab;
   gItemPtr^.StartRegularStatement;
   case CurWord.Kind of
      sy_Now: Reasoning;
   othercases
   begin
      ProcessSentence;
      case CurWord.Kind of
         sy_Proof:
            @<Parse ``\texttt{proof}'' block@>;
      othercases
      begin
         gItemPtr^.StartJustification;
         SimpleJustification;
         gItemPtr^.FinishJustification;
         gItemPtr^.FinishCompactStatement;
         while CurWord.Kind = sy_DotEquals do
         @<Parse iterative equations@>;
      end;
      endcases;
   end;
   endcases;
end;

@ @<Parse ``\texttt{proof}'' block@>=
            begin
               gItemPtr^.StartJustification;
               if ProofPragma then Reasoning else IgnoreProof;
               gItemPtr^.FinishJustification;
            end

@ @<Parse iterative equations@>=
         begin
            gItemPtr^.StartIterativeStep;
            ReadWord;
            TermExpression;
            gItemPtr^.ProcessIterativeStep; 
            gItemPtr^.StartJustification;
            SimpleJustification;
            gItemPtr^.FinishJustification;
            gItemPtr^.FinishIterativeStep;
         end

@* [S] Patterns.
Visible arguments (compared to ``hidden arguments'') appear to the
left or right of a functor or predicate (or to the left of an
attribute, or to the right of a mode or
structure). The \\{gVisibleNbr} state variable is initialized to zero
when the Parser starts parsing visible arguments, and the Parser
increments it for each visible argument in the pattern.

If a non-identifier appears in a pattern, Mizar raises a 300 error. So
you cannot be clever and try to trick Mizar into thinking ``\texttt{0 + x}''
is a pattern.

@^Error, 300@>
\label{GetVisible:parser.pas}

@<Parse patterns (\texttt{parser.pas})@>=
{{\it Patterns}}

var gVisibleNbr: integer;

procedure GetVisible;
begin
   gItemPtr^.ProcessVisible; {(\section\xref{extItemObj.ProcessVisible})}
   inc(gVisibleNbr);
   Accept(Identifier,paIdentExp3); @^Error, 300@>
end;

@ @<Error...@>=
   paIdentExp3           = 300;

@ We will need to Parse a comma-separated list of identifiers when
determining a pattern.

@<Parse patterns (\texttt{parser.pas})@>=
procedure ReadVisible;
begin
   gItemPtr^.StartVisible;
   gVisibleNbr:=0;
   repeat
      GetVisible;
   until not Occurs(sy_Comma);
   gItemPtr^.FinishVisible; 
end;

@ There are two cases to consider when determining the pattern for a
mode: either the Parser is looking at ``\texttt{set}'' as a type,
or---the more interesting case---the Parser is looking at an
identifier which appears in a vocabulary file as a mode symbol. 

@<Parse patterns (\texttt{parser.pas})@>=
procedure GetModePattern;
var lModesymbol:integer;
begin
   gItemPtr^.StartModePattern; {(\section\xref{extItemObj.StartModePattern})}
   case CurWord.Kind of
      sy_Set:
         @<Parse pattern for ``\texttt{set}'' as a mode@>;
      ModeSymbol:
         @<Parse pattern for a mode symbols@>
   othercases WrongWord(paWrongModePatternBeg); @^Error, 303@>
   endcases; @/
   gItemPtr^.FinishModePattern; {(\section\xref{extItemObj.FinishModePattern})}
end;

@ @<Error...@>=
   paWrongModePatternBeg = 303;

@ @<Parse pattern for ``\texttt{set}'' as a mode@>=
         begin
            if AheadWord.Kind = sy_Of then WrongWord(paWrongModePatternSet) @^Error, 315@>
            else ReadWord;
         end

@ @<Error...@>=
   paWrongModePatternSet = 315;

@ The ``\<Kind>\\{MaxArgs}'' entry is initialized to |$FF| before
|ReadVisible| is invoked, which is \PASCAL/ for $\H{FF}=255$. So if
the \\{ModeMaxArgs} entry for the mode symbol is (1) less than the
number of arguments parsed, or (2) uninitialized; then we should
update its entry with the \\{gVisibleNbr} state variable's current value.

@d get_index_compare_to_default(#) == [#] = $FF
@d entry_is_unitialized(#) == #.fList^get_index_compare_to_default

@<Parse pattern for a mode symbols@>=
         begin
            lModeSymbol:=CurWord.Nr;
            gVisibleNbr:=0;
            ReadWord;
            gItemPtr^.ProcessModePattern;
            if Occurs(sy_Of) then ReadVisible;
            if (ModeMaxArgs.fList^[lModeSymbol] < gVisibleNbr) or
                  (entry_is_uninitialized(ModeMaxArgs)(lModeSymbol)) then
               ModeMaxArgs.fList^[lModeSymbol] := gVisibleNbr;
         end

@ Parsing the visible arguments for a functor relies on this helper function.

@^Error, 370@>

@<Parse patterns (\texttt{parser.pas})@>=
procedure ReadParams;
begin
   if Occurs(sy_LeftParanthesis) then
   begin
      ReadVisible;
      Accept(sy_RightParanthesis,paRightParenthExp5) @^Error, 370@>
   end
   else if CurWord.Kind = Identifier then
   begin
      gItemPtr^.StartVisible;
      GetVisible;
      gItemPtr^.FinishVisible; @+
   end;
end;

@ @<Error...@>=
   paRightParenthExp5    = 370;

@ Attribute patterns allows for arguments \emph{only on the right} of
the attribute symbol, i.e., something like
$$\hbox{\texttt{attr} } \underbrace{\<Identifier>\hbox{ \texttt{is} }\<Arguments>\ \<Attribute-Name>}_{{\rm pattern}}\hbox{ \texttt{means}}\dots$$

\label{GetAttrPattern:parser.pas}


@^Error, 306@>
@^Error, 370@>
@^Error, 383@>

@<Parse patterns (\texttt{parser.pas})@>=
procedure GetAttrPattern;
begin
   gItemPtr^.StartAttributePattern;
   gVisibleNbr:=0;
   GetVisible;
   gItemPtr^.ProcessAttributePattern;
   Accept(sy_Is,paIsExp); @^Error, 383@>
   if Occurs(sy_LeftParanthesis) then
   begin
      ReadVisible;
      Accept(sy_RightParanthesis,paRightParenthExp11) @^Error, 370@>
   end
   else if CurWord.Kind = Identifier then ReadVisible;
   gItemPtr^.FinishAttributePattern;
   Accept(AttributeSymbol,paAttrExp2); @^Error, 306@>
end;

@ @<Error...@>=
   paAttrExp2            = 306;
   paRightParenthExp11   = 370;
   paIsExp                = 383;

@ Functor patterns generically look like:
$$\hbox{\texttt{func} }\underbrace{\<Arguments>\ \<Identifier>\ \<Arguments>}_{{\rm pattern}}\hbox{ \texttt{->}}\dots$$
or
$$\hbox{\texttt{func} }\underbrace{\<Left-Bracket>\ \<Arguments>\ \<Right-Bracket>}_{{\rm pattern}}\hbox{ \texttt{->}}\dots$$

\label{GetFuncPattern:parser.pas}

@<Parse patterns (\texttt{parser.pas})@>=
procedure GetFuncPattern;
begin
   gItemPtr^.StartFunctorPattern;
   case CurWord.Kind of
      Identifier,InfixOperatorSymbol,sy_LeftParanthesis:
         @<Parse infix functor pattern@>;
      LeftCircumfixSymbol,sy_LeftSquareBracket,sy_LeftCurlyBracket:
         @<Parse bracket functor pattern@>;
   othercases
   begin
      WrongWord(paWrongFunctorPatternBeg); @^Error, 399@>
      gItemPtr^.FinishFunctorPattern; @+
   end;
   endcases;
end;

@ @<Error...@>=
   paWrongFunctorPatternBeg = 399;

@ @<Parse infix functor pattern@>=
         begin
            ReadParams;
            gItemPtr^.ProcessFunctorSymbol; { (\section\xref{extItemObj.ProcessFunctorSymbol}) }
            Accept(InfixOperatorSymbol,paFunctExp2); @^Error, 302@>
            ReadParams;
            gItemPtr^.FinishFunctorPattern;
         end

@ @<Error...@>=
   paFunctExp2           = 302;

@ @<Parse bracket functor pattern@>=
         begin
            ReadWord;
            ReadVisible;
            gItemPtr^.FinishFunctorPattern;
            case Curword.Kind of
               sy_RightSquareBracket,sy_RightCurlyBracket,sy_RightParanthesis: ReadWord;
            othercases Accept(RightCircumfixSymbol,paRightBraExp2); @^Error, 310@>
            endcases;
         end

@ @<Error...@>=
   paRightBraExp2        = 310;

@ Predicate patterns resemble infix functor patterns.

\label{GetPredPattern:parser.pas}
@<Parse patterns (\texttt{parser.pas})@>=
procedure GetPredPattern;
var lPredSymbol: integer;
begin
   gItemPtr^.StartPredicatePattern;
   if CurWord.Kind = Identifier then ReadVisible;
   gItemPtr^.ProcessPredicateSymbol;
   case CurWord.Kind of
      sy_Equal,PredicateSymbol:
         @<Parse predicate pattern@>;
   othercases WrongWord(paWrongPredPattern); @^Error, 301@>
   endcases;
   gItemPtr^.FinishPredicatePattern;
end;

@ @<Error...@>=
   paWrongPredPattern    = 301;

@ @<Parse predicate pattern@>=
         begin
            lPredSymbol:=CurWord.Nr;
            if CurWord.Kind =sy_Equal then lPredSymbol:=EqualitySym;
            gVisibleNbr:=0;
            ReadWord;
            if CurWord.Kind = Identifier then ReadVisible;
            if (PredMaxArgs.fList^[lPredSymbol] < gVisibleNbr) or
                  (entry_is_uninitialized(PredMaxArgs)(lPredSymbol)) then
               PredMaxArgs.fList^[lPredSymbol] := gVisibleNbr;
         end

@ The ``specification'' (appearing in a non-expandable mode and
functor definitions) refers to the ``\texttt{->} \<Type>'' portion
which gives the type for the functor or mode.

@<Parse patterns (\texttt{parser.pas})@>=
procedure Specification;
begin
   gItemPtr^.StartSpecification;
   Accept(sy_Arrow,paArrowExp1); @^Error, 385@>
   TypeExpression;
   gItemPtr^.FinishSpecification;
end;

@ @<Error...@>=
   paArrowExp1            = 385;

@ Parsing a structure pattern is a bit misleading. Unlike the previous
procedures, this will actually parse the entirety of a structure
definition:
$$\hbox{\texttt{struct }}\<Identifier>\hbox{ \texttt{(} }\<Types>\hbox{ \texttt{)}}\hbox{ \texttt{(\#} } \<Fields>\hbox{ \texttt{\#)}}$$

@<Parse patterns (\texttt{parser.pas})@>=
procedure GetStructPatterns;
var lStructureSymbol: integer;
begin
   gBlockPtr^.CreateItem(itDefStruct);
   ReadWord;
   @<Parse ancestors of structure, if there are any@>;
   @<Parse ``\texttt{over}'' and any structure arguments, if any@>;
   gItemPtr^.StartFields; @/
   @<Update max arguments for structure symbol, if needed@>;
   @<Parse the fields of the structure definition@>;
end;

@ @<Parse ancestors of structure, if there are any@>=
   if CurWord.Kind = sy_LeftParanthesis then
   begin
      repeat
         gItemPtr^.StartPrefix;
         ReadWord;
         TypeExpression;
         gItemPtr^.FinishPrefix;
      until CurWord.Kind <> sy_Comma;
      Accept(sy_RightParanthesis,paRightParenthExp6); @^Error, 370@>
   end

@ @<Error...@>=
   paRightParenthExp6    = 370;

@ @<Parse ``\texttt{over}'' and any structure arguments, if any@>=
   gItemPtr^.ProcessStructureSymbol;
   lStructureSymbol := $FF;
   if CurWord.Kind = StructureSymbol then lStructureSymbol:=CurWord.Nr;
   Accept(StructureSymbol,paStructExp1); @^Error, 304@>
   if Occurs(sy_Over) then ReadVisible

@ @<Error...@>=
   paStructExp1          = 304;

@ @<Update max arguments for structure symbol, if needed@>=
   if lStructureSymbol <> $FF then
      if (StructModeMaxArgs.fList^[lStructureSymbol] < gVisibleNbr) or
            (entry_is_uninitialized(StructModeMaxArgs)(lStructureSymbol)) then
         StructModeMaxArgs.fList^[lStructureSymbol] := gVisibleNbr

@ @<Parse the fields of the structure definition@>=
   Accept(sy_StructLeftBracket,paLeftDoubleExp3); @^Error, 363@>
   repeat
      @<Parse field for the structure definition@>;
   until not Occurs(sy_Comma);
   gItemPtr^.FinishFields;
   Accept(sy_StructRightBracket,paRightDoubleExp2) @^Error, 373@>

@ @<Error...@>=
   paLeftDoubleExp3      = 363;
   paRightDoubleExp2     = 373;

@ @<Parse field for the structure definition@>=
      gItemPtr^.StartAggrPattSegment;
      repeat
         gItemPtr^.ProcessField;
         Accept(SelectorSymbol,paSelectExp1); @^Error, 305@>
      until not Occurs(sy_Comma);
      Specification;
      gItemPtr^.FinishAggrPattSegment

@ @<Error...@>=
   paSelectExp1          = 305;

@* [S] Definitions.
Non-expandable modes, i.e., modes of the form
$$\hbox{\texttt{mode} }\<Identifier>\hbox{ \texttt{of} }\<Arguments>\hbox{ \texttt{->} }\<Type>\hbox{ \texttt{means} }\<Formula>$$

@<Parse definitions (\texttt{parser.pas})@>=
{{\it Definitions}}

procedure ConstructionType;
begin
   gItemPtr^.StartConstructionType; {(\section\xref{extItemObj.StartConstructionType})}
   if CurWord.Kind = sy_Arrow then
   begin
      ReadWord;
      TypeExpression @+
   end;
   gItemPtr^.FinishConstructionType; {(\section\xref{extItemObj.FinishConstructionType})}
end;

@ Parsing correctness conditions amounts to looping through every
``\<Correctness> \<Justification>\texttt{;}'' statement, with a
fallback ``\texttt{correctness} \<Justification>\texttt{;}''
correctness condition.

There is a comment, ``o jaki tu item chodzi? definitional-item?'',
which Google translates from Polish as, ``What item are we talking
about here? Definitional-item?'' I have swapped this into the code snippet.

\label{Correctness:parser.pas}

@<Parse definitions (\texttt{parser.pas})@>=
procedure Correctness;
begin
   while CurWord.Kind = sy_CorrectnessCondition do
   begin
      StillCorrect:=true;
      gBlockPtr^.CreateItem(itCorrCond);
      ReadWord;
      Justification; 
      Semicolon;
   end;
   gItemPtr^.ProcessCorrectness; {(\section\xref{extItemObj.ProcessCorrectness}) What item are we talking about here? Definitional-item?}
   if CurWord.Kind = sy_Correctness then {``\texttt{correctness}'' catchall}
   begin
      StillCorrect:=true;
      gBlockPtr^.CreateItem(itCorrectness);
      ReadWord;
      Justification; 
      Semicolon;
   end;
end;
@

\label{Definition:parser.pas}
@<Parse definitions (\texttt{parser.pas})@>=
procedure Definition;
var lDefKind: TokenKind;
lDefiniensExpected: boolean;
begin
   lDefKind:=CurWord.Kind;
   lDefiniensExpected:=true;
   case CurWord.Kind of
      sy_Mode:
         @<Parse mode definition@>;
      sy_Attr:
         begin
            gBlockPtr^.CreateItem(itDefAttr);
            ReadWord;
            GetAttrPattern; @+
         end;
      sy_Struct:
         begin
            GetStructPatterns;
            lDefiniensExpected:=false; @+
         end;
      sy_Func:
         begin
            gBlockPtr^.CreateItem(itDefFunc);
            ReadWord;
            GetFuncPattern;
            ConstructionType;
         end;
      sy_Pred:
         begin
            gBlockPtr^.CreateItem(itDefPred);
            ReadWord;
            gItemPtr^.StartDefPredicate;
            GetPredPattern;
         end;
   endcases;
   if lDefiniensExpected then
      @<Parse definiens@>;
   Semicolon;
   Correctness;
   while (CurWord.Kind = sy_Property) do
   begin
      gBlockPtr^.CreateItem(itProperty);
      StillCorrect:=true;
      ReadWord;
      Justification;
      Semicolon;
   end;
   gBlockPtr^.FinishDefinition;
end;

@ @<Parse mode definition@>=
         begin
            gBlockPtr^.CreateItem(itDefMode);
            ReadWord;
            GetModePattern;
            case CurWord.Kind of
               sy_Is:
                  begin
                     gItemPtr^.StartExpansion;
                     ReadWord;
                     TypeExpression;
                     lDefiniensExpected:=false;
                  end;
            othercases ConstructionType;
            endcases;
         end

@ @<Parse definiens@>=
      case CurWord.Kind of
         sy_Means:
            @<Parse ``\texttt{means}'' definiens@>;
         sy_Equals:
            @<Parse ``\texttt{equals}'' definiens@>;
      endcases

@ @<Parse ``\texttt{means}'' definiens@>=
            begin
               gItemPtr^.ProcessMeans;
               ReadWord;
               if Occurs(sy_Colon) then
               begin
                  gItemPtr^.ProcessDefiniensLabel;
                  Accept(Identifier,paIdentExp10); @^Error, 300@>
                  Accept(sy_Colon,paColonExp2); @^Error, 384@>
               end
               else gItemPtr^.ProcessDefiniensLabel;
               gItemPtr^.StartDefiniens;
               FormulaExpression;
               if CurWord.Kind = sy_If then
               @<Parse ``means'' definition-by-cases@>@;
               else gItemPtr^.FinishOtherwise;
               gItemPtr^.FinishDefiniens;
            end

@ @<Error...@>=
   paIdentExp10          = 300;
   paColonExp2            = 384;

@ @<Parse ``means'' definition-by-cases@>=
               begin
                  gItemPtr^.StartGuard;
                  ReadWord;
                  FormulaExpression;
                  gItemPtr^.FinishGuard;
                  while Occurs(sy_Comma) do
                  begin
                     FormulaExpression;
                     gItemPtr^.StartGuard;
                     Accept(sy_If,paIfExp); @^Error, 381@>
                     FormulaExpression;
                     gItemPtr^.FinishGuard;
                  end;
                  if CurWord.Kind = sy_Otherwise then
                  begin
                     gItemPtr^.StartOtherwise;
                     ReadWord;
                     FormulaExpression;
                     gItemPtr^.FinishOtherwise; @+
                  end;
               end

@ @<Error...@>=
   paIfExp                = 381;

@ @<Parse ``\texttt{equals}'' definiens@>=
            if lDefKind <> sy_Func then
            begin
               WrongWord(paUnexpEquals); @^Error, 186@> @+
            end
            else
            begin
               gItemPtr^.ProcessEquals;
               ReadWord;
               if Occurs(sy_Colon) then
               begin
                  gItemPtr^.ProcessDefiniensLabel;
                  Accept(Identifier,paIdentExp10); @^Error, 300@>
                  Accept(sy_Colon,paColonExp2); @^Error, 384@>
               end
               else gItemPtr^.ProcessDefiniensLabel;
               gItemPtr^.StartEquals;
               TermExpression;
               if CurWord.Kind = sy_If then
               @<Parse ``equals'' definition-by-cases@>
               else gItemPtr^.FinishOtherwise;
               gItemPtr^.FinishDefiniens;
            end

@ @<Error...@>=
   paUnexpEquals         = 186;

@ @<Parse ``equals'' definition-by-cases@>=
               begin
                  gItemPtr^.StartGuard;
                  ReadWord;
                  FormulaExpression;
                  gItemPtr^.FinishGuard;
                  while Occurs(sy_Comma) do
                  begin
                     TermExpression;
                     gItemPtr^.StartGuard;
                     Accept(sy_If,paIfExp); @^Error, 381@>
                     FormulaExpression;
                     gItemPtr^.FinishGuard;
                  end;
                  if CurWord.Kind = sy_Otherwise then
                  begin
                     gItemPtr^.StartOtherwise;
                     ReadWord;
                     TermExpression;
                     gItemPtr^.FinishOtherwise;
                  end;
               end

@ When introducing a ``\texttt{synonym}'' or ``\texttt{antonym}'', the
Parser needs to determine \emph{what kind of thing} is being
introduced as a synonym or antonym.

\Ithink{This could probably be turned into an \&{case} statement, but
I am just transcribing the code as faithfully as possible.}

@d is_attr_pattern == (CurWord.Kind = Identifier) and (AheadWord.Kind = sy_Is)
@d is_infix_pattern == (CurWord.Kind in [LeftCircumfixSymbol,sy_LeftCurlyBracket,
                             sy_LeftSquareBracket,sy_LeftParanthesis,
                             InfixOperatorSymbol]) or
              ((CurWord.Kind = Identifier) and (AheadWord.Kind = InfixOperatorSymbol))
@d is_predicate_pattern == (CurWord.Kind = PredicateSymbol) or@|
              (CurWord.Kind =sy_Equal) or@|
              ((CurWord.Kind = Identifier) and
              (AheadWord.Kind in [sy_Comma,PredicateSymbol,sy_Equal]))
@d is_selector_pattern == (CurWord.Kind = sy_The) and (AheadWord.Kind = SelectorSymbol)
@d is_forgetful_functor_pattern == (CurWord.Kind = sy_The) and (AheadWord.Kind = StructureSymbol)

@<Parse definitions (\texttt{parser.pas})@>=
function CurrPatternKind: TokenKind;
begin
   if CurWord.Kind = ModeSymbol then
      CurrPatternKind:=ModeSymbol
   else if CurWord.Kind = StructureSymbol then
      CurrPatternKind:=StructureSymbol @t\2@>
   else if is_attr_pattern then
      CurrPatternKind:=AttributeSymbol @t\2@>
   else if is_infix_pattern then
      CurrPatternKind:=InfixOperatorSymbol @t\2@>
   else if is_predicate_pattern then
      CurrPatternKind:=PredicateSymbol @t\2@>
   else if is_selector_pattern then
      CurrPatternKind:=SelectorSymbol @t\2@>
   else if is_forgetful_functor_pattern then
      CurrPatternKind:=ForgetfulFunctor @t\2@>
   else CurrPatternKind:=sy_Error@t\1\1\1\1\1\1@>;
end;

@ The Parser is looking at the ``\texttt{synonym}'' token when this
procedure is invoked.


@<Parse definitions (\texttt{parser.pas})@>=
procedure Synonym;
begin
   ReadWord;
   case CurrPatternKind of
      ModeSymbol:
         begin {Mode synonym}
            gBlockPtr^.CreateItem(itModeNotation);
            GetModePattern;
            gItemPtr^.ProcessModeSynonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetModePattern;
         end;
      AttributeSymbol:
         begin {Attribute synonym}
            gBlockPtr^.CreateItem(itAttrSynonym);
            GetAttrPattern;
            gItemPtr^.ProcessAttrSynonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetAttrPattern;
         end;
      InfixOperatorSymbol:
         begin {Functor synonym}
            gBlockPtr^.CreateItem(itFuncNotation);
            GetFuncPattern;
            gItemPtr^.ProcessFuncSynonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetFuncPattern;
         end;
      PredicateSymbol:
         begin {Predicate synonym}
            gBlockPtr^.CreateItem(itPredSynonym);
            gItemPtr^.StartDefPredicate;
            GetPredPattern;
            gItemPtr^.ProcessPredSynonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetPredPattern;
         end
   othercases
   begin
      gBlockPtr^.CreateItem(itIncorrItem);
      ErrImm(paWrongPattBeg1); @^Error, 314@>
   end;
   endcases;
end;

@ @<Error...@>=
   paWrongPattBeg1       = 314;
   paForExp               = 382;

@ Antonyms only make sense for attributes and predicates. A 314 error is
raised for any other kind of antonym.

@^Error, 314@>

@<Parse definitions (\texttt{parser.pas})@>=
procedure Antonym;
begin
   ReadWord;
   case CurrPatternKind of
      Attributesymbol:
         begin {Attribute antonym}
            gBlockPtr^.CreateItem(itAttrAntonym);
            GetAttrPattern;
            gItemPtr^.ProcessAttrAntonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetAttrPattern;
         end;
      PredicateSymbol:
         begin {Predicate antonym}
            gBlockPtr^.CreateItem(itPredAntonym);
            gItemPtr^.StartDefPredicate;
            GetPredPattern;
            gItemPtr^.ProcessPredAntonym;
            Accept(sy_For, paForExp); @^Error, 382@>
            GetPredPattern;
         end
   othercases
   begin
      gBlockPtr^.CreateItem(itIncorrItem);
      ErrImm(paWrongPattBeg2);  @^Error, 314@>
   end;
   endcases;
end;

@ @<Error...@>=
   paWrongPattBeg2       = 314;

@


@<Parse definitions (\texttt{parser.pas})@>=
procedure UnexpectedItem;
begin
   case CurWord.Kind of
      sy_Case,sy_Suppose,sy_Hereby:
         begin
            ErrImm(paWrongItemBeg); @^Error, 391@>
            ReadWord;
            if CurWord.Kind  = sy_That then ReadWord;
            PrivateItem;
         end;
      sy_Per:
         begin
            gBlockPtr^.CreateItem(itIncorrItem);
            ErrImm(paWrongItemBeg); @^Error, 391@>
            ReadWord;
            if CurWord.Kind  = sy_Cases then
            begin
               ReadWord;
               InCorrStatement;
               SimpleJustification; @+
            end;
         end;
   othercases
   begin
      ErrImm(paUnexpItemBeg); @^Error, 392@>
      StillCorrect:=true;
      PrivateItem; @+
   end;
   endcases;
end;

@ @<Error...@>=
   paUnexpItemBeg         = 392;

@ The Parser is currently looking at the ``\texttt{definition}''
token, so it will construct a definition block AST.

@<Parse definitions (\texttt{parser.pas})@>=
procedure DefinitionalBlock;
var DefPos:Position;
begin
   gBlockPtr^.CreateItem(itDefinition);
   gBlockPtr^.CreateBlock(blDefinition);
   DefPos:=CurPos;
   ReadWord;
   while CurWord.Kind <> sy_End do
   @<Parse item in definition block@>;
   KillBlock;
   AcceptEnd(DefPos);
end;

@ @<Parse item in definition block@>=
   begin
      StillCorrect:=true;
      gBlockPtr^.ProcessRedefine;
      if Occurs(sy_Redefine) then
         @<Check we are redefining a mode, attribute, functor, or predicate@>;
      case CurWord.Kind of
         sy_Mode,sy_Attr,sy_Struct,sy_Func,sy_Pred:
            Definition;
         sy_Begin,EOT,sy_Reserve,sy_Scheme,sy_Theorem,
         sy_Definition,sy_Registration,sy_Notation: break;
         Pragma: ProcessPragmas;
      othercases
      begin
         @<Parse loci, assumptions, unexpected items in a definition block@>;@/
         Semicolon;
      end;
      endcases;
   end

@ @<Check we are redefining a mode, attribute, functor, or predicate@>=
         if not (CurWord.Kind in [sy_Mode,sy_Attr,sy_Func,sy_Pred]) then
            Error(PrevPos,paUnexpRedef) @^Error, 273@>

@ @<Error...@>=
   paUnexpRedef          = 273;

@ @<Parse loci, assumptions, unexpected items in a definition block@>=
         case CurWord.Kind of
            sy_Let:
               begin
                  gBlockPtr^.CreateItem(itLociDeclaration);
                  Generalization; @+
               end;
            sy_Given: ExistentialAssumption;
            sy_Assume:
               begin
                  gBlockPtr^.CreateItem(itAssumption);
                  ReadWord;
                  Assumption; @+
               end;
            sy_Canceled: Canceled;
            sy_Case,sy_Suppose,sy_Per,sy_Hereby: UnexpectedItem;
         othercases PrivateItem;
         endcases

@ The Parser's current token is ``\texttt{notation}''.
Notation blocks are very similar in structure to definition
blocks. Unsurprisingly, the Parser's code has a similar structure as
parsing a definition block.


@<Parse definitions (\texttt{parser.pas})@>=
procedure NotationBlock;
var DefPos:Position;
begin
   gBlockPtr^.CreateItem(itDefinition);
   gBlockPtr^.CreateBlock(blNotation);
   DefPos:=CurPos;
   ReadWord;
   while CurWord.Kind <> sy_End do
   @<Parse item for notation block@>;
   KillBlock;
   AcceptEnd(DefPos);
end;

@ @<Parse item for notation block@>=
   begin
      StillCorrect:=true;
      case CurWord.Kind of
         sy_Begin,EOT,sy_Reserve,sy_Scheme,sy_Theorem,sy_Definition,
         sy_Registration,sy_Notation: break;
         Pragma: ProcessPragmas;
      othercases
      @<Parse semicolon-separated items in a notation block@>;
      endcases;
   end

@ @<Parse semicolon-separated items in a notation block@>=
      begin
         case CurWord.Kind of
            sy_Synonym: Synonym;
            sy_Antonym: Antonym;
            sy_Let:
               begin
                  gBlockPtr^.CreateItem(itLociDeclaration);
                  ReadWord;
                  FixedVariables; @+
               end;
         othercases UnexpectedItem;
         endcases; @/
         Semicolon;
      end
@

\label{ATTSubexpression}

@d ahead_is_type == (AheadWord.Kind in [sy_Set,ModeSymbol,StructureSymbol])
@d is_attr_token == (CurWord.Kind in [AttributeSymbol,sy_Non]) or@|
            (CurWord.Kind in (TermBegSys - [sy_LeftParanthesis,StructureSymbol])) or@|
            ((CurWord.Kind = sy_LeftParanthesis) and
                not(ahead_is_type)) or@|
            (CurWord.Kind =  StructureSymbol) and (AheadWord.Kind = sy_StructLeftBracket)

@<Parse definitions (\texttt{parser.pas})@>=
procedure ATTSubexpression(var aExpKind: ExpKind);
var lAttrExp: boolean;
begin
   aExpKind:=exNull;
   gSubexpPtr^.StartAttributes;
   while is_attr_token do
   begin
      gSubexpPtr^.ProcessNon;
      lAttrExp:=CurWord.Kind = sy_Non;
      if CurWord.Kind = sy_Non then ReadWord;
      @<Parse arguments for attribute expression@>;
      if CurWord.Kind = AttributeSymbol then
      begin
         aExpKind:=exAdjectiveCluster;
         gSubexpPtr^.ProcessAttribute;
         ReadWord; @+
      end
      else
      begin
         if lAttrExp or (aExpKind = exAdjectiveCluster) then {|aExpKind = exAdjectiveCluster| is never true}
         begin
            gSubexpPtr^.ProcessAttribute;
            SynErr(CurPos,paAttrExp3); @^Error, 306@>
         end;
         break;
      end;
   end;
   gSubexpPtr^.CompleteAttributes;
end;

@ @<Error...@>=
   paAttrExp3            = 306;

@ @<Parse arguments for attribute expression@>=
      if (CurWord.Kind in (TermBegSys - [StructureSymbol])) or@|
            (CurWord.Kind =  StructureSymbol) and (AheadWord.Kind = sy_StructLeftBracket)
      then
      begin
         if aExpKind = exNull then aExpKind:=exTerm;
         gSubexpPtr^.StartAttributeArguments;
         ProcessArguments;
         gSubexpPtr^.FinishAttributeArguments;
      end

@ \node{Registration clusters.}

\label{RegisterCluster:parser.pas}
@<Parse definitions (\texttt{parser.pas})@>=
procedure RegisterCluster;
var lExpKind: ExpKind;
begin
   gBlockPtr^.CreateItem(itCluster);
   ReadWord;
   if (CurWord.Kind = Identifier) and (AheadWord.Kind = sy_Arrow)
   then ErrImm(paFunctExp4);
   gItemPtr^.StartAttributes; {(\section\xref{extItemObj.StartAttributes})}
   gItemPtr^.CreateExpression(exAdjectiveCluster); {(\section\xref{extItemObj.CreateExpression})}
   gExpPtr^.CreateSubexpression;
   ATTSubexpression(lExpKind);
   case lExpKind of
      exTerm: gSubexpPtr^.CompleteClusterTerm;
      exNull,exAdjectiveCluster: gSubexpPtr^.CompleteAdjectiveCluster;
   endcases; @/
   KillSubexpression;
   KillExpression;
   case lExpKind of
      exTerm:
         @<Parse functor registration cluster@>;
      exNull,exAdjectiveCluster:
         case CurWord.Kind of
            sy_Arrow:
               @<Parse conditional registration cluster@>;
            sy_For:
               @<Parse existential registration cluster@>;
         othercases
         begin
            SynErr(CurPos,paForOrArrowExpected); @^Error, 406@>
            gItemPtr^.FinishConsequent;
            gItemPtr^.CreateExpression(exType);
            gExpPtr^.CreateSubexpression;
            gSubexpPtr^.StartType;
            gSubexpPtr^.InsertIncorrType;
            gSubexpPtr^.CompleteType;
            gSubexpPtr^.CompleteClusterType;
            KillSubexpression;
            KillExpression;
            gItemPtr^.FinishClusterType;
         end;
         endcases;
   endcases;
   Semicolon;
   Correctness;
end;

@ @<Error...@>=
   paForOrArrowExpected   = 406;

@ @<Parse functor registration cluster@>=
         begin
            gItemPtr^.FinishClusterTerm;
            Accept(sy_Arrow,paArrowExp2); @^Error, 385@>
            gItemPtr^.CreateExpression(exAdjectiveCluster);
            gExpPtr^.CreateSubexpression;
            gSubexpPtr^.StartAttributes;
            ATTSubexpression(lExpKind);
            if lExpKind <> exAdjectiveCluster then
            begin
               ErrImm(paAdjClusterExp) @^Error, 223@>
            end;
            gSubexpPtr^.CompleteAdjectiveCluster;
            KillSubexpression;
            KillExpression;
            gItemPtr^.FinishConsequent;
            if CurWord.Kind = sy_For then
            begin
               ReadWord;
               gItemPtr^.CreateExpression(exType);
               gExpPtr^.CreateSubexpression;
               gSubexpPtr^.StartType;
               gSubexpPtr^.StartAttributes;
               GetAdjectiveCluster;
               RadixTypeSubexpression;
               gSubexpPtr^.CompleteAttributes;
               gSubexpPtr^.CompleteType;
               gSubexpPtr^.CompleteClusterType;
               KillSubexpression;
               KillExpression;
            end;
            gItemPtr^.FinishClusterType;
         end

@ @<Error...@>=
   paAdjClusterExp       = 223;
   paArrowExp2            = 385;

@ @<Parse conditional registration cluster@>=
               begin
                  gItemPtr^.FinishAntecedent;
                  ReadWord;
                  gItemPtr^.CreateExpression(exAdjectiveCluster);
                  gExpPtr^.CreateSubexpression;
                  gSubexpPtr^.StartAttributes;
                  ATTSubexpression(lExpKind);
                  if lExpKind <> exAdjectiveCluster then
                  begin
                     ErrImm(paAdjClusterExp); @^Error, 223@>
                  end;
                  gSubexpPtr^.CompleteAdjectiveCluster;
                  KillSubexpression;
                  KillExpression;
                  gItemPtr^.FinishConsequent;
                  Accept(sy_For,paForExp); @^Error, 382@>
                  gItemPtr^.CreateExpression(exType);
                  gExpPtr^.CreateSubexpression;
                  gSubexpPtr^.StartType;
                  gSubexpPtr^.StartAttributes;
                  GetAdjectiveCluster;
                  RadixTypeSubexpression;
                  gSubexpPtr^.CompleteAttributes;
                  gSubexpPtr^.CompleteType;
                  gSubexpPtr^.CompleteClusterType;
                  KillSubexpression;
                  KillExpression;
                  gItemPtr^.FinishClusterType;
               end

@ @<Parse existential registration cluster@>=
               begin
                  gItemPtr^.FinishConsequent;
                  ReadWord;
                  gItemPtr^.CreateExpression(exType);
                  gExpPtr^.CreateSubexpression;
                  gSubexpPtr^.StartType;
                  gSubexpPtr^.StartAttributes;
                  GetAdjectiveCluster;
                  RadixTypeSubexpression;
                  gSubexpPtr^.CompleteAttributes;
                  gSubexpPtr^.CompleteType;
                  gSubexpPtr^.CompleteClusterType;
                  KillSubexpression;
                  KillExpression;
                  gItemPtr^.FinishClusterType;
               end

@ \node{Reduction registration.}

@<Parse definitions (\texttt{parser.pas})@>=
procedure Reduction;
var lExpKind: ExpKind;
begin
   gBlockPtr^.CreateItem(itReduction);
   ReadWord;
   if (CurWord.Kind = Identifier) and (AheadWord.Kind = sy_Arrow)
   then ErrImm(paFunctExp4); @^Error, 302@>
   gItemPtr^.StartFuncReduction;
   TermExpression;
   gItemPtr^.ProcessFuncReduction;
   Accept(sy_To,paToExp); @^Error, 404@>
   TermExpression;
   gItemPtr^.FinishFuncReduction;
   Semicolon;
   Correctness;
end;

@ @<Error...@>=
   paFunctExp4           = 302;
   paToExp                = 404;

@ \node{Identification registration.}

@<Parse definitions (\texttt{parser.pas})@>=
procedure Identification;
begin
   gBlockPtr^.CreateItem(itIdentify);
   ReadWord;
   {begin}
   gItemPtr^.StartFuncIdentify;
   GetFuncPattern;
   gItemPtr^.ProcessFuncIdentify;
   Accept(sy_With, paWithExp); @^Error, 390@>
   GetFuncPattern;
   gItemPtr^.CompleteFuncIdentify;
   {  end;}
   if CurWord.Kind = sy_When then
   begin
      ReadWord;
      repeat
         gItemPtr^.ProcessLeftLocus;
         Accept(Identifier,paIdentExp3); @^Error, 300@>
         Accept(sy_Equal,paEqualityExp1); @^Error, 380@>
         gItemPtr^.ProcessRightLocus;
         Accept(Identifier,paIdentExp3);
      until not Occurs(sy_Comma);
   end;
   Semicolon;
   Correctness;
end;

@ @<Error...@>=
   paWithExp              = 390;

@ \node{Property registration.}

@<Parse definitions (\texttt{parser.pas})@>=
procedure RegisterProperty;
begin
   gBlockPtr^.CreateItem(itPropertyRegistration);
   case PropertyKind(CurWord.Nr) of
      sySethood:
         begin
            ReadWord;
            Accept(sy_of, paOfExp); @^Error, 256@>
            gItemPtr^.StartSethoodProperties;
            TypeExpression;
            gItemPtr^.FinishSethoodProperties;
            Justification;
         end;
   othercases
   begin
      SynErr(CurPos,paStillNotImplemented); @^Error, 400@>
   end;
   endcases; @/
   Semicolon;
end;

@ @<Error...@>=
   paStillNotImplemented  = 400;

@


@<Parse definitions (\texttt{parser.pas})@>=
procedure RegistrationBlock;
var DefPos:Position;
begin
   gBlockPtr^.CreateItem(itDefinition);
   gBlockPtr^.CreateBlock(blRegistration);
   DefPos:=CurPos;
   ReadWord;
   while CurWord.Kind <> sy_End do
   begin
      StillCorrect:=true;
      case CurWord.Kind of
         sy_Cluster: RegisterCluster;
         sy_Reduce: Reduction;
         sy_Identify: Identification;
         sy_Property: RegisterProperty;
         sy_Begin,EOT,sy_Reserve,sy_Scheme,sy_Theorem,sy_Definition,
         sy_Registration,sy_Notation: break;
         Pragma: ProcessPragmas;
      othercases
      begin
         case CurWord.Kind of
            sy_Let:
               begin
                  gBlockPtr^.CreateItem(itLociDeclaration);
                  ReadWord;
                  FixedVariables; @+
               end;
            sy_Canceled: Canceled;
            sy_Case,sy_Suppose,sy_Per,sy_Hereby: UnexpectedItem;
         othercases PrivateItem;
         endcases; @/
         Semicolon;
      end;
      endcases;
   end;
   KillBlock;
   AcceptEnd(DefPos);
end;

@ \node{Reservation.}

\label{Reservation:parser.pas}

@<Parse definitions (\texttt{parser.pas})@>=
procedure Reservation;
begin
   gBlockPtr^.CreateItem(itReservation);
   ReadWord;
   repeat
      gItemPtr^.StartReservationSegment;
      repeat
         gItemPtr^.ProcessReservedIdentifier;
         Accept(Identifier,paIdentExp11); @^Error, 300@>
      until not Occurs(sy_Comma);
      Accept(sy_For,paForExp); @^Error, 382@>
      gItemPtr^.CreateExpression(exResType);
      TypeSubexpression;
      KillExpression;
      gItemPtr^.FinishReservationSegment;
   until not Occurs(sy_Comma);
   gItemPtr^.FinishReservation;
end;

@ @<Error...@>=
   paIdentExp11          = 300;

@ \node{Theorem.}


@<Parse definitions (\texttt{parser.pas})@>=
procedure Theorem;
begin
   gBlockPtr^.CreateItem(itTheorem);
   ReadWord;
   ProcessLab;
   gItemPtr^.StartTheoremBody;
   ProcessSentence;
   gItemPtr^.FinishTheoremBody;
   Justification;
   gItemPtr^.FinishTheorem;
end;

@ \node{Axiom.}

@<Parse definitions (\texttt{parser.pas})@>=
procedure Axiom;
begin
   gBlockPtr^.CreateItem(itAxiom);
   ReadWord;
   ProcessLab;
   gItemPtr^.StartTheoremBody;
   ProcessSentence;
   gItemPtr^.FinishTheoremBody;
   gItemPtr^.FinishTheorem;
end;

@* [S] Scheme blocks.

\label{SchemeBlock:parser.pas}

@<Parse scheme block (\texttt{parser.pas})@>=
{{\it Main (with Schemes)}}

procedure SchemeBlock;
var SchemePos: Position;
begin
   gBlockPtr^.CreateItem(itSchemeBlock);
   gBlockPtr^.CreateBlock(blPublicScheme);
   ReadWord;
   gBlockPtr^.CreateItem(itSchemeHead);
   gItemPtr^.ProcessSchemeName;
   SchemePos:=PrevPos;
   if CurWord.Kind = Identifier then ReadWord;
   @<Parse scheme parameters@>;
   Accept(sy_RightCurlyBracket,paRightCurledExp3); @^Error, 372@>
   gItemPtr^.FinishSchemeHeading;
   Accept(sy_Colon,paColonExp3); @^Error, 384@>
   FormulaExpression; {Scheme-conclusion}
   gItemPtr^.FinishSchemeThesis;
   @<Parse scheme premises@>;
   gItemPtr^.FinishSchemeDeclaration;
   @<Parse justification for scheme@>;
   KillBlock;
end;

@ @<Error...@>=
   paRightCurledExp3     = 372;
   paColonExp3            = 384;

@ @<Parse scheme parameters@>=
   Accept(sy_LeftCurlyBracket,paLeftCurledExp); @^Error, 362@>
   repeat
      gItemPtr^.StartSchemeSegment;
      repeat
         gItemPtr^.ProcessSchemeVariable;
         Accept(Identifier,paIdentExp13); @^Error, 300@>
      until not Occurs(sy_Comma);
      gItemPtr^.StartSchemeQualification;
      case CurWord.Kind of
         sy_LeftSquareBracket:
            begin
               ReadWord;
               ReadTypeList;
               gItemPtr^.FinishSchemeQualification;
               Accept(sy_RightSquareBracket,paRightSquareExp5); @^Error, 371@>
            end;
         sy_LeftParanthesis:
            begin
               ReadWord;
               ReadTypeList;
               gItemPtr^.FinishSchemeQualification;
               Accept(sy_RightParanthesis,paRightParenthExp9); @^Error, 370@>
               Specification;
            end;
      othercases
      begin
         ErrImm(paWrongSchemeVarQual); @^Error, 364@>
         gItemPtr^.FinishSchemeQualification;
         Specification;
      end;
      endcases;
      gItemPtr^.FinishSchemeSegment;
   until not Occurs(sy_Comma)

@ @<Error...@>=
   paIdentExp13          = 300;
   paLeftCurledExp       = 362;
   paWrongSchemeVarQual  = 364;
   paRightParenthExp9    = 370;
   paRightSquareExp5     = 371;

@ @<Parse scheme premises@>=
   if CurWord.Kind = sy_Provided then
      repeat
         gItemPtr^.StartSchemePremise;
         ReadWord;
         ProcessLab;
         ProcessSentence;
         gItemPtr^.FinishSchemePremise;
      until CurWord.Kind <> sy_And

@ @<Parse justification for scheme@>=
   if CurWord.Kind = sy_Proof then
   begin
      KillItem; {only |KillItem| which is run outside of |Semicolon| procedure}
      if not ProofPragma then
      begin
         gBlockPtr^.StartSchemeDemonstration;
         IgnoreProof;
         gBlockPtr^.FinishSchemeDemonstration;
      end
      else
      begin
         StillCorrect:=true;
         Accept(sy_Proof,paProofExp); @^Error, 389@>
         gBlockPtr^.StartSchemeDemonstration;
         LinearReasoning;
         if CurWord.Kind = sy_Per then NonBlockReasoning;
         AcceptEnd(SchemePos); 
         gBlockPtr^.FinishSchemeDemonstration;
      end;
   end
   else
   begin
      Semicolon;
      if not ProofPragma then
      begin
         gBlockPtr^.StartSchemeDemonstration;
         IgnoreProof;
         gBlockPtr^.FinishSchemeDemonstration;
      end
      else
      begin
         StillCorrect:=true;
         if CurWord.Kind = sy_Proof then
         begin
            WrongWord(paProofExp); @^Error, 389@>
            StillCorrect:=true;
            ReadWord;
         end;
         gBlockPtr^.StartSchemeDemonstration;
         LinearReasoning;
         if CurWord.Kind = sy_Per then NonBlockReasoning;
         AcceptEnd(SchemePos);
         gBlockPtr^.FinishSchemeDemonstration;
      end;
   end

@* [S] Main parse procedure.
The main \\{Parse} method essentially skips ahead to the first
``\texttt{begin}'', then skips ahead to the first top-level block
statement.

\label{parser.pas::Parse}

@d skip_to_begin == @+ ReadTokenProc;
  while (CurWord.Kind <> sy_Begin) and (CurWord.Kind <> EOT) do ReadTokenProc

@<Main parse method (\texttt{parser.pas})@>=
procedure Parse;
begin
   skip_to_begin; {Skips ahead until EOT or finds `begin`}
   if CurWord.Kind = EOT
   then ErrImm(213)
   else 
   @<Parse proper text@>; {|CurrWord.Kind = sy_Begin|} @#
   KillBlock;
end;

@ Parsing the ``text proper'' checks that we have encountered a
``\texttt{begin}'' keyword, then parses the block statements in the
article's contents.

Note that
\\{ProcessBegin}  (\section\xref{extBlockObj.ProcessBegin})
and
\\{StartProperText} (\section\xref{extBlockObj.StartProperText})
are both implemented in the extended block class. 

\Ithink{The 213 magic number should be made a constant, something like |paBegExpected|?}

@<Parse proper text@>=
   begin
      gBlockPtr^.StartProperText;
      gBlockPtr^.ProcessBegin;
      Accept(sy_Begin,213); @^Error, 213@>
      while CurWord.Kind <> EOT do
      @<Parse next block@>;
   end

@ When parsing the next top-level block in a Mizar article, we tell
Mizar's Parser we are not in ``panic mode''. Then we test for
unexpected ``\texttt{end}'' tokens. If we can recover a
``\texttt{begin}'' token, just start the loop over again.

If we encounter an ``end of text'' token, then we should terminate the
loop.

Otherwise, we dispatch the Parser's control depending on the kind of
token we encounter.

@<Parse next block@>=
      begin
         @<Parse pragmas and begins@>;
         StillCorrect:=true; {we are not in panic mode}
         if CurWord.Kind = sy_End then
         begin
            @<Skip all \texttt{end} tokens, report errors@>;
            if CurWord.Kind = sy_Begin then continue;
         end;
         if CurWord.Kind = EOT then break; @#
         case CurWord.Kind of
            sy_Scheme: SchemeBlock;
            sy_Definition: DefinitionalBlock;
            sy_Notation: NotationBlock;
            sy_Registration: RegistrationBlock;
            sy_Reserve: Reservation;
            sy_Theorem: Theorem;
            sy_Axiom: Axiom;
            sy_Canceled: Canceled;
            sy_Case,sy_Suppose, sy_Per,sy_Hereby: UnexpectedItem;
         othercases PrivateItem;
         endcases; @#
         Semicolon; {block is expected to end in a semicolon}
      end

@ The \\{ProcessPragmas} (\section\xref{ProcessPragmas:parser})
consumes a token when the current token is a pragma. So we effectively
have a loop where we consume all the pragmas and the
``\texttt{begin}'' keywords until we find something else.

@<Parse pragmas and begins@>=
         while CurWord.Kind in [sy_Begin,Pragma] do
         begin
            ProcessPragmas;
            if CurWord.Kind = sy_Begin then
            begin
               gBlockPtr^.ProcessBegin;
               ReadTokenProc;
            end;
         end

@ In the unfortunate event that the Parser has stumbled across an
``\texttt{end}'' token, skip all the ``\texttt{end}'' and semicolon
tokens and report errors.

@<Skip all \texttt{end} tokens, report errors@>=
            repeat
               ErrImm(216);
               ReadTokenProc;
               if CurWord.Kind = sy_Semicolon then ReadTokenProc;
            until CurWord.Kind <> sy_End

@* [] Index. Underlined entries in an index item refers to which section
defines the identifier. Primitive types
(\\{char}, \\{Boolean}, \\{string}, etc.) are omitted from the index.
